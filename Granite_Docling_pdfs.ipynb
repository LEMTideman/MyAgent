{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82b6c6bb-ed09-43eb-845e-8f056b3041a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tidemanlem\\Documents\\Course_Alexey_Grigorev\\MyAgent\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import hashlib\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "from dataclasses import dataclass, asdict\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Iterable, List\n",
    "\n",
    "# ----------------------------\n",
    "# Windows/HF cache tweaks (set BEFORE Docling imports)\n",
    "# ----------------------------\n",
    "# Put HF cache somewhere inside your project (optional but tidy)\n",
    "BASE = Path.cwd()\n",
    "HF_HOME = BASE / \".hf_cache\"\n",
    "os.environ.setdefault(\"HF_HOME\", str(HF_HOME))\n",
    "\n",
    "# Warning suppression (WinError 1314)\n",
    "os.environ.setdefault(\"HF_HUB_DISABLE_SYMLINKS_WARNING\", \"1\")\n",
    "\n",
    "# ----------------------------\n",
    "# Docling imports + PDF pipeline options (disable OCR)\n",
    "# ----------------------------\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b927efa-dea6-4323-8c1f-1012420959d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Data model / utilities\n",
    "# ----------------------------\n",
    "@dataclass\n",
    "class RagDoc:\n",
    "    doc_id: str\n",
    "    source: str  # local path\n",
    "    title: str\n",
    "    text: str\n",
    "    fetched_at_utc: str\n",
    "    sha256: str\n",
    "    meta: Dict[str, Any]\n",
    "\n",
    "def utc_now_iso() -> str:\n",
    "    return time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime())\n",
    "\n",
    "def sha256_text(s: str) -> str:\n",
    "    return hashlib.sha256(s.encode(\"utf-8\", errors=\"ignore\")).hexdigest()\n",
    "\n",
    "def safe_slug(s: str, max_len: int = 80) -> str:\n",
    "    s = s.strip().lower()\n",
    "    s = re.sub(r\"[^a-z0-9]+\", \"-\", s).strip(\"-\")\n",
    "    return s[:max_len] if s else \"doc\"\n",
    "\n",
    "def make_doc_id(prefix: str, source: str, content_hash: str) -> str:\n",
    "    slug = safe_slug(source)\n",
    "    short = content_hash[:12] if content_hash else \"nohash\"\n",
    "    return f\"{prefix}-{slug}-{short}\"\n",
    "\n",
    "def ensure_dir(path: Path) -> None:\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def write_doc(out_dir: Path, doc: RagDoc) -> None:\n",
    "    json_path = out_dir / f\"{doc.doc_id}.json\"\n",
    "    txt_path = out_dir / f\"{doc.doc_id}.txt\"\n",
    "\n",
    "    with json_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(asdict(doc), f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    with txt_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(doc.text or \"\")\n",
    "\n",
    "    jsonl_path = out_dir / \"docs.jsonl\"\n",
    "    with jsonl_path.open(\"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(asdict(doc), ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "def collect_pdfs(root: Path) -> List[Path]:\n",
    "    if not root.exists():\n",
    "        return []\n",
    "    if root.is_file() and root.suffix.lower() == \".pdf\":\n",
    "        return [root]\n",
    "    if root.is_dir():\n",
    "        return sorted(root.rglob(\"*.pdf\"))\n",
    "    return []\n",
    "\n",
    "def build_docling_converter_no_ocr() -> DocumentConverter:\n",
    "    pdf_options = PdfPipelineOptions()\n",
    "    pdf_options.do_ocr = False  # key change: do not run OCR\n",
    "\n",
    "    return DocumentConverter(\n",
    "        format_options={\n",
    "            InputFormat.PDF: PdfFormatOption(pipeline_options=pdf_options)\n",
    "        }\n",
    "    )\n",
    "\n",
    "def file_fingerprint(p: Path) -> str:\n",
    "    \"\"\"\n",
    "    Cheap + reliable-enough fingerprint for incremental runs:\n",
    "    absolute path + size + last-modified timestamp.\n",
    "    If you prefer strongest correctness, compute sha256 of the PDF bytes instead (slower).\n",
    "    \"\"\"\n",
    "    st = p.stat()\n",
    "    return f\"{str(p.resolve())}|{st.st_size}|{int(st.st_mtime)}\"\n",
    "\n",
    "def load_manifest(out_dir: Path) -> Dict[str, Any]:\n",
    "    manifest_path = out_dir / \"manifest.json\"\n",
    "    if manifest_path.exists():\n",
    "        return json.loads(manifest_path.read_text(encoding=\"utf-8\"))\n",
    "    return {\"version\": 1, \"files\": {}}  # files[fingerprint] = {doc_id, source, ...}\n",
    "\n",
    "def save_manifest(out_dir: Path, manifest: Dict[str, Any]) -> None:\n",
    "    manifest_path = out_dir / \"manifest.json\"\n",
    "    manifest_path.write_text(json.dumps(manifest, ensure_ascii=False, indent=2), encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6762f5b-cb12-474c-a91b-5008bc3194c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_pdfs_docling(\n",
    "    converter: DocumentConverter,\n",
    "    pdf_paths: Iterable[Path],\n",
    "    out_dir: Path,\n",
    ") -> None:\n",
    "    ensure_dir(out_dir)\n",
    "\n",
    "    manifest = load_manifest(out_dir)\n",
    "    seen: Dict[str, Any] = manifest.setdefault(\"files\", {})\n",
    "\n",
    "    for pdf_path in pdf_paths:\n",
    "        pdf_path = pdf_path.resolve()\n",
    "\n",
    "        fp = file_fingerprint(pdf_path)\n",
    "\n",
    "        # Skip document if already processed and unchanged\n",
    "        if fp in seen:\n",
    "            print(f\"[skip] {pdf_path.name}\")\n",
    "            continue\n",
    "\n",
    "        # Otherwise process with Docling\n",
    "        try:\n",
    "            result = converter.convert(pdf_path, raises_on_error=False)\n",
    "        except Exception as e:\n",
    "            print(f\"[error] {pdf_path} → {e}\")\n",
    "            continue\n",
    "\n",
    "        doc_obj = getattr(result, \"document\", None)\n",
    "        errors = getattr(result, \"errors\", None) or []\n",
    "\n",
    "        if doc_obj is None:\n",
    "            print(f\"[failed] {pdf_path} → no document returned; errors={errors}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            content = (doc_obj.export_to_markdown() or \"\").strip()\n",
    "        except Exception as e:\n",
    "            print(f\"[error] {pdf_path} → export_to_markdown() failed: {e}\")\n",
    "            continue\n",
    "\n",
    "        if not content:\n",
    "            print(f\"[empty] {pdf_path} (no text layer or export failed)\")\n",
    "            continue\n",
    "\n",
    "        text_hash = sha256_text(content)\n",
    "        slug_base = f\"{pdf_path.parent.name}-{pdf_path.stem}\"\n",
    "        doc_id = make_doc_id(\"pdf\", slug_base, text_hash)\n",
    "\n",
    "        doc = RagDoc(\n",
    "            doc_id=doc_id,\n",
    "            source=str(pdf_path),\n",
    "            title=pdf_path.stem,\n",
    "            text=content,\n",
    "            fetched_at_utc=utc_now_iso(),\n",
    "            sha256=text_hash,\n",
    "            meta={\n",
    "                \"file_name\": pdf_path.name,\n",
    "                \"file_size\": pdf_path.stat().st_size,\n",
    "                \"mtime\": int(pdf_path.stat().st_mtime),\n",
    "                \"docling_errors\": [str(e) for e in errors],\n",
    "            },\n",
    "        )\n",
    "\n",
    "        write_doc(out_dir, doc)\n",
    "\n",
    "        # Record in manifest to avoid multiple rounds of processing\n",
    "        seen[fp] = {\n",
    "            \"doc_id\": doc_id,\n",
    "            \"source\": str(pdf_path),\n",
    "            \"file_name\": pdf_path.name,\n",
    "            \"file_size\": pdf_path.stat().st_size,\n",
    "            \"mtime\": int(pdf_path.stat().st_mtime),\n",
    "            \"sha256_text\": text_hash,\n",
    "            \"written_at_utc\": utc_now_iso(),\n",
    "        }\n",
    "        save_manifest(out_dir, manifest)\n",
    "\n",
    "        print(f\"[pdf] wrote {doc_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0887689-53b0-48b7-8149-b14e74d549c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 60 PDFs under: C:\\Users\\tidemanlem\\Documents\\Course_Alexey_Grigorev\\MyAgent\\pdfs\n",
      "[pdf] wrote pdf-pdfs-15-things-you-must-know-about-ai-governance-in-china-oliver-patel-cc4e5d1af4b9\n",
      "[pdf] wrote pdf-pdfs-a-practical-guide-to-ai-and-copyright-oliver-patel-19cc0438337e\n",
      "[pdf] wrote pdf-pdfs-ai-governance-in-practice-report-2024-iapp-8da99f96370f\n",
      "[pdf] wrote pdf-pdfs-ai-openness-a-primer-for-policymakers-oecd-31d8c2826e76\n",
      "[pdf] wrote pdf-pdfs-ai-risk-management-singapore-506923eb3328\n",
      "[pdf] wrote pdf-pdfs-ai-risk-management-framework-nist-8840ff2438cf\n",
      "[pdf] wrote pdf-pdfs-ai-risk-management-framework-playbook-nist-1a939802ec83\n",
      "[pdf] wrote pdf-pdfs-ai-security-concerns-in-a-nutshell-62a50d12c363\n",
      "[pdf] wrote pdf-pdfs-artificial-intelligence-systems-and-the-gdpr-belgium-662050b41ff0\n",
      "[pdf] wrote pdf-pdfs-assessing-high-risk-ai-systems-under-the-eu-ai-act-from-legal-requirements--a2b99c97c526\n",
      "[pdf] wrote pdf-pdfs-bsi-eu-ai-act-whitepaper-final-2-9-24-2ca62ebf0cb4\n",
      "[pdf] wrote pdf-pdfs-debunking-10-common-eu-ai-act-misconceptions-part-1-oliver-patel-7dd2f38489b3\n",
      "[pdf] wrote pdf-pdfs-debunking-10-common-eu-ai-act-misconceptions-part-2-oliver-patel-8e29920044d1\n",
      "[pdf] wrote pdf-pdfs-eu-ai-act-simplification-oliver-patel-3edb2b6586f2\n",
      "[pdf] wrote pdf-pdfs-european-union-artificial-intelligence-act-bird-bird-778dc0538cbf\n",
      "[pdf] wrote pdf-pdfs-fbpml-organisationbp-v1-0-0-17-30-11fbd2c46970\n",
      "[pdf] wrote pdf-pdfs-fbpml-organisationbp-v1-0-0-38-40-bca994bd46db\n",
      "[pdf] wrote pdf-pdfs-fbpml-organisationbp-v1-0-0-7-15-6d3ca3e3086e\n",
      "[pdf] wrote pdf-pdfs-fbpml-technicalbp-v1-0-0-13-30-15e1c3308018\n",
      "[pdf] wrote pdf-pdfs-fbpml-technicalbp-v1-0-0-32-62-434b15725995\n",
      "[pdf] wrote pdf-pdfs-fbpml-technicalbp-v1-0-0-63-87-8f7a10124ab7\n",
      "[pdf] wrote pdf-pdfs-fbpml-technicalbp-v1-0-0-7-9-edc20a4a010f\n",
      "[pdf] wrote pdf-pdfs-general-purpose-ai-model-compliance-guide-part-1-oliver-patel-2ef267d5ff1b\n",
      "[pdf] wrote pdf-pdfs-general-purpose-ai-model-compliance-guide-part-2-oliver-patel-8a89bcb2e20d\n",
      "[pdf] wrote pdf-pdfs-governing-ai-in-2026-onetrust-327e9d741e59\n",
      "[pdf] wrote pdf-pdfs-how-could-the-eu-ai-act-change-oliver-patel-0e00aa8548c8\n",
      "[pdf] wrote pdf-pdfs-industrial-ai-robustness-card-evaluating-and-monitoring-time-series-models-5449434a5fcc\n",
      "[pdf] wrote pdf-pdfs-initial-reflections-on-agentic-ai-governance-oliver-patel-a3ca9cf145f0\n",
      "[pdf] wrote pdf-pdfs-legal-alignment-for-safe-and-ethical-ai-e33765950104\n",
      "[pdf] wrote pdf-pdfs-lost-in-vagueness-towards-context-sensitive-standards-for-robustness-assess-9759edc205d7\n",
      "[pdf] wrote pdf-pdfs-machinery-817608aeb447\n",
      "[pdf] wrote pdf-pdfs-navigating-the-eu-ai-act-foreseeable-challenges-in-qualifying-deep-learning-b0924fed24ef\n",
      "[pdf] wrote pdf-pdfs-netherlands-ai-act-guide-f93ca11c5a5d\n",
      "[pdf] wrote pdf-pdfs-prohibited-ai-practices-oliver-patel-1c299f998524\n",
      "[pdf] wrote pdf-pdfs-proposal-digital-omnibus-5f6a24febe2c\n",
      "[pdf] wrote pdf-pdfs-singapore-governance-for-agentic-ai-107524b18879\n",
      "[pdf] wrote pdf-pdfs-the-blueprint-for-agentic-ai-in-industral-operations-c9c7b9a92ce1\n",
      "[pdf] wrote pdf-pdfs-the-eu-ai-act-newsletter-72-europe-s-competitiveness-2a158c852ebb\n",
      "[pdf] wrote pdf-pdfs-the-eu-ai-act-newsletter-74-human-rights-are-not-optional-5a7784a711e8\n",
      "[pdf] wrote pdf-pdfs-the-eu-ai-act-newsletter-82-gpai-code-of-practice-goes-live-5a7784a711e8\n",
      "[pdf] wrote pdf-pdfs-the-eu-ai-act-newsletter-83-gpai-rules-now-apply-2a158c852ebb\n",
      "[pdf] wrote pdf-pdfs-the-eu-ai-act-newsletter-84-trump-vs-global-regulation-2a158c852ebb\n",
      "[pdf] wrote pdf-pdfs-the-eu-ai-act-newsletter-85-concerns-over-chatbots-and-relationships-a85849a3f44a\n",
      "[pdf] wrote pdf-pdfs-the-eu-ai-act-newsletter-86-concerns-around-gpt-5-compliance-5a7784a711e8\n",
      "[pdf] wrote pdf-pdfs-the-eu-ai-act-newsletter-87-digital-simplification-consultation-launches-2a158c852ebb\n",
      "[pdf] wrote pdf-pdfs-the-eu-ai-act-newsletter-88-resources-to-support-implementation-5a7784a711e8\n",
      "[pdf] wrote pdf-pdfs-the-eu-ai-act-newsletter-89-ai-standards-acceleration-updates-2a158c852ebb\n",
      "[pdf] wrote pdf-pdfs-the-eu-ai-act-newsletter-90-digital-simplification-package-imminent-2a158c852ebb\n",
      "[pdf] wrote pdf-pdfs-the-eu-ai-act-newsletter-91-whistleblower-tool-launch-2a158c852ebb\n",
      "[pdf] wrote pdf-pdfs-the-eu-ai-act-newsletter-92-ai-sandboxes-consultation-open-5a7784a711e8\n",
      "[pdf] wrote pdf-pdfs-the-eu-ai-act-newsletter-93-transparency-code-of-practice-first-draft-2a158c852ebb\n",
      "[pdf] wrote pdf-pdfs-the-eu-ai-act-newsletter-94-grok-nudification-scandal-5a7784a711e8\n",
      "[pdf] wrote pdf-pdfs-the-eu-ai-act-newsletter-95-one-law-or-a-hundred-5a7784a711e8\n",
      "[pdf] wrote pdf-pdfs-the-language-of-trustworthy-ai-glossary-nist-dfa16a5f31a8\n",
      "[pdf] wrote pdf-pdfs-the-protect-framework-managing-data-risks-in-the-ai-era-oliver-patel-cda79ebd0a7b\n",
      "[pdf] wrote pdf-pdfs-the-singapore-consensus-on-global-ai-safety-research-priorities-6a7795a9bc09\n",
      "[pdf] wrote pdf-pdfs-the-ultimate-guide-to-ai-literacy-oliver-patel-c43706585b13\n",
      "[pdf] wrote pdf-pdfs-trust-and-transparency-in-ai-industry-voices-on-data-ethics-and-compliance-9148829b9ca7\n",
      "[pdf] wrote pdf-pdfs-u-s-ai-law-policy-explained-oliver-patel-f7bc9f242e09\n",
      "[pdf] wrote pdf-pdfs-what-is-president-trump-s-ai-policy-by-oliver-patel-3b1b363b61c0\n"
     ]
    }
   ],
   "source": [
    "base = Path.cwd()\n",
    "pdfs_root = base / \"pdfs\"\n",
    "out_dir = base / \"data\" / \"granite_docling_pdfs\"\n",
    "\n",
    "pdf_paths = collect_pdfs(pdfs_root)\n",
    "print(f\"Found {len(pdf_paths)} PDFs under: {pdfs_root}\")\n",
    "\n",
    "converter = build_docling_converter_no_ocr()\n",
    "ingest_pdfs_docling(converter, pdf_paths, out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cf9b1f-1e5d-4821-8bfe-7b988618b7ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
