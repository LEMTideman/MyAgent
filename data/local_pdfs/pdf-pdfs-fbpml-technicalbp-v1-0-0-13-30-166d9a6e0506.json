{
  "doc_id": "pdf-pdfs-fbpml-technicalbp-v1-0-0-13-30-166d9a6e0506",
  "source_type": "local_pdf",
  "source": "C:\\Users\\tidemanlem\\Documents\\Course_Alexey_Grigorev\\MyAgent\\pdfs\\FBPML_TechnicalBP_V1.0.0-13-30.pdf",
  "title": "FBPML_TechnicalBP_V1.0.0-13-30",
  "text": "Notice: This document and its content has been licensed under the  Creative Commons Attribution license  by the  Foundation (Stichting) for Best Practices in Machine Learning  (kvk number: \n\n> 82610363). Any subsequent and/or other use, copying and/or adaptation of this document or its content must abide by the appropriate licensing terms & conditions as reflected thereunder.\n\n13 FBPML Technical Best Practices v1.0.0. \n\nControl:  Aim: \n\n2.1.  Product Team \n\nComposition \n\nDocument and define a clear diversity \n\nof Product Team roles and expertises \n\nneeded for the Product, inclusive of, \n\namongst other things, engineers, data \n\nscientists, Product Managers, and user \n\nexperience experts. Once established, \n\nrecruit accordingly. \n\nTo (a) assemble a robust team \n\nfor Product and/or Model design, \n\ndevelopment and deployment; \n\nand (b) highlight associated risks \n\nthat might occur in the Product \n\nLifecycle. \n\n2.2.  Product Team \n\nRoles \n\nDocument and allocate clear Product \n\nTeam roles and expectations for Product \n\nTeam members, including expectations \n\nfor, and the structure of, intra-Product \n\nTeam collaboration and overlapping \n\nresponsibilities. \n\nTo (a) ensure that Product Team \n\nroles are clearly defined; and \n\n(b) highlight associated risks \n\nthat might occur in the Product \n\nLifecycle. \n\n2.3.  Product Team \n\nStrengths and \n\nSkills Analysis \n\nDocument and assess the range of \n\nProduct Team member skills and \n\ninterests. Attempt to match member skills \n\nand interests to appropriate Product Team \n\nRoles as much as is practically possible. \n\nTo (a) ensure Product Team skill \n\nalignment and continued interest; \n\nand (b) highlight associated risks \n\nthat might occur in the Product \n\nLifecycle. \n\n2.4.  Product \n\nManagement \n\nDocument and allocate a clear Product \n\nManagement role and duties to Product \n\nManagers, inclusive of ensuring that \n\nProduct Managers have suitable Product \n\noversight, a clear understanding of \n\nProduct Team dynamics, and a contextual \n\nunderstanding of the Product and its \n\noperationalisation. \n\nPlease see Section 3 of the Organisation \n\nBest Practices Guideline for further \n\ncontext. \n\nTo (a) ensure that Product Manager \n\nroles are clearly defined; and \n\n(b) highlight associated risks \n\nthat might occur in the Product \n\nLifecycle. \n\nObjective: \n\nTo (a) ensure a balanced Product Team composition that fosters close collaboration and enhances a diversity of \n\nskills; and (b) to promote Product Team coordination and understanding through thorough team organization. \n\n# Section 2. Team Composition \n\nFBPML Technical Best Practices v1.0.0. Notice: This document and its content has been licensed under the  Creative Commons Attribution license  by the  Foundation (Stichting) for Best Practices in Machine Learning  (kvk number: \n\n> 82610363). Any subsequent and/or other use, copying and/or adaptation of this document or its content must abide by the appropriate licensing terms & conditions as reflected thereunder.\n\n14 FBPML Technical Best Practices v1.0.0. \n\nControl:  Aim: \n\n3.1.  Industry Context  Incorporate regulations, standards, and norms \n\nthat reflect industry values, boundaries, and \n\nconstraints during each phase of Product design and \n\ndeployment. Document and define clear qualitative \n\nmetrics and counter-metrics in Product & Outcome \n\nDefinitions, Data & Model Metrics and Acceptance \n\nCriteria Metrics, as relevant, as discussed in Section \n\n4 - Problem Mapping; Section 5 - Model Decision-\n\nMaking. \n\nTo (a) assemble a \n\nrobust team for Product \n\nand/or Model design, \n\ndevelopment and \n\ndeployment; and (b) \n\nhighlight associated risks \n\nthat might occur in the \n\nProduct Lifecycle. \n\n3.2.  Deployment \n\nContext \n\nIncorporate an understanding of the technical and \n\ninfrastructure aspects of the deployed Product \n\ninto the Product design process. Ensure that \n\ninfrastructure, integration, and scaling requirements \n\nand limitations are considered during the Problem \n\nMapping and Planning phases and document and \n\ndefine clear requirements for the Organisation \n\nCapacity Analysis, Product Scaling Analysis, Product \n\nIntegration Strategy, Product Risk Analysis, Testing \n\n- Automation Analysis, and POC-to-Production \n\nAnalysis, as discussed in Section 4 - Problem \n\nMapping; Section 6 - Management & Monitoring; \n\nSection 8 - Testing. \n\n3.3.  Societal Context  Research and consider the on and off platform \n\neffects of Product deployment on end users, their \n\ncommunities, and societies during each phase \n\nof Product design and deployment. Ensure that \n\nbehavioral shifts, power balance, and cultural \n\nconcerns are considered during the Problem Mapping \n\nand Planning phases, and that these provide input \n\nfor the Problem Statement & Solution Mapping, \n\nOutcome Definition, Product & Outcome Definitions \n\nData & Model Metrics, Product Risk Analysis, User \n\nExperience Mapping, Model Type - Best Fit Analysis, \n\nAcceptance Criteria, Privacy, Testing Participants, \n\nand Accuracy Perception, as discussed in Section \n\n4 - Problem Mapping; Section 7 - Privacy; Section 8 -\n\nTesting; Section 9 - Managing Expectations. \n\nObjective: \n\nTo ensure the Product Team’s continual access to a deep understanding of the various external contexts that \n\naffect the successful design and deployment of the Product. \n\n# Section 3. Context \n\nFBPML Technical Best Practices v1.0.0. Notice: This document and its content has been licensed under the  Creative Commons Attribution license  by the  Foundation (Stichting) for Best Practices in Machine Learning  (kvk number: \n\n> 82610363). Any subsequent and/or other use, copying and/or adaptation of this document or its content must abide by the appropriate licensing terms & conditions as reflected thereunder.\n\n15 FBPML Technical Best Practices v1.0.0. \n\nObjective: \n\nTo determine and define an appropriate, feasible and solvable business problem through consideration of several \n\ninteracting analyses. \n\nControl:  Aim: \n\n4.1.  Problem Statement \n\n& Solution Mapping \n\nDocument and define clear problem \n\nstatements in terms of (i) User \n\nneeds, (ii) Organisation problem, \n\nand/or (iii) Organization opportunity. \n\nSubsequently, document and define \n\nclear solutions to the problem \n\nstatements, inclusive of the \n\ncontextual needs and/or variants of \n\nthe problem statements and/or their \n\nsolutions. \n\nTo ensure Products have clear scopes \n\nto warrant (a) their effective oversight, \n\nmanagement and execution, as well as \n\n(b) allow for the accurate evaluation of \n\nProduct risks and controls. \n\n4.2.  Data Capacity \n\nAnalysis \n\nMap and document the state of the \n\ndata delivery pipeline and available \n\ndatabases required to support the \n\nproblem statements and solutions. \n\nTo (a) ensure that the data pipeline is \n\nsufficient to support Product(s) and \n\nenable the desired Outcomes; and (b) \n\nhighlight associated risks that might \n\noccur in the Product Lifecycle. \n\n4.3.  Product Definitions  Document and define clear Product \n\ndefinitions, aims, requirements and \n\ninternal deliverables having regard \n\nfor the above Problem Statement & \n\nSolution Mapping analysis, inclusive of \n\nsubsequent iterations thereof. \n\nTo ensure Product(s) have clear scope \n\nto warrant (a) their effective oversight, \n\nmanagement and execution, as well as \n\n(b) allow for the accurate evaluation of \n\nProduct risks and controls. \n\n4.4.  Outcomes \n\nDefinitions \n\nDocument, delineate, and define clear \n\nProduct Outcomes and Outcomes \n\ndeliveries based on the above \n\nProduct Definitions and the Problem \n\nStatement & Solution Mapping \n\nanalysis, inclusive of subsequent \n\niterations thereof. \n\nTo ensure Product(s) have clear scopes \n\nto warrant (a) their effective oversight, \n\nmanagement and execution, as well as \n\n(b) allow for the accurate evaluation of \n\nProduct risks and controls. \n\n4.5.  Product & Outcome \n\nDefinitions Data & \n\nModel Metrics \n\nDocument and define the above \n\nProduct and Outcome Definitions in \n\nterms of clear Model and data metrics. \n\nTo ensure Product(s) have clear scopes \n\nto warrant (a) their effective oversight, \n\nmanagement and execution, as well as \n\n(b) to allow for the accurate evaluation \n\nof Product risks and controls. \n\n# Section 4. Problem Mapping \n\nFBPML Technical Best Practices v1.0.0. Notice: This document and its content has been licensed under the  Creative Commons Attribution license  by the  Foundation (Stichting) for Best Practices in Machine Learning  (kvk number: \n\n> 82610363). Any subsequent and/or other use, copying and/or adaptation of this document or its content must abide by the appropriate licensing terms & conditions as reflected thereunder.\n\n16 FBPML Technical Best Practices v1.0.0. \n\n4. Problem Mapping - FBPML Technical Best Practices v1.0.0. \n\n4.6.  Organisation \n\nCapacity Analysis \n\nDocument and assess whether \n\nthe organisation has the requisite \n\ncapacity to achieve the above \n\nProduct Outcome and Product Metric \n\nDefinitions given the Product Team \n\nComposition and Product Team \n\nStrengths and Skills and Data Capacity \n\nAnalyses. If constraints detected, \n\nreiterate formulations of Product \n\nand/or Outcome Definitions to \n\naccommodate organisation capacity. \n\nTo (a) ensure that the Organization \n\nhas sufficient capacity to support \n\nProduct(s) and enable desired \n\nOutcomes; and (b) highlight associated \n\nrisks that might occur in the Product \n\nLifecycle. \n\n4.7.  Product Scaling \n\nAnalysis \n\nDocument and assess the estimated \n\ndegree to which the Product can \n\nbe feasibly scaled within Product \n\nDomains and the Organisation, having \n\nconsideration for the Organisation \n\nCapacity Analysis. \n\nTo (a) ensure that the Organization \n\nhas sufficient capacity to support \n\nthe Product(s) and enable the desired \n\nOutcomes as the Product scales; and \n\n(b) highlight associated risks that \n\nmight occur in the Product Lifecycle. \n\n4.8.  Product Integration \n\nStrategy \n\nDocument and assess the processes \n\nneeded to integrate and scale \n\nthe Product into organisational \n\nstructures based on the Organisation \n\nCapacity and Product Scaling \n\nAnalyses. If constraints detected and/ \n\nor integration appears unfeasible, \n\nreiterate formulations of Product \n\nand/or Outcome Definitions and/ \n\nor review the Organisation Capacity \n\nand/or Product Scaling Analyses to \n\naccommodate a practical Product \n\nIntegration Strategy. \n\nTo (a) ensure the Product and Outcome \n\nDefinitions can be achieved within the \n\nbounds of the Organisation Capacity \n\nand Product Scaling Analyses; and (b) \n\nhighlight associated risks that might \n\noccur in the Product Lifecycle. \n\n4.9.  Product Risk \n\nAnalysis \n\nDocument and assess the estimated \n\nrisks associated with Product design, \n\ndevelopment, implementation, and \n\noperation, inclusive of considerations \n\nfrom the Product Scaling Analysis, and \n\nthe Product Integration Strategy. \n\nTo (a) ensure Products have clear risk \n\nportfolios to warrant (i) their effective \n\noversight, management and execution, \n\nas well as (ii) to allow for the accurate \n\nevaluation of Product risks and \n\ncontrols; and (b) highlight associated \n\nrisks that might occur in the Product \n\nLifecycle. Notice: This document and its content has been licensed under the  Creative Commons Attribution license  by the  Foundation (Stichting) for Best Practices in Machine Learning  (kvk number: \n\n> 82610363). Any subsequent and/or other use, copying and/or adaptation of this document or its content must abide by the appropriate licensing terms & conditions as reflected thereunder.\n\n17 FBPML Technical Best Practices v1.0.0. \n\n4. Problem Mapping - FBPML Technical Best Practices v1.0.0. \n\n4.10.  Product Cost \n\nAnalysis \n\nCollaborate with Finance and \n\npurchasing to document and assess \n\nthe estimated costs associated \n\nwith Product design, development, \n\nimplementation, and operation, \n\ninclusive of considerations from the \n\nProduct Scaling Analysis, the Product \n\nIntegration Strategy, and the Product \n\nRisk Analysis. \n\nTo (a) ensure a realistic project \n\nbudget is provided; and (b) highlight \n\nassociated risks that might occur in \n\nthe Product Lifecycle. \n\n4.11.  User Experience \n\nMapping \n\nDocument and assess the user \n\nexperience and the desired \n\nexperience for various user groups, \n\nwhen interacting with the Product (e.g. \n\nusing Norman’s Usability Heuristics). \n\nConsider mitigation strategies for \n\npossible negative impacts on and off \n\nplatform. If gaps in user experience \n\nare detected or a need for process \n\nredesign or behavioral changes are \n\nuncovered reiterate formulations of \n\nOutcome Definition, as discussed \n\nin Section 4 - Problem Mapping, \n\nOrganisation Capacity Analysis, \n\nand Product Integration Strategy \n\nto accommodate an effective user \n\nexperience. \n\nTo (a) ensure an effective user \n\nexperience; and (b) highlight \n\nassociated risks that might occur in \n\nthe Product Lifecycle. Notice: This document and its content has been licensed under the  Creative Commons Attribution license  by the  Foundation (Stichting) for Best Practices in Machine Learning  (kvk number: \n\n> 82610363). Any subsequent and/or other use, copying and/or adaptation of this document or its content must abide by the appropriate licensing terms & conditions as reflected thereunder.\n\n18 FBPML Technical Best Practices v1.0.0. \n\nObjective: \n\nTo determine the most desirable and feasible model to achieve the desired Product Outcomes through \n\nconsideration of several interacting analyses. \n\nControl:  Aim: \n\n5.1.  Model Type - Metric \n\nFit Analysis \n\nDocument and assess the Model \n\nrequirements needed to meet \n\nthe Product Definitions, Outcome \n\nDefinitions, and Product & Outcome \n\nDefinitions Data & Model Metrics, \n\nas discussed in Section 4 - Problem \n\nMapping. \n\nTo ensure that chosen Model(s) meet \n\nthe requirements of the Product \n\nDefinitions, Outcome Definitions, and \n\nProduct & Outcome Definitions Data & \n\nModel Metrics. \n\n5.2.  Model Type - Risk \n\nAnalysis \n\nDocument and assess Model \n\nrequirements needed to meet the \n\nExplainability Requirements and \n\nProduct Risk Analysis, as discussed in \n\nSection 16 - Explainability; Section 4 -\n\nProblem Mapping. \n\nTo ensure that chosen Model(s) meet \n\nthe requirements of the Explainability \n\nRequirements and Product Risk \n\nAnalysis. \n\n5.3.  Model Type -\n\nOrganisation \n\nAnalysis \n\nDocument and assess the \n\ncompatibility of potential Models with \n\nthe Organisation Capacity Analysis, \n\nProduct Scaling Analysis, and Product \n\nIntegration Strategy, as discussed in \n\nSection 4 - Problem Mapping, given \n\ntechnical considerations. \n\nTo ensure that chosen Model(s) meet \n\nthe requirements of the Organisation \n\nCapacity Analysis, Product Scaling \n\nAnalysis, and Product Integration \n\nStrategy. \n\n5.4.  Model Type - Best \n\nFit Analysis \n\nDocument and assess the most \n\nappropriate Models that best meet the \n\nrequirements of, and which produces \n\nthe most favorable outcome given the \n\ntrade-offs between, the Model Type \n\n- Metric Fit, Risk and Organization \n\nAnalyses. \n\nTo (a) ensure that the most appropriate \n\nModel(s) are chosen; and (b) highlight \n\nassociated risks that might occur in \n\nthe Product Lifecycle. \n\n5.5.  Acceptance \n\nCriteria - Metrics \n\nDocument and define the desired \n\nperformance for an acceptable Model \n\nin terms of clear Model and data \n\nmetrics that are written from the end \n\nuser's perspective. \n\nTo (a) determine the metrics and \n\ndesired performance for an acceptable \n\nModel; and (b) highlight associated \n\nrisks that might occur in the Product \n\nLifecycle. \n\n# Section 5. Model Decision-Making \n\nFBPML Technical Best Practices v1.0.0. Notice: This document and its content has been licensed under the  Creative Commons Attribution license  by the  Foundation (Stichting) for Best Practices in Machine Learning  (kvk number: \n\n> 82610363). Any subsequent and/or other use, copying and/or adaptation of this document or its content must abide by the appropriate licensing terms & conditions as reflected thereunder.\n\n19 FBPML Technical Best Practices v1.0.0. \n\n5. Model Decision-Making - FBPML Technical Best Practices v1.0.0. \n\n5.6.  Acceptance \n\nCriteria -\n\nAccuracy, Bias, and \n\nFairness \n\nDocument and define clear, narrow \n\naccuracy goals and metrics that \n\nmanage the tradeoff of accuracy \n\nand explainability. Document and \n\ndefine the Model requirements \n\nneeded to meet the Fairness & Non-\n\nDiscrimination goals, as discussed \n\nmore thoroughly and technically \n\nin Section 11 - Fairness & Non-\n\nDiscrimination. \n\nTo (a) ensure appropriate accuracy, \n\nbias and fairness metrics for Model(s); \n\nand (b) highlight associated risks that \n\nmight occur in the Product Lifecycle. \n\n5.7.  Acceptance \n\nCriteria -\n\nError Rate Analysis \n\nConsider the Societal and Industry \n\nContexts in determining the \n\nacceptable method for error \n\nmeasurement, as discussed in Section \n\n4 - Problem Mapping. Document and \n\ndefine the acceptable error types and \n\nrates for the Product as required by \n\nRepresentativeness & Specification, \n\nas discussed more thoroughly \n\nand technically in Section 13 -\n\nRepresentativeness & Specification. \n\nAnalyze any potential tension between \n\nachievable and acceptable error rates \n\nand determine whether that tension \n\ncan be resolved. \n\nTo (a) ensure appropriate error type \n\nand rate metrics for Model(s); and (b) \n\nhighlight associated risks that might \n\noccur in the Product Lifecycle. \n\n5.8.  Acceptance \n\nCriteria -\n\nKey Business \n\nMetrics / Targeted \n\nMetrics \n\nDocument and define the key business \n\nmetrics (KPIs) as determined in \n\nProblem Statement & Solution \n\nMapping, as discussed in Section \n\n4 - Problem Mapping, and translate \n\nthem into metrics that can be tracked \n\nwithin the framework of chosen \n\nModel(s), or into proxy metrics if direct \n\ntracking is not feasible. \n\nTo (a) ensure appropriate business \n\nmetrics for Model(s); and (b) highlight \n\nassociated risks that might occur in \n\nthe Product Lifecycle. \n\n5.9.  Technical \n\nConsiderations \n\nDocument and assess technical issues \n\nthat should be considered during the \n\nModel selection process. \n\nTo (a) ensure that technical issues are \n\nconsidered when selecting Models; \n\nand (b) highlight associated risks that \n\nmight occur in the Product Lifecycle. Notice: This document and its content has been licensed under the  Creative Commons Attribution license  by the  Foundation (Stichting) for Best Practices in Machine Learning  (kvk number: \n\n> 82610363). Any subsequent and/or other use, copying and/or adaptation of this document or its content must abide by the appropriate licensing terms & conditions as reflected thereunder.\n\n20 FBPML Technical Best Practices v1.0.0. \n\nObjective: \n\nTo ensure an effective and auditable Product Lifecycle. \n\nControl:  Aim: \n\n6.1.  Product \n\nRequirements \n\nDraft and document clear Product requirements. \n\nReview Model Type - Metrics and Acceptance \n\nCriteria, as discussed in Section 4 - Problem \n\nMapping, to ensure alignment. Regularly review \n\nProduct & Outcome Definitions Data & Model \n\nMetrics and User Experience Mapping, as \n\ndiscussed in Section 4 - Problem Mapping, and \n\nupdate as necessary \n\nTo (a) ensure current, clear, \n\nand actionable Product \n\nrequirements; and (b) highlight \n\nassociated risks that might \n\noccur in the Product Lifecycle. \n\n6.2.  Product \n\nRoadmap and \n\nPipeline \n\nDevelop and document a Product roadmap \n\nand pipeline that enable the experience \n\nenvisioned in the User Experience Mapping, as \n\ndiscussed in Section 4 - Problem Mapping, and \n\ninclude the following sections: Schedule and \n\nmilestones, tasks and deliverables, limitations \n\nand exclusions (scope), initial prioritization, and \n\nmethods for determining future priority. \n\nTo (a) ensure a clear, \n\nactionable, and prioritized \n\nProduct roadmap and pipeline; \n\nand (b) highlight associated \n\nrisks that might occur in the \n\nProduct Lifecycle. \n\n6.3.  Experimentation \n\nConstraints \n\nDevelop and document a method for evaluating \n\nthe quality of predictions. Develop and \n\ndocument criteria for determining when to stop \n\nthe experimentation process. \n\nTo (a) develop processes to \n\nensure a balance between \n\neffectiveness and efficiency in \n\nthe experimentation cycle; and \n\n(b) highlight associated risks \n\nthat might occur in the Product \n\nLifecycle. \n\n6.4.  Behavioral \n\nChange Analysis \n\n- Process \n\nChanges \n\nResearch and assess the business processes \n\nthat will be affected by the new Product and/ \n\nor the infrastructure changes that enable the \n\nProduct. Review the User Experience Mapping, \n\nData Capacity Analysis, and Organisation \n\nCapacity Analysis, as discussed in Section 4 -\n\nProblem Mapping, and reformulate as necessary. \n\nDevelop and document a plan to retrain affected \n\nparties as necessary and mitigate business \n\ndisruptions as much as feasible. \n\nTo (a) determine business \n\nprocesses that may be affected \n\nby the project and create a plan \n\nto retrain or mitigate impacts \n\nas necessary; and (b) highlight \n\nassociated risks that might \n\noccur in the Product Lifecycle. \n\n# Section 6. Management & \n\n# Monitoring \n\nFBPML Technical Best Practices v1.0.0. Notice: This document and its content has been licensed under the  Creative Commons Attribution license  by the  Foundation (Stichting) for Best Practices in Machine Learning  (kvk number: \n\n> 82610363). Any subsequent and/or other use, copying and/or adaptation of this document or its content must abide by the appropriate licensing terms & conditions as reflected thereunder.\n\n21 FBPML Technical Best Practices v1.0.0. \n\n6. Management & Monitoring - FBPML Technical Best Practices v1.0.0. \n\n6.5.  Behavioral \n\nChange Analysis \n\n- Social (Off-\n\nPlatform) \n\nResearch and document ways in which the \n\nProduct can be abused or negatively impact \n\ncustomers, end users, or the broader society. \n\nDevelop and document a plan to mitigate \n\nnegative impacts as much as feasible. Develop \n\nand document counter metrics to assess \n\nwhether users or the model are ‘gaming’ the \n\nsystem. \n\nTo (a) determine (i) negative \n\nproduct uses, (ii) negative \n\nproduct impacts (iii) negative \n\nuser or model behaviors \n\nand create a plan to counter \n\nbehaviors or mitigate impacts \n\nas necessary; and (b) highlight \n\nassociated risks that might \n\noccur in the Product Lifecycle. \n\n6.6.  Resource \n\nAssessment \n\nDocument the processes, tools, and staffing \n\nthat are required for every phase of the \n\nproject, including the Data Capacity Analysis, \n\nOrganisation Capacity Analysis, Product \n\nScaling Analysis, and Product Cost Analysis, \n\nas discussed in Section 4 - Problem Mapping, \n\nbefore starting each phase of the project and \n\nupdate as necessary. \n\nTo (a) ensure adequate \n\nresources and funding during \n\nevery phase of the Product \n\nLifecycle; and (b) highlight \n\nassociated risks that might \n\noccur in the Product Lifecycle. \n\n6.7.  POC-to-\n\nProduction \n\nChecklist \n\nDocument and define a POC-to-Production \n\nChecklist that details the existing system \n\nmodifications, and new system builds, required \n\nfor integrating the Product into Organisation \n\ninfrastructure and incorporating additional data \n\nsources. If gaps in organisational capacity are \n\ndetected, reiterate formulations of Organisation \n\nCapacity Analysis, as discussed in Section 4 -\n\nProblem Mapping, as necessary. \n\nTo (a) ensure sufficient planning \n\nfor Product development and \n\nproduction; and (b) highlight \n\nassociated risks that might \n\noccur in the Product Lifecycle. \n\n6.8.  Update Schedule  Document and define a POC-to-Production \n\nChecklist that details the existing system \n\nmodifications, and new system builds, required \n\nfor integrating the Product into Organisation \n\ninfrastructure and incorporating additional data \n\nsources. If gaps in organisational capacity are \n\ndetected, reiterate formulations of Organisation \n\nCapacity Analysis, as discussed in Section 4 -\n\nProblem Mapping, as necessary. \n\nTo (a) ensure the Product \n\nand its related software are \n\nupdated and upgraded regularly \n\nand that the schedule for \n\nsaid updates are coordinated \n\nwith information technology \n\ndepartment(s); and (b) highlight \n\nassociated risks that might \n\noccur in the Product Lifecycle. Notice: This document and its content has been licensed under the  Creative Commons Attribution license  by the  Foundation (Stichting) for Best Practices in Machine Learning  (kvk number: \n\n> 82610363). Any subsequent and/or other use, copying and/or adaptation of this document or its content must abide by the appropriate licensing terms & conditions as reflected thereunder.\n\n22 FBPML Technical Best Practices v1.0.0. \n\n6. Management & Monitoring - FBPML Technical Best Practices v1.0.0. \n\n6.9.  Project Records  Develop and document a process for preserving \n\ndata of the information considered when making \n\nsignificant product decisions. Include any \n\nmethods for standardized experiment tracking \n\nand artifact capturing that are developed \n\nby Data Science and Engineering. Develop \n\na continuously maintained and consistently \n\navailable repository for Product Requirements \n\nand any data related to their updates. \n\nTo (a) maintain a historical \n\nrecord of Product and data \n\nand ensure that all iterations \n\nof Product Requirements \n\nare continuously available to \n\nStakeholders; and (b) highlight \n\nassociated risks that might \n\noccur in the Product Lifecycle. \n\n6.10.  Project Records \n\n- Stakeholder \n\nSign-offs \n\nDevelop a standard Stakeholder Sign-off \n\nDocument to be utilized (i) after the finalization \n\nof the following documents and analyses: \n\nProblem Statement & Solution Mapping, \n\nOutcomes Definition, Product & Outcome \n\nDefinitions, Product Integration Strategy, Model \n\nType - Best Fit Analysis, Acceptance Criteria -\n\nKey Business Metrics/Targeted Metrics, Testing \n\nDesign and Scheduling Framework, Resource \n\nAssessment, as discussed in Section 4 - Problem \n\nMapping, Section 5 - Model Decision-Making; \n\nand (ii) at Project Checkpoints, as discussed in \n\nSection 10 - Project Checkpoints. \n\nTo (a) ensure stakeholder \n\nbuy-in; and (b) provide an \n\nauditable record of project and \n\nstakeholder expectations at \n\nevery major project decision-\n\npoint. \n\n6.11.  Custody  Develop a system for documenting the chain \n\nof custody for Product(s) and the data, \n\nmicroservices, and applications that it is built on \n\nand with, that indicates: i) provenance ii) control \n\niii) transfer, iv) analysis, and v) transformation. \n\nTo (a) ensure that the building \n\nblocks of the Product can be \n\ntraced back to their origins; (b) \n\nallow for undesirable changes \n\nto be reverted; and (c) highlight \n\nassociated risks that might \n\noccur in the Product Lifecycle. Notice: This document and its content has been licensed under the  Creative Commons Attribution license  by the  Foundation (Stichting) for Best Practices in Machine Learning  (kvk number: \n\n> 82610363). Any subsequent and/or other use, copying and/or adaptation of this document or its content must abide by the appropriate licensing terms & conditions as reflected thereunder.\n\n23 FBPML Technical Best Practices v1.0.0. \n\nObjective: \n\nTo determine the most appropriate and feasible privacy-preserving techniques for the Product. \n\nControl:  Aim: \n\n7.1.  Decentralization \n\nMethod Analysis \n\nConsider the appropriateness of utilizing \n\nmethods for distributing data or training across \n\ndecentralized devices, services, or storage. \n\nWhen analyzing federated learning methods, \n\nconsider Data Capacity Analysis, Product \n\nIntegration Strategy, Product Traceability, and \n\nFairness & Non-Discrimination, as discussed \n\nmore thoroughly in Section 4 - Problem Mapping; \n\nSection 21 - Product Traceability; and Section 11 \n\n- Fairness & Non-Discrimination. When analyzing \n\ndifferential privacy methods, consider Data \n\nQuality - Noise, as discussed more thoroughly in \n\nSection 12 - Data Quality. \n\nTo (a) ensure appropriate \n\nprivacy-preserving techniques \n\nthat are aligned with chosen \n\nModels; and (b) highlight \n\nassociated risks that might \n\noccur in the Product Lifecycle. \n\n7.2.  Cryptographic \n\nMethods Analysis \n\nConsider the appropriateness of utilizing \n\nmethods for encrypting all or various parts of \n\nthe data and/or Model pipeline. When analyzing \n\nhomomorphic encryption methods, consider \n\nProduct Integration Strategy and Product \n\nScaling Analysis, as discussed more thoroughly \n\nin Section 4 - Problem Mapping. Additionally, \n\nconsider -\n\n(a) whether the types of operations and \n\ncalculations that can be performed meet the \n\nrequirements of Model Type - Best Fit Analysis, \n\nas discussed more thoroughly in Section 5 -\n\nModel Decision-Making; and/or \n\n(b) whether the encrypted Model processing \n\nspeed is acceptable with consideration for real \n\nworld robustness and direct user interaction, \n\nas discussed more thoroughly in Section 14 -\n\nPerformance Robustness. \n\nTo (a) ensure appropriate \n\nprivacy-preserving techniques \n\nthat are aligned with chosen \n\nModels; and (b) highlight \n\nassociated risks that might \n\noccur in the Product Lifecycle. \n\n# Section 7. Privacy \n\nFBPML Technical Best Practices v1.0.0. Notice: This document and its content has been licensed under the  Creative Commons Attribution license  by the  Foundation (Stichting) for Best Practices in Machine Learning  (kvk number: \n\n> 82610363). Any subsequent and/or other use, copying and/or adaptation of this document or its content must abide by the appropriate licensing terms & conditions as reflected thereunder.\n\n24 FBPML Technical Best Practices v1.0.0. \n\nObjective: \n\nTo ensure (a) that robust, effective, and efficient strategies, methodologies and schedules are developed for \n\ntesting the Product; and (b) clear maintenance metrics and/or phases to warrant continued Product alignment \n\nwith chosen metrics and performance goals. \n\nControl:  Aim: \n\n8.1.  Testing Design \n\nand Scheduling \n\nFramework \n\nDocument and define a testing design and \n\nschedule that does not artificially constrain \n\nthe testing process. Incorporate the Feedback \n\nLoop Analysis in the testing design. Review the \n\nAutomation Analysis in determining what level \n\nof automation is appropriate for each stage of \n\ntesting. Ensure the individuals chosen through \n\nthe Testing Participant Identification process \n\nare involved at the earliest stages of the testing \n\nschedule as practical. Post Product deployment, \n\ndocument and define a framework and process \n\nfor testing and selecting variations of the \n\nproduction Model. \n\nTo (a) ensure a robust and \n\nfeasible testing design and \n\nscheduling framework that \n\nallows for effective Product \n\noptimization; and (b) highlight \n\nassociated risks that might \n\noccur in the Product Lifecycle. \n\n8.2.  Testing \n\nParticipant \n\nIdentification \n\nDocument and define a process for identifying \n\ntest participants as required by User Experience \n\nMapping and Societal Context, as discussed in \n\nSection 4 - Problem Mapping; and Section 3 -\n\nContext. Determine a framework for ensuring \n\nthat testing participants are intentionally \n\ndiverse across use cases, user types and roles, \n\nand internal and external Stakeholders. \n\nTo (a) ensure testing for user \n\nimpact and participant pool \n\ndiversity; and (b) highlight \n\nassociated risks that might \n\noccur in the Product Lifecycle. \n\n# Section 8. Testing \n\nFBPML Technical Best Practices v1.0.0. Notice: This document and its content has been licensed under the  Creative Commons Attribution license  by the  Foundation (Stichting) for Best Practices in Machine Learning  (kvk number: \n\n> 82610363). Any subsequent and/or other use, copying and/or adaptation of this document or its content must abide by the appropriate licensing terms & conditions as reflected thereunder.\n\n25 FBPML Technical Best Practices v1.0.0. \n\n8. Testing - FBPML Technical Best Practices v1.0.0. \n\n8.3.  Automation \n\nAnalysis \n\nDetermine and define data, Model, and \n\ncomponent integration validations that can be \n\nreasonably automated. Assess and define any \n\nprocesses during the development, deployment, \n\nor maintenance phases that could benefit \n\nfrom integrating automation into the testing \n\ninfrastructure. Be sure to review -\n\n(a) the Organisation Capacity Analysis, as \n\ndiscussed in Section 4 - Problem Mapping, while \n\ndetermining the feasibility of automating the \n\nidentified processes; and/or \n\n(b) the Industry, Deployment, and Societal \n\nContexts, as discussed in Section 3 - Context, to \n\nuncover any gaps or misalignment raised by the \n\nautomation of any identified process. \n\nTo (a) identify suitable and \n\neffective areas for incorporating \n\ntesting automation within \n\nthe Product development, \n\ndeployment, and maintenance \n\nphases; and (b) highlight \n\nassociated risks that might \n\noccur in the Product Lifecycle. \n\n8.4.  Feedback Loop  Document and define a feedback loop that \n\nenables monitoring of stability, performance, \n\nand operations metrics, and counter-metrics, \n\nas required by Performance Robustness, \n\nMonitoring and Maintenance, and Systemic \n\nStability, as discussed more thoroughly in \n\nSection 14 - Performance Robustness; Section \n\n15 - Monitoring & Maintenance; and Section 20 \n\n- Systemic Stability. Develop and incorporate a \n\nmethod for flagging bias and for issue reporting. \n\nDocument and define a process for real-time \n\nsharing of testing participant feedback with \n\nthe development and maintenance teams. \n\nIncorporate the Feedback Loop in the Testing \n\nDesign and Scheduling Framework to ensure \n\nthat the features the Model is utilizing are \n\nacceptable for the application during the \n\ndevelopment, deployment, and maintenance \n\nphases. \n\nTo (a) ensure robust and \n\nresponsive feedback loop \n\nmeasures that enable monitoring \n\nof necessary metrics and \n\neffectively integrate into the \n\nTesting Design and Scheduling \n\nFramework; and (b) highlight \n\nassociated risks that might \n\noccur in the Product Lifecycle. Notice: This document and its content has been licensed under the  Creative Commons Attribution license  by the  Foundation (Stichting) for Best Practices in Machine Learning  (kvk number: \n\n> 82610363). Any subsequent and/or other use, copying and/or adaptation of this document or its content must abide by the appropriate licensing terms & conditions as reflected thereunder.\n\n26 FBPML Technical Best Practices v1.0.0. \n\nFBPML Technical Best Practices v1.0.0. \n\nObjective: \n\nTo effectively set and communicate realistic Product expectations to Stakeholders and obtain their buy-in. \n\nControl:  Aim: \n\n9.1.  Performance  Product management should attempt to set \n\nrealistic Product performance expectations \n\nfor Stakeholders through periodic stakeholder \n\ndiscussions on the following issues: (i) limited \n\nindustry understanding of what tasks are \n\ndifficult for the Product; (ii) difficulty of \n\ndetermining what type of modifications -\n\nnetwork design, input features, or training data \n\n- will create the greatest Product improvement; \n\nand (iii) Model improvement can stall \n\nsignificantly while experimenting with different \n\nvariable modifications. \n\nTo (a) effectively communicate \n\nrealistic Product performance \n\nexpectations throughout the \n\ndevelopment process; and (b) \n\nhighlight associated risks that \n\nmight occur in the Product \n\nLifecycle. \n\n9.2.  Timeframe  Product management should set expectations \n\nfor long-term investment in the Product for \n\nStakeholders, specifically focusing on: (i) the \n\nunpredictability of Product improvement; (ii) \n\nProduct difficulties are traditionally hard to \n\ndiagnose as they are often caused by subtle \n\nissues of intersecting inputs; and (iii) it is \n\npossible for the Product to completely stall with \n\nabsolutely no discernible improvement in spite \n\nof significant time and effort. \n\nTo (a) effectively set Stakeholder \n\nexpectations regarding the \n\ndifficulty of locking down \n\nProduct timelines; and (b) \n\nhighlight associated risks that \n\nmight occur in the Product \n\nLifecycle. \n\n9.3.  Accuracy \n\nperception \n\nThe Product Team should work to ensure that \n\nthe solution will be accurate enough to meet a \n\nvariety of different Stakeholders’ expectations, \n\nrecognizing that each group of Stakeholders will \n\nhave different views on what is ‘accurate’ based \n\non their interaction with the Product. Product \n\nmanagement should set and communicate \n\nexpectations in-line with the achievable level of \n\naccuracy for each user group. \n\nTo (a) effectively communicate \n\nachievable accuracy levels, \n\nconsidering individual \n\nStakeholder accuracy \n\npreferences; and (b) highlight \n\nassociated risks that might \n\noccur in the Product Lifecycle. \n\n# Section 9. Managing Expectations Notice: This document and its content has been licensed under the  Creative Commons Attribution license  by the  Foundation (Stichting) for Best Practices in Machine Learning  (kvk number: \n\n> 82610363). Any subsequent and/or other use, copying and/or adaptation of this document or its content must abide by the appropriate licensing terms & conditions as reflected thereunder.\n\n27 FBPML Technical Best Practices v1.0.0. \n\n9. Managing Expectations - FBPML Technical Best Practices v1.0.0. \n\n9.4.  POC-to-\n\nProduction \n\nThe Product Team should effectively \n\ncommunicate that infrastructure is often the \n\ndetermining factor for the success of the POC-\n\nto-Production transition and rely heavily on \n\nthe POC-to-Production Checklist, as discussed \n\nin Section 6 - Management & Monitoring, to \n\nset and align Stakeholder expectations of the \n\ntransition process. The Product Team should set \n\nthe expectation, before beginning the transition \n\nprocess, that novel problems will likely arise \n\nduring the transition that may significantly \n\naffect the timeline and costs. The Product Team \n\nshould be on alert for integration issues arising \n\nclose to the final release of the solution, which \n\nthe Product Manager should communicate to \n\nrelevant Stakeholders, along with progress \n\nupdates, at a progressively more frequent \n\ncadence. \n\nTo (a) uncover and communicate \n\nissues that may delay the \n\ntransition of the solution from \n\nPOC-to-Production or make that \n\ntransition less feasible; and \n\n(b) highlight associated risks \n\nthat might occur in the Product \n\nLifecycle. \n\n9.5.  Production \n\nCosts \n\nReview and analyze the finalized POC budget to \n\ndetermine a realistic Product implementation \n\nbudget. Review the Product Cost Analysis as \n\ndiscussed in Section 4 - Problem Mapping to \n\nensure its continued accuracy and reformulate \n\nas necessary. The Product Team should \n\neffectively communicate to Stakeholders that \n\nthe budget for implementation will likely be \n\nin-line or more expensive than the cost to get \n\nthrough POC. \n\nTo (a) ensure realistic \n\nexpectations for a sufficient \n\nProduct implementation budget \n\nare communicated; and (b) \n\nhighlight associated risks that \n\nmight occur in the Product \n\nLifecycle. Notice: This document and its content has been licensed under the  Creative Commons Attribution license  by the  Foundation (Stichting) for Best Practices in Machine Learning  (kvk number: \n\n> 82610363). Any subsequent and/or other use, copying and/or adaptation of this document or its content must abide by the appropriate licensing terms & conditions as reflected thereunder.\n\n28 FBPML Technical Best Practices v1.0.0. \n\nObjective: \n\nTo ensure that necessary factors are considered at key decision points. \n\nControl:  Aim: \n\n10.1.  Machine \n\nLearning \n\nAppropriate \n\nTool Analysis \n\nThe Product Team should work cross-functionally with \n\nStakeholders to define and document a Machine Learning \n\nchecklist that considers the following areas, amongst \n\nother things: \n\na.  Is there a different approach that will generate a \n\ngreater return more quickly; \n\nb.  Given the results of the Data Capacity Analysis, \n\ndoes the Organisation have enough secure, non-\n\ndiscriminatory, representative, high quality data for \n\nevery stage of the process; \n\nc.  Can the problem be solved by simple rules; \n\nd.  Does the Product solution require emotional \n\nintelligence or empathy; \n\ne.  Does the Product solution need to be fully \n\ninterpretable or explainable; \n\nf.  Given the results of the Organisation Capacity \n\nAnalysis, does the Organization have the people, \n\nprocesses, and tools necessary to productize the end \n\nproduct; \n\ng.  Can the consequences of Product failure be easily \n\nfixed or mitigated; and/or \n\nh.  What other non-technical solutions can be used \n\nto augment the Product and its offering and/or, \n\nmore directly, whether Machine Learning is the best \n\nsolution for the Product at hand. \n\nTo (a) ensure that \n\nMachine Learning is the \n\nappropriate method \n\nfor solving the chosen \n\nproblem; and (b) highlight \n\nassociated risks that \n\nmight occur in the \n\nProduct Lifecycle. \n\n# Section 10. Project Checkpoints Notice: This document and its content has been licensed under the  Creative Commons Attribution license  by the  Foundation (Stichting) for Best Practices in Machine Learning  (kvk number: \n\n> 82610363). Any subsequent and/or other use, copying and/or adaptation of this document or its content must abide by the appropriate licensing terms & conditions as reflected thereunder.\n\n29 FBPML Technical Best Practices v1.0.0. \n\n10. Project Checkpoints- FBPML Technical Best Practices v1.0.0. \n\n10.2  Data Buy v. \n\nBuild Analysis \n\nThe Product Team should work cross-functionally with \n\nrelevant Stakeholders to define and document a Buy v. \n\nBuild checklist that considers the following areas: \n\na.  Does the Organisation have enough data for every \n\nstage of the process (training, POC, production) \n\nand for every purpose (replacing stale/flawed data, \n\nmeasuring success); \n\nb.  Does the Organisation have the right type of data for \n\nevery stage of the process (training, POC, production) \n\nand for every purpose (replacing stale/flawed data, \n\nmeasuring success); \n\nc.  Is bought data secure and free of privacy concerns; \n\nd.  Is the bias in the bought data limited, mitigatable, or \n\nremovable; \n\ne.  Given the results of the Data Quality Analysis, does \n\nthe Organisation have quality data and are datasets \n\ncomplete; \n\nf.  Given the Product Team Composition, does the \n\nOrganisation have the staffing and expertise to clean, \n\nprepare, and maintain internal data; and/or \n\ng.  Given the Data Capacity Analysis, is the necessary \n\ndata easily and readily available internally. \n\nTo (a) ensure that the \n\nOrganisation’s decision \n\nto either purchase data \n\nor utilize in-house data \n\nis appropriate based on \n\nOrganisation capacity \n\nand/or constraints; and \n\n(b) highlight associated \n\nrisks that might occur in \n\nthe Product Lifecycle. Notice: This document and its content has been licensed under the  Creative Commons Attribution license  by the  Foundation (Stichting) for Best Practices in Machine Learning  (kvk number: \n\n> 82610363). Any subsequent and/or other use, copying and/or adaptation of this document or its content must abide by the appropriate licensing terms & conditions as reflected thereunder.\n\n30 FBPML Technical Best Practices v1.0.0. \n\n10. Project Checkpoints- FBPML Technical Best Practices v1.0.0. \n\n10.3  Model Buy v. \n\nBuild Analysis \n\nThe Product Team should work cross-functionally with \n\nrelevant Stakeholders to define and document a Buy v. \n\nBuild checklist that considers the following areas: \n\na.  Is the scope of the Product manageable, given the \n\nresults of the Organisation Capacity Analysis; \n\nb.  Can bought Models be used for other Products (eg. \n\ntransfer learning); \n\nc.  Does the Organisation have the in-house expertise \n\nrequired to acquire and label the training data, given \n\nthe Product Team Composition; \n\nd.  How much would it cost to acquire a properly labeled \n\ntraining dataset; \n\ne.  Given the Product Team Composition, does the \n\nOrganisation have the in-house expertise required to \n\nretrain Models, if necessary; \n\nf.  How important is Model customization and, if so, can \n\nbought Models be customised; \n\ng.  Are the Acceptance Criteria - Accuracy, Bias, and \n\nFairness requirements for bought Models feasible \n\ngiven the timeline, Product Team Composition, and \n\nOrganisation Capacity Analysis; and/or \n\nh.  What are the usage limits and costs for pre-trained \n\nModels. \n\nTo (a) ensure that the \n\nOrganisation’s decision \n\nto either purchase or \n\nbuild the Models is \n\nappropriate based on \n\nOrganisation capacity \n\nand/or constraints; and \n\n(b) highlight associated \n\nrisks that might occur in \n\nthe Product Lifecycle. \n\n10.4  POC-to-\n\nProduction \n\nGo/No-Go \n\nAnalysis \n\nThe Product Team should work cross-functionally with \n\nrelevant Stakeholders to define and document a Go/No-\n\nGo checklist that considers qualitative and quantitative \n\nfactors in the following areas: \n\na.  Can POC-to-Production Checklist be adequately \n\naddressed; \n\nb.  Is the Product Cost Analysis still feasible; \n\nc.  Does the Product Team have approval for a Product \n\nmaintenance budget; \n\nd.  Are the updates, upgrades, and add-ons to the data \n\ninfrastructure near completion; \n\ne.  What is the state of customer process reconstruction \n\nand end-user training; \n\nf.  Has the failsafe, rollback, or emergency shutdown \n\nplan been completed and approved; and/or \n\ng.  Have the communication and mitigation plans in case \n\nof failsafe, rollback, or emergency shutdown been \n\ncompleted and approved. \n\nTo (a) ensure that the \n\nsolution should be \n\ndeployed in production \n\nand/or Product Domains; \n\nand (b) highlight \n\nassociated risks that \n\nmight occur in the \n\nProduct Lifecycle.",
  "fetched_at_utc": "2026-02-08T18:50:43Z",
  "sha256": "166d9a6e0506c0fa81e351c96dd63f920d7bd6700137808dad36fb7be7041508",
  "meta": {
    "file_name": "FBPML_TechnicalBP_V1.0.0-13-30.pdf",
    "file_size": 368603,
    "relative_path": "pdfs\\FBPML_TechnicalBP_V1.0.0-13-30.pdf",
    "jina_status": 20000,
    "jina_code": 200,
    "usage": {
      "tokens": 9618
    }
  }
}