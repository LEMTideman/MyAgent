{
  "doc_id": "pdf-pdfs-fbpml-technicalbp-v1-0-0-7-9-a2d2073e84c2",
  "source_type": "local_pdf",
  "source": "C:\\Users\\tidemanlem\\Documents\\Course_Alexey_Grigorev\\MyAgent\\pdfs\\FBPML_TechnicalBP_V1.0.0-7-9.pdf",
  "title": "FBPML_TechnicalBP_V1.0.0-7-9",
  "text": "Notice: This document and its content has been licensed under the  Creative Commons Attribution license  by the  Foundation (Stichting) for Best Practices in Machine Learning  (kvk number: \n\n> 82610363). Any subsequent and/or other use, copying and/or adaptation of this document or its content must abide by the appropriate licensing terms & conditions as reflected thereunder.\n\n7FBPML Technical Best Practices v1.0.0. \n\n1.1.  Absolute Reproducibility  means a guarantee that any and all results, outputs, outcomes, artifacts, \n\netc can be exactly reproduced under any circumstances. \n\n1.2.  Best Practice Guideline  means this document. \n\n1.3.  Confidence Value  means a measure of a Model’s self-reported certainty that the given Output \n\nis correct. \n\n1.4.  Data Generating \n\nProcess \n\nmeans the process, through physical and digital means, by which Records \n\nof data are created (usually representing events, objects or persons). \n\n1.5.  Data Science  means an interdisciplinary field that uses scientific methods, processes, \n\nalgorithms and computational systems to extract knowledge and insights \n\nfrom structural and/or unstructured data. \n\n1.6.  Domain  means the societal and/or commercial environment within which the \n\nProduct will be and/or is operationalised. \n\n1.7.  Edge Case  means an outlier in the space of both input Features and Model Outputs. \n\n1.8.  Error Rate  means the frequency of occurrence of errors in the (Sub)population \n\nrelative to the size of the (Sub)population \n\n1.9.  Evaluation Error  means the difference between the ground truth and a Model’s prediction or \n\noutput. \n\n1.10.  Fairness & Non-\n\nDiscrimination \n\nmeans the property of Models and Model outcomes to be free from bias \n\nagainst Protected Classes. \n\n1.11.  Features  mean the different attributes of datapoints as recorded in the data. \n\n1.12.  Hidden Variable  means an attribute of a datapoint or an attribute of a system that \n\nhas a causal relation to other attributes, but is itself not measured or \n\nunmeasurable. \n\n1.13.  Human-Centric Design \n\n& Redress \n\nmeans orienting Products and/or Models to focus on humans and their \n\nenvironments through promoting human and/or environment centric \n\nvalues and allowing for redress. \n\n1.14.  Implementation  means every aspect of the Product and Model(s) insertion of and/or \n\napplication to Organisation systems, infrastructure, processes and culture \n\nand Domains and Society. \n\n1.15.  Incident  means the occurrence of a technical event that affects the integrity of a \n\nProduct and/or Model. \n\n1.16.  Label  means the Feature that represents the (supposed) ground-truth values \n\ncorresponding to the Target Variable. \n\nAs used in this Best Practice Guideline, the following terms shall have the following meanings where capitalised. \n\nAll references to the singular shall include references to the plural, where applicable, and vice versa. Any terms \n\nnot defined or capitalised in this Best Practice Guideline shall hold their plain text meaning as cited in English and \n\ndata science. \n\n# Section 1. Definitions Notice: This document and its content has been licensed under the  Creative Commons Attribution license  by the  Foundation (Stichting) for Best Practices in Machine Learning  (kvk number: \n\n> 82610363). Any subsequent and/or other use, copying and/or adaptation of this document or its content must abide by the appropriate licensing terms & conditions as reflected thereunder.\n\n8FBPML Technical Best Practices v1.0.0. \n\n1. Definitions - FBPML Technical Best Practices v1.0.0. \n\n1.17.  Machine Learning  means the use and development of computer systems and Models that \n\nare able to learn and adapt with minimal explicit human instructions by \n\nusing algorithms and statistical modelling to analyse, draw inferences, and \n\nderive outputs from data. \n\n1.18.  Model  means Machine Learning algorithms and data processing designed, \n\ndeveloped, trained and implemented to achieve set outputs, inclusive of \n\ndatasets used for said purposes unless otherwise stated. \n\n1.19.  Organisation  means the concerned juristic entity designing, developing and/or \n\nimplementing Machine Learning. \n\n1.20.  Outcome  means the resultant effect of applying Models and/or Products. \n\n1.21.  Output  means that which Models produce, typically (but not exclusively) \n\npredictions or decisions. \n\n1.22.  Performance \n\nRobustness \n\nmeans the propensity of Products and/or Models to retain their desired \n\nperformance over diverse and wide operational conditions. \n\n1.23.  Product  means the collective and broad process of design, development, \n\nimplementation and operationalisation of Models, and associated \n\nprocesses, to execute and achieve Product Definition(s), inclusive of, \n\namongst other things, the integration of such operations and/or Models \n\ninto organisation products, software and/or systems. \n\n1.24.  Product Manager  means either a Design Owner and/or Run Owner as identified in the \n\nOrganisation Best Practice Guideline in Sections 3.1.4. & 3.1.7. respectively. \n\n1.25.  Product Team  means the collective group of Organisation employees directly charged \n\nwith designing, developing and/or implementing the Product. \n\n1.26.  Product Subjects  means the entities and/or objects that are represented as data points in \n\ndatasets and/or Models, and who may be the subject of Product and/or \n\nModel outcomes. \n\n1.27.  Project Lifecycle  means the collective phases of Products from initiation to termination \n\n- such as design, exploration, experimentation, development, \n\nimplementation, operationalisation, and decommissioning - and their \n\nmutual iterations. \n\n1.28.  Protected Classes  mean (Sub)populations of Product Subjects, typically persons, that are \n\nprotected by law, regulation, policy or based on Product Definition(s) \n\n1.29.  Root Cause Analysis  means the activity and/or report of the investigation into the primary \n\ncausal reasons for the existence of some behaviour (usually an error or \n\ndeviation). \n\n1.30.  Safety  means real Product Domain based physical harms that result through \n\nProducts and/or Models applications. \n\n1.31.  Security  means the resilience of Products and/or Models against malicious and/ \n\nor negligent activities that result in Organisational loss of control over \n\nconcerned Products and/or Models. Notice: This document and its content has been licensed under the  Creative Commons Attribution license  by the  Foundation (Stichting) for Best Practices in Machine Learning  (kvk number: \n\n> 82610363). Any subsequent and/or other use, copying and/or adaptation of this document or its content must abide by the appropriate licensing terms & conditions as reflected thereunder.\n\n9FBPML Technical Best Practices v1.0.0. \n\n1. Definitions - FBPML Technical Best Practices v1.0.0. \n\n1.32.  Selection Function  means a (where possible mathematical) description of the probability or \n\nproportion of all real Subjects that might potentially be recorded in the \n\ndataset that are actually recorded in a dataset. \n\n1.33.  Stakeholders  mean the department(s) and/or team(s) within the Organisation who do \n\nnot conduct data science and/or technical Machine Learning, but have a \n\nmaterial interest in Product Machine Learning. \n\n1.34.  (Sub)population  means any group of persons, animals, or any other entities represented \n\nby a piece of data , that is part of a larger (potential) dataset and \n\ncharacterized by any (combination of) attributes. The importance of (Sub) \n\npopulations is particularly high when some (Sub)populations are vulnerable \n\nor protected (Protected Classes). \n\n1.35.  Systemic Stability  means the stability of Organisation, Domain, society and environment as a \n\ncollective ecosystem. \n\n1.36.  Target of Interest  means the fundamental concept that the Product is truly interested in \n\nwhen all is said and done, even if it is something that is not (objectively) \n\nmeasureable. \n\n1.37.  Target Variable  means the Variable which a Model is made to predict and/or output. \n\n1.38.  Traceability  means the ability to trace, recount, and reproduce Product outcomes, \n\nreports, intermediate products, and other artifacts, inclusive of Models, \n\ndatasets and codebases. \n\n1.39.  Variables  mean the different attributes of subjects or systems which may or may not \n\nbe measured.",
  "fetched_at_utc": "2026-02-08T18:50:48Z",
  "sha256": "a2d2073e84c287ca7fc7f721b93d8bf9a5d57a19d9762573a085ef82c292fe7a",
  "meta": {
    "file_name": "FBPML_TechnicalBP_V1.0.0-7-9.pdf",
    "file_size": 115002,
    "relative_path": "pdfs\\FBPML_TechnicalBP_V1.0.0-7-9.pdf",
    "jina_status": 20000,
    "jina_code": 200,
    "usage": {
      "tokens": 1809
    }
  }
}