{
  "doc_id": "web-ai-act-service-desk-ec-europa-eu-en-ai-act-article-3-cdeb70c4d5e9",
  "source_type": "web",
  "source": "https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-3",
  "title": "Article 3: Definitions | AI Act Service Desk",
  "text": "```markdown\n# Article 3: Definitions\n\n## Summary\n\n[Article 3](https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-3) of the AI Act provides definitions for terms used throughout the AI Act.\n\nThe summaries are meant to provide helpful explanation but are not legal binding.\n\n### Definition 1: 'AI system'\n\n**Definition:** A machine-based system that operates with varying levels of autonomy and exhibits adaptiveness after deployment, generating outputs such as predictions, content, recommendations, or decisions influenced by input.\n\n### Definition 2: 'Risk'\n\n**Definition:** The combination of the probability of an occurrence of harm and its severity.\n\n### Definition 3: 'Provider'\n\n**Definition:** Natural or legal persons, public authorities, agencies, or other bodies that develop an AI system or a general-purpose AI model and place them on the market or put them into service under their own name or trademark.\n\n### Definition 4: 'Deployer'\n\n**Definition:** Natural or legal persons, public authorities, agencies, or other bodies using an AI system under their authority except where the AI system is used in the course of a personal non-professional activity.\n\n### Definition 5: 'Authorised Representative'\n\n**Definition:** Natural or legal persons located or established in the Union receiving and accepting a written mandate from a provider of an AI system or a general-purpose AI model to perform and carry out obligations and procedures established by this Regulation.\n\n### Definition 6: 'Importer'\n\n**Definition:** Natural or legal persons located or established in the Union importing an AI system bearing the name or trademark of a natural or legal person established in a third country.\n\n### Definition 7: 'Distributor'\n\n**Definition:** Natural or legal persons in the supply chain offering an AI system on the Union market.\n\n### Definition 8: 'Operator'\n\n**Definition:** Providers, manufacturers, deployers, authorised representatives, importers, and distributors.\n\n### Definition 9: 'Placing on the Market'\n\n**Definition:** First making available of an AI system or a general-purpose AI model on the Union market.\n\n### Definition 10: 'Making Available on the Market'\n\n**Definition:** Supplying an AI system for distribution or use on the Union market in return for payment or free of charge.\n\n### Definition 11: 'Putting into Service'\n\n**Definition:** Supplying an AI system for first use directly to a deployer or for own use within the Union for its intended purpose.\n\n### Definition 12: 'Intended Purpose'\n\n**Definition:** Use for which an AI system is intended by its provider, including specific contexts and conditions of use specified in instructions for use, promotional materials, and technical documentation.\n\n### Definition 13: 'Reasonably Foreseeable Misuse'\n\n**Definition:** Use of an AI system beyond its intended purpose that may result from reasonable human behavior interactions with other systems.\n\n### Definition 14: 'Safety Component’\n\n**Definition:** Component within a product or AI system fulfilling safety functions that ensures it meets expectations regarding health and safety.\n\n### Definition 15: 'Instructions for Use’\n\n**Definition:** Information provided by the provider to inform deployers about an AI system's intended purpose and proper use.\n\n### Definition 16: 'Recall of an AI System’\n\n**Definition:** Any measure aimed at returning a provider's product to their original state before it was placed on sale.\n\n### Definition 17: 'Withdrawal of an AI System’\n\n**Definition:** Preventing an AI system from being made available again on the market once deployed by deploying parties like providers and distributors.\n\n### Definition 18: 'Performance of an AI System’\n\n**Definition:** Ability of an AI system to achieve its intended purpose without causing harm to people or property.\n\n### Definition 19: ‘Notifying Authority’\n\n**Definition**: National authority responsible for setting up and implementing necessary procedures for assessing conformity assessment bodies and monitoring them according to Chapter III Section 2 regulations.\n\n### Definition 20: ‘Conformity Assessment’\n\n**Definition**: Process demonstrating whether requirements set out in Chapter III Section 2 relating to high-risk AI systems have been fulfilled through third-party assessments such as testing, certification, and inspections.\n\n### Definition 21: ‘Conformity Assessment Body’\n\n**Definition**: BOD that performs third-party conformity assessment activities including testing certifications and inspections under these provisions.\n\n### Definition 22: ‘Notified Body’\n\n**Definition**: Conformity assessment body notified according to this regulation and other relevant Union harmonization legislation providing means to comply with certain requirements established under this Regulation.\n\n### Definition 23: ‘Substantial Modification’\n\n**Definition**: Change to an existing product after its placement on the market that affects compliance with requirements set out in Chapter III Section 2 leading to modifications affecting its intended purpose while maintaining functionality similar to before if feasible upon review by authorized representatives (AR).\n\n### Definition 24: ‘CE Marking’\n\n**Definitions**: Mark indicating compliance with requirements set out in Chapter III Section 2 provided it complies with relevant Union harmonization legislation concerning CE marking requirement adherence. It does not qualify as placing products onto the market nor putting them into service per Article III Section II paragraph (5).\n\n### Definition 25: ‘Post-Market Monitoring System’\n\n**Definitions**: All activities carried out by providers of high-risk systems to collect experience gained from their usage. These include collecting feedback from users during deployment phases prior to marketing release stages. They aim at identifying immediate corrective actions needed before further deployment occurs. This includes conducting tests before placing products onto markets. It involves various methods such as user surveys via online platforms like Google Forms etc., questionnaires distributed among users via mailings etc., interviews conducted face-to-face etc., webinars etc., focus groups etc., workshops held offline etc., seminars organized online etc., meetings convened virtually etc., discussions held over email chats etc..\n\n---\n\n## Relevant Recitals\n\n* [Recital 12](https://ai-act-service-desk.ec.europa.eu/en/ai-act/recital-12)\n* [Recital 13](https://ai-act-service-desk.ec.europa.eu/en/ai-act/recital-13)\n* [Recital 14](https://ai-act-service-desk.ec.europa.eu/en/ai-act/recital-14)\n* [Recital 15](https://ai-act-service-desk.ec.europa.eu/en/ai-act/recital-15)\n* [Recital 16](https://ai-act-service-desk.ec.europa.eu/en/ai-act/recital-16)\n* [Recital 17](https://ai-act-service-desk.ec.europa.eu/en/ai-act/recital-17)\n* [Recital\n```",
  "fetched_at_utc": "2025-12-28T19:43:00Z",
  "sha256": "cdeb70c4d5e9c7f7305f8d587db311332c1f784e737cbe6e802f1e21dd97e135",
  "meta": {
    "jina_status": 20000,
    "jina_code": 200,
    "description": null,
    "links": null,
    "images": null,
    "usage": {
      "tokens": 12000
    }
  }
}