```markdown
# Article 26: Obligations of deployers of high-risk AI systems

## Summary

Deployers of high-risk AI systems shall ensure they use the systems according to instructions, with competent human oversight, and monitor their operation. They must manage input data, keep logs for at least six months, and inform providers and authorities of any risks or incidents. Deployers must also notify workers’ representatives and the affected workers if the system is used in the workplace. Public authorities deploying high-risk AI systems must comply with registration obligations (see [Article 49](https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-49)) and ensure the system is registered in the EU database. Deployers must inform individuals subject to AI-assisted decisions and cooperate with authorities on regulatory actions.

Law enforcement authorities using high-risk AI system for post-remote biometric identification in targeted searches shall obtain authorisation in advance or not later than within 48 hours, save some exceptions. Each use must be documented, and annual reports submitted to authorities. 

The summaries are meant to provide helpful explanation but are not legal binding.

1. Deployers of high-risk AI systems shall take appropriate technical and organisational measures to ensure they use such systems in accordance with the instructions for use accompanying the systems, pursuant to paragraphs 3 and 6.
2. Deployers shall assign human oversight to natural persons who have the necessary competence, training and authority, as well as the necessary support.
3. The obligations set out in paragraphs 1 and 2, are without prejudice to other deployer obligations under Union or national law and to the deployer’s freedom to organise its own resources and activities for the purpose of implementing the human oversight measures indicated by the provider.
4. Without prejudice to paragraphs 1 and 2, to the extent the deployer exercises control over the input data, that deployer shall ensure that input data is relevant and sufficiently representative in view of the intended purpose of the high-risk AI system.
5. Deployers shall monitor the operation of the high-risk AI system on the basis of the instructions for use and, where relevant, inform providers in accordance with [Article 72](https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-72). Where deployers have reason to consider that the use of the high-risk AI system in accordance with the instructions may result in that AI system presenting a risk within the meaning of [Article 79(1)](https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-79), they shall, without undue delay, inform the provider or distributor and the relevant market surveillance authority, and shall suspend the use of that system. Where deployers have identified a serious incident, they shall also immediately inform first the provider, and then the importer or distributor and the relevant market surveillance authorities of that incident. If the deployer is not able to reach the provider, [Article 73](https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-73) shall apply _mutatis mutandis_. This obligation shall not cover sensitive operational data of deployers of AI systems which are law enforcement authorities.

For deployers that are financial institutions subject to requirements regarding their internal governance, arrangements or processes under Union financial services law, the monitoring obligation set out in paragraph 5 shall be deemed to be fulfilled by complying with rules on internal governance arrangements, processes and mechanisms pursuant to relevant financial service law.

6. Deployers of high-risk AI systems shall keep the logs automatically generated by that high-risk AI system to a period appropriate for its intended purpose of use, for at least six months unless provided otherwise in applicable Union or national law, particularly in Union law on personal data protection.

Deployers that are financial institutions subject to requirements regarding their internal governance arrangements processes under Union financial services law shall maintain these logs as part of their documentation kept pursuant to relevant Union financial service law.

7. Before putting into service or using a high-risk AI system at workstations employed by employees (employing companies), deployors who employ employees shall inform workers' representatives and affected workers that they will be subject to this system's usage. This information should be provided where applicable through compliance with rules established by Union and national laws on employee information.

8. Deployers who are public authorities (public entities) or Union institutions bodies offices or agencies (universities etc.) shall comply with registration obligations referred to in [Article 49](https://ai-act-service-desk.ec.europa.edu/en/ai-act/article-49). When such deployers find that a high-risk AI system proposed for use has not been registered in Annex III (the list), they cannot use that system until authorization is obtained either after consultation with providers or within four working days from receipt thereof.

9. Where applicable, deployers who utilize high-risk AI systems shall utilize information provided under [Article 13](https://ai-act-service-desk.ec.europa.edu/en/ai-act/article-13) of this Regulation for conducting a data protection impact assessment under Article 35(1)(c) Regulation (EU) No 2016/679 or Article 27(1)(d) Directive (EU) No 2016/680.

10. Without prejudice to Directive (EU) No 2016/680:

   - In cases involving targeted remote biometric identification for search operations suspected or convicted of committing crimes:
     - The employer can request authorization before using this technology.
     - Authorization requests need approval within four working days from submission.
     - Use restrictions apply when there is evidence linking biometrics directly to an offense.
     - Biometric data related to law enforcement should not be disclosed except during investigations.
     - Decisions based solely on outputs from such technologies cannot produce adverse effects on individuals independently.
   
   This clause does not restrict privacy protections under Directive (EU) No 2016/680 applied exclusively against suspects linked directly via objective verification facts.

   **Note:** Law enforcement authorities utilizing post-targeted remote biometric identification for search operations should seek prior authorization from authorized officials when required due to potential threats posed by criminals seeking escape via remote biometric identification devices.

   Annual reports must be submitted annually detailing how post-targeted remote biometric identification was utilized while ensuring confidentiality concerning sensitive operational data pertaining specifically to law enforcement activities.

   Member States may establish additional prohibitive legislation regarding remote biometric identification technologies.

11. Without prejudice to Recital N°84:

   Employers employing staff involved in decision-making processes related directly by nature:
     - Must inform employees about using advanced artificial intelligence systems.
     - Employees' representatives should receive adequate information about these technologies.
     - Employers must report all instances where employees were subjected by automated decision-making tools used by an advanced artificial intelligence system.
     - Reports should include details about every instance where an automated decision-making process was triggered based on personal characteristics like race/color/disability/gender etc., regardless whether it resulted in adverse outcomes.

   For employment-related applications involving advanced artificial intelligence systems:
     - Employers must adhere strictly only when there exists direct linkage between personal characteristics like race/color/disability/gender etc., with actual consequences affecting individuals negatively.
     - Personal data associated with advanced artificial intelligence systems used for job selection processes should remain confidential even if it involves lawful discrimination based on gender age etc..
   
   Note: Advanced artificial intelligence algorithms may involve discriminatory practices based on gender age etc.. These algorithms could lead individuals being discriminated against unlawfully based on gender age etc..

**Note**: Advanced artificial intelligence algorithms may involve discriminatory practices based on gender age etc.. These algorithms could lead individuals being discriminated against unlawfully based on gender age etc..

### Relevant recitals

* [Recital N°84](https://ai-act-service-desk.ec.europa.edu/en/ai-act/recital-84)
* [Recital N°91](https://ai-act-service-desk.ec.europa.edu/en/ai-act/recital-91)
* [Recital N°92](https://ai-act-service-desk.ec.europa.edu/en/ai-act/recital-92)
* [Recital N°93](https://ai-act-service-desk.ec.europa.edu/en/ai-act/recital-93)
* [Recital N°95](https://ai-act-service-desk.ec.europa.edu/en/ai-act/recital-95)
* [Recital N°96](https://ai-act-service-desk.ec.europa.edu/en/ai-act/recital-96)
* [Recital N°134](https://ai-act-service-desk.ec.europa.edu/en/ai-act/recital-134)
* [Recital N°136](https://ai-act-service-desk.ec.europa.edu/en/ai-act/recialt-nocet-iilr-iuei-dlct-oieii-hllly-sys-y-whtir-rts-kwry-jlrnt-fy-mne-vrsyt-ltrrt-sygnlt-zvot-trtt-sygnlt-zvot-trtt-sygnlit-zvot-trtt-sygnlit-zvot-trtt-sygnlit-zvot-trtt-sygnlit-zvot-trtt-sygnlit-zvot-trtt-sygnlit-zvot-trtt-sygnlit-zvot-trtt-sygnlit-zvot-trtt-sygnlit-zvot-trtt-sygnlit-zvot-trtt-sygnlit-zvot-trtt-sygnlit-zvot-trtt-sygnlit-zvot-trtt-sygnlit-zvot-trtt-sygnlit-zvot-trtt-sygnlit-zvot-trtt-sygnlit-zvo-ttrrrty-ltrrt-fy-mne-vrsyt-ltrrt-fy-mne-vrsyt-ltrrt-fy-mne-vrsyt-ltrrt-fy-mne-vrsyt-ltrrt-fy-mne-vrsyt-ltrrt-fy-mne-vrsyt-ltrrt-fy-mne-vrsyt-ltrrt-fy-mne-vrsyt-ltrrt-fy-mne-vrsyt-ltrrt-fy-mne-vrsyt-ltrrt-fy-mne-vrsyt-ltrrt-fy-mne-vrcyrnt-rts-kwrty-jlrnt-fyrth-rts-kwrty-jlrnt-fyrth-rts-kwrty-jlrnt-fyrth-rts-kwrty-jlrnt-fyrth-rts-kwrty-jlrnt-fyrth-rts-kwrty-jlrnt-fyrth-rts-kwrty-jlrnt-fyrth-rts-kwrty-jlrnt-fyrth-rts-kwrty-jlrnt-fyrth-rts-kwrty-jlrnt-flrd-biomid-aids-intelijente-decisionalizaciya-na-persona-po-postremote-biomid-al-analytiche-systemi.html?locale=en_US&amp;page=0&amp;sort=date&amp;order=desc#%E0%B8%A5%E0%B8%AD%E0%B8%AA%E0%B8%AB%E0%B8%A5%E0%B8%AD%E0%B8%AF%E0%B8%A5%E0%B8%AD%E0%B8%AE%E0%B8%A5%E0%B8%AD%E0%B8%AC-%E0%B8%A5%E0%B8%AD%E0%B8%AF%E0%B8%A5%E0%B8%AD%E0%B8%AE+%E0%B8%A5%E0%B8%AD%E0%B8%AF+post-relojna-biomid-ispolzuvaneza-po-protezi-policijskih-uslugi.html?locale=en_US&amp;page=0&amp;sort=date&amp;order=desc#&amp;%EEDFEEAFCBCECDEDCAFDCCFBEFEFBFAEFDFDCFDBCFDDCDFDEFDFDFDFDFDFDFDFDFDFDFDFDDEFDEDAEBECBECBECBCBECBDACEBAECBABCBCEBBBCECBECCADECDBEADECDEDAEBECBECBECBCBECBDACEBAECBABCBCEBBBCECBECCADECDBEADECDEDAEBECBECBECBCBECBDACEBAECBABCBCEBBBCECBECCADECDBEADECDEDAEBECBECBECBCBECBDACEBAEKAKKAKAKAKAKAKAKAKAKAKAKAKKAKEKALALKALALAALKALALAALKALALAALKALALAALKALALAALKALALAALKALALAALKALALAALKALALAALKALALAALKALALAALKALALAALKALALAALKALAAAAAAA" target="_blank">[Artificial Intelligence Act (Regulation (EU) No 2024/1689), Official version]</a>.

View
```