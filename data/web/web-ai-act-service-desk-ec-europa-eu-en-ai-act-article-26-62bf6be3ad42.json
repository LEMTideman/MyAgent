{
  "doc_id": "web-ai-act-service-desk-ec-europa-eu-en-ai-act-article-26-62bf6be3ad42",
  "source_type": "web",
  "source": "https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-26",
  "title": "Article 26: Obligations of deployers of high-risk AI systems | AI Act Service Desk",
  "text": "```markdown\n# Article 26: Obligations of deployers of high-risk AI systems\n\n## Summary\n\nDeployers of high-risk AI systems shall ensure they use the systems according to instructions, with competent human oversight, and monitor their operation. They must manage input data, keep logs for at least six months, and inform providers and authorities of any risks or incidents. Deployers must also notify workers’ representatives and the affected workers if the system is used in the workplace. Public authorities deploying high-risk AI systems must comply with registration obligations (see [Article 49](https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-49)) and ensure the system is registered in the EU database. Deployers must inform individuals subject to AI-assisted decisions and cooperate with authorities on regulatory actions.\n\nLaw enforcement authorities using high-risk AI system for post-remote biometric identification in targeted searches shall obtain authorisation in advance or not later than within 48 hours, save some exceptions. Each use must be documented, and annual reports submitted to authorities. \n\nThe summaries are meant to provide helpful explanation but are not legal binding.\n\n1. Deployers of high-risk AI systems shall take appropriate technical and organisational measures to ensure they use such systems in accordance with the instructions for use accompanying the systems, pursuant to paragraphs 3 and 6.\n2. Deployers shall assign human oversight to natural persons who have the necessary competence, training and authority, as well as the necessary support.\n3. The obligations set out in paragraphs 1 and 2, are without prejudice to other deployer obligations under Union or national law and to the deployer’s freedom to organise its own resources and activities for the purpose of implementing the human oversight measures indicated by the provider.\n4. Without prejudice to paragraphs 1 and 2, to the extent the deployer exercises control over the input data, that deployer shall ensure that input data is relevant and sufficiently representative in view of the intended purpose of the high-risk AI system.\n5. Deployers shall monitor the operation of the high-risk AI system on the basis of the instructions for use and, where relevant, inform providers in accordance with [Article 72](https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-72). Where deployers have reason to consider that the use of the high-risk AI system in accordance with the instructions may result in that AI system presenting a risk within the meaning of [Article 79(1)](https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-79), they shall, without undue delay, inform the provider or distributor and the relevant market surveillance authority, and shall suspend the use of that system. Where deployers have identified a serious incident, they shall also immediately inform first the provider, and then the importer or distributor and the relevant market surveillance authorities of that incident. If the deployer is not able to reach the provider, [Article 73](https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-73) shall apply _mutatis mutandis_. This obligation shall not cover sensitive operational data of deployers of AI systems which are law enforcement authorities.\n\nFor deployers that are financial institutions subject to requirements regarding their internal governance, arrangements or processes under Union financial services law, the monitoring obligation set out in paragraph 5 shall be deemed to be fulfilled by complying with rules on internal governance arrangements, processes and mechanisms pursuant to relevant financial service law.\n\n6. Deployers of high-risk AI systems shall keep the logs automatically generated by that high-risk AI system to a period appropriate for its intended purpose of use, for at least six months unless provided otherwise in applicable Union or national law, particularly in Union law on personal data protection.\n\nDeployers that are financial institutions subject to requirements regarding their internal governance arrangements processes under Union financial services law shall maintain these logs as part of their documentation kept pursuant to relevant Union financial service law.\n\n7. Before putting into service or using a high-risk AI system at workstations employed by employees (employing companies), deployors who employ employees shall inform them about being subject to this high-risk AI system's usage. This information should be provided according to existing rules on employee information transparency.\n\n8. Deployers who are public authorities or entities under Union law governing communications networks content technology (Connect Directorate-General) shall comply with registration obligations referred to in [Article 49](https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-49). When such entities find that a new high-risk AI system proposed for use has not been registered in Annex III (the list), they cannot utilize that system until authorization is obtained through an authorized process outlined elsewhere.\n\n9. Where applicable, entities deploying high-risk AI systems shall use information provided under [Article 13](https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-13) of this Regulation for conducting a data protection impact assessment under Article 35(1)(c) Regulation (EU) No 2016/679 or Article 27(1)(d) Directive (EU) No 2016/680.\n\n10. Without prejudice to Directive (EU) No 2016/680:\n\n   - In cases involving targeted searches conducted against suspects suspected or convicted of committing crimes:\n     - Entities deploying such systems need authorization before starting their use.\n     - Use can only continue if there is an explicit link between biometric identification results and specific criminal offenses.\n     - Biometric data related to law enforcement agencies will not be disclosed publicly.\n     - Decisions based solely on outputs from these systems resulting in adverse effects on individuals would require prior approval from judicial authorities.\n   \n   This clause does not restrict how biometrics are processed generally under Directive (EU) No 2016/680.\n\n**Note:** Directives (EU) No 2016/680 governs \"biometric\" data specifically referring to biometric IDs like passports etc., while this regulation refers broadly as \"personal data.\" These directives specify different restrictions depending on whether personal data includes biometric identifiers.\n\nEntities deploying such systems should submit annual reports detailing their uses excluding disclosures related exclusively to law enforcement agencies' operations.\n\nMembers states may establish additional privacy regulations concerning these types of technologies.\n\n11. Without prejudice to Recital N°84:\n\n   High-risk entities proposing decision-making tools should inform users about their presence on this platform before deployment.\n\n12. Deployers should collaborate with competent authorities when taking actions aimed at implementing this Regulation.\n\n### Relevant recitals\n\n* [Recital N°84](https://ai-act-service-desk.ec.europa.eu/en/ai-act/recital-84)\n* [Recital N°91](https://ai-act-service-desk.ecEuropEaL/publication/AIActServiceDesk_EN.pdf?file=publication%2FAIActServiceDesk_EN.pdf#page=5)\n* [Recital N°92](https://ai-act-service-desk.ec.europa.eu/en/ai-act/recital-92)\n* [Recital N°93](https://ai-act-service-desk.ec.europa.eu/en/ai-actservicedesk/pdf/AIAct_ServiceDesk_EN.pdf?file=publication%2FAIAct_ServiceDesk_EN.pdf#page=5)\n* [Recital N°95](https://ai.act.service.desKt.europe.EU/publication/AIActServiceDesk_EN.pdf?file=publication%2FAIActServiceDesk_EN.pdf#page=5)\n* [Recital N°96](https://www.ai.act.service.desKt.europe.EU/publication/AIActServiceDesk_EN.pdf?file=publication%2FAIActServiceDesk_EN.pdf#page=5)\n* [Recital N°134](https://www.ai.act.service.desKt.europe.EU/publication/AIActServiceDesk_EN.pdf?file=publication%2FAIActServiceDesk_EN.pdf#page=5)\n* [Recital N°136](https://www.ai.act.service.desKt.europe.EU/publication/AIActServiceDesk_EN.pdf?file=publication%2FAIActServiceDesk_EN.pdf#page=5)\n* [Recital N°143](https://www.ai.act.service.desKt.europe.EU/publication/AIActServiceDesk_EN.pdf?file=publication%2FAIActServiceDesk_EN.pdf#page=5)\n\nView official text: **[Artificial Intelligence Act (Regulation (EU) 2024/1689), Official version dated June 13th]** ([Official version PDF download]) \n```",
  "fetched_at_utc": "2026-02-09T20:33:49Z",
  "sha256": "62bf6be3ad42098602407023f3243b624fb302e0cee17350b570c34b76337830",
  "meta": {
    "jina_status": 20000,
    "jina_code": 200,
    "description": null,
    "links": null,
    "images": null,
    "usage": {
      "tokens": 12000
    }
  }
}