```markdown
# Article 15: Accuracy, robustness and cybersecurity

## Chapter III: High-Risk AI Systems

### Section 2: Requirements for High-Risk AI Systems

#### Summary
High-risk AI systems must be designed to achieve an appropriate level of accuracy, robustness, and cybersecurity throughout their lifecycle. The levels of accuracy and the relevant accuracy metrics of high-risk AI systems shall be declared in the accompanying instructions of use. High-risk AI systems should be resilient to errors, inconsistencies and faults. Cybersecurity should be ensured, with measures to prevent cyber-attacks, including data and model poisoning, adversarial examples, and confidentiality breaches. Technical solutions should be tailored to the system's risks and context.

The summaries are meant to provide helpful explanation but are not legal binding.

1. High-risk AI systems shall be designed and developed in such a way that they achieve an appropriate level of accuracy, robustness, and cybersecurity, and that they perform consistently in those respects throughout their lifecycle.
2. To address the technical aspects of how to measure the appropriate levels of accuracy and robustness set out in paragraph 1 and any other relevant performance metrics, the Commission shall, in cooperation with relevant stakeholders and organizations such as metrology and benchmarking authorities, encourage, as appropriate, the development of benchmarks and measurement methodologies.
3. The levels of accuracy and the relevant accuracy metrics of high-risk AI systems shall be declared in the accompanying instructions of use.
4. High-risk AI systems shall be as resilient as possible regarding errors, faults or inconsistencies that may occur within the system or the environment in which the system operates, in particular due to their interaction with natural persons or other systems. Technical and organizational measures shall be taken in this regard.
   - The robustness of high-risk AI systems may be achieved through technical redundancy solutions, which may include backup or fail-safe plans.
   - High-risk AI systems that continue to learn after being placed on the market or put into service shall be developed in such a way as to eliminate or reduce as far as possible the risk of possibly biased outputs influencing input for future operations (feedback loops), and as to ensure that any such feedback loops are duly addressed with appropriate mitigation measures.
5. High-risk AI systems shall be resilient against attempts by unauthorized third parties to alter their use, outputs or performance by exploiting system vulnerabilities.
   - The technical solutions aiming to ensure the cybersecurity of high-risk AI systems shall be appropriate to the relevant circumstances and the risks.
   - The technical solutions to address AI-specific vulnerabilities shall include, where appropriate, measures to prevent, detect, respond to, resolve and control for attacks trying to manipulate the training data set (data poisoning), or pre-trained components used in training (model poisoning), inputs designed to cause the AI model to make a mistake (adversarial examples or model evasion), confidentiality attacks or model flaws.

### Relevant Recitals
- [Recital 27](/en/ai-act/recital-27)
- [Recital 66](/en/ai-act/recital-66)
- [Recital 74](/en/ai-act/recital-74)
- [Recital 75](/en/ai-act/recital-75)
- [Recital 76](/en/ai-act/recital-76)
- [Recital 77](/en/ai-act/recital-77)
- [Recital 78](/en/ai-act/recital-78)
- [Recital 114](/en/ai-act/recital-114)
- [Recital 115](/en/ai-act/recital-115)

View the [official text](https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=OJ:L_202401689). The text used in this tool is the ‘[Artificial Intelligence Act (Regulation (EU) 2024/1689), Official version of 13 June 2024](https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=OJ:L_202401689)’.

---

**AI Act Service Desk**

This site is managed by:
Directorate-General for Communications Networks, Content and Technology

* [Accessibility](/en/accessibility-statement)

**Contact us**
* Contact the AI Office: [CNECT-AIOFFICE@ec.europa.eu](mailto:CNECT-AIOFFICE@ec.europa.eu)

**About us**
* Copyright notice: [/en/copyright-statement]
* Legal notice: [/en/legal-statement]
* Privacy statement: [/en/statement-data-protection]
* About Directorate-General CONNECT: [https://commission.europa.eu/about-departments-and-executive-agencies/connect_en]

[![European Commission Logo](https://webtools.europa.eu/images/logos/logo.png)](https://commission.europa.eu/index_en)

* Contact Europe:
  * Contact Europe via email: [contact.europe@commission.europa.eu]
  * Follow Europe on social media:
    * Twitter: [@EUEUCommsNetwok]
    * Facebook: [@EUEUCommsNetwok]
    * Instagram: [@EUEUCommsNetwok]
    * LinkedIn: [@EUEUCommsNetwok]
    * YouTube: [@EUEUCommsNetwok]
    * Flickr: [@EUEUCommsNetwok]
    * Pinterest: [@EUEUCommsNetwok]
    * Tumblr: [@EUEUCommsNetwok]
    * Vimeo: [@EUEUCommsNetwok]

* Resources for partners:
  * Partnerships & Projects
  * Publications
* Report an IT vulnerability:
  * Vulnerabilities reported here will help improve our services.

* Languages on our websites:
  * English
  * German
  * French
* Cookies Policy:
  * https://commission.europa.eu/resources-partners_en
* Privacy Policy:
  * https://commission.europa.eu/data-protection/general-data-protection-regulation/gdpr/en/data-protection-notices/
```