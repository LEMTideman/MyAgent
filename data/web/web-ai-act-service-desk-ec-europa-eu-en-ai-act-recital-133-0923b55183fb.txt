```markdown
# Recital 133

A variety of AI systems can generate large quantities of synthetic content that becomes increasingly hard for humans to distinguish from human-generated and authentic content. The wide availability and increasing capabilities of those systems have a significant impact on the integrity and trust in the information ecosystem, raising new risks of misinformation and manipulation at scale, fraud, impersonation and consumer deception. In light of those impacts, the fast technological pace and the need for new methods and techniques to trace origin of information, it is appropriate to require providers of those systems to embed technical solutions that enable marking in a machine readable format and detection that the output has been generated or manipulated by an AI system and not a human. Such techniques and methods should be sufficiently reliable, interoperable, effective and robust as far as this is technically feasible, taking into account available techniques or a combination of such techniques, such as watermarks, metadata identifications, cryptographic methods for proving provenance and authenticity of content, logging methods, fingerprints or other techniques, as may be appropriate. When implementing this obligation, providers should also take into account the specificities and the limitations of the different types of content and the relevant technological and market developments in the field, as reflected in the generally acknowledged state of the art. Such techniques and methods can be implemented at the level of the AI system or at the level of the AI model, including general-purpose AI models generating content, thereby facilitating fulfilment of this obligation by the downstream provider of the AI system. To remain proportionate, it is appropriate to envisage that this marking obligation should not cover AI systems performing primarily an assistive function for standard editing or AI systems not substantially altering the input data provided by the deployer or the semantics thereof.

### This Recital relates to

*   [Article 50: Transparency obligations for providers and deployers of certain AI systems](/en/ai-act/article-50)

View the [official text](https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=OJ:L_202401689). The text used in this tool is the ‘[Artificial Intelligence Act (Regulation (EU) 2024/1689), Official version of 13 June 2024](https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=OJ:L_202401689)’.

---

## Contact Us

*   [Contact us](mailto:CNECT-AIOFFICE@ec.europa.eu)
*   [Accessibility](/en/accessibility-statement)

## About Us

*   [Copyright notice](/en/copyright-notice)
*   [Legal notice](/en/legal-notice)
*   [Privacy statement](/en/privacy-statement-ai-act-service-desk-website)
*   [About Directorate-General CONNECT](https://commission.europa.eu/about-departments-and-executive-agencies/communications-networks-content-and-technology_en)

## Additional Links

*   [Contact Europe's Commission](https://commission.europa.eu/contact-eu/social-media-channels_en#/search?page=0&institutions=european_commission)
*   [Resources for partners](https://commission.europa.eu/resources-partners_en)
*   [Report an IT vulnerability](https://commission.europa.eu/resources-partners_en/report-an-it-vulnerability_en)

## Legal Information

*   [Cookies](https://commission.europa.eu/cookies_en)
*   [Privacy policy](https://commission.europa.eu/privacy-policy_en)
*   [Legal notice](https://commission.europa.eu/legal-notice_en)
```