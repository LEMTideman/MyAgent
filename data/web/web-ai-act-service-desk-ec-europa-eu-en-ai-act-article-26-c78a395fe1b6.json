{
  "doc_id": "web-ai-act-service-desk-ec-europa-eu-en-ai-act-article-26-c78a395fe1b6",
  "source_type": "web",
  "source": "https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-26",
  "title": "Article 26: Obligations of deployers of high-risk AI systems | AI Act Service Desk",
  "text": "```markdown\n# Article 26: Obligations of deployers of high-risk AI systems\n\n## Summary\n\nDeployers of high-risk AI systems shall ensure they use the systems according to instructions, with competent human oversight, and monitor their operation. They must manage input data, keep logs for at least six months, and inform providers and authorities of any risks or incidents. Deployers must also notify workers’ representatives and the affected workers if the system is used in the workplace. Public authorities deploying high-risk AI systems must comply with registration obligations (see [Article 49](https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-49)) and ensure the system is registered in the EU database. Deployers must inform individuals subject to AI-assisted decisions and cooperate with authorities on regulatory actions.\n\nLaw enforcement authorities using high-risk AI system for post-remote biometric identification in targeted searches shall obtain authorisation in advance or not later than within 48 hours, save some exceptions. Each use must be documented, and annual reports submitted to authorities. \n\nThe summaries are meant to provide helpful explanation but are not legal binding.\n\n1. Deployers of high-risk AI systems shall take appropriate technical and organisational measures to ensure they use such systems in accordance with the instructions for use accompanying the systems, pursuant to paragraphs 3 and 6.\n2. Deployers shall assign human oversight to natural persons who have the necessary competence, training and authority, as well as the necessary support.\n3. The obligations set out in paragraphs 1 and 2, are without prejudice to other deployer obligations under Union or national law and to the deployer’s freedom to organise its own resources and activities for the purpose of implementing the human oversight measures indicated by the provider.\n4. Without prejudice to paragraphs 1 and 2, to the extent the deployer exercises control over the input data, that deployer shall ensure that input data is relevant and sufficiently representative in view of the intended purpose of the high-risk AI system.\n5. Deployers shall monitor the operation of the high-risk AI system on the basis of the instructions for use and, where relevant, inform providers in accordance with [Article 72](https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-72). Where deployers have reason to consider that the use of the high-risk AI system in accordance with the instructions may result in that AI system presenting a risk within the meaning of [Article 79(1)](https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-79), they shall, without undue delay, inform the provider or distributor and the relevant market surveillance authority, and shall suspend the use of that system. Where deployers have identified a serious incident, they shall also immediately inform first the provider, and then the importer or distributor and the relevant market surveillance authorities of that incident. If the deployer is not able to reach the provider, [Article 73](https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-73) shall apply _mutatis mutandis_. This obligation shall not cover sensitive operational data of deployers of AI systems which are law enforcement authorities.\n\nFor deployers that are financial institutions subject to requirements regarding their internal governance, arrangements or processes under Union financial services law, the monitoring obligation set out in paragraph 5 shall be deemed to be fulfilled by complying with rules on internal governance arrangements, processes and mechanisms pursuant to relevant financial service law.\n\n6. Deployers of high-risk AI systems shall keep the logs automatically generated by that high-risk AI system to a period appropriate for its intended purpose of use, for at least six months unless provided otherwise in applicable Union or national law, particularly in Union law on personal data protection.\n\nDeployers that are financial institutions subject to requirements regarding their internal governance arrangements processes under Union financial services law shall maintain these logs as part of their documentation kept pursuant to relevant Union financial service law.\n\n7. Before putting into service or using a high-risk AI system at workstations employed by employees (employing companies), deployors who employ employees shall inform them about being subject to this high-risk AI system's usage. This information should be provided according to existing rules on employee information transparency.\n\n8. Deployers who are public authorities or entities under Union law governing communications networks content technology (Connect Directorate-General) shall comply with registration obligations referred to in [Article 49](https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-49). When such entities find that a new high-risk AI system proposed for use has not been registered in Annex III (High-Risk List), they cannot utilize that system until authorization is obtained through an authorized process outlined elsewhere.\n\n9. Where applicable, entities deploying high-risk AI systems shall use information provided under [Article 13](https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-13) of this Regulation for conducting a data protection impact assessment under Article 35(1)(c) Regulation (EU) No 2016/679 or Article 27(1)(d) Directive (EU) No 2016/680.\n\n10. Without prejudice to Directive (EU) No 2016/680:\n\n   - In cases involving targeted searches conducted against suspects suspected or convicted of committing crimes:\n     - Entities deploying such systems need authorization before starting their use.\n     - Authorization requests can be addressed either by judicial authority or administrative authority whose decision is legally binding.\n     - The entity deploying these systems does not have permission from judicial authority or administrative authority alone.\n     - Law enforcement agencies using these systems for targeted searches must seek prior authorization from courts or administrative bodies whose decisions are legally binding.\n     - Each instance requires authorization approval within four working days after requesting it.\n     - Annual reports must be submitted annually detailing how these systems were utilized.\n     - Member States may establish additional restrictions on their deployment based on Union legislation concerning criminal investigations.\n\n   - For law enforcement purposes involving initial identification based on objective evidence directly linked to a crime:\n     - These entities must adhere strictly within what is necessary for criminal investigation purposes.\n     - Use limitations include restricting access only when necessary for criminal investigation purposes related specifically to a specific crime.\n     - Such instances cannot involve targeting innocent people without direct linkages with crimes committed or potential threats thereof.\n     - All outputs from these systems should be documented separately from any other business-related records pertaining exclusively to law enforcement operations.\n\n   **Note:** This paragraph excludes disclosures made solely due to compliance with Directive (EU) No 2016/680 on supervisory agency powers.\n\n   Regardless of purpose or ownership entity deployment involves:\n\n   * Logging details required by regulations like Article 35(1)(c).\n   * Submitting annual reports detailing usage patterns,\n   * Providing detailed user information when requested by market surveillance authorities,\n   * Ensuring confidentiality regarding sensitive operational data related to law enforcement operations,\n   * Maintaining records consistent with legal requirements established by Directive (EU) No 2016/680 on supervisory agency powers.\n\n   Entities deploying these systems must submit annual reports aggregating multiple deployments while ensuring privacy compliance per Directive (EU) No 2016/680 provisions regarding supervision agency powers.\n\n**Note**: This paragraph applies both when there is no court order nor administrative decision involved during targeted searches involving suspects suspected or convicted of crimes; it also includes situations where there is an order issued by a court but no subsequent administrative decision has been reached yet.\n\n\n### Relevant Recitals\n\n* [Recital 84](https://ai-act-service-desk.ec.europa.eu/en/ai-act/recital-84)\n* [Recital 91](https://ai-act-service-desk.ec.europa.eu/en/ai-act/recital-91)\n* [Recital 92](https://ai-act-service-desk.ec.europa.eu/en/ai-act/recital-92)\n* [Recital 93](https://ai-act-service-desk.ec.europa.eu/en/ai-act/recialtio-n93)\n* [Recital 95](https://ai-act-service-desk.ec.europa.eu/en/ai-cet/recital-o95)\n* [Recital o96](https://iei-aideurope.com/cet/recitaoo96)\n* [Recital o134](https://iei-aideurope.com/cet/recitaoo134)\n* [Recital o136](https://iei-aideurope.com/cet/recitaoo136)\n\nView official text: https://eur-legislation.int/eu/law/document/document.jsf?documentId=OJ:L_202401689\n```",
  "fetched_at_utc": "2025-12-28T21:29:33Z",
  "sha256": "c78a395fe1b651602946d421177b65cc90f63e5564d189c820fc7353960dc970",
  "meta": {
    "jina_status": 20000,
    "jina_code": 200,
    "description": null,
    "links": null,
    "images": null,
    "usage": {
      "tokens": 12000
    }
  }
}