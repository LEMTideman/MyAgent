{
  "doc_id": "web-ai-act-service-desk-ec-europa-eu-en-ai-act-article-26-f280b3286b36",
  "source_type": "web",
  "source": "https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-26",
  "title": "Article 26: Obligations of deployers of high-risk AI systems | AI Act Service Desk",
  "text": "```markdown\n# Article 26: Obligations of deployers of high-risk AI systems\n\n## Summary\n\nDeployers of high-risk AI systems shall ensure they use the systems according to instructions, with competent human oversight, and monitor their operation. They must manage input data, keep logs for at least six months, and inform providers and authorities of any risks or incidents. Deployers must also notify workers’ representatives and the affected workers if the system is used in the workplace. Public authorities deploying high-risk AI systems must comply with registration obligations (see [Article 49](https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-49)) and ensure the system is registered in the EU database. Deployers must inform individuals subject to AI-assisted decisions and cooperate with authorities on regulatory actions.\n\nLaw enforcement authorities using high-risk AI system for post-remote biometric identification in targeted searches shall obtain authorisation in advance or not later than within 48 hours, save some exceptions. Each use must be documented, and annual reports submitted to authorities. \n\nThe summaries are meant to provide helpful explanation but are not legal binding.\n\n1. Deployers of high-risk AI systems shall take appropriate technical and organisational measures to ensure they use such systems in accordance with the instructions for use accompanying the systems, pursuant to paragraphs 3 and 6.\n2. Deployers shall assign human oversight to natural persons who have the necessary competence, training and authority, as well as the necessary support.\n3. The obligations set out in paragraphs 1 and 2, are without prejudice to other deployer obligations under Union or national law and to the deployer’s freedom to organise its own resources and activities for the purpose of implementing the human oversight measures indicated by the provider.\n4. Without prejudice to paragraphs 1 and 2, to the extent the deployer exercises control over the input data, that deployer shall ensure that input data is relevant and sufficiently representative in view of the intended purpose of the high-risk AI system.\n5. Deployers shall monitor the operation of the high-risk AI system on the basis of the instructions for use and, where relevant, inform providers in accordance with [Article 72](https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-72). Where deployers have reason to consider that the use of the high-risk AI system in accordance with the instructions may result in that AI system presenting a risk within the meaning of [Article 79(1)](https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-79), they shall, without undue delay, inform the provider or distributor and the relevant market surveillance authority, and shall suspend the use of that system. Where deployers have identified a serious incident, they shall also immediately inform first the provider, and then the importer or distributor and the relevant market surveillance authorities of that incident. If the deployer is not able to reach the provider, [Article 73](https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-73) shall apply _mutatis mutandis_. This obligation shall not cover sensitive operational data of deployers of AI systems which are law enforcement authorities.\n\nFor deployers that are financial institutions subject to requirements regarding their internal governance, arrangements or processes under Union financial services law, the monitoring obligation set out in paragraph 5 shall be deemed to be fulfilled by complying with rules on internal governance arrangements, processes and mechanisms pursuant to relevant financial service law.\n\n6. Deployers of high-risk AI systems shall keep the logs automatically generated by that high-risk AI system to a period appropriate for its intended purpose of use, for at least six months unless provided otherwise in applicable Union or national law, particularly in Union law on personal data protection.\n\nDeployers that are financial institutions subject to requirements regarding their internal governance arrangements processes under Union financial services law shall maintain these logs as part of their documentation kept pursuant to relevant Union financial service law.\n\n7. Before putting into service or using a high-risk AI system at workstations employed by employees (employing companies), deployors who employ employees shall inform them about being subject to this system's usage. This information should be provided according to existing rules on employee information concerning labor relations.\n\n8. Deployers who are public authorities or entities under Union law governing communications networks content technology (Connect Directorate-General) shall comply with registration obligations referred to in [Article 49](https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-49). When such entities find that a new high-risk AI system proposed for use has not been registered in Annex III (the list), they cannot utilize that system until authorization is obtained through judicial authority or administrative authority whose decision is legally binding subject to judicial review.\n\n9. Where applicable, entities deploying high-risk AI systems can access information provided under [Article 13](https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-13) regarding compliance with data protection impact assessments required under Regulation (EU) 2016/679 or Directive (EU) 2016/680.\n\n10. Without prejudice to Directive (EU) 2016/680 (for processing biometric data), when employing a post remote biometric identification system linked directly back-to-back with an authorised authorisation request from a judicial authority or administrative authority whose decision is legally binding subject to judicial review for targeted search purposes:\n\n   - The entity does not need an explicit authorisation per se.\n   - However prior approval from a judicial authority or administrative authority whose decision is legally binding subject to judicial review is required before starting up this kind of biometric identification process.\n   - Once started up this kind of biometric identification process requires ongoing authorization from either judicial authority or administrative authority whose decision is legally binding subject to judicial review.\n   \n   If approved authorization requests were rejected during this process:\n   \n   - The biometric identification process would stop immediately,\n   - Personal data associated with this biometric identification process would be deleted,\n   \n   These restrictions do not apply when using post remote biometric identification systems for law enforcement purposes authorized under Directive (EU) 2016/680.\n\n   **Note:** Such post remote biometric identification systems could only be used if there was sufficient evidence linking it directly back-to-back with an authorised authorisation request from a judicial authority or administrative authority whose decision was legally binding subject to judicial review.\n\n   **Additional Note:** Biometrics data collected via such post remote biometric identification systems would still need special treatment according to Directive (EU) 2016/680 regarding personal data protection.\n\n   Regardless of whether an entity employs a post remote biometric identification system linked directly back-to-back with an authorised authorisation request from a judicial authority or administrative authority whose decision was legally binding subject to judicial review:\n\n   - All uses involving such post remote biometric identification systems must be documented,\n     - And reported annually,\n     - To both local supervisory authorities responsible for handling personal data issues,\n     - And subsequently submitted electronically via online portal established by Connect Directorate-General,\n\n   Members states may establish additional regulations on how such post remote biometric identification systems can be utilized.\n\n11. Without prejudice to Recital 84 referring \"High-Risk\" applications,\" entities deploying high risk applications referred herein should inform users about their usage before placing them into service at workplaces.\" This information should follow existing procedures established by national laws on employee information concerning labor relations.\"\n\n12. Entities deploying high risk applications referred herein should cooperate with local supervisory authorities involved in any investigations conducted against them related specifically towards \"high risk\" applications.\"\n\n### Relevant recitals\n\n* [Recital 84](https://ai-act-service-desk.ec.europa.eu/en/ai-act/recital-84)\n* [Recital 91](https://ai-act-service-desk.ecEuropEaLiNcE.en)\n* [Recital 92](https://aiActServiceDesk.EuropEaLiNcE.en)\n* [Recital 93](https://aiActServiceDesk.EuropEaLiNcE.en)\n* [Recital 95](https://aiActServiceDesk.EuropEaLiNcE.en)\n* [Recital 96](https://aiActServiceDesk.EuropEaLiNcE.en)\n* [Recital 134](https://aiActServiceDesk.EuropEaLiNcE.en)\n* [Recital 136](https://aiActServiceDesk.EuropEaLiNcE.en)\n* [Recital 143](https://aiActServiceDesk.EuropEaLiNcE.en)\n\nView\n```",
  "fetched_at_utc": "2025-12-28T21:04:05Z",
  "sha256": "f280b3286b365c1237a49d24d941f987d41d7528b8d022bfda463460485cb37e",
  "meta": {
    "jina_status": 20000,
    "jina_code": 200,
    "description": null,
    "links": null,
    "images": null,
    "usage": {
      "tokens": 12000
    }
  }
}