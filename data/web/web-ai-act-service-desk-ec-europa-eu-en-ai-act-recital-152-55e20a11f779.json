{
  "doc_id": "web-ai-act-service-desk-ec-europa-eu-en-ai-act-recital-152-55e20a11f779",
  "source_type": "web",
  "source": "https://ai-act-service-desk.ec.europa.eu/en/ai-act/recital-152",
  "title": "Recital 152 | AI Act Service Desk",
  "text": "```markdown\n# Recital 152\n\nIn order to support adequate enforcement as regards AI systems and reinforce the capacities of the Member States, Union AI testing support structures should be established and made available to the Member States.\n\n### This Recital relates to\n\n*   [Article 84: Union AI testing support structures](/en/ai-act/article-84)\n\n---\n\n## Overview\n\nView the [official text](https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=OJ:L_202401689). The text used in this tool is the ‘[Artificial Intelligence Act (Regulation (EU) 2024/1689), Official version of 13 June 2024](https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=OJ:L_202401689)’.\n\n---\n\n## Related Links\n\n*   [Chapter I: General Provisions](#chapter-i-general-provisions)\n*   [Chapter II: Prohibited AI Practices](#chapter-ii-prohibited-ai-practices)\n*   [Chapter III: High-Risk AI Systems](#chapter-iii-high-risk-ai-systems)\n*   [Chapter IV: Transparency Obligations for Providers and Deployers of Certain AI Systems](#chapter-iv-transparency-obligations-for-providers-and-deployers-of-certain-ai-systems)\n*   [Chapter V: General-Purpose AI Models](#chapter-v-general-purpose-ai-models)\n*   [Chapter VI: Measures in Support of Innovation](#chapter-vi-measures-in-support-of-innovation)\n*   [Chapter VII: Governance](#chapter-vii-governance)\n*   [Chapter VIII: EU Database for High-Risk AI Systems](#chapter-viii-eu-database-for-high-risk-ai-systems)\n*   [Chapter IX: Post-Market Monitoring, Information Sharing and Market Surveillance](#chapter-ix-post-market-monitoring-information-sharing-and-market-surveillance)\n*   [Chapter X: Codes of Conduct and Guidelines](#chapter-x-codes-of-conduct-and-guidelines)\n*   [Chapter XI: Delegation of Power and Committee Procedure](#chapter-xi-delegation-of-power-and-committee-procedure)\n*   [Chapter XII: Penalties](#chapter-xii-penalties)\n\n---\n\n## Chapter I: General Provisions\n\n### Article 1: Subject matter\n[Link to article]\n\n### Article 2: Scope\n[Link to article]\n\n### Article 3: Definitions\n[Link to article]\n\n### Article 4: AI literacy\n[Link to article]\n\n---\n\n## Chapter II: Prohibited AI Practices\n\n### Article 5: Prohibited AI practices\n[Link to article]\n\n---\n\n## Chapter III: High-Risk AI Systems\n\n### Section 1: Classification of AI Systems as High-Risk\n#### Article 6\n[Link to article]\n#### Article 7\n[Link to article]\n\n### Section 2: Requirements for High-Risk AI Systems\n#### Article 8\n[Link to article]\n#### Article 9\n[Link to article]\n#### Article 10\n[Link to article]\n#### Article 11\n[Link to article]\n#### Article 12\n[Link to article]\n#### Article 13\n[Link to article]\n#### Article 14\n[Link to article]\n#### Article 15\n[Link to article]\n#### Article 16\n[Link to article]\n#### Article 17\n[Link to article]\n#### Article 18\n[Link to article]\n#### Article 19\n[Link to article]\n#### Article 20\n[Link to article]\n####Article 21 Article 22 Article 23 Article 24 Article 25 Article 26 Article 27 Article 28 \n##### Section     Articles      Articles       Articles          Articles           Articles             Articles             Articles             Articles             Articles             Articles             Articles             Articles             Articles             Articles             Articles             Articles             Articles\n\n### Section 3: Obligations of Providers and Deployers of High-Risk AI Systems and Other Parties\n\n#### Article 16:\n[Link to article]  \n**Human Rights Impact Assessment:**  \nFor high-risk AI systems, human rights impact assessments must be conducted.  \n**Risk Management System:**  \nA risk management system must be implemented.  \n**Data and Data Governance:**  \nProvision of data must be ensured.  \n**Technical Documentation:**  \nDocumentation must be kept.  \n**Record Keeping:**  \nRecords must be kept.  \n**Transparency and Provision of Information:**  \nInformation about the use of artificial intelligence must be provided.  \n**Human Oversight:**  \nHuman oversight mechanisms must be established.  \n**Accuracy, Robustness, and Cybersecurity:**  \nEnsuring accuracy, robustness, and security is necessary.\n\n##### Sections:\n\n###### **Providers & Deployers**\n\n| Requirement | Description |\n|-------------|-------------|\n| **General Purpose AI Models**: | \n| * Classification Rule | \n| * Compliance with Specific Requirements |\n| **High-Risk AI Systems**: | \n| * Compliance with Specific Requirements |\n\n###### **Other Parties**\n\n| Requirement | Description |\n|-------------|-------------|\n| **Notifying Authorities & Notified Bodies**: | \n| * Notification Procedures |\n| * Certification Body Functionality |\n| * Approval Process for Notified Bodies |\n\n###### **Supervisors & Regulators**\n\n| Requirement | Description |\n|-------------|-------------|\n| **Union Institutions & BODS**: | \n| * Decision Making Authority |\n| * Regulatory Sandboxes |\n\n###### **National Competent Authorities**\n\n| Requirement | Description |\n|-------------|-------------|\n| **Designation of National Competent Authorities**: | \n\n|\n\n---\n\n## Chapter IV: Transparency Obligations for Providers and Deployers of Certain AI Systems\n\n### Section A - Classification Rules\n\n##### Part A - General Purpose Artificial Intelligence Models\n\n##### Part B - Non-High-Risk Model Processing\n\n##### Part C - Special Considerations for General Purpose Models with Systematic Risk\n\n##### Part D - Code Of Practice For Generative Models With Systematic Risk\n\n---\n\n## Chapter V: General-Purpose Artificial Intelligence Models (GenAI)\n\n### Section A - Classification Rules\n\n##### Part A - GenAI Categories\n\n##### Part B - Non-GenAI Processing Methods\n\n##### Part C - Special Considerations for GenAI with Systematic Risk\n\n##### Part D - Code Of Practice For GenAI With Systematic Risk\n\n---\n\n## Chapter VI: Measures in Support of Innovation\n\n### Section A - Implementation Details for Innovation Programs\n\n##### Section B - Enforcement Mechanisms for Innovation Programs\n\n---\n\n## Chapter VII: Governance at Union Level (Governance Framework)\n\n### Section A - Key Entities Established at Union Level\n\n##### Section B - Structure And Functions Of The European Artificial Intelligence Board (EAIB)\n\n##### Section C - Task Assignment Of The EAIB And Its Committees / Forums / Working Groups / Experts Panel / Forum On Research Projects And Technologies To Be Developed By The Board Or Its Committees/Forum/\n\n##### Section D - Membership Of The EAIB And Other Boards At Regional Levels (Regional Boards)\n\n---\n\n## Chapter VIII: EU Database for High-Risk AI Systems (Database)\n\n---\n\n## Chapter IX: Post-Market Monitoring, Information Sharing, And Market Surveillance (Post-Market Monitoring, Information Sharing, And Market Surveillance)\n\n### Section A - Post-Market Monitoring Programmes For High-Risk Products And Services Under Regulation (EU) No. E.U./No. R.E.C.L.A.M.I.N.G.S.T.H.R.A.V.E., No. L. No. S.P.O.F.I.D.A., No. N.B.I., No. M.E.U., No. P.E.U., No. T.E.U., No. G.E.U., No. O.E.U.\n\n##### Section B - Reporting Of Serious Incidents Regarding These Products And Services Under Regulation (EU) No E.U./No R.E.C.L.A.M.I.N.G.S.T.H.R.A.V.E.\n\n##### Section C - Enforcement Actions Against Companies Using These Products Or Services That Present Risks Under Regulation (EU) No E.U./No R.E.C.L.A.M.I.N.G.S.T.H.R.A.V.E.\n\n##### Section D - Joint Action Between Members To Address Potential Risks Through An Interim Safeguards Mechanism As Provided In Regulation (EU) No E.U./No R.E.C.L.A.M.I.N.G.S.T.H.R.A.V.E.\n\n![Image description](https://webtools.europa.eu/images/icons/icon-alert.png \"Alert Icon\")\n\n---\n\n\n```",
  "fetched_at_utc": "2025-12-29T09:39:51Z",
  "sha256": "55e20a11f77915ff1c52d407cc5ba2412af5ec32142a165ec336f102eb086616",
  "meta": {
    "jina_status": 20000,
    "jina_code": 200,
    "description": null,
    "links": null,
    "images": null,
    "usage": {
      "tokens": 12000
    }
  }
}