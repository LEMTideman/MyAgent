{
  "doc_id": "web-ai-act-service-desk-ec-europa-eu-en-ai-act-article-12-5f7d748cd338",
  "source_type": "web",
  "source": "https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-12",
  "title": "Article 12: Record-keeping | AI Act Service Desk",
  "text": "```markdown\n# Article 12: Record-keeping\n\n## Chapter III: High-Risk AI Systems\n### Section 2: Requirements for High-Risk AI Systems\n\n### Summary\nFor high-risk AI systems record-keeping obligation applies. High-risk AI systems must have automatic logging capabilities to record events throughout their lifecycle. These logs should help identify risks, support post-market monitoring, and track system operation. For remote biometric identification systems, logs must include usage periods, reference databases, input data, and the identities of individuals verifying results. This ensures traceability and facilitates ongoing oversight and risk management.\n\nThe summaries are meant to provide helpful explanation but are not legal binding.\n\n### Recitals\n* [Recital 66](/en/ai-act/recital-66)\n* [Recital 71](/en/ai-act/recital-71)\n* [Recital 131](/en/ai-act/recital-131)\n\nView the [official text](https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=OJ:L_202401689). The text used in this tool is the ‘[Artificial Intelligence Act (Regulation (EU) 2024/1689), Official version of 13 June 2024](https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=OJ:L_202401689)’.\n\n---\n\n## Related Links\n* [Chapter I: General Provisions](#chapter-i-general-provisions)\n* [Chapter II: Prohibited AI Practices](#chapter-ii-prohibited-ai-practices)\n* [Chapter III: High-Risk AI Systems](#chapter-iii-high-risk-ai-systems)\n* [Chapter IV: Transparency Obligations for Providers and Deployers of Certain AI Systems](#chapter-iv-transparency-obligations-for-providers-and-deployers-of-certain-ai-systems)\n* [Chapter V: General-Purpose AI Models](#chapter-v-general-purpose-ai-models)\n* [Chapter VI: Measures in Support of Innovation](#chapter-vi-measures-in-support-of-innovation)\n* [Chapter VII: Governance](#chapter-vii-governance)\n* [Chapter VIII: EU Database for High-Risk AI Systems](#chapter-viii-eu-database-for-high-risk-ai-systems)\n* [Chapter IX: Post-Market Monitoring, Information Sharing and Market Surveillance](#chapter-ix-post-market-monitoring-information-sharing-and-market-surveillance)\n* [Chapter X: Codes of Conduct and Guidelines](#chapter-x-codes-of-conduct-and-guidelines)\n* [Chapter XI: Delegation of Power and Committee Procedure](#chapter-xi-delegation-of-power-and-committee-procedure)\n* [Chapter XII: Penalties](#chapter-xii-penalties)\n\n## Chapter I: General Provisions\n### Article 12. Record-keeping\n\n#### Summary\nFor high-risk AI systems record-keeping obligation applies. High-risk AI systems must have automatic logging capabilities to record events throughout their lifecycle. These logs should help identify risks, support post-market monitoring, and track system operation. For remote biometric identification systems, logs must include usage periods, reference databases, input data, and the identities of individuals verifying results. This ensures traceability and facilitates ongoing oversight and risk management.\n\nThe summaries are meant to provide helpful explanation but are not legal binding.\n\n#### Relevant Recitals\n* [Recital 66](/en/ai-act/recital-66)\n* [Recital 71](/en/ai-act/recital-71)\n* [Recital 131](/en/ai-act/recital-131)\n\nView the official text at https://eur-lex.europa.eu/legal-content/EN/TXT/. The text used in this tool is the 'Artificial Intelligence Act (Regulation (EU) 2024/1689)'.\n\n---\n\n## Chapter II: Prohibited AI Practices\n### Article 5. Prohibited AI practices\n\n#### Summary\nProhibitions apply to various aspects such as bias mitigation strategies, transparency requirements, human supervision mechanisms, accuracy assurance protocols, security safeguards for data handling processes.\n\n#### Relevant Recitals\n* [Recital 55](/en/ai-act/recital-55)\n\nView the official text at https://eur-lex.europa.eu/legal-content//EN/TXT/.\n\n---\n\n## Chapter III: High-Risk AI Systems\n### Section 2. Requirements for High-Risk AI Systems\n\n#### Summary\nRequirements outline specific technical measures necessary for high-risk AI systems to maintain operational integrity while ensuring compliance with specified standards.\n\n#### Relevant Recitals\n* [Recital 55](/en/ai-act/recital-\n```",
  "fetched_at_utc": "2025-12-28T20:12:56Z",
  "sha256": "5f7d748cd3387e2168b99f711e65cf804c012211cee2e8c1783b9f844eaa80a8",
  "meta": {
    "jina_status": 20000,
    "jina_code": 200,
    "description": null,
    "links": null,
    "images": null,
    "usage": {
      "tokens": 12000
    }
  }
}