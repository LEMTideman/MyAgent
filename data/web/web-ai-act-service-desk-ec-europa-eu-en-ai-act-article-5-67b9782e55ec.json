{
  "doc_id": "web-ai-act-service-desk-ec-europa-eu-en-ai-act-article-5-67b9782e55ec",
  "source_type": "web",
  "source": "https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-5",
  "title": "Article 5: Prohibited AI practices | AI Act Service Desk",
  "text": "```markdown\n# Article 5: Prohibited AI practices\n\n## Summary\n\n[Article 5](https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-5) prohibits the placing on the EU market, putting into service or use of certain AI systems for manipulative, exploitative and social scoring practices, which by their inherent nature violate fundamental rights and EU values. It also outlaws certain AI systems used for individual criminal offence risk assessment and prediction based solely on profiling or personality traits and characteristics, untargeted scraping to develop facial recognition databases, emotion recognition and biometric categorization. Real-time remote biometric identification in publicly accessible spaces for the purposes of law enforcement is also prohibited with some exceptions.\n\nThe summaries are meant to provide helpful explanation but are not legal binding.\n\n### 1\\. The following AI practices shall be prohibited:\n\n(a) the placing on the market, the putting into service or the use of an AI system that deploys subliminal techniques beyond a person’s consciousness or purposely manipulative or deceptive techniques, with the objective, or the effect of materially distorting the behavior of a person or a group of persons by appreciably impairing their ability to make an informed decision, thereby causing them to take a decision that they would not have otherwise taken in a manner that causes or is reasonably likely to cause that person, another person or group of persons significant harm;\n\n(b) the placing on the market, the putting into service or the use of an AI system that exploits any of the vulnerabilities of a natural person or a specific group of persons due to their age, disability or a specific social or economic situation, with the objective, or the effect, of materially distorting the behavior of that person or a person belonging to that group in a manner that causes or is reasonably likely to cause that person or another person significant harm;\n\n(c) the placing on the market, the putting into service or the use of an AI system for evaluating or classifying natural persons or groups of persons over a certain period of time based on their social behavior or known, inferred or predicted personal or personality characteristics, with social scores leading to either:\n   - detrimental or unfavorable treatment of certain natural persons or groups of persons in social contexts unrelated to those in which the data was originally generated or collected;\n   - detrimental or unfavorable treatment of certain natural persons or groups of persons that is unjustified or disproportionate to their social behavior and its gravity;\n\n(d) the placing on the market, putting into service for this specific purpose, or using an AI system for making risk assessments of natural persons in order to assess或predict risk levels associated with criminal offenses based solely on profiling individuals based on these profiles alone (which includes criminal offense risk assessment and prediction based solely on profiling). This prohibition does not apply to AI systems used to support human assessments involving individuals in criminal investigations and prosecutions while maintaining objective links between crimes directly linked to criminal acts.\n\n(e) placing on the market, putting into service for this specific purpose, using an AI system for making risk assessments regarding individuals' likelihood of committing crimes solely based on demographic factors (such as age).\n\n(f) placing on the market, putting into service for this specific purpose using an AI system for creating databases containing facial images obtained through untargeted scraping from online sources.\n\n(g) placing on the market, putting into service for this specific purpose using an AI system for inferring emotions from individuals without direct access to their behavioral patterns.\n\n(h) using 'real-time' remote biometric identification systems in public places primarily aimed at identifying victims of abduction, trafficking in humans, sexual exploitation cases (including missing people searches), preventing terrorist attacks (with a minimum detention period), and localizing suspects suspected of committing crimes punishable by at least four years imprisonment.\n\nPoint (h) applies only when necessary and proportionate measures are implemented during situations considered urgent.\n\n(i) The use must be authorized only if it is assessed as necessary and proportionate by law enforcement authorities after conducting fundamental rights impact assessments according to Article 27. These measures must ensure minimal disruption to citizens' rights and freedoms while addressing legitimate concerns about potential harms.\n\n(j) Using 'real-time' remote biometric identification systems exclusively for law enforcement purposes requires prior authorization granted by judicial authorities. In emergencies requiring immediate action without authorization approval within 24 hours can be initiated without authorization approval.\n\n(k) Each use must be reported annually via national markets surveillance authorities and national data protection authorities. Annual reports will include aggregated data from Member States but will exclude sensitive operational data.\n\n(l) This Article does not affect prohibitions applicable where an AI practice violates other Union laws.\n\n### Relevant Recitals\n\n* [Recital 3](https://ai-act-service-desk.ec.europa.eu/en/ai-act/recital-3)\n* [Recital 26](https://ai-act-service-desk.ec.europa.eu/en/ai-act/recital-26)\n* [Recital 28](https://ai-act-service-desk.ec.europa.eu/en/ai-act/recital-28)\n* [Recital 29](https://ai-act-service-desk.ec.europa.eu/en/ai-act/recital-29)\n* [Recital 30](https://ai-act-service-desk.ec.europa.eu/en/ai-act/recital-30)\n* [Recital 31](https://ai-act-service-desk.ec.europa.eu/en/ai-act/recrial-31)\n* [Recital 32](https://ai-act-service-desk.ec.europa.eu/en/ai-act/recialt-32)\n* [Recital 33](https://ai-act-service-desk.ec.europa.eu/en/ai-atlrecialt-33)\n* [Recital 34](https://ai-act-service-desk.ec.europa.eu/en/aiaatrecialt-34)\n* [Recital 35](https://ai-act-service-desk.ec.europa.eu/en/aiaatrecialt--35)\n* [Recital 36](https://ai-actservice.deskc.com/en/aiaatrecialt--36)\n\n### Other Resources\n\n[Guidelines on prohibited AI practices](https://ai-act-service-desk.ec.europa.eu/sites/default/files/2025-08/guidelines_on_prohibited_artificial_intelligence_practices_established_by_regulation_eu_20241689_ai_act_english_ied3r5nwo50xggpcfmwckm3nuc_112367.pdf)\n\nView the official text at: https://eur-legis.ejusticepro.net/juris/document.jsf?text=https%3A%2F%2Feur-legis.ejusticepro.net%2Fjuris%2Fdocument.jsf%3Ftext%3DEU-LAW%40EN&docid=OJ:L_202401689&doctype=TEXT&lang=en\n```",
  "fetched_at_utc": "2025-12-28T20:55:10Z",
  "sha256": "67b9782e55ecc74c2b86cb8704ed9fdc3cc462e52ac2b7deb3e478f111c1e68e",
  "meta": {
    "jina_status": 20000,
    "jina_code": 200,
    "description": null,
    "links": null,
    "images": null,
    "usage": {
      "tokens": 12000
    }
  }
}