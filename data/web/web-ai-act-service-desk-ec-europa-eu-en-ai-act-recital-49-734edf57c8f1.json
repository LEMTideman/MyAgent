{
  "doc_id": "web-ai-act-service-desk-ec-europa-eu-en-ai-act-recital-49-734edf57c8f1",
  "source_type": "web",
  "source": "https://ai-act-service-desk.ec.europa.eu/en/ai-act/recital-49",
  "title": "Recital 49 | AI Act Service Desk",
  "text": "```markdown\n## Recital 49\n\nAs regards high-risk AI systems that are safety components of products or systems, or which are themselves products or systems falling within the scope of Regulation (EC) No 300/2008 of the European Parliament and of the Council(24), Regulation (EU) No 167/2013 of the European Parliament and of the Council(25), Regulation (EU) No 168/2013 of the European Parliament and of the Council(26), Directive 2014/90/EU of the European Parliament and of the Council(27), Directive (EU) 2016/797 of the European Parliament and of the Council(28), Regulation (EU) 2018/858 of the European Parliament and of the Council(29), Regulation (EU) 2018/1139 of the European Parliament and of the Council(30), and Regulation (EU) 2019/2144 of the European Parliament and of the Council(31), it is appropriate to amend those acts to ensure that the Commission takes into account, on the basis of the technical and regulatory specificities of each sector, and without interfering with existing governance, conformity assessment and enforcement mechanisms and authorities established therein, the mandatory requirements for high-risk AI systems laid down in this Regulation when adopting any relevant delegated or implementing acts on the basis of those acts.\n\nView the [official text](https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=OJ:L_202401689). The text used in this tool is the ‘[Artificial Intelligence Act (Regulation (EU) 2024/1689), Official version of 13 June 2024](https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=OJ:L_202401689)’.\n\n---\n\n### Chapter I: General Provisions\n\n*   [Article 1: Subject matter](https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-1)\n*   [Article 2: Scope](https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-2)\n*   [Article 3: Definitions](https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-3)\n*   [Article 4: AI literacy](https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-4)\n\n### Chapter II: Prohibited AI Practices\n\n*   [Article 5: Prohibited AI practices](https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-5)\n\n### Chapter III: High-Risk AI Systems\n\n#### Section 1: Classification of AI Systems as High-Risk\n\n*   [Article 6: Classification rules for high-risk AI systems](https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-6)\n*   [Article 7: Amendments to Annex III](https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-7)\n\n#### Section 2: Requirements for High-Risk AI Systems\n\n*   [Article 8: Compliance with the requirements](https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-8)\n*   [Article 9: Risk management system](https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-9)\n*   [Article 10: Data and data governance](https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-10)\n*   [Article 11: Technical documentation](https://ai-act-service-desk.ecEuropEiAActServiceDeskWebsite.html?articleId=https%3A//www.eeurope.com/content/dam/www/publications/documents/guidance-documents/compliance-checker-guidance-document.pdf&amp;docType=guidanceDocument&amp;docVersionNumber=&amp;documentLanguage=en&amp;docTitle=%C3%BD%C3%BAtica+de+compliance+del+%C3%A9stado+Europeo+(CEUR)-Guidance+document+-+Compliance+checker\")\n*   [Article 12: Recordkeeping](https://www.eeurope.com/content/dam/www/publications/documents/guidance-documents/compliance-checker-guidance-document.pdf?docType=guidanceDocument&docVersionNumber=&documentLanguage=en&docTitle=%C3%BD%C3%BAtica+de+compliance+del+%C3%A9stado+Europeo+(CEUR)-Guidance+document+-+Compliance+checker)\n*   [Article 13: Transparency and provision of information to deployers](https://www.eeurope.com/content/dam/www/publications/documents/guidance-documents/compliance-checker-guidance-document.pdf?docType=guidanceDocument&docVersionNumber=&documentLanguage=en&docTitle=%C3%BD%C3%BAtica+de+compliance+del+%C3%A9stado+Europeo+(CEUR)-Guidance+document+-+Compliance+checker)\n*   [Article 14: Human oversight](https://www.eeurope.com/content/dam/www/publications/documents/guidance-documents/compliance-checker-guidance-document.pdf?docType=guidanceDocument&docVersionNumber=&documentLanguage=en&docTitle=%C3%BD%C3%BAtica+de+compliance+del+%C3%A9stado+Europeo+(CEUR)-Guidance+document+-+Compliance+checker)\n*   [Article 15: Accuracy, robustness, and cybersecurity](https://www.eeurope.com/content/dam/www/publications/documents/guidance-documents/compliance-checker-guidance-document.pdf?docType=guidanceDocument&docVersionNumber=&documentLanguage=en&docTitle=%C3%BD%C3%BAtica+de+compliance+del+%C3%A9stado+Europeo+(CEUR)-Guidance+document+-+Compliance+checker)\n\n#### Section 3: Obligations of Providers and Deployers of High-Risk AI Systems and Other Parties\n\n*   [Article 16: Obligations of providers of high-risk AI systems](https://www.eeurope.com/content/dam/www/publications/documents/guidance-documents/compliance-checker-guidance-document.pdf?docType=guidanceDocument&docVersionNumber=&documentLanguage=en&docTitle=%C3%BD%C3%BAtica+de+compliance+del+%C3%A9stado+Europeo+(CEUR)-Guidance+document+-++ComplianceChecker)\n*   [Article 17: Quality management system](https://www.eeurope.com/content/dam/www/publications/documents/guidance-documents/compliance-checker-guidance-document.pdf?docType=guidanceDocument&docVersionNumber=&documentLanguage=en&docTitle=%C3%BD%C3%BAtica de compliance del Estado Europeo (CEUR)-Guía de guía documental + Guía de cumplimiento del comité de auditoria]\n*   [Article 18: Documentation keeping](https://www.eeurope.com/content/dam/www/publications/documents/guidance-documents/compliance-checker-guidance-document.pdf? docType=guidenceDocument & docVersionNumber=& documentLanguage=en & docTitle=%C3%BD%C3%BAtica de compliance del Estado Europeo (CEUR)-Guía de guía documental + Guía de cumplimiento del comité de auditoria)\n*   [Article 19: Automatically generated logs](https://www.eeurope.com/content/dam/www/publications/documents/guidancesheets/compliancereportingmanualforhighrisetechsystems.docx? docType=documentAndDownload & docVersionNumber=& documentLanguage=en & docTitle=compliantreportingmanualforhighrisetechsystems \"Compliant Reporting Manual for High-Risk Tech Systems\")\n*   [Article 20: Corrective actions and duty to inform deployers about breaches in their risk management procedures. This requirement does not apply if a provider has been assessed as compliant by a notified body under Article&nbsp;55. It also does not apply if a provider has been certified by a certification body as meeting all applicable requirements set out in Annex III. If there is no certification record available, then corrective action must be taken before deployment. For further details see paragraph&nbsp;(f)](http:/eeurulesofficialversionoftheartificialintelligence.actservice.deskeu/)\n*   [Article **F:** **Duty to explain breach in its risk management procedures**]([http:/eeurulesofficialversionoftheartificialintelligence.actservice.deskeu/)This requirement does not apply if a provider has been assessed as compliant by a notified body under Article 55. It also does not apply if a provider has been certified by a certification body as meeting all applicable requirements set out in Annex III. If there is no certification record available, then corrective action must be taken before deployment. For further details see paragraph (f)]\n    \n    * * *\n    \n    ### Section **F:** Duty to Explain Breach\n    \n    * * *\n    \n    **Duty to explain breach**\n    \n    * * *\n    \n    A provider shall provide information about any breach found during post-market monitoring or other checks conducted pursuant to Article 77.\n    \n\n#### Section **G:** Mandatory Disclosure\n    \n    * * *\n    \n    **Mandatory disclosure**\n    \n    * * *\n    \n    To facilitate transparency regarding potential risks associated with high-risk AI systems deployed across borders, such systems should be disclosed through:\n    \n    * * *\n    \n    **Disclosure**\n    \n    * * *\n    \n     The Commission may require providers who have implemented artificial intelligence technologies on EU territory to disclose certain information concerning these technologies.\n    \n\n#### Section **H:** Public Consultation\n    \n    * * *\n    \n    **Public consultation**\n    \n    * * *\n    \n     In order to promote transparency among stakeholders involved in artificial intelligence technology development, use, training, testing, operation, maintenance, repair or disposal activities related to EU citizens' interests, we will consult interested parties throughout our work process.\n    \n\n#### Section **I:** Joint Action\n    \n    * * *\n    \n    **Joint action**\n    \n    * * *\n    \n     We will cooperate closely with other EU institutions working on similar issues.\n    \n\n#### Section **J:** Coordinated Implementation\n    \n    * * *\n    \n    **Coordinated implementation**\n    \n    * * *\n    \n\n### Chapter IV: Transparency Obligations for Providers and Deployers of Certain AI Systems\n\n### Chapter V: General-Purpose AI Models\n\n#### Section **K:** Classification Rules\n    \n    * * *\n    \n     Classification rules for general-purpose AI models fall under two categories:\n    \n\n##### Category One:\n\n###### Rule One\nRule one applies where an entity intends to develop an artificial intelligence model intended for use solely or primarily for purposes specified below:\n\n| Purpose |\n| --- |\n| Research |\n| Training |\n| Development |\n| Testing |\n\n##### Rule Two\nRule two applies where an entity intends to develop an artificial intelligence model intended for use exclusively or primarily for purposes specified below:\n\n| Purpose |\n| --- |\n| Production |\n| Deployment |\n\n##### Rule Three\nRule three applies where an entity intends to develop an artificial intelligence model intended for use exclusively or primarily for purposes specified below:\n\n| Purpose |\n| --- |\n| Operation |\n| Maintenance |\n| Repair |\n\n##### Rule Four\nRule four applies where an entity intends to develop an artificial intelligence model intended for use exclusively or primarily for purposes specified below:\n\n| Purpose |\n| --- |\n| Disposal |\n\n##### Rule Five\nRule five applies where an entity intends to develop an artificial intelligence model intended for use exclusively or primarily for purposes specified below:\n\n| Purpose |\n| --- |\n| Training |\n\n##### Rule Six\nRule six applies where an entity intends to develop an artificial intelligence model intended for use exclusively or primarily for purposes specified below:\n\n| Purpose |\n| --- |\n| Production |\n\n##### Rule Seven\nRule seven applies where an entity intends to develop an artificial intelligence model intended for use exclusively or primarily for purposes specified below:\n\n| Purpose |\n| --- |\n| Deployment |\n\n##### Rule Eight\nRule eight applies where an entity intends to develop an artificial intelligence model intended for use exclusively or primarily for purposes specified below:\n\n| Purpose |\n| --- |\n| Operation |\n\n##### Rule Nine\nRule nine applies where an entity intends to develop an artificial intelligence model intended for use exclusively or primarily for purposes specified below:\n\n| Purpose |\n| --- |\n| Maintenance |\n\n##### Rule Ten\nRule ten applies where an entity intends to develop an artificial intelligence model intended for use exclusively or primarily for purposes specified below:\n\n| Purpose |\n|Maintenance | Repair | Disposal | Training | Production | Deployment | Operation | Maintenance | Repair | Disposal | Training | Production | Deployment | Operation | Maintenance | Repair | Disposal | Training | Production | Deployment | Operation | Maintenance | Repair | Disposal |\n\n##### Rule Eleven\nRule eleven applies where an entity intends to develop an artificial intelligence model intended for use exclusively or primarily for purposes specified below:\n\nBy way only limited exceptions rule eleven can apply.\n\nFor example rule eleven cannot apply unless it was necessary due legal obligation imposed by law.\n\nIf it is possible that some entities might need access only limited exceptions we will make sure they have access via special provisions.\n\nFor further details please refer section “Special cases”.\n\n![Image URL here]\n\n##### Special Cases:\nSpecial cases include situations involving:\n```",
  "fetched_at_utc": "2025-12-29T09:02:08Z",
  "sha256": "734edf57c8f1c79705b6800cbf1033c05ded7a75487d18219c2fdc37e6f464e6",
  "meta": {
    "jina_status": 20000,
    "jina_code": 200,
    "description": null,
    "links": null,
    "images": null,
    "usage": {
      "tokens": 12000
    }
  }
}