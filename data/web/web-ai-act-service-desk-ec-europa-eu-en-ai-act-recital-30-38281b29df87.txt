```markdown
# Recital 30

## Biometric Categorization Systems

Biometric categorisation systems that are based on natural persons’ biometric data, such as an individual person’s face or fingerprint, to deduce or infer an individual's political opinions, trade union membership, religious or philosophical beliefs, race, sex life, or sexual orientation should be prohibited. That prohibition should not cover the lawful labelling, filtering, or categorisation of biometric data sets acquired in line with Union or national law according to biometric data, such as the sorting of images according to hair color or eye color, which can for example be used in the area of law enforcement.

### This Recital relates to

*   [Article 5: Prohibited AI practices](/en/ai-act/article-5)

---

[![European Commission logo](https://webtools.europa.eu/images/flags/eu.svg)](https://commission.europa.eu/index_en)
**An official website of the European Union**
**An official EU website**

How do you know?

All official European Union website addresses are in the **europa.eu** domain.

[See all EU institutions and bodies](https://european-union.europa.eu/institutions-law-budget/institutions-and-bodies/search-all-eu-institutions-and-bodies_en)

---

This site uses cookies. Visit our [cookies policy page](http://localhost/en/node/14) or click the link in any footer for more information and to change your preferences.

[Accept all cookies] 
[Accept only essential cookies]

---

## Menu

*   [Home](/en)
*   [AI Act Explorer](/en/ai-act-explorer)
*   [Compliance Checker](/en/eu-ai-act-compliance-checker)
*   [Contact the AI Act Service Desk](/en/ai-act-service-desk)
*   [AI Act Timeline](/en/ai-act/timeline/timeline-implementation-eu-ai-act)
*   [Resources](/en/resources)
*   [National Resources](/en/national-resources)
*   [FAQ](/en/faq)

---

## Chapter I: General Provisions

### Article 1: Subject Matter
[Affected by this section]

### Article 2: Scope
[Affected by this section]

### Article 3: Definitions
[Affected by this section]

### Article 4: AI Literacy
[Affected by this section]

---

## Chapter II: Prohibited AI Practices

### Article 5: Prohibited AI Practices
[Affected by this section]

---

## Chapter III: High-Risk AI Systems

### Section 1: Classification of AI Systems as High-Risk
#### Article 6: Classification Rules for High-Risk AI Systems
[Affected by this section]
#### Article 7: Amendments to Annex III
[Affected by this section]

### Section 2: Requirements for High-Risk AI Systems
#### Article 8: Compliance with the Requirements
[Affected by this section]
#### Article 9: Risk Management System
[Affected by this section]
#### Article 10: Data and Data Governance
[Affected by this section]
#### Article 11: Technical Documentation
[Affected by this section]
#### Article 12: Record Keeping
[Affected by this section]
#### Article 13: Transparency and Provision of Information to Deployers
[Affected by this section]
#### Article 14: Human Oversight
[Affected by this section]
#### Article 15: Accuracy, Robustness, and Cybersecurity
[Affected by this section]

### Section 3: Obligations of Providers and Deployers of High-Risk AI Systems and Other Parties
#### Article 16: Obligations of Providers of High-Risk AI Systems
[Affected by this section]
#### Article 17: Quality Management System
[Affected by this section]
#### Article 18: Documentation Keeping
[Affected by this section]
#### Article 19: Automatically Generated Logs
[Affected by this section]
#### Article 20: Corrective Actions and Duty of Information Protection
[Affected by this section]
####Article 21 : Cooperation with Competent Authorities 
Affecting this section      
Article 22 : Authorized Representatives of Providers of High-Risk AI Systems 
Affecting this section      
Article 23 : Obligations of Importers 
Affecting this section      
Article 24 : Obligations of Distributors 
Affecting this section      
Article 25 : Responsibilities Along the AI Value Chain 
Affecting this section      
Article 26 : Obligations of Deployers of High-Risk AI Systems 
Affecting this section      
Article 27 : Fundamental Rights Impact Assessment for High-Risk AI Systems 
Affecting this section   

### Section 4: Notifying Authorities and Notified Bodies

#### Article 28 : Notifying Authorities 
Affecting this section      
Article 29 : Application of a Conformity Assessment Body for Notification 
Affecting this section      
Article 30 : Notification Procedure 
Affecting this section      
Article 31 : Requirements Relating to Notified Bodies 
Affecting this section      
Article 32 : Presumption of Conformity with Requirements Relating to Notified Bodies 
Affecting the noted body    

##### Section 5 — Standards, Conformity Assessment, Certificates, Registration

#### Articles:
*   **Article:** \[Number\]: Harmonized Standards and Standardization Deliverables (Link)   
    Affects sections related to harmonizing standards.
*   **Articles:** \[Number\]: Common Specifications (Link)   
    Affects sections related to common specifications.
*   **Articles:** \[Number\]: Presumption of Conformity with Certain Requirements (Link)   
    Affects sections related to presumption of conformity.
*   **Articles:** \[Number\]: Conformity Assessment (Link)   
    Affects sections related to conformance assessments.
*   **Articles:** \[Number\]: Certificates (Link)   
    Affects sections related to certificates.
*   **Articles:** \[Number\]: Information Obligations of Notified Bodies (Link)   
    Affects sections related to information obligations.
*   **Articles:** \[Number\]: Subsidy Assessments (Link)   
    Affects sections related to subsidy assessments.
*   **Articles:** \[Number\]: EU Declaration of Conformity (Link)   
    Affects sections related to EU declarations.
*   **Articles:** \[Number\]: CE Markings (Link)   
    Affects sections related to CE markings.
*   **Articles:** \[Number\]: Registration (Link)   
    Affects sections related to registration.

---

## Chapter IV: Transparency Obligations for Providers and Deployers of Certain AI Systems

### Section I:
#### Articles:
*   **Article**: \[Number\]: Transparency Obligations for Providers and Deployers (Link)

---

## Chapter V: General-Purpose AI Models

### Section I:
#### Articles:
*   **Article**: \[Number\]: Classification Rules for General-Purpose AI Models as General-Purpose AI Models With Systematic Risk (Link)   
    Applies when identifying general-purpose models with systemic risks.
*   **Article**: \[Number\]: Procedure (Link)   

### Section II:
#### Articles:
*   **Article**: \[Number\]: Obligations for Providers of General-Purpose AI Models (Link)   
    Applies when providing general-purpose models.
*   **Article**: \[Number\]: Authorized Representatives for Providers of General-Purpose AI Models (Link)

### Section III:
#### Articles:
*   **Article**: \[Number\]: Obligations for Providers Of General-Purpose AI Models With Systematic Risk (Link)

### Section IV:
#### Articles:
*   **Article**: \[Number\]: Codes Of Practice (Link)

---

## Chapter VI: Measures in Support of Innovation

### Sections I & II:
#### Articles:
*   **Article**: \[Number\]: Artificial Intelligence Regulatory Sandboxes (Links)
     * To provide a safe environment where new technologies can evolve without causing harm.
     * Includes detailed arrangements and functioning details about artificial intelligence regulatory sandboxes.
     * Provides guidance on how these sandboxes operate effectively.
     * Offers tools like codes-of-practice that help implement regulations better.

##### Section III:

###### Articles:
*   **Article**: \[Number\]: Additional Processing For Developing Certain Artificial Intelligence Systems in Public Interest in Regulatory Sandbox (Links)
     * Allows processing personal data under specific circumstances within regulated sandbox environments aimed at promoting innovation through advanced technology applications.

##### Section IV:

###### Articles:
*   **Article**: \[Number\]: Testing Of High-Risk Artificial Intelligence Systems In Real World Conditions Outside Regulatory Sandbox (Links)
     * Enables testing high-risk systems using real-world scenarios outside specified regulatory sandbox settings.

##### Section V:

###### Articles:
*   **Article**: \[Number\]: Informed Consent To Participate In Testing In Real World Conditions Outside Regulatory Sandbox (Links)
     * Requires informed consent from users before participating in tests conducted outside a regulated sandbox setting.

##### Section VI:

###### Articles:
*   **Article**: \[Number\]: Measures For Providers And Deployers Including Small And Medium Enterprises And Startups (Links)
     * Supports innovation efforts among small businesses including startups who may have less resources but still want access to technological advancements.

##### Section VII:

###### Articles:
*   **_article":_\[\number"\]\): Deregulations For Specific Operators Or Activities Underlying These Operators' Activities. Links_

---

## Chapter VII: Governance

### Sections I & II:

###### Articles:

| Title | Description |
|-------|-------------|
| _Section I:_ | ... |
| _Section II:_ | ... |

---

## Chapter VIII: EU Database for High-Risk AI Systems

### Section I:

| Title | Description |
|-------|-------------|
| _Section I:_ | ... |

---

## Chapter IX Post-Market Monitoring, Information Sharing and Market Surveillance

### Sections I & II & III & IV:

###### Articles:

| Title | Description |
|-------|-------------|
| _Section I:_ | ... |
| _Section II:_ | ... |
| _Section III:_ | ... |
| _Section IV:_ | ... |

---

## Chapter X Code Of Conduct And Guidelines

### Sections I & II:

###### Articles:

| Title | Description |
|-------|-------------|
| _Section I:_ | ... |
| _Section II:_ | ... |

---

## Chapter XI Delegation Of Power And Committee Procedure

### Sections I & II:

###### Articles:

| Title | Description |
|-------|-------------|
| _Section I:_ | ... |
| _Section II:_ | ... |

---

## Chapter XII Penalties

### Sections I & II & III & IV & V & VI & VII & VIII & IX & X & XI & XII & XIII & XIV & XVIIIXVIIIIXIXXIVXXVIIXVIIIXVIIIIXXIXXIVXXVIIXVIIIXVIIIIXXIXXIVXXVIIXVIIIXVIIIIXXIXXIVXXVIIXVIIIXVIIIIXXIVXXVIIXVIIIXVIIIIXXIVXXVIIXVIIIXVIIIIXXI.XI.II.III.IV.VI.VI.VI.VI.VI.VI.VI.VI.VI.VI.VI.VI.VI.VI.VI.VI.VI.III.IVV.IVV.IVV.IVV.IVV.IVV.IVV.IVV.IVV.IVV.IVV.IVV.IVV.IVV.JJJ.JJJ.JJJ.JJJ.JJJ.JJJ.JJJ.JJJ.JJJ.JJJ.JJJ.JJJ.JJJ.JJJ.JJJ.HHH.HHH.HHH.HHH.HHH.HHH.HHH.HHH.HHH.HHH.HHH.HHH.HHH.HHH.TTT.TTT.TTT.TTT.TTT.TTT.TTT.TTT.TTT.TTT.TTT.TTT.TTT.TTT.TTT.UUU.UUU.UUU.UUU.UUU.UUU.UUU.UUU.UUU.UUU.UUU.UUU.UUU.UUU.WWW.WWWW.WWWW.WWWW.WWWW.WWWW.WWWW.WWWW.WWWW.WWWW.WWWW.YYY.YYYY.YY.YYY.YY.YYY.YY.YYY.YY.YYY.ZZZ.ZZZ.ZZZ.ZZZ.ZZZ.ZZZ.ZZZ.ZZZ.ZZZ.ZZZ.ZZZ.ZZZ.ZZZ.ZZZ.ZZYZZYZZYZZ.XXXX.XXXXX.XXXXX.XXXXX.XXXXX.XXXXX.XXXXX.XXXXX.XXXXX.XXXXX.XXXXX.XXXXX.XXXXX.XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX|

View the [official text](https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=OJ:L_202401689). The text used in this tool is the ‘Artificial Intelligence Act (Regulation (EU) 2024/1689), Official version of 13 June 2024’.

---
```