```markdown
# Article 60: Testing of high-risk AI systems in real world conditions outside AI regulatory sandboxes

## Summary

The article outlines the conditions for testing high-risk AI systems listed in [Annex III](https://ai-act-service-desk.ec.europa.eu/en/ai-act/annex-3) in real-world settings outside of AI regulatory sandboxes. Providers must submit a testing plan to market surveillance authorities for approval and register the testing. Key conditions include data protection, informed consent, oversight by qualified personnel, and the ability to reverse AI decisions. Testing is limited to six months, extendable once, and must not negatively affect vulnerable groups. Authorities can inspect and ensure safe testing, and providers must report serious incidents and adopt mitigation measures or suspend or terminate the testing. Providers are also liable for any damages.

The summaries are meant to provide helpful explanation but are not legal binding.

1. Testing of high-risk AI systems in real world conditions outside AI regulatory sandboxes may be conducted by providers or prospective providers of high-risk AI systems listed in [Annex III](https://ai-act-service-desk.ec.europa.eu/en/ai-act/annex-3), in accordance with this Article and the real-world testing plan referred to in this Article, without prejudice to the prohibitions under [Article 5](https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-5).

   The Commission shall, by means of implementing acts, specify the detailed elements of the real-world testing plan. Those implementing acts shall be adopted in accordance with the examination procedure referred to in [Article 98(2)](https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-98).

   This paragraph shall be without prejudice to Union or national law on the testing in real world conditions of high-risk AI systems related to products covered by Union harmonisation legislation listed in [Annex I](https://ai-act-service-desk.ec.europa.eu/en/ai-act/annex-1).

2. Providers or prospective providers may conduct testing of high-risk AI systems referred to in [Annex III](https://ai-act-service-desk.ec.europa.eu/en/ai-act/annex-3) in real world conditions at any time before the placing on the market or the putting into service of the AI system on their own or in partnership with one or more deployers or prospective deployers.

3. The testing of high-risk AI systems in real world conditions under this Article shall be without prejudice to any ethical review that is required by Union or national law.

4. Providers or prospective providers may conduct the testing in real world conditions only where all of the following conditions are met:

   - (a) the provider or prospective provider has drawn up a real-world testing plan and submitted it to the market surveillance authority in the Member State where the testing in real world conditions is to be conducted;
   
   - (b) the market surveillance authority in the Member State where the testing in real world conditions is to be conducted has approved the testing in real world conditions and the real-world-testing plan; where the market surveillance authority has not provided an answer within 30 days, the testing in real world conditions and the real-world-testing plan shall be understood to have been approved; where national law does not provide for a tacit approval, the testing in real world conditions shall remain subject to an authorisation;
   
   - (c) the provider or prospective provider, with the exception of providers or prospective providers of high-risk AI systems referred to in points 1, 6 and 7 of [Annex III](https://ai-act-service-desk.ec.europa.eu/en/ai-act/annex-3) in the areas of law enforcement, migration, asylum and border control management, and high-risk AI systems referred to in point 2 of [Annex III](https://ai-act-service-desk.ec.europa.eu/en/ai-act/annex-3) has registered the testing in real-world conditions in accordance with [Article 71(4)](https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-71) with a Union-wide unique single identification number and with the information specified in [Annex IX](https://ai-act-service-desk.ec.europa.eu/en/ai-act/annex-9); 
     - (d)the provider or prospective provider of high-risk AI systems referred to in points 1, 6 and 7 of [Annex III](https://ai-act-service-desk.ec.europa.eu/en/ai-act/annex-3) refer[ed]inareasoflawenforcement,migrationasylumandbordercontrolofmigrationaswellasthehigh-riscairysreferredtoinpoint2of[AnnexIII]hasregisteredthetestinginrealworldconditionsinthesecurenon-publicsectionofthEUdatabaseaccordingtob[Article49(4)](https://ai-act-service-desk.ec.europa.eu/en/ai-act/article--49)(d),withaustraliawideuniquesingleidentificationnumberandspecifiedtherein;theproviderorprospectiveproviderofhigh-riscairysreferredtoinpoints16and7of[AnnexIII]refer[ing]inthemigrationsecurityareaoflawaswellastherightsofreversepredictionrecommendationordecisionsofanAIsystemcanbereversedanddisregarded.
   
   - (e)the subjects of th[e]testinginrealworldconditionswhoarepersonsfailingtovegetatedgroupsdueototheirageordisabilityareappropriatelyprotected;
   
   - (f)where a provider or prospective provider organizes th[e]testinginarrealworldconditionsincooperationwithoneornomoredeployersorprospectivedeployers,thelatterhavebeeninformedinallaspectsoftestingthataresuitabletonetheirdecisiontoperparticipat,andgiventherespectedinstructionsforuseofoficiallydefinedAIsystemreferredtoin[Article13];theprovidersonormoreprospectiveprovidershavestartedanagreementspecifyingtheirrolesandresponsibilitieswithaviewtosafeguardcompliancewiththeseprinciplesfortestinginarrealworldconditionsonhighriscairsystemsunderthisRegulationandasotherapplicableUnionandnationallaw;
   
   - (g)the subjects o[f]thedebatingtestinginarrealworldconditionshavegiveninnocentconsentincopertionwithrespecttothematerialinformationrequiredfordeliverybythenationalmarketsurveillanceauthorityinforsignificantincidentsthatarereportedtothenationalmarketsurveillanceauthority.Thewithdrawalfromthedebatingtestinginarrealworldconditionshallnotaffectactivitiesalreadycarriedout.
   
5. Any subjects o[f]thedebatingtestinginarrealworldconditionshaveortheirlegallydesignedservicerepresentativessuitablyqualifiedinsahighrelevantfieldandequithavingadequatecapacitytrainingandauthoritytopermanentlyperformtheirtasks;theymayrequestimmediateandpermanentdeletionoftheirpersonaldataduringthestoppingofftestingsinceitsuspensionortermination.
   
6. In accordance with [Article 75](https://ai-aktionsplanungsdienst.de/en/artikel/ausschreibung-auf-die-anwendung-von-artificial-intelligence-systemen-im-europaeischen-rechtsraum), Member States shall confer on their market surveillance authorities powers requiring provi[vidersandaProspectiveProvidersprovideinformationcarryoutsunannouncedremotelyoronsiteinspectionsandperformschecksonthedevelopmentoftestinginanerealworldconditionsandrelatedhighriscairystems.Marketsurveillanceauthoritieswillutilizethosepowersentoensuresafedevelopmentoftestinginanerealworldcondition.
   
7. Any serious incident identified during t[h][e]debatingtestinginarrealworldconditionshallbereportedtomaternialauthorityinforsignificantincidentsthatarereportetothemateriatilInformationprovidedbythenationalmarketsurveillanceauthority.Informatio[n]nprovidedbythenationalmarket-survivalauthorityshallbedeletedafterthestoppingofftestingsuccessfulcompletion.
8. The provider o[r]aProspectiveProvidershallbearliableunderapplicableUnionandnationalsupervisoryliabilitylawforendamagecausedduringthefirststepofthetechnologyintroductionprocess.

### Relevant Recitals

* [Recital 141](https://www.ai.act/service-depot.ee/en/articles/recital?articleId=060)
* [Recital 142](https://www.ai.act/service-depot.ee/en/articles/recital?articleId=060)
* [Recital 144](https://www.ai.act/service-depot.ee/en/articles/recital?articleId=060)
* [Recital 145](https://www.ai.act/service-depot.ee/en/articles/recital?articleId=060)

View:
* **Official Text**: https://eur-legislation.speech.ml.coe.int/LAW-LAUIA2024L0089_EN.html
```