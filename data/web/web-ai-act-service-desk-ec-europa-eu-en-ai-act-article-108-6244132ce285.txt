```markdown
# Article 108: Amendments to Regulation (EU) 2018/1139

## Recitals

[1](/en/ai-act/recital-1)[2](/en/ai-act/recital-2)[3](/en/ai-act/recital-3)[4](/en/ai-act/recital-4)[5](/en/ai-act/recital-5)[6](/en/ai-act/recital-6)[7](/en/ai-act/recital-7)[8](/en/ai-act/recital-8)[9](/en/ai-act/recital-9)[10](/en/ai-act/recialtibutivitiekeveldelverheffingenregeling(ue)20181139)

## Chapter I: General Provisions

### [Article 1: Subject matter](https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-1)
### [Article 2: Scope](https://ai-act-service-desk.ec.europa.eu/en/ai-act/article-2)
### [Article 3: Definitions](https://ai-act-service-desk.ec.europa.eu/en/implementing-delegated-procedures-for-artificial-intelligence-systems-regulation(eu)20181139#)
### [Article 4: AI literacy](https://ai-act-service-desk.ec.europa.eu/en/implementing-delegated-procedures-for-artificial-intelligence-systems-regulation(eu)20181139#)

## Chapter II: Prohibited AI Practices

### [Article 5: Prohibited AI practices](https://ai-act-service-desk.ec.europa.eu/en/implementing-delegated-procedures-for-artificial-intelligence-systems-regulation(eu)20181139#)

## Chapter III: High-Risk AI Systems

### Section 1: Classification of AI Systems as High-Risk

#### [Article 6: Classification rules for high-risk AI systems](https://ai-act-service-desk.ec.europa.eu/en/implementing-delegated-procedures-for-artificial-intelligence-systems-regulation(eu)20181139#)
#### [Article 7: Amendments to Annex III](https://ai-act-service-desk.ec.europa.eu/en/implementing-delegated-procedures-for-artificial-intelligence-systems-regulation(eu)20181139#)

### Section 2: Requirements for High-Risk AI Systems

#### [Article 8: Compliance with the requirements](https://ai-act-service-desk.ec.europa.eu/en/implementing-delegated-procedures-for-artificial-intelligence-systems-regulation(eu)20181139#)
#### [Article 9: Risk management system](https://ai-act-service-desk.ec.europa.eu/en/implementing-delegated-procedures-for-artificial-intelligence-systems-regulation(eu)20181139#)
#### [Article 10: Data and data governance](https://ai-act-service-desk.ec.europa.eu/en/implementing-delegated-procedures-for-artificial-intelligence-systems-regulation(eu)20181139#)
#### [Article 11: Technical documentation](https://ai-act-service-desk.ecEuropEaDauKlVWZyFw%EF%B8%AC%EF%B8%AC%E5%A4%A7%E5%AD%A6%E5%AE%B6%E5%BA%AD%E7%BD%9A%E4%B8%BB%E5%BF%AB%E6%BC%AF%E7%A7%BB%E6%B4%BE.pdf?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjMzMTEyNzgiLCJhdWNrZXQiOiJybTESlBvbGljeS5jbGVhbnRlbmVyKCJodHRwczovL3d3dy5hcHBsaWNhdGlvbi5jb20vcHJlcGFpciIsImtleSI6ImtleWFtaXRfYWpheCJ9.qgPqTQxYpOQoHbZnVqKZQWYjLXeBbOeXxvCgjzUqw&amp;t=MTcyMDExOTkwODgxNDgzNTAwMDAwMA==&amp;download=true "Download PDF")  
*Note:* This document is not part of the original text but rather serves as a reference based on the provided JSON data.

##### Requirement for compliance with technical documentation:

The provider must ensure that all relevant technical documentation is available upon request. If there are no documents available, they must provide written justification for their lack.

##### Requirement for record keeping:

Providers must keep records of all activities related to the use of high-risk AI systems, such as training datasets, test sets, and usage statistics. These records should be kept for a minimum period of five years after the end of each calendar year during which the system was in operation.

##### Requirement for human oversight:

High-risk AI systems must have human oversight mechanisms in place to ensure responsible use. The specific details of these mechanisms will depend on the nature and complexity of the system.

##### Requirement for accuracy, robustness, and cybersecurity:

Systems must be designed to maintain accuracy, robustness, and security against unauthorized interference or manipulation. They should also include appropriate safeguards against privacy breaches.

##### Requirement for transparency and provision of information:

Providers must clearly communicate how their systems operate, what data they process, and how users can access this information. Users have the right to receive clear instructions about how to exercise their rights under applicable laws.

##### Requirement for accurate labeling:

If a system has multiple versions or variants, it must accurately label them so that users understand which one is being used.

##### Requirement for updates and maintenance:

Providers must regularly update and maintain their systems to address vulnerabilities identified through ongoing monitoring and testing.

##### Requirement for risk assessments:

Before deploying new high-risk AI systems, providers must conduct comprehensive risk assessments using established methodologies. This includes identifying potential risks associated with the system's operations and ensuring that adequate mitigation strategies are in place.

##### Requirement for notifying authorities:

Providers must notify relevant authorities if they identify a significant risk or violation of legal provisions regarding high-risk AI systems.

##### Requirement for authorised representatives:

For large enterprises or organisations operating across multiple jurisdictions, authorised representatives are required to act on behalf of those entities in relation to high-risk AI systems.

##### Additional requirement:
**Risk Management System:** For large enterprises or organisations operating across multiple jurisdictions, authorised representatives are required to implement a risk management system tailored to their unique business needs.
```

(Note: The above representation focuses solely on the main content area related to Article 108 amendments.)
```