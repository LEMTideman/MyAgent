{
  "doc_id": "web-ai-act-service-desk-ec-europa-eu-en-ai-act-recital-4-12ce6b28b534",
  "source_type": "web",
  "source": "https://ai-act-service-desk.ec.europa.eu/en/ai-act/recital-4",
  "title": "Recital 4 | AI Act Service Desk",
  "text": "```markdown\n# Recital 4\n\nAI is a fast-evolving family of technologies that contributes to a wide array of economic, environmental, and societal benefits across the entire spectrum of industries and social activities. By improving prediction, optimizing operations and resource allocation, and personalizing digital solutions available for individuals and organizations, the use of AI can provide key competitive advantages to undertakings and support socially and environmentally beneficial outcomes, for example in healthcare, agriculture, food safety, education and training, media, sports, culture, infrastructure management, energy, transport and logistics, public services, security, justice, resource and energy efficiency, environmental monitoring, the conservation and restoration of biodiversity and ecosystems, and climate change mitigation and adaptation.\n\nView the [official text](https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=OJ:L_202401689). The text used in this tool is the ‘[Artificial Intelligence Act (Regulation (EU) 2024/1689), Official version of 13 June 2024](https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=OJ:L_202401689)’.\n\n---\n\n## Chapter I: General Provisions\n\n### Article 1: Subject Matter\n- [Article 1: Subject matter](/en/ai-act/article-1)\n\n### Article 2: Scope\n- [Article 2: Scope](/en/ai-act/article-2)\n\n### Article 3: Definitions\n- [Article 3: Definitions](/en/ai-act/article-3)\n\n### Article 4: AI Literacy\n- [Article 4: AI Literacy](/en/ai-act/article-4)\n\n## Chapter II: Prohibited AI Practices\n\n### Article 5: Prohibited AI Practices\n- [Article 5: Prohibited AI Practices](/en/ai-act/article-5)\n\n## Chapter III: High-Risk AI Systems\n\n### Section 1: Classification of AI Systems as High-Risk\n\n#### Article 6: Classification Rules for High-Risk AI Systems\n- [Article 6: Classification Rules for High-Risk AI Systems](/en/ai-act/article-6)\n- [Article 7: Amendments to Annex III](/en/ai-act/article-7)\n\n#### Section 2: Requirements for High-Risk AI Systems\n\n##### Article 8: Compliance with the Requirements\n- [Article 8: Compliance with the Requirements](/en/ai-act/article-8)\n##### Article 9: Risk Management System\n- [Article 9: Risk Management System](/en/ai-act/article-9)\n##### Article 10: Data and Data Governance\n- [Article 10: Data and Data Governance](/en/ai-act/article-10)\n##### Article 11: Technical Documentation\n- [Article 11: Technical Documentation](/en/ai-act/article-11)\n##### Article 12: Record Keeping\n- [Article 12: Record Keeping](/en/ai-act/article-12)\n##### Article 13: Transparency and Provision of Information to Deployers\n - [Article 13: Transparency and Provision of Information to Deployers]( /en/ai-act/article--transparency-information-deployers \"Transparency\")\n##### Article 14 Human Oversight \n   - [Human Oversight]( /en/human-overwatch \"Human Overlook\")\n##### Article 15 Accuracy Robustness & Cybersecurity \n   - [Accuracy Robustness & Cybersecurity]( /accuracy \"Accuracy\")\n\n#### Section 3：Obligations of Providers and Deployers of High-Risk AI Systems and Other Parties\n\n##### Article 16：Obligations of Providers of High-Risk AI Systems\n   - [Providers of High-Risk AI Systems]( /providers-high-risk-systems \"Providers\")\n   - **Subsections**\n     - **Section A:** Obligations under Articles:\n       - **Article**: \\[Link\\]\n       - **Paragraph**: \\[Number\\]\n     - **Section B:** Additional Obligations:\n       - **Article**: \\[Link\\]\n       - **Paragraph**: \\[Number\\]\n\n##### Article 17 Quality Management System  \n   - [Quality Management System]( /quality-management-system \"Quality Management System\")\n\n##### Article 18 Document Keeping  \n   - [Document Keeping]( /document-knowledge-management \"Document Knowledge Management\")\n\n##### Article 19 Automatically Generated Logs  \n   - [Automatically Generated Logs]( /automatically-generated-log-files \"Automatically Generated Logs\")\n\n##### Article **20:** Corrective Actions & Duty of Information  \n   - \\[Link\\]\n\n##### Article **21:** Cooperation with Competent Authorities  \n   - \\[Link\\]\n\n##### Article **22:** Authorized Representatives of Providers of High-Risk AI Systems  \n   - \\[Link\\]\n\n##### Article **23:** Obligations of Importers  \n   - \\[Link\\]\n\n##### Article **24:** Obligations of Distributors  \n   - \\[Link\\]\n\n##### Section A. OBLIGATIONS OF PROVIDERS AND DISTRIBUTORS IN PARTICULAR SITES OF THE VALUE CHAIN:\n\n###### ARTICLE **25:** RESPONSIBILITIES ALONG THE AI VALUE CHAIN  \n   - \\[Link\\]\n\n###### ARTICLE **26:** OBLIGATIONS OF DEPLOYERS OF HIGH-RISK AI SYSTEMS  \n   - \\[Link\\]\n\n###### ARTICLE **27:** FUNDAMENTAL RIGHTS IMPACT ASSESSMENT FOR HIGH-RISK AI SYSTEMS  \n   - \\[Link\\]\n\n#### Section **4:** NOTIFYING AUTHORITIES AND NOTIFIED BODY'S\n\n##### ARTICLE **28:** NOTIFICATION AUTHORITY’S  \n   – \\[Link\\]\n   \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n#### Section **5:** STANDARDS CONFORMITY ASSESSESMENT CERTIFICATES REGISTRATION\n\n###### ARTICLE **40:** HARMONISED STANDARDS AND STANDARDISATION DELIVERABLES  \n   – \\[Link\\]\n   \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n#### Section **6:** CODES OF PRACTICE\n\n###### ARTICLE **56:** CODES OF PRACTICE  \n   – \\[Link\\] \n\n## Chapter IV: Transparency Obligations for Providers and Deployers of Certain AI Systems\n\n### Section A. Classification Rules\n\n#### ARTICLE **50:** TRANSPARENCY OBLIGATIONS FOR PROVIDERS AND DEPLOYERS OF CERTAIN AI SYSTEMS WITHIN ANNEX III\n--- \n\\[Description here...\\]\n\n## Chapter V: General-Purpose AI Models\n\n### Section A. Classification Rules For General-Purpose AI Models With Systematic Risk\n\n#### ARTICLES \n* **ARTICLE 5. CLASSIFICATION RULES FOR GENERAL-PURPOSE AI MODELS WITH SYSTEMATIC RISK**\n    * **ARTICLE 5. CLASSIFICATION RULES FOR GENERAL-PURPOSE AI MODELS WITH SYSTEMATIC RISK**\n    * **ARTICLE**\n\n### Section B. Obligations for Providers Of General-Purpose Ai Models With Systematic Risk\n\n#### ARTICLES \n* **ARTICLE**\n* **ARTICLE**\n\n### Section C. Code Of Practice For General Purpose Ai Models With Systematic Risk\n\n#### ARTICLES \n* **ARTICLE**\n\n## Chapter VI : Measures In Support Of Innovation\n\n### Sections A To E.\n\n#### SECTION A. CLASSIFICATION RULES FOR GENERAL PURPOSE.AI MODELS WITH SYSTEMIC RISK\n\n* **SECTION A. CLASSIFICATION RULES FOR GENERAL PURPOSE.AI MODELS WITH SYSTEMIC RISK**\n* **SECTION**\n\n#### SECTION B. OBLIGATIONS FOR PROVIDERS OF GENERAL PURPOSE.AI MODELS WITH SYSTEMIC RISK\n\n* **SECTION B. OBLIGATIONS FOR PROVIDERS OF GENERAL PURPOSE.AI MODELS WITH SYSTEMIC RISK**\n* **SECTION**\n\n#### SECTION C. CODES OF PRACTICE FOR PROVIDER OR DEPLOYER OF GENERAL PURPOSE.AI MODEL WITH SYSTEMIC RISK\n\n* **SECTION C. CODES OF PRACTICE FOR PROVIDER OR DEPLOYER OF GENERAL PURPOSE.AI MODEL WITH SYSTEMIC RISK**\n* **SECTION**\n\n## Chapter VII : Governance At Union Level And National Competent Authorities\n\n### Sections A To D.\n\n#### SECTION A . GRIEVANCE OVER PROVISIONAL DECISIONS BY THE COMPETENT AUTHORITIES OR OTHER MATTERS RELATED TO THE IMPLEMENTATION OF THIS REGULATION AT UNION LEVEL.\n\n* **SECTION A . GRIEVANCE OVER PROVISIONAL DECISIONS BY THE COMPETENT AUTHORITIES OR OTHER MATTERS RELATED TO THE IMPLEMENTATION OF THIS REGULATION AT UNION LEVEL.\"\n* \"**SECTION\"\n\n#### SECTION B . NATIONAL COMPETENT AUTHORITIES.\n\n* **SECTION B . NATIONAL COMPETENT AUTHORITIES.\"\n* \"**SECTION\"\n\n## Chapter VIII : EU DATABASE FOR HIGH-RISK.aiSystems Listed In Annex III.\n\n### SECTION A .\n\n#### ARTICLES \n* **ARTICLE**\n* \"**ARTICLE\"\n```",
  "fetched_at_utc": "2026-02-10T08:19:01Z",
  "sha256": "12ce6b28b53417ae22bec35b52db1971e91791586b21996cd7d2a2dae1b6d736",
  "meta": {
    "jina_status": 20000,
    "jina_code": 200,
    "description": null,
    "links": null,
    "images": null,
    "usage": {
      "tokens": 12000
    }
  }
}