{
  "doc_id": "web-ai-act-service-desk-ec-europa-eu-en-ai-act-recital-91-28841abf7b9c",
  "source_type": "web",
  "source": "https://ai-act-service-desk.ec.europa.eu/en/ai-act/recital-91",
  "title": "Recital 91 | AI Act Service Desk",
  "text": "```markdown\n# Recital 91\n\n## Introduction\n\nGiven the nature of AI systems and the risks to safety and fundamental rights possibly associated with their use, including as regards the need to ensure proper monitoring of the performance of an AI system in a real-life setting, it is appropriate to set specific responsibilities for deployers. Deployers should in particular take appropriate technical and organisational measures to ensure they use high-risk AI systems in accordance with the instructions of use and certain other obligations should be provided for with regard to monitoring of the functioning of the AI systems and with regard to record-keeping, as appropriate. Furthermore, deployers should ensure that the persons assigned to implement the instructions for use and human oversight as set out in this Regulation have the necessary competence, in particular an adequate level of AI literacy, training and authority to properly fulfil those tasks. Those obligations should be without prejudice to other deployer obligations in relation to high-risk AI systems under Union or national law.\n\n### This Recital relates to\n\n*   [Article 14: Human oversight](/en/ai-act/article-14)\n*   [Article 26: Obligations of deployers of high-risk AI systems](/en/ai-act/article-26)\n\n---\n\n## Recital Text\n\n**Recital 91**\n\nGiven the nature of AI systems and the risks to safety and fundamental rights possibly associated with their use, including as regards the need to ensure proper monitoring of the performance of an AI system in a real-life setting, it is appropriate to set specific responsibilities for deployers. Deployers should in particular take appropriate technical and organisational measures to ensure they use high-risk AI systems in accordance with the instructions of use and certain other obligations should be provided for with regard to monitoring of the functioning of the AI systems and with regard to record-keeping, as appropriate. Furthermore, deployers should ensure that the persons assigned to implement the instructions for use and human oversight as set out in this Regulation have the necessary competence, in particular an adequate level of AI literacy, training and authority to properly fulfil those tasks. Those obligations should be without prejudice to other deployer obligations in relation to high-risk AI systems under Union or national law.\n\n---\n\n## Related Articles\n\n*   [Article 14: Human oversight](/en/ai-act/article-14)\n*   [Article 26: Obligations of deployers of high-risk AI systems](/en/ai-act/article-26)\n\n---\n\n## Legal Note\n\nView the [official text](https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=OJ:L_202401689). The text used in this tool is the ‘[Artificial Intelligence Act (Regulation (EU) 2024/1689), Official version of 13 June 2024](https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=OJ:L_202401689)’.\n\n---\n```",
  "fetched_at_utc": "2025-12-29T09:16:54Z",
  "sha256": "28841abf7b9cc38a8d6d5b6e1e453fabc156c2f101455934df3b96ff1e32d58b",
  "meta": {
    "jina_status": 20000,
    "jina_code": 200,
    "description": null,
    "links": null,
    "images": null,
    "usage": {
      "tokens": 12000
    }
  }
}