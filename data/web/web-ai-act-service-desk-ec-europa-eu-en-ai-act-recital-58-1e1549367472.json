{
  "doc_id": "web-ai-act-service-desk-ec-europa-eu-en-ai-act-recital-58-1e1549367472",
  "source_type": "web",
  "source": "https://ai-act-service-desk.ec.europa.eu/en/ai-act/recital-58",
  "title": "Recital 58 | AI Act Service Desk",
  "text": "```markdown\n# Recital 58\n\n## Another Area in Which the Use of AI Systems Deserves Special Consideration\n\nThe use of AI systems in accessing and enjoying essential private and public services and benefits necessary for people to fully participate in society or to improve their standard of living requires special attention. Natural persons applying for or receiving essential public assistance benefits and services from public authorities, such as healthcare services, social security benefits, social services providing protection in cases like maternity, illness, industrial accidents, dependency, or old age and loss of employment, are typically dependent on these benefits and services and face vulnerabilities related to the responsible authorities. If AI systems are used for determining whether such benefits and services should be granted, denied, reduced, revoked, or reclaimed by authorities, including whether beneficiaries are rightfully entitled to them, these systems may have a significant impact on individuals' livelihoods and could infringe their fundamental rights such as the right to social protection, non-discrimination, human dignity, or an effective remedy. This Regulation should not hinder the development and use of innovative approaches in the public administration unless they do not pose a high risk to legal and natural persons. Additionally, AI systems intended for evaluating credit scores or creditworthiness of natural persons should also be classified as high-risk AI systems due to potential discrimination against individuals or groups based on race, ethnicity, gender, disability status, age, or sexual orientation. These systems can perpetuate historical patterns of discrimination while creating new forms of discriminatory impacts. While some AI systems used for risk assessment and pricing in relation to natural persons for health and life insurance fall within this category but do not constitute high-risk under this Regulation due to their limited impact on individuals' lives and finances. Furthermore, AI systems aimed at evaluating and classifying emergency calls by natural persons or dispatching emergency first response services should also be classified as high-risk because they make critical decisions regarding the safety and welfare of individuals without adequate safeguards against bias or discrimination.\n\n### Related Article\n\n[Article 6: Classification rules for high-risk AI systems](/en/ai-act/article-6)\n\n---\n\nView the [official text](https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=OJ:L_202401689). The text used in this tool is the 'Artificial Intelligence Act (Regulation (EU) 2024/1689), Official version of 13 June 2024'.\n\n---\n```\n\n(Note: The refined markdown focuses strictly on the core content extracted from the original HTML document's \"Recital 58\" section.)\n```",
  "fetched_at_utc": "2025-12-29T09:04:49Z",
  "sha256": "1e1549367472c48b880369f6bdbd9181b513300198dfb7e20e8c7c3df38affc0",
  "meta": {
    "jina_status": 20000,
    "jina_code": 200,
    "description": null,
    "links": null,
    "images": null,
    "usage": {
      "tokens": 12000
    }
  }
}