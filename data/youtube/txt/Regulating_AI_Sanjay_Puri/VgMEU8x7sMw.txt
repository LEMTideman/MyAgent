We've already seen the impact, the
negative impact of AI on the civil
rights of individuals, right? We've
heard about individuals being denied
access to housing or, you know, even
getting financing to buy a house because
of automated systems. They've been
denied health insurance claims. The
challenge with automated systems is that
we don't always know when we're being
harmed or impacted by that, right? If
you apply to a job and you get a
rejection letter at 3:00 a.m. in your
email inbox, you know, it's really hard
to tell if that rejection was because of
something that some system saw on your
resume. You know, it could be a sort of
protected class aspect and it made a
decision based off that. And so
therefore, it's violative of civil
rights laws. It's a road map. And if you
read it carefully, you see that a lot of
the points raised are very sort of broad
in general. You know, take one example
of like liability, like who's liable, a
developer or deployer? And the language
in the road map says, well, you know,
committee should think through whether
or not additional standards are created.
Welcome to the regulating AI podcast.
Join host Sanjay Pury as he explores the
dynamic and developing world of
artificial intelligence governance. Each
episode features deep dives with global
leaders at the forefront of regulating
AI responsibly, tackling the challenges
using AI can bring about head-on and
enabling balance without hindering
[Music]
innovation. Welcome to regulating AI,
the podcast where we delve into the
complex landscape of AI regulation,
seeking to ensure that the future of AI
is fair, transparent, and responsible.
I'm your host Sanjay Puri and today we
have a distinguished guest who's at the
forefront of shaping AI policy to center
civil rights as a core issue. Joining us
is Koshub KJ Bakchi the vice president
of the center for civil rights and
technology at the leadership conference
on civil and human rights. The
leadership conference has a rich history
dating back to its founding in 1950.
Rooted in the commitment to social
justice and the power of coalition
building, KJ brings a wealth of
experience and insight into the
conversation around AI regulation,
advocating for policies that prioritize
civil rights in the face of rapid
technological advancement. We are all
thrilled to have him here today to share
his expertise and perspectives. KJ,
thank you so much for joining the
regulating AI podcast. Yeah, thank you
for having me, Sanjay. Wonderful. KJ, to
our global listeners, can you provide
them with an overview for the center for
civil rights and technology and its
mission? Yeah, absolutely. So, the
leadership conference on civil and human
rights, as you referenced, was founded
in the 1950s. This was the the same time
that Dr. Martin Luther King and his
allies were marching on Washington. And
during the same time, the leadership
conference on civil and human rights was
formed to focus on the legislative part
of implementing and enforcing civil
rights protections. And so that started
with the voting rights act uh and then
continued on through the other sort of
major pieces of legislation we've seen
as it impacts civil rights, you know, in
the US mainly. And so with the sort of
progression of the intersections of
where civil rights conversations are
going right now, whether it's housing,
access to education, access to credit,
financial services, even decisions
around healthcare, all of it is having
some sort of intersection with automated
systems or AI. And so last I want to say
September, last September 2023, the
center was formally launched and
announced. And then I I took on the role
in late October as vice president to
sort of continue the the media and
technology work that the leadership
conference was always undertaking, but
to really build out a full-on center,
the first of its kind for a legacy civil
rights organization to really attack the
sort of and to be engaged in the issues
around AI and civil rights, you know,
from a holistic standpoint. And so we've
been building up our team. We've been
engaging on issues beyond just the sort
of what we're seeing in the the
headlines and and really trying to make
sure that civil rights and any sort of
protections and guardrails are in place
when we talk about AI governance. Well,
that's fantastic. It's a one-of-a-kind
organization as you said KJ. U KJ as you
said uh talked about the guard rails.
What do you think are the most pressing
civil rights issues concerning the rapid
uh advancement of AI technologies? I
think, you know, it's important to
remind your listeners that we've already
seen the impact, the negative impact of
AI on the civil rights of individuals,
right? We've heard about individuals
being denied access to housing or, you
know, even getting financing to buy a
house because of automated systems.
They've been denied health insurance
claims. Um and we've also seen in the
criminal justice system that though that
facial recognition technology another AI
powered tool has been the sort of basis
for individually individuals being
wrongfully arrested. So, you know, it's
important to point out that look, the
conversation around generative AI last
year really kind of infused everything,
everyone to focus on AI as if it's this
new thing. But the truth is it's been
around and automated systems have been
around for quite some time to the the
impact of even making humanlike
decisions, right? Which is our sort of
thinking of AI is more than just a
simple sort of machine learning, but are
you making humanlike decisions that
impact individuals lives? So, this has
already been happening for quite some
time. And so for us it is critical when
we think about these systems you know we
look at it in sort of different parts
right the first is when you're actually
developing the system the product the
tool the second is when you actually
deploy it and the third is based on
those results what are you actually
doing with the system so doing impact
assessments really making sure that the
data you're using to power and develop
these systems are actually coming from
legally obtained you know folks have
given consent and so on. Ensuring that's
part of that process. Being clear about
what's the purpose of this system and
are you actually developing something
that's meeting that that goal and then
once it's deployed ensuring that there's
monitoring and transparency and
understanding okay like this is the
decision that it's making. This is the
impact it's having. And finally that
third part what do you do once you've
determined what has actually been done.
So, if you find out that this system is
actually coming out with discriminatory,
you know, results for people of color,
for let's say African-Americans or, you
know, Asians, are you keeping the system
on the market? Are you using the tool
still or are you completely taking
offline reassessing and bringing it back
into, you know, we say the word
compliance, but there really isn't a
strong set of sort of AI governance
tools yet uh to follow. But like the the
idea there is again that's how we're
thinking about sort of how do you think
through protecting individuals from
negative impacts. There's a whole list
of principles I could point you to as
well. We've uh you know in our coalition
entry points we have a number of
coalition groups that we work with. Um
we've listed out a number of principles
fairness accountability transparency.
But the basic point, the fundamental
point that we're really pushing is that
no system should be used as a basis for
a discriminatory result. Wow. So that's
a pretty big charter that you have KJ.
You're talking about right from the
beginning of building these foundation
models to complete implementation and
use. So just for my understanding and
our listeners are you engaged at all uh
parts of the distribution of information
whether it is when the foundation let's
just talk about how they train the data
the foundation models uh a lot of people
have issues with how the data is being
trained whether it's issues of privacy
bias etc. talk to our listeners. Are you
engaged or are there concerns you have
regarding how the data is being trained
right now? Oh, absolutely. Yeah. I mean,
the the joke I make and I made this this
joke on the panel I referenced I was
telling you about offline, the impact
panel last week. You know, to me AI is
really privacy and more fancy clothing,
right? I think the idea of these
systems, they're all powered by data.
and the conversations we were having in
like 2018 2019 uh and even now we're
sort of seeing another resurgence of a
comprehensive privacy bill going through
Congress we were you know in before I
even joined the leadership conference I
was working for another civil rights
organization on tech issues this is the
basis of like what our conversations
were about right this is we were
definitely thinking through how is data
obtained do folks have the ability to
understand when they're interacting with
a any kind of product or tool that the
tool is sucking up its, you know, this
personal data and this is how it's going
to be used and do you have the ability,
do you have the right to have that
information deleted? Do you have the
right to transparency knowing how long
that data will actually be stored on
you? So yeah again yes 100% we've been
you know involved in those conversations
and I should point out that look the
center was launched you know in
September but as I referenced it's
continuing the work that the leadership
conference did and tech space so while
AI is on everyone's mind right now we
work on other tech policy issues right
we work on privacy we work on broadband
access we work on platform
accountability so you know kind of
bringing us to the frame of AI and how
data is collected absolutely we
definitely been involved in those
conversations and you know I think I
join a lot of my civil society friends
in arguing that we can talk about AI
governance all we want but until we have
a strong foundation for how data should
be collected the governance it will be
important but you know it topples right
if you don't have a strong foundation
something topples over and so I think
that is going to be a critical
conversation for those of us in the
policy fight to have as well so KJ when
you're talking to you know the handful
of companies that have large foundation
models, how receptive uh do you find
them towards what you're I mean being
receptive but how engaged are they in
addressing some of the things that you
talked about? Yeah, you know, this is a
question we get get quite a bit, right?
Because as a civil rights organization,
especially in the tech space, you know,
a lot of companies see us as sort of the
the one-stop shop. It's not just the
leadership conference staff, but you
know, we have a coalition of 240
organizations that maybe focus on a
constituency that that company's really
trying to reach, right? We have we have
organizations that focus on the Spanish
speaking communities, on the a, you
know, AAPI community, uh, the
African-American community, as well as,
you know, people with disabilities and
so on. So, for us, we engage a lot with
companies. And I do want to point out
that it's not only the sort of big tech
companies that are chatting with us and
saying this is how we're thinking about
AI governance internally. It is also the
sort of the ride sharing companies, the
home sharing companies. You have the
smaller AI companies that are you know
coming you know I'm trying not to blow
anyone's spot up because a lot of these
conversations are under NDA and and
private but again we are talking to
folks across the board from big tech
smaller entry points and look everyone's
receptive. I think the challenge, and we
may talk about this later, the challenge
is these are all companies, right? At
the end of the day, they're all in the
private sector. They all have
shareholders and they have board members
to sort of respond to. And so, while
good governance is something that is a
value that all these companies are
getting a lot of attention for now,
right? Like are they following good
these these values around civil rights
and just generally around making sure
that if a decision is made that could
impact someone's life? are these
companies thinking through how to avoid
that? They're all receptive. I think the
implementation, the execution part is
always where we see mixed results. And
again, I think that is that the tension
between wanting to do the right thing
because you know your users will benefit
from this. But at the same time, you
know, let's take the example of data
collection. We know there was a point
maybe not now, right? But Cambridge
Analytica and all this happened in 20 20
uh the 2016 election, right? We know
that the data practices there, the data
broker practices there that that you
know Facebook before it became meta was
involved with was created all this
harmful impact on our democracy, right?
Creating disinformation, disinformation
and so on. So there's a shift in company
culture based on what the feedback is.
We definitely have been involved in more
conversations and I would say you know
when I joined this space in 2017
um but I do think that again what
execution looks like is critical and I
do think that's where legislation is
going to be the final purveyor of of
what the results look like. It's not you
know companies can have good intent but
if you don't have congressional you know
passed bills that's going to be an
issue. I will quickly point out that the
AI executive order that came out um in
October of last year because it impacts
vendors that that are doing business
with government there will we are
starting to see some impact there right
there are procurement guidelines that
are that are kind of coming into play so
again do companies want to do the right
thing I'm not you know there are folks
in our space that are very critical of
of companies intentions and so on prior
to coming to leadership conference I was
at a tech industry trade association so
I know the folks that are involved in
these big tech companies individually
personally and everyone wants to do the
right thing at that level but do I think
governance creates guard rails and you
know it doesn't matter about intention
at that point now you are doing the
right thing because it is ingrained in
law so the executive order has been a
major shift in the conversation what
companies have to do but as we all know
executive orders don't impact private
sector you know doesn't impact private
sector as a whole and it only you how
many companies are actually playing with
the federal government, right? It's
probably the big tech companies that we
already know about. So again, impact is
going to be important. So KJ, uh since
you talked about uh the executive order
and the legislation, uh the EU has
passed the EU AI act and we uh have had
over 200 bills that have gone through uh
US Congress as you know very well. And
then uh Senator Schumer, the majority
leader, has had many of these listening
sessions. I'm sure you've been part of
some of them. Uh but then recently he
came out with something saying we need
$32 billion. And that looks like
basically it. Uh maybe there's going to
be some bills uh that Senator
Clolobashar might come out regarding
election interference, etc. What are
what are your thoughts on uh where we
are at right now? Yeah, I think that's a
really good question and I think
especially given the fact that your
audience right is is sort of sitting in
a global perspective. Yep. The biggest
thing that I remind folks whether I'm on
panels or speaking you know casually
among friends is that you know the EU
system and the even the culture and the
thought process around privacy as again
we talked about the foundation of all
these things that we're we're mentioning
today the the conversation around
privacy just as a cultural value in
Europe like I'm not a historian but I
would argue that it is is a value it is
it is held to a higher standard right
what is my privacy an individual. And so
I think what you saw with
GDPR and that sort of movement was a
critical part of that culture connecting
to the legislative process there. And I
do think that again EU AI act I do think
Europe moves faster on some of these you
know technological sort of system
governing technological systems and the
US does. I think the challenge for the
US on the you know US legislative side
is that there the same culture does not
exist. I think the conversations around
AI governance or privacy, anything in
the tech policy space quickly devolves
into innovation versus equity. And you
know, I think you're seeing Senator
Schumer and the Senate generally trying
to be like, all right, fine. We're going
to we're going to slow feed, you know,
the public a sort of AI framework. We're
going to call it a road map. We're not
going to call it legislation. It's a
road map. And if you read it carefully,
you see that a lot of the points raised
are very sort of broad in general. You
know, take one example of like
liability, like who's liable, a
developer or deployer. And the language
in the road map says, well, you know,
committee should think through whether
or not additional standards are created.
And so because you have this sort of
slow feeding the public overall AI
governance, you see the committees
taking a sort of peacemeal approach,
right? So Clolobachar's, you know, three
voting rights bills that that made it
through markup, you know, are a good
example of that, right? It's it's a it's
it's leaving it through. I'm not, you
know, it's leaving it to our American
legislative process, but the politics of
are you pro- industry or are you
anti-industry u and I see that clearly
being someone who came from the civil
rights space but spent some time in the
private sector working with these
companies directly as a trade
association government affairs you know
sort of professional and then coming
back to the civil rights part of the
conversation I've seen that the divide
is vast and I think the challenge here
is people are are looking at anything
coming out of Congress and that gets a
sort of a target on its back. So the AI
roadmap, I think it's important to
remind your listeners that it's not
legislation at all, right? There's no
mandate. It's literally trying to take
those AI for conversations and trying to
put it into something in a bipartisan
basis. And so, you know, a lot of us
were not surprised that the focus was
well, let's think about government
investment and that $32 billion that you
quoted is what came up. But then
conversations around governance were
sort of put in the back burner. And
that's why you see a lot of folks
including you know our organization came
out critically saying look there's
nothing in this road map talking about
prevention of harms. There's nothing
talking about mitigation of harm.
There's nothing talking about like what
is a remedy once harm has occurred. What
is a private right of action mean for an
individual who's been harmed by one of
these systems and wants to take action.
So again I would say that in terms of
the global race on governance I would
say the EU is you know way much much
more advanced terms of analyzing whether
I think the similar provisions would
work in a domestic sense you know I
think that I'll leave that to the
experts to kind of do that comparative
basis but for me as someone who's worked
in you know the sort of policy space for
you know over a decade now in in the US
I think our politics around
tech policy governance is just always
going to have a difficult
tricky you know kind of status and
that's why it's important for all of us
in the ecosystem those of us in the
civil rights space those of in the sort
of tech rights space to continue to push
on these these principles
uh KJ uh you made some fantastic
points do you think if you look at what
Senator Schumer Senator Rounds and
Senator Young and Senator Martin from
New Mexico kind of have also changed the
paradigm a little bit. You talked about
innovation versus equity. I have a
feeling it's now becoming national
security versus equity also. Uh so I
want you to tell our listeners what that
means because they talked about you know
where China is and really we we just
can't everything else needs to take kind
of a backseat versus what we are doing.
So a thought from a leader like you on
something of that nature. I think you're
right. I think that's exactly what is
happening. And you know to illustrate it
the panel I I keep referencing for your
listeners who are wondering what the
heck I'm talking about. I was on a panel
last week for an organization that
wanted to have a conversation around AI.
And the panel included myself and
someone else from civil society. Uh it
included someone from you know the sort
of the from the healthcare perspective
from Palunteer and then it had someone
from the national security side. And it
was fascinating because the conversation
the individual from the national
security side was having versus what I
was saying were very different. Right? I
think from national security side
there's a sort of a sense of urgency and
a sense of we need to get this out now.
You can't stifle and you cannot stifle
the building of these systems. You can't
keep trip. His exact words were you know
we can't keep tripping over the idea of
risk risk risk risk. And from the civil
rights side that's exactly what we're
saying. we're saying all this has
gigantic risk when it comes to the
impact it can have on individuals. Um
and so I think look the challenge is you
are right I I agree entirely that you
have this sort of these three kind of
points that are living out by themselves
right national security equity and
innovation and I think you know the
argument that we've continued to push is
that it's not innovative if it is not
equitable it's not again you're not
building security if again domestically
you have people who are not getting jobs
or access to housing if you are
wrongfully arresting people because the
systems that we've pushed through
because of lack of governance are able
to live, you know, freely. So, I think
it is it is challenging. I'm not going
to I'm not going to come to you with a
perfect answer. I think it's challenging
to kind of bring together those three
disperate points because I do think
there's there are valid arguments for
why we should be pushing on one side
over the other. Obviously, I would say
that it is overall better for a
company's bottom line to be protective
of the users that it's selling its
products to. And I think it is again we
can think about a global perspective and
about national security and talk about
the threat that countries like China
pose in the sort of AI development. But
again, look at and you know the from a
comparative standpoint, look at the
government structure. look at the
governance structure of a country like
China versus the US, right? As a
democracy and as a civil rights
organization, it is imperative for us to
argue for the safeguarding of democracy
as we develop these tools. And so, you
know, we'll probably talk about a little
later, but AI and voting is significant
to that. And so while I can understand
what my colleagues who are kind of
coming at from different perspectives
say for us if you are it's not just
about like making sure that users aren't
getting impacted in a negative way. It's
about the whole system of democracy that
is could be undermined right without
like having these tools like developed
in a way that is protective of everyone.
Um KJ I've had uh a lot of members of
Congress and Senate come on the show and
a lot of them make the argument and I
want you to react to this is when I
bring up this issue that Sanjay we have
a lot of protections already in place
they said the equal employment
opportunity commission the DOJ uh the
FDA you the housing authority etc. Uh
it's not like we don't have protections.
If there there maybe there are some gaps
but we already have a lot of laws and
protections in place to do this. KJ, how
do you react to a lot of uh members of
Congress who come on the show and have
made this point? Well, I would I would
first agree with them that existing laws
should definitely apply to AI systems
and and any sort of it shouldn't matter
where the harm is originating from like
that. You know, if there's if we need
to, you know, uphold those protections,
we need to uphold those protections. The
challenge is this, right? And this is
where I get to even though I went to law
school. I my joke is like I you know I'm
not a real lawyer. I just play one on TV
like you know I went to law school got
my license and all that but I never
practiced traditionally. But you know
the the difference between and I guess
before I even jump into trying to you
know play a lawyer on TV. I'll just do a
quick history sort of you know reminder
for folks. When it comes to something
like the Fair Housing Act, there was a
time where you would have essentially
testers go to an apartment complex,
right? Someone who' be an
African-American person, they would go
and ask for a, you know, a lease, a
12-month lease, and the landlord would
the, you know, the management office or
landlord would deny it and say, "Oh, you
know, we already have somewhere. We're
good." And then you'd have another sort
of tester from, you know, our as a
government, you know, agent come a
person, a white person come to the same
landlord management office and ask for a
12-month lease and they would get it
accepted and then they would build a
case over time. And, you know, that's
how the enforcement of that law came
into, you know, would come into being.
The challenge with automated systems is
that we don't always know when we're
being harmed or impacted by that, right?
If you apply to a job and you get a
rejection letter at 3:00 a.m. in your
email inbox, you don't know, you know,
it's really hard to tell if that
rejection was because of something that
some system saw on your resume that, you
know, could be could be potentially, you
know, could be a sort of protected class
aspect and it made a decision based off
that and so therefore it's violative of
civil rights laws. Um, this example
comes a lot with access to benefits,
right? Right. They used to live in New
Jersey has been trying to figure out
they're having a lot of people in the
state come and say, "Hey, we're not
getting access to our benefits." And
it's these automated systems that we
know automated systems are behind the
process of determining who gets
benefits. We aren't getting them. We
should be, but we're not able to kind of
clearly connect the dots. So, the
argument here is that we try to raise is
like, look, we understand existing laws
are important and we want to uphold
those. The EEOC came out with guidance
saying that title 7 of the civil rights
act would still be enforced whether it's
a tech system. You know, HUD came out
with guidance saying the Fair Housing
Act still applies to tech, you know,
tech based systems. But when we're
talking about AI governance, we're
talking about before the system is even
deployed. And we're talking about when
you are actually deploying, how are you
actually testing the system for
discriminatory impact? So, it's a
little, you know, I I don't I think it's
a little bit of a sort of mislead to say
it's either or, right? like, oh, it's
either the existing civil rights laws or
this is where we're at. Again, these
laws, a lot of these laws were passed in
the 60s, you know, some of them in the
70s. Like, do could we have imagined
could th the people who passed those
laws even have imagined that we'd be so
ingrained with technology in our
systems? I don't think they could have.
And so it's important for us just like
we update our you know any sort of
regulations around cars for example
vehicles on the road going from horse
and buggy to you know having you know
engines to requiring seat belts now we
have automated vehicles on the road like
you're going to need the ability to
update regulations and so the
conversation we're having is really
about updating existing protections to
make them more sort of applicable and
not about saying let's ignore the old
laws. No, that makes a lot of sense. Um,
so u you know how do we make sure that
civil society organizations
uh like yours um I mean do you think
they have a role to play in shaping AI
regulations and policies KJ? Yeah,
absolutely. And I think we have been
part of those those conversations.
Again, um you know, we have like our
coalition is
240 or you know groups overall. Not
every group is focused on tech and
telecom, but we do have a you know a
media telecom task force that has a
number of those coalition members
sitting on that. We have a civil rights
table that has a number of coalition
organizations sitting on that. And then
we have tech policy organizations that
are not really part of our 240 coalition
group but they are in the tech policy
space and we work closely with them.
These are the folks who frankly have
more of the technical expertise
sometimes right they have technologists
who like work in the companies and are
now advising civil society on this. So
it's already happening. Uh it's it's
important for us to have that space and
I'll be honest like I do think you know
you are seeing much more receptivity
from Congress to to garner like
widespread feedback. We see that when
not only with when we're talking about
the roadmap uh but you know all the AI
bills you talked about many of those
bills those authors come and talk to our
our office about getting feedback on
where they can strengthen it and you
know when there are multiple hearings
happening as well on AI bills or even
national security and AI something that
we said maybe hard to connect the dots
we know that we've had conversations
with committee staff on how do they make
sure that they're representing the civil
society perspective there so I I
definitely think it's important to
continue that tradition
Um KJ U I asked this to members of
Congress and I'll after you give me your
answer I'll tell you what they say is
would do you advocate for uh independent
regulatory body for AI.
That's right. I asked this to every
member of Congress and Senate but I
won't tell you their answer till you
tell me yours. This is so this is going
to you know uh our our comms
professionals on the call so hopefully I
don't get in any trouble here. I know.
So, I will say that if you want. No,
it's like it's not it's not that
serious. I'm just just joking around.
Like I think
there's there are organizations that
have an official stance on this. I know
that we have partners who partner
organizations that are very gung-ho. We
need to create an independent agency to,
you know, stack it with with the experts
and all that. I would say my personal
experience of working in government and
policy is that it is very challenging to
stand up a new agency and to ensure that
it has consistent robust funding. Uh you
know we saw the Supreme Court decision
come out I believe this week or sorry
last week uh today's Monday come out
last week that essentially said that the
CFPB's funding structure is still
upheld. And so when that agency is an
example like illustrative example for me
how tough it is to maintain and you know
keep building existing structures
existing sort of branches of of
government. what we do support and I'm
the you know forgetting the the name of
the bill off the top of my head but it's
a Senator Marky bill that essentially
talks about making like stacking each
existing agency with technologists and
with a dedicated civil rights office
that focuses on the intersection of tech
and whatever that issue is. I think
that's a strong model of like of where
we should be thinking about. I think
look do I do I think conceptually is it
important to create a whole independent
body to really be focused with experts
and to have them come into I sure I
think conceptually it's a great idea but
even the AI executive you know order uh
when the OM memo was launched and I had
you know I was invited to speak at the
white house before these chief AI
officers I could see the sort of the
just the disperate agencies right the
different groups that they all represent
you have the agriculture in the room
with DOJ and you know health and human
is trying to then create like another
independent agency to then be part of
government as a whole but also be
focused on this critical area is is
challenging. So uh I don't think you get
an endorsement from from KJ Bachi to
create an independent body but I you
know I respect our our colleagues who
are really focusing on on kind of moving
that agenda forward. So I'll give you
the answer that I majority answer and it
was exactly what you said. They said in
this town firstly the bureaucracy and
getting people to agree on an agency as
you said they they've been fighting this
CFPB for what 10 How long has CFPB been
around man? 10 years at least. Yeah. So
think about it. So the answer from every
member of Congress even some who said it
was a good idea they said cannot happen.
Uh so that uh is definitely a issue. Now
you talked about uh maybe having each
agency having expertise and stuff. Now
didn't
OM make it mandatory to have the chief
AI officers but you're saying advocating
a separate civil rights office along
with that? What what I just for our
listeners can you clarify what you ask?
So this is like again like I I don't I
mean you are quoting me because I'm on
your podcast but I believe the the
proposal that came from the legislative
branch right from Congress was the bill
was essentially to have each agency have
a dedicated civil rights office that
would be focused on those issues as and
also to staff each of those agencies
with tech experts to focus on these
issues. I do think yes you're right the
the OM memo the AI executive order calls
on right appointing chief AI officers
which was huge and then on you know
creating inter agency working groups and
all that. I will just my one critique of
that of what we saw with the AI
executive order is that some agencies
appointed real experts to be their chief
AI officers, right? uh people who really
have the technical skills and understand
the intersection between their agency
and civil rights and we work with those
chief AI officers closely. But then you
also have agencies that have major
impacts on individuals that have large
budgets and their chief AI officer are
essentially folks who were kind of given
an additional responsibility, right?
They were the chief sort of financial
officer. They were they sort of more on
the operations side of the agency
because they had oversight over the
whole agency. The thinking was well,
let's just give you this let's task you
with this as well. I I think and it's
like they have to, right? the AI
executive order has a very short
timeline and you know maybe there isn't
enough time to bring in the experts to
really head up these efforts but again
creating the that's why the legisl
legislative approach to us is a little
more intriguing because it's saying
bring in real experts into this into
this effort. Um, and you know, look, it
goes without saying the thing with any
executive order is that if the political
winds change and we have someone else in
the White House, then that can sort of
dis, you know, dismantle some of the
changes that have already happened that
we're seeing under this administration.
And that's why again like taking that
legislative approach uh is something
where again we would really like stress
that. No, that's uh I think you made
some uh excellent points about the chief
AI officer. Um in terms of KJ, uh let's
talk about workforce. Um you know
there's uh KJ all kinds of uh statistics
thrown around McKenzie IMF 60% of the
workforce could get disrupted this that
uh we have a digital divide in our
country. Some people warn of an AI
divide and now with this massive
transformation that could be coming. Is
that something your organization is
looking at as to how AI could have you
know uh an impact on uh you know the
workforce on the diversity of the
workforce etc. Yeah, absolutely.
Absolutely. We we have a number of labor
organizations including the AFL CIO that
that's sit as part of our coalition. And
so when we talk about workforce and the
impact on the workforce with AI, we
definitely, you know, we're keeping them
in mind. And I'll also say that there
are organizations that are focused on
specific constituencies such as the
Asian community or the Latino community
that are getting investment from the
private sector to start thinking through
creating more AI literacy to help
develop the future workforce training.
So this is definitely something on our
mind. I think we think literacy is
really one step but I do think looking
at existing there are existing sort of
statutory frameworks that focus on
industries that are impacted right by
job displacement and so how do you kind
of look at funding those mechanisms. Um
the example I can give you is from my
previous role at the trade association
where we were working with a lot of
trucking
uh trucking folks folks who represent
like truckers who were concerned that
the development of AI in vehicles
autonomous vehicles especially in
trucking would start displacing some of
like what's impacting these drivers and
so the conversation that a lot of folks
were having behind closed doors it never
came into fruition and never moved into
a bill that could move through the
market process into the floor the
conversations were about funding these
grants that exist for displaced
industries, right? They're usually meant
to kind of impact sort of when an
emergency happens and like a mining
community is impacted or something like
that, right? To fund like to help with
the transition on that process. So, I
think we need to be cognizant
that current forecasts for what the
impact on different communities will be
and the workforce. I think it is still
early to tell. I think I'm a little
different from some of my colleagues in
the space who are much more sort of you
know ringing the bell and saying look we
need to think about this today. I agree
we should be thinking about it today.
But I also do think that if we start
thinking through developing strong
literacy which by the way is not just
about AI right even access to these
systems and broadband if which is
another issue we focus on making sure
that the folks you know children in
schools are actually getting access to
these systems and tools at home because
they have internet access to make them
more comfortable with it so that they
can play with it in a workforce is
critical as well. And so I I do think,
you know, long story short, I would say
we do think about these issues. I also
do think that the numbers are still
early to tell, but I do we the solution
can't just be focused on literacy and
training. It has to be focused on what
actually does happen to those who will
be displaced because their jobs are
impacted by it. And I will say that the
one thing the one statistic I will
continue to to kind of stress and agree
with is that those industries that will
be impacted are most more than likely
going to be those industries that have a
high number of people of color in those
roles. And so how do we ensure that
there's a inability to ensure that those
those communities are taken care of and
protected is is a tough conversation to
have with some people because you're
these these tools haven't they're not
all out there yet. we're not seeing all
the job displacement that folks are
forecasting. So, I'm not super
conservative like some folks are. I'm
also not as forthright in saying like,
look, like it's all this is all going to
happen like we're we're basically
screwed at this point. I think there's
an ability to to start kind of curbing
some of that as we think through what
the future of work looks like.
Um KJ I talked to a lot of u um sea
level execs of enterprises and I asked
them and most of the fortune 500
companies today have an ethics board
they say uh AI ethics board to guard
against um you know biases etc etc. Uh
the reason I'm asking you that is should
there be in your view independent audits
and some kind of an oversight mechanism
to monitor AI systems you think for
potential civil right violations? I
think I think it depends on how you're
framing it, right? Like I
think so I'll I'll point to the the uh
the AI executive order and then the OM
memo that came out kind of creating an
instruction manual for how agencies
should follow this AI executive order.
There are two categories that it
specifically the memo specifically calls
out. And that is technology that is
safety impacting and technology that is
rights impacting. And so it essentially
calls for and says like look if this
tool is somehow rights impacting here's
a criteria of how you analyze this tool.
Here's what you do if the tool is found
to be discriminatory. So does that
should that work be designated to an
independent board in a company or should
it be a federal sort of entity? You know
that I I think has to be sort of fleshed
out in conversation. I think that's so I
think two things come to mind right one
is like the fact that private sector is
saying like look we're already doing
this a lot of this compliance on our
own. Uh, so either leave us alone,
right? Don't don't make it harder on us.
Or B, it's yeah, we welcome it, right?
We're already doing this. Cool. Like
create whatever guidance you want. We
want to know how we can strengthen our
own internal challenges. I think that's,
you know, kind of naming the the the
sort of landscape that there are
companies that have come out saying like
AI governance conversations, let's have
it. I do think though going back to the
earlier point, if you have a bottom line
that you need to protect, I don't think
having companies be sort of self-reliant
on their own enforcement and compliance
is going to be enough. I do think there
needs to be something in law or you know
through an executive order if it's about
procurement with the government uh that
creates stronger guard rails. Now who
does that analyzing I think depends. I
think if you're the executive, you know,
if you're the executive branch and
you're an agency buying a tool, let's
say like facial recognition technology,
for example, if you're buying a new
system, um, then you need to follow the
guidelines that are in the OM guidance,
right? Because you're the one procuring
it. If you're a developer, there should
be guidance that you can look to be
like, all right, we want to make sure
that this is what our assessment is. If
you're a deployer, if you're the one
putting it on the market, how do we make
sure that you have your guardrail? So
who the person should be I think is an
interesting conversation. I don't think
it should be left to private you know
sector alone. I think we've seen with
data in 2017 you know what happened with
Cambridge Analytica that you know as
moderate as I may be and criticizing
companies overall I don't think
companies can be left to their own
devices in something that is as
important as protecting our civil
rights.
Okay. So some kind of an oversight uh is
what you're saying should be there. It
can't be just the companies. Since we
talked about companies, uh KJ, um I this
is also a question I ask uh senators and
members of Congress that look at what's
happened in social media. We have
basically five, six, seven, eight
companies that control our town hall,
town square uh of democracy. Uh do you
worry the same thing could uh be the
case in AI? uh few Silicon Valley
companies, maybe a French company at a
token French company here and there,
maybe Ger one German company uh
basically and three four Silicon Valley
companies and implications of that
thought process. Yeah, absolutely.
Sorry, I cut you. I was trying to jump
in very Yes, I I agree. Everything you
just said I I agree with. I think that's
why we support the create AI act. We
haven't formally endorsed it, but it is
a bill that we support that talks about
significant investment of government
resources into creating and I know I I
believe the frame the road map that you
that we're talking about the Senate AI
road map references this a little bit.
So I do think that government investment
is critical here. We all in this space
know that it takes a lot of data, it
takes a lot of computing power to create
these tools and there's a reason why big
tech companies are the ones who are kind
of like holding the gate right now. So
again, I do think major investment is is
critical to ensure that smaller entrance
or mid-size entrance can actually start
developing some of these tools kind of
access to some of that computing power
and to kind of to be com you know
competitive. Uh I do think there is a
competition argument to make but it's
also you know again this is coming from
my opinion leadership conference does
not work on competition issues
officially but just as it impacts you
know diverse communities for us to have
multiple choices right we see that that
Twitter uh now X completely changed
their content moderation policies after
Elon Musk took over and you see people
leaving that to be like, "All right,
well, we're going to either utilize
Instagram more. We're going to use
threads, we're going to just use Signal,
you know, as as the way to communicate,
we're going to use, you know, IMES group
chat because we want to talk to people
and let people know what's up. But we
also understand that we don't like this
one option." So, I think options are
critical. I think you're seeing it a
little bit, not as aggressively, but in
the brow web browser space, right? You
have duck.go, go you have Misilla trying
to be like look we're going to we have
better in their argument we have better
data uh collection pro you know
practices than our than our competitors
in the space but it's like I think op
choices are always good right and I
think we don't want to create the same
issue that we saw with some of the sort
of social media not and I I don't know
if I agree with the sort of town hall
sort of assessment but I do agree that
we saw what happened in 2017 is because
you have like one or two major platforms
really controlling like how people are
exchanging information about the
election. Yeah. Uh KJ uh want to talk
about uh international collaboration. Uh
most companies these days are global. So
uh you have the EU AI act as member of
Congress uh told me two weeks ago that
the Europeans are uh regulatory
superpowers. We are innovation
superpowers.
uh we don't seem to have an act now.
There are 20 states who are putting
together some kind of a regulation. Uh
China has its own thing etc. Is is that
something that's of impact
to your uh organization etc or would you
do you think harmonization of uh
regulation or at least some kind of
governance would be helpful in that
sense? I do think I mean so first I
think we have to give a shout out to
Colorado right that passed the first
governance right law they think it's
just like very recent news and the
approach they took is interesting saying
that developers and deployers much have
a sort of reasonable must exercise
reasonable care when it comes to sort of
high-risisk systems and they have their
definition of what high risk is. So
I you know I think that's what we're
going to see more of. I think I think
that while Congress sort of delays, you
see states are going to try to fill that
void. I will just use the privacy
argument as the privacy debate as a sort
of comparative point. I haven't seen
states or even Congress be
motivated on in a sort of as a body by
like what's happening in other
countries, right? I haven't seen that
model for m multiple reasons, right? We
also have a constitution. So we have a
lot of first amendment protections. And
so what sort of impositions can be
placed on companies, you know, and what
how the constitutional protections might
be implicated always comes into play in
our conversations versus the the EU. I
I'm
not convinced that we need a sort of
global standard because I've seen how
with the GDPR coming into play, they're
doing just fine in enforcing their side
right now. People debate like how
effective GDPR is versus not, but my
point is they have that sort of
mechanism there and we see it on the US
side when we have to click on cookies or
accept cookies and all the other
transparency items. I think you can have
frameworks, you know, that, you know,
countrywide that allow users to come and
interface. But I I do think that the US
I think the other point that I really
try to stress is that I think we're
uniquely positioned given the the just
the the grand diversity we have and the
history of how you know data has been
collected on marginalized communities,
how it is sold to data brokers. Uh, I
mean the stories are fascinating and
also horrifying, right? You have stories
about data brokers using Muslim dating
apps to collect information and then
selling that to the Department of
Homeland Security to help DHS surveil
Muslim communities in certain areas. So
when I think about impacts on our sort
of like communities of color, our
marginalized groups, our minority
communities, I do think that because we
are uniquely situated there, I do think
that the governance here has to be very
focused on making sure that that we're
all protected overall versus what I
think would be essentially sort of like
a copy paste of like what other
countries are doing, which is like
they're governing their own bodies and
that's that's you know important to do.
I think we need governance overall. I do
think but I but again my sort of amateur
observation of Congress is that I don't
see members of Congress being like man
we need to hurry up because EU the EU
did this or man the EU AI act has this
so we need to do this as well. I think
in conversations with allies, you may
see Senator Clolobachar and others sort
of commending um what is happening on
this side, but overall like I I think
we're just in a for better or for worse,
we're very much like focused on our own
protections and systems. And so while I
think we should look at foreign
countries as potential models to take
from that and learn from it, I do think
that because of our unique constituency
and population, you know, we need to
really be focused on that instead of
just thinking about governance just for
governance sake. So focus on our stuff.
Um KJ, I think that's uh what you're
saying, KJ. Uh early on you alluded to
our elections and the role of AI, deep
fakes, etc. in our elections. Um we had
during the New Hampshire primary, as you
know, there were robocalls and things
like that that were done using AI, etc.
your thoughts on the whole issue of uh
dem democracy and you know the worries
across the world there are about 60
elections that are happening or in the
process of happening um what are your
thoughts and how does uh your
organization or how do you think about
that? Sure. So we are definitely very
focused on the intersection of AI and
voting. uh we you know the AI roadmap
talking about putting more investment
into election systems across the country
to make sure that they're better
equipped to kind of handle the the
spread of you know AI powered misin
disinformation or you know even attacks
on their systems like on just the the
election system itself uh is is
something that we definitely are very
supportive of. I think what we have seen
and I keep going back to Cambridge
Analytica because I think that that was
a sort of a strong illustrative example
of how foreign powers that were trying
to sort of interfere or even domestic
you know it could have been domestic
actors as well. there's folks are kind
of, you know, have their own opinion on
that. But the point is when you have an
election and you have folks who are
coming from like say the
African-American community and you have,
you know, you have what do they call
them? I'm forgetting the name now, like
Facebook groups, right? That would
essentially be like this is for Black
Lives Matter and getting here like come
to this place and rally. And then you
have that same individual data being
used that's been collected to get folks
who are showing sort of antipathy or
aggression against Black Lives Matter
that movement and creating work, you
know, groups there to like get folks who
are against this ideology and saying,
"Hey, come to this place at this time
and being used to like create tension
and aggression there." We've seen how
that has happened. And so I think for us
when we think about the impact AI has,
it's really about manipulation and about
the spread of disinformation and
misinformation to either dissuade folks
from voting or showing up to the voting
booth on the right day or right time. So
I think you know there are a few things
that we're doing right beyond supporting
legislation that is coming out. We also
do have a in-house boiler boiler room
operation that is tracking election
related disinformation misinformation on
the major platforms and we work with our
partners in the space uh including
Spitfire strategies to create
inoculation messaging and then we spread
that out to our various networks that
are focused you know that are on the
ground. So that is direct that is our
most I would say one of our most
aggressive sort of grassroots approaches
to fighting disinfo misinfo is to create
this inoculation messaging and then
disseminating it across uh the systems.
What we're planning on doing this year
is sort of very specific community
focused trainings on how to fight
disinfo misinfo. So for the
African-American community, for the
Latino community, for the AAPI
community, um because we've seen that
disinformation spreads differently among
different communities even though the
result may be the same. So for the AAPI
community, for example, you have a lot
of folks from China using WeChat, right?
You have folks from South Asia using
WhatsApp. And so you see that how things
can spread very quickly on those
mechanisms. So how do we empower folks
who are on the ground to sort of help
counter some of that? That's something
that we're also very invested in. So
beyond legislation, which is tough
because again elections don't just
happen federally, you're also having
local and statewide elections. It's
really about the individual impact
there. Well, that's great. So you are
prepared, you have a war room and this
is obviously a big concern uh because
our democracy is very very valuable. Um
KJ, finally I mean I have like a zillion
questions. We'll need to get you back
there, but uh I also value your time. Uh
finally, what advice would you give to
the policy makers and regulators who are
listening and we have a lot of uh by the
way EU and other countries regulators
also who listen as they're navigating
the complex landscape of AI governance
and civil rights.
Yeah. No, that's like and I want to just
respond to what you're saying earlier.
I'm always happy to come back and chat
more. I think this has been a great
conversation. You really covered quite a
bit and you gave sort of showcase. I
took you in so many so many ways and
there were so many other ways I wanted
to take you but please yeah go ahead. No
no no I'm always here for the ride. So
yeah whenever you're ready I'm happy to
come back. Um I'll say look I I think
we're seeing we're seeing models of what
good AI governance can look like and I
would just point people to the policy
makers and so on to the approach that
the Colorado law takes which is talking
about it's not about overall any system
that uses AI and trying to take it from
that approach because that becomes
difficult. How do you define AI? At what
point do you come in? But thinking about
impact, thinking taking an impact based
approach, which is what the Colorado law
tries to take on, right? By saying if
you're a high-risisk system that you
know then and they define what a
high-risisk system is, then you know
developers developers and deployers have
to use re they have to exercise
reasonable care. I think on a stronger
note you see in the OM memo that talks
about the AI executive order that says
like look if your system is going to be
rights impacting or safety impacting you
have to go through these criteria and so
when you take a more impactbased
approach towards legislating it is much
more sort of tangible and concrete I
think when folks are trying to go into
the the take it from like the maybe more
linear approach like let's define AI and
what's an AI system and what's not an AI
system we've you know we've had folks
from different states reach out to us
asking us like in in our legislation
we're defining AI like this what do you
think and we'll give them feedback and
be like well look in this context you're
not really capturing XYZ when you define
it like this and so you know we're
always happy to be a resource to folks
and we give feedback that way but if I
were to wave a sort of magic uh wand and
you know have policy makers follow my my
suggestions I'd say like look take a
very core impactbased approach and also
make sure that civil rights is
explicitly called out and that any
system that has disperate impact or
negative impact on someone's individual
and civil their civil rights needs to
just be completely it has to be
prohibited. Uh I think you can build a
base from that, right? Once you protect
individuals and you can think about what
does transparency look like? What does
accountability look like? What does
fairness look like? What does equity
look like? But the base has to be
impact. You're impacting people with
these systems and you know I would just
we remind members all the time when we
talk to them and I would just remind
your you know your listeners about that
as well. Well that's great. So
impactbased just make sure uh they do
that. Uh KJ, didn't the Colorado uh
legislation kind of follow Connecticut?
Uh sort of
uh was it kind of I mean Connecticut
didn't happen, but they followed uh
Connecticut, right? I'm not So that
Colorado Connecticut listeners, so I'm
not but I do think that Connecticut was
You're right. They were on the approach.
The last I saw was the governor of
Connecticut felt that they were kind of
moving too quickly and they wanted to
let us kind of allow more innovation to
flourish for building governance. I
think based on everything I've been
saying for the past hour, that's clearly
not our approach or our our mentality,
but you know, um we leave it to the
state legislators to to get back in the
game and to, you know, follow Colorado's
lead and start developing strong
legislation. But, you know, final final
point before I uh turn it over to you.
You know, baseline legislation, federal
baseline legislation is always what
we're advocating for first first and
foremost for that. We, you know, whether
you're in Colorado, Nevada, you as a
user should know what your rights are.
You should have a reasonable expectation
of what when you interact with the
system of any kind, what you can ask for
and what you can see. And that only
happens through federal baseline
legislation. privacy or AI governance.
Awesome. Thank you KJ really for sharing
such uh valuable insights and
perspectives you know today with us. Um,
you know, your dedication to ensuring
that civil right remains at the
forefront of AI formulation is truly
commendable. And to our listeners, I
hope this conversation has provided you
with a much deeper understanding of the
complex interplay between AI and civil
rights and the importance of proactive
regulation and governance to safeguard
our fundamental rights and freedoms.
Thank you for tuning into regulating AI.
Until next time, keep exploring, keep
questioning, and keep advocating for a
just and equitable future. Thank you,
KJ. This was fabulous. As I I could have
just gone on for at least an hour more.
Really, we need to have you back again.
Thank you. Thank you. No, thank you to
you and your team. This was great. Thank
you.
[Music]
