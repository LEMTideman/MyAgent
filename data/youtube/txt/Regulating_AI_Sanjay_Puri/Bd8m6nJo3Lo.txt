will we have a healthy level of
competition allowing AI content to be
copyrightable is actually beneficial for
model
development welcome to the regulating AI
podcast join host Sanjay pury as he
explores the dynamic and developing
world of artificial intelligence
governance each episode features deep
Dives with global leaders at the
Forefront of regulating AI responsibly
tackling the challenges using AI can
bring about head-on and enabling balance
without hindering
[Music]
Innovation welcome to the regulating AI
podcast artificial intelligence AI
stands at the Forefront of technological
Revolution so how do we regulate it
without stifling Innovation our podcast
features insights from various
perspectives we've had industry leaders
to government officials to leaders of
advocacy groups together they address
pivotal question question that are
needed to create practical and sensible
legislation I'm very excited to have
Professor Alex Yang with us today he's a
professor of management science and
operations at the London Business School
he got his PhD at the boot School of
Business at the University of Chicago
he's also been a visiting professor at
the University of Hong Kong I invited
him on this show as it is very important
to get many different perspectives
towards framing AI legislation and we
need to get Global perspectives on this
transformative technology welcome Alex
it's an absolute pleasure to have you on
the regulating AI podcast DJ thank you
for having me I've been a big fan of the
show I enjoyed some of your uh your
previous podcast which have been uh very
informative and inside well thank you
Professor uh that's very kind of you
Professor for our listeners uh who are
Global political leaders their staff
Think Tank people industry and advocacy
groups can you tell us a little bit
about your background and a little bit
about what you do to begin this
conversation my my interaction with AI
actually started very early so uh back
in undergraduate I was uh my major is in
electrical engineering well the specific
major back in China was actually called
Automation and uh so my first sort of
class on AI was probably in the last
century I I I feel sort of bad in the
sense that I've learned neuron Network
back then but I I wasn't Visionary
enough to see that it's going to evolve
into this super powerful technology as
we see it today and uh after that I went
to the the US for uh my graduate school
and as you mentioned I graduate from uh
the Chicago Booth the business school
doctor degree in uh in management and uh
since then I've been living mostly in
London uh my research have been focusing
on mainly how do you think from a very
holistic value what I would call Value
chain
perspective uh in understanding a lot of
the pricing issues uh we see in today's
business world so uh my recent work
involves applying this value chain
approach on digital platforms and uh
most recently artificial intelligence
thank you for that uh background uh you
had tremendous background Professor when
you look at uh artificial intelligence
what do you see the biggest risk that we
should be looking at from AI well that's
a that's a trillion dollar question for
me I I I grew up watching uh watching
the Terminators movies so I always
thought that existential risk is the
biggest risk but of course if I think
about a I do a lot of research related
to racek management if you think about
how do we manage race uh there's the two
dimensions of a risk one is the
probability How likely this is going to
happen and the other is the the value I
state if this really happened how bad
could it be for human for if I look if I
we look at this two Dimension I would
say the biggest risk in terms of value
at stake and I don't think the
probability is completely zero exactly a
existential risk so in terms of
Regulation against this type of race the
regulatory focus is probably more on
monitoring right especially monitoring
at a global scale the good thing about
training artificial especially extremely
uh powerful artificial intelligence
model is that there is a very sort of if
if we think of from a value chain of
Supply te perspective there is a clear
Hardware battle which is computer chips
and that allows global government if
they could work together to
identify uh who have the capability of
creating this type of risk and that
allows them to better to better monitor
that uh but if I think about risk that
are probably a little bit more pricing I
I would say probably large scale job
displacement so we have SE over the last
20 30 years globalization has already
caused the develop developed country a
lot of jobs but those are mostly blue
color workers right and gbi there are a
lot of research that show this will
probably replace or change the the job
description job responsibility of a lot
of white color
workers so I I personally believe
governments or Regulatory Agencies need
to act proactively uh on this Dimension
Professor you identified two main risks
one is an existential risk uh so I want
to address both both of them and the
other one is the job uh displacement
that will happen in terms of existential
risk I presume you're talking about AGI
uh you know artificial Journal
intelligence where this AI becomes even
more powerful uh than human beings we've
had uh many guests we've had guests who
believe in existential risk people who
really believe that we need a pause Etc
when you look at AGI and you know we had
mark Zuckerberg from meta saying that
they are going to even open source AGI
you know open source that technology you
uh have a tremendous background in this
for our listeners do you have a time
frame or can you even predict a time
frame for AGI or some level so to give
Regulators some perspective because
there's a follow on question to that but
do you have any kind of a perspective or
are you a believer that we should have
some kind of a pause system uh for in
terms of this that's a great question I
I don't have a time lap to be completely
honest I don't know if anyone have that
right if you talk to if you listen to uh
like true expert like Jack Hinton right
he was he think there is a a sort of
tangible probability tangible race I do
think there is we should think of a a
trigger mechanism where if something
happens we should start to pause this I
I don't think we are at that stage yet
uh in particular because right now whe
whether you you refer to this as
artificial general intelligence or some
people like to call this uh if we're
really talking about skynight type of
thing is really super artificial
intelligence I I don't think we are not
we're there yet the sort of good side I
guess in this in terms of safety of this
is uh artificial intelligence are still
mainly in the space you can't uh the
current artificial intelligence if you
look at robotics they can't really
physically take over the world which
makes me a little bit more relieved so
but I do think government all over the
world should start collaborate and uh
start to talk trying to figure out a
trigger mechanism it's a little bit like
in that Dimension it's a little bit bit
like I like to to relate that to uh to
nuclear weapon made some very good
points Professor one is uh we are not
there yet and nobody really knows which
is true whether it's uh Jeff Hinton or
others and then we should have some kind
of a trigger mechanism like similar to
nuclear weapons a lot of our guests keep
talking about the nuclear weapons and
things of that nature to follow up
Nobody Knows the timeline but suddenly
the world woke up one day and we had
chat GPT I hope it's not going to be the
suddenly we we wake up a few months or
timeline Etc and we have you call it
super intelligence and then everybody is
scrambling trying to figure out and you
say a trigger
mechanism uh just to follow that up a
little bit that would involve a lot of
international collaboration because you
know it's like the nuclear uh stuff if
everybody agrees to nuclear but there
are a few uh countries who don't and
really the value of the trigger mechan
ISM would be lost so you are visualizing
a a real International collaboration
because we have a lot of international
uh listeners we have listeners from
around the world we have legislators who
listen around the world also so you are
saying that International collaboration
is very critical how do you visualize
that happening uh Professor wow I I
could it's good very good question I I I
think it could take in different uh
format right like a few months ago the
UK had
the asmit right which involved pretty
much all the major economies in the
world which I think a good start there
of course has to be some trust that is
buil up gradually uh now if we look at
there there Sims it's it's almost it
almost makes I don't want to start the
show with being very fastic but it
almost got me sometimes I wonder if the
uh the the world simulation theory is
actually true
uh do do do you think that the our
audience are they familiar with the
simulation Theory why don't you please
tell them because we have uh audience of
all kinds so it would be helpful just
briefly if you can tell the uh well the
idea of uh are you talking about
something like the Matrix oh certainly
almost yes okay well I don't audience
more laugh than that so the idea of of
course this is a hypothetical sort of
almost like SciFi or you can call it
conspiracy sort of thing right the idea
is we don't live in the real world the
real world that we live here was
actually a super realistic a simulation
that was run by some other agent right
whether a super computer or some uh
super intelligent species if you play
game you would know that the game are
designed in a way to sort of entertain
the gamers and if we are the the NPCs in
the game then the game designers would
like to create things that that sort of
entertains them but make us suffering so
right now we have This brilliant
technology which will bring in
tremendous amount of productivity but on
the other hand it's also it also
imposes some major risk but this
technology particularly happened at a
point where people are talking about der
risking de globalization there's a lot
of geopolitical tension uh the timing is
is not perfect I think if we're really
going to make this work there has to be
more trust build among major economies
especially those economies that have
significant comp computing power or
significant production capacity that
could generate that this type of
computer Professor you uh talked I mean
we've had many many many guests we've
never had somebody talk about the Matrix
and this uh simulation Theory which is
very very interesting that we are
actually part of some uh entertaining
some people and uh maybe this podcast is
too uh entertaining some of these pieces
but that's a very interesting uh concept
now the question that kind of relates to
what you're saying is there is this
whole issue of as you said trust there
is this whole AI nationalism that has
happened and you hear uh the head of
Nvidia Jensen Hong talk about how every
country should have their own large
language model and you're starting to
see a lot of countries saying hey we
need to invest it's like the nuclear
Club if you don't have an a large
language model part of it is you know it
gives people an ego boost but also I
think to retain their culture their
language uh and those things I think it
is very important but how do you see
this AI nationalism uh kind of play out
because it's also there are some checks
and balances with these chips as you
said these expensive processing happen
do you believe every country should have
uh their own large language more
specifically if we're talking about
model level I believe so because we're
really thinking uh building these models
of course there are different layers of
the model right you have the
foundational model you can fine tune it
right you can each of in principle could
build sort of a customized Lang large
language model I probably they are not a
foundational model that is different
from others this type of customization
is helpful so I think whether we're
talking about a specific country a
specific Market or a specific sort of
community which they have a their local
dialect right I'm origin from China we
have a lot of local dialect that if they
want to preserve I certainly think uh we
should trade models that incorporate
this so that this is you made a great
point I haven't thought about this
before but large language model probably
could act as a means to preserve to
better preserve this type of cultural
heritage right we were teaching
generative a last year the first time
Inland business school and a few of my
students were telling me that one
interesting application they used ttbt
is actually to practice the their second
or third language and that of course
buil on the the the the sort of
requirement the foundation that uh this
language is embedded within within the
lar Lang model to that extent um I I
would think I'm mostly positive that we
should have large language models that
capture if not all the vast majority of
existing U knowledge base or uh
languages in terms of AI nationalism I
think that probably is a little bit
different so uh should every how should
every country have n media I I I don't
know what uh what Mr hang is going to
say about this so the these are
tremendous amount of investment and
there are uh if you think about Supply
te investment one of these factories
will cost billions of dollars and I
don't know if every economy should uh be
Reinventing the v a very good point I
think related that you were alluding to
is if you think about chip back right
China is almost now forced to build up
their own chip making Capac it could
lead to some unintended consequences
that the West didn't need back like I'm
conjecturing a little bit right if you
think about uh China is a country that
has uh tremendous production capacity
this is a country where uh the
government is very sort of flexible in
terms of Designing their industrial
policies like if you see uh today's uh
Financial Times have article saying a
lot of city government in China were
actually handing handing out these uh
coupons or vs they call Computer vs to
AI to AI startups because Computing is
expensive and the government want to
subsidize right this uh as a supply CH
person this scenario sounds very
familiar to me right if you look at
solar panel you look at uh electrical
vehicle especially electrical vehicle
batteries well I don't think the West
would want to have the scenario where
China using this large scale industrial
policy to really push for AI chips or
for other Computing chips that one day
could uh flood would flood the West
Market it's so that's why I think it's
important to have P back to our
International collaboration point of
view I think it's important that uh
countries starts to have more
constructive dialogue more constructive
dialogue uh I completely agree with you
Professor you touched on some things
being based in London obviously uh
you're familiar with the EU uh with the
you know the UK safety Summit they had
give us a little bit if you have some
experience in terms of what China is
doing in terms of its regulation because
people say that they've been very strong
on uh in fact in many ways ahead of most
countries or even EU do you have some
perspective in terms of what China is
doing in terms of AI regulation I I'm
not a China expert I have lived in us
for the last 20 years my of course I
still uh because of my background my
Heritage I I still pay attention to to
China's policy right my very high level
understanding is China at this level at
this like industrial policy level China
is quite pragmatic
and they really wanted to especially
they are seeking for a new sort of
growth driver right for for the economy
uh the this you may find my my co-
author's work more related iiz it's a
better is is a much capable expert on
Chinese regulation yeah Professor the
whole concept of Open Source versus
closed Source you subtly touched a
little bit on it there are two schools
of thought that open source is good for
Innovation entrepreneurship meta IBM
Mistral to a certain extent just
recently announced a close Source deal
also with Microsoft and then there is
open AI Microsoft that are on the close
Source there are some people who say hey
uh there's some risk to it what are your
thoughts in terms of this school of
thought I I agree on I agree with both
schools of thought I think there is
certainly the positive side right the
open source if look at the entire
science Community it's buil it's based
on open source and it certainly enables
a lot of uh great like in terms of uh
research idea generation right which
could come back to to benefit everybody
but there there is also the risk
component what if this open source model
is used by some wrong players some
malicious users so so that that's why I
believe right now the technology Giants
are probably adopting a two- tiered
approach right their most advanced uh
models are not open source they only
because there is a sign significant
amount of risk related to the most the
state of the art model which they are
still playing with or testing if we're
being more and uh but the second tier
which they more or less have very good
idea of what what the model is capable
or is uncapable able to do open source
it is probably going to lead more
positive side versus NE versus uh
negative side one complication here is
the competition landscape we think about
there is one sort of good intended
company who have this policy they will
space they will manage their or release
their model in this optimal two layer
sort of structure but if we take cons uh
competition into consideration I think
it become l as clear whether some people
because they are not considered the the
AI leaders in the world they may go more
aggressive they try to compete create a
different dimension to compete that may
actually leads to some more overly
aggressive policy in terms of releasing
open source models I think that that's
something we need to we need to we need
to look at so that leads me to uh really
the question that you kind of alluded to
in the us and even with the EU act that
they did there is a been a fear of
Monopoly of tech companies controlling
AI like they control social media uh the
eui act with its basically horizontal
approach has tried to do it even though
maybe there's some room to be left are
you concerned about because it takes so
much money to build some of these models
whether it's large language models Etc
are you concerned about monopolies and
what Solutions do you have for our
Regulators here in the US to some extent
I do uh but in general I think the
technology space if we look at uh what
especially generative AI right I'm not
completely concerned like this doesn't
worry me that much because 10 years ago
if we think about the leader of AI
that's absolutely Google we have ARA go
and the Transformer model was developed
by Google brain everybody think
AI is going to be dominated by Google
but then the this the product that
really surpris the world is not
developed by Google of course we say
this is related to Microsoft but this
still shows sort of the entrepreneurial
sort of spirit or the the capability uh
you mentioned uh mistro that's that's
another example right it's a very very
small company lied by a few people yeah
they they've been they've made
tremendous success so on that part I'm
not particularly worried that Monopoly
is going to hinder uh Innovation to that
to that extent but I I do worry a little
bit about in general compet the the lack
of competition on the welfare of
consumers this however is probably more
of a more generic a more General uh uh
competition policy problem which we have
which we have accumulated hundreds maybe
more than 100 Years of knowledge on how
to do that course I mean you uh two
points that you just made one is uh when
you look at companies like mstr most of
these companies now have investments
from these big tech companies open AI
with Microsoft uh Mr recently got uh
investment from because the amount of
money that is needed very few uh people
even VCS are going to PK up it's these
cashr tech companies and Tropic is
Google Amazon on and on so it's
basically uh the same companies that are
doing that that's a little bit of a
worrisome but when you saw recently what
a Google image generator some uh the
Fiasco that happened that tells you the
stakes that are there for people who are
going to control these large language
models because they can tell you about
our history they can educate you about
our history about our health about our
culture about our medicine in whatever
way they want and that can be a little
worrisome any thoughts that you have on
that the Gemini uh incident is is indeed
very interesting and uh this my
understanding is this has something to
do with the implicit uh prompt
transformation prompt engineering that
uh Google want to build in right if this
type of technology is done correctly is
actually it's a great booster for
productivity
right if I look at some of the prompt
they wrote I can never write prompt as
good as they do but I I share your point
that we we don't want to have one or two
technology companies to sort of detate a
lot of things to that extent I'm
relatively optimistic because it seems
that different companies are taking
different approaches open AI is not
super aggressive on this type of promptu
transformation they're doing something
else they they provide a little bit more
transparency and Google probably as a
bigger player they are more concerned
about their reputational damage so they
want to be more proactive in the DI
front but now with this uh backlash I
think uh being a large company will also
require them to will also sort of force
them to take one step back I think that
that's a good uh that's a good thing in
general if even you look at for example
uh we've been talking about data privacy
right if I make a parallel Ai and data
privacy the big players are taking
different approach right AI like apple
is in general adopting a more privacy
conscious model well some other players
though to generally more private privacy
conscious so I choose to use Apple
product because I'm more certain that
whatever I have stays within myself
within this device uh the other thing
related to Monopoly I think that's
related is also
when we talk about regulation we really
want to think about what kind of
regulatory policy that could help
incentivize uh these startup AI
companies to create more sort of more
Innovative Revenue models right or more
sustainable Revenue models that could
allow them to be a challenger to to the
big place so far we've been addressing
your one uh big worry about AI risk uh
which is the exist po ential risk now
let's talk about the other one which is
the job loss that you talked about there
have been all kinds of reports McKenzie
IMF came out with a report that in the
you know the developed World it could be
up to 60% and mainly White Collar jobs
you know we the thing is programmers
Jensen Wong said you don't need
programmers anymore uh marketing people
customers uh Representatives recently
there's a fintech company called cler
they announced that they're uh letting I
think 700 customer service reps go major
transformation is underway Maybe not
immediately maybe a year or two but
everybody that has been on this show and
this has said that it is underway
firstly do you agree with that what will
be the scale of that transformation and
what can governments because this will
not just be a United States or a UK or
EU issue I have a feeling it'll be a
global phenomenon so what can
governments do towards that so those are
basically three questions do you agree
transformation what what will be the
scale of it and what would you recommend
governments to do right uh great
questions so for the first one yes I
agree that there will be transformation
I'm reasonably I'm more sort of probably
more optimistic on that front I think
there are challenges but also
opportunity there will be some jobs that
are being replaced bed but there are
also new jobs that are going to be
created or not not new jobs but some
sectors are going to be expanded right
for example content creators I wasn't a
well I I don't have the artistic
background or skill to generate any
content for consumption but now with uh
mid Journey or with Sora if I have my
literally liter uh skill I can transform
that and become probably a a content
creator is some industry uh in terms of
scale I've seen a few reports that have
given indexes of different Industries as
you're seeing customer service
representatives are probably going to be
affected to a larger extent than some
other Industries third question what the
what the uh government can do I think
they are to to to that extent I I would
think the government regulation there
are some more General government
regulation policy and there are more
industry specific policy on regulation
at very high level I think industry
agnostic we want to focus on this
probably true for a lot of general
purpose Technologies right we want
upskale our Uh current Workforce uh we
want to retrain some of them so they can
do some other job I mentioned about
content creation as been one but if we
think about two years ago we wouldn't
have uh this position called prompt
engineer but now we do and there's a
huge Market because you still need from
a regular people and a large language
model you still need someone to
translate the the other dimension of
course is also providing a social safety
right this is related to I think uh I I
do a little bit research on blockchain
as well so I've been uh looking at uh
Sam utman op the founder of OPI actually
have another project called World coin
the idea is by collecting biological
data you can sort of build a database
where eventually when the day comes you
can have a very efficient way to
distribute a a uniform uh basic income
I'm I'm not 100% uh on board with
collecting large scale biological
biometric information uh but I think
more or less we're moving towards that
direction right because digital
transformation is really about replacing
a lot of variable cost by fix cost and
there will be a a large scale redistri
redistribution uh effort which has which
should be led by the government so so
that's more on the generic policy part
right in terms of specific industry
policy I think that really depends on
what uh what kind of specific impact
gener VI or AI has on this right in uh
in the recent paper that we wrote we
basically focus on the creative industry
we're arguing two related regulations
basically the baru Stander and
copyrightability which is whether AI
content should be uh enjoy copyright
protection right the idea there is
basically to recm make policy
recommendations based on how economic
agents in the in the entire value chain
will react right how would this uh
industry specific policies should or
these these regulations should would
help develop both uh the AI Foster both
AI technology as well as to increase the
creators Collective income as well as
balancing uh social welfare again you
raised some very interesting points you
said uh you are uh obviously uh you see
some level of reskilling is going to be
necessary one of our guests who came in
had suggested a AI transformation fund
you said we are slowly moving towards
Ubi Universal basic income now we've had
that direction towards that because
we've had several Venture capitalists
like VOD kosla and others saying that's
where the future is going to be and
government should look at that even
though that's in some places it's
controversial and then you talked about
cre
creators safety from a before I get to
the creators part from a fund standpoint
for this transform information that
people need to do do you think having
some kind of a fund available for
companies or some kind of incentives
available for the companies for them to
upskill or res skill like you suggested
is necessary Professor uh this is a very
interesting idea just to clarify so this
fond is for is it so set up by companies
like technology Giants who made a lot of
money in AI or was it for every company
like I work in a school should my school
put aside a certain budget which one was
that the one of the suggestions was
where these AI companies were going to
make a lot of money they would pour some
money into this fund the government
would match that fund and you would have
this AI transformation fund that would
be available for companies maybe who are
laying off people so they would be able
to Res skill them so that they're ready
for the next job because major
transformation is as you said is coming
so this is this was just uh a thought
which I've kind of expanded on that
maybe the these AI companies were going
to benefit in huge ways should put some
kind of an investment into this fund but
it's any thoughts on that on an AI
transformation f i I haven't thought
about that it's it's a very interesting
idea I I think as long as it I don't
necessarily agree that this should be
made compulsory but I think it's
probably incentive compatible for some
of the technology companies to do that
anyway right at least at minimal they
could develop more materials for
potential users and uh there is because
eventually they could be their whether
direct um customer or indirect consumer
uh doing this type of thing would
actually help the technology companies
as well I don't even know if the
government need to match the fund given
given that the incentive is strong
enough for technology companies yeah I
think it's it's a great idea well we'll
follow up on that uh with you uh
professor professor you talked uh about
a paper that you did on um some of the
creative folks just when an AI creates
um generates some creative output text
music images that resembles copyrighted
work who in your view holds a copyright
does it depend on human intervention or
the specific training data used uh this
is uh this very good question I I think
the status quo is not very clear uh
because different legislations uh
different jurisdictions now already
there are already cases coming up and
they've reached very different
conclusion for example in the US uh
there have been a few a few rulings
saying a generated content even though
it has a big comp human component and it
has been uh prestigious award art awards
that could not be that could not enjoy
copyright right in uh in the more recent
Chinese case they actually the judge
actually granted this type of copyrights
uh yeah our paper we are we're actually
taking a different perspective from what
have been what have been done in the in
the legal Community which they mainly
look into they look back into legal
tradition right our Point here is
because the value chain the the content
creation value chain is very different
when AI is involved so the policy should
be taken into consideration of not only
those traditional things but also how
the type of policies will affect content
creators income as well as further AI
development which could have some SP
over effecta right and uh our point
there is basically if you think about
whether AI content should be
copyrightable right there are uh there
are different trof so if I make AI
content more uh copyrightable that well
encourages AI generation AI content
generation which has a positive side or
have a negative side right the positive
side is because AI generation is a
basically requires a lower entry barrier
it's lower cost so it would encourage
more content generation right that will
eventually could benefit consumers but
this could also Crow out some content
creators or substitute some content
creators were traditionally doing pure
human generation right so there's a bit
of substitution effect it's not clear
whether that's good or bad uh then it
also has a on the AI company right for
example if I post this question where I
make AI content where a lot called AI
content to enjoy a copyright would that
encourage the a company to further
develop the a models or would they
actually dis encourage that right this
is actually unclear our model shows that
our is shows that this really depends on
the competition landscape because when I
make the output that you generate more
valuable maybe I'm I'm already happy
with this so I'm not going to generate a
lot so this happens when I going back to
your earlier point if there's a lack of
competition the a copyrightability may
actually not help AI company not help
model development but when we have a
healthy level of competition allowing AI
content to be copyrightable is actually
B beneficial for model development I
think that was also the approach the the
sort of argument the Chinese judge who
was ruling in favor of this that that
that's argument as well so there are
other dimensions as as well but our
point was basically when we look at
these policies whether it's FAU standard
or AI copyrightability they should
really be S I don't want to say scenario
specific but they they should really be
conditioned towards different industrial
structures technology development and
another thing we we we emphasized is
data availability we've had the CEO of
the copyright Association on our podcast
and their view is that if data is
ingested that has copyright in there
then that is copyright and attribution
is to whether it's Financial or per se
the question obviously is if you were to
take from a creator uh perspective what
safeguards uh would be most helpful for
them to protect their work uh so that to
ensure that they get proper attribution
if it influences AI generated outputs uh
Professor I'm not wearing the Creator's
hat no these are small people small
entrepreneurs or somebody's written a an
essay or a a song or something like so I
I think is a very interesting angle that
you pointed out right when you first
talk about creators so uh so they come
through my mind two type of creators one
is the type of creator that they use
generative a tools to create content
right that's what we were talking about
whether these content should be
copyrightable so that they can generate
a stream of income the other is as you
mentioned if I will call them human
Creator or original Creator maybe there
is a feeling that their uh sort of
welfare has been ferred or they were not
uh properly compensated when their
material is used by the AI so that's
that falls into the the the sort of
category of the fa use standard there
are different uh I I believe there are
different approaches to look at this
problem so if I think about from a
social welfare maximization perspective
the argument is really whether you have
whether in the current environment you
already have efficient data that has
training data that has already be
generated or you are already the AI
company already sort of data that they
really want to incentivize creators to
generate new original data for AI
training our analysis or our argument
basically these two scenarios are
different right in the first case if we
already have a lot of training data new
training data is not that crucial for uh
for AI development in general we we our
argument is uh General fair use have is
uh have its benefit right of course you
can argue there's some Fair need
concerns but in the other D in the other
regime where we say uh we have a scars a
limited amount of trading data in that
case even from the AI company's
perspective they may not have realized
that but even from the AI companies
perspective more strict uh fair use
standard which gave more rights to the
creators will be beneficial because they
may run into the scenario that they
don't have training data to work with
right that that's from a more sort of
social welfare maximization perspective
then if we look at exactly how you could
actually do this I really believe in the
ronal coast type of approach you
basically bargain you negotiate uh in
the shadow of the law uh the idea is I I
I believe different stakeholders of
different players in the value chain the
Creator value chain could play different
roles right a lot of companies these
days when AI companies when they obtain
trading data most of them have uh passed
the state where they just craw data from
the internet right they normally P A lot
of them purchase it either from a
publisher from a platform or from a
third party sort of data aggregator this
type of new intermediaries like data
intermediary right they could play a
role in terms of facilitating uh colle
collective bargaining right or if uh say
some companies wants to sign some
exclusive contracts with certain
creators I think that falls into more of
value chain business model Innovation
perspective I think there are a lot of
things that that certainly can be done
so that's very interesting what you're
saying is data aggregators will be
something that will come up and that'll
be something that will be engage with we
have entrepreneurs lisening I'm sure uh
that's also a business opportunity but
also you're saying it'll depend on the
quantity of data that is available uh
for ingestion that's where it will all
come down to in terms of fair use other
areas Professor we've covered many many
different areas we've covered
existential risk we've covered
employment uh transformation we've
covered open source course we've covered
monopolies we've covered uh copyright
creators rules and there's so many more
that I could ask you about but maybe we
need to get you on again uh because uh
this has been a very very interesting
conversation Professor finally for our
audience if you were to leave them with
some thoughts uh opinions or input as we
build towards sensible regulation uh
please if you have a few minutes to tell
them your thoughts sure I I think uh
sensible regulation is is of course very
important for the development of AI and
for human welfare right and what I was
what I want to uh Advocate is really a
sensible regulatory regime or sensible
regulatory uh decisions needs to be made
in a highly inter disciplinary way right
there is the ethical perspective there
is the legal perspective and there is
the business perspective my research M
mainly falls into the business uh uh
Dimension and even if we look at the
entire value chain of AI right for each
uh industry that AI could be applied to
uh we could adopt more uh sort of
methodological approach uh to look at
different different links within this
value chain and we could uh The
Regulators or the the The Business
Leaders right look at how would each
each stakeholder will react to certain
uh regulation and uh so basically to to
to call some economic term we want the
regulation to be uh the regulation has
to be incentive compatible and uh we
want it to we want to have more
comprehensive understanding of the
business value chain so that we don't
run into uh this type of iint
consequence to to take one step back
even after taking this comprehensive
approach there will be some consequences
which we don't foree we don't foresee
right that's the nature of fast rapidly
developing Technologies so uh another
important point I want to uh highlight
is the regulation should be really done
in the igel uh adoptive way right I
would say I I I would think more
principle based regulation rather than
rule based regulation uh that is more
that's going to be more beneficial not
only for business but for the uh for our
overall Community those are some
fantastic points more agile based um not
rule based principle based um uh
Professor Yang thank you so much uh for
giving our listeners some uh amazing
insights across the board it's been a
great conversation I'm sure our
listeners really appreciate it and uh
for our listeners these conversations
from a diverse background become really
important so please keep listening and
uh continue this dialogue thank you so
much Professor Yang for being with us
thank than being a tremendous tit for me
thank
you thanks for tuning in to the
regulating AI innovate responsibly
podcast you'll find links in the show
notes to any resources mentioned on the
show if you're enjoying our podcast
please subscribe so you'll never miss an
episode and leave us a festar review
