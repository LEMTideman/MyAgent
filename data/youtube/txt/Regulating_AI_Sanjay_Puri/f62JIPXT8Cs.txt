I think it's a matter also of uh
strengthening the uh prioritization in
the political discourse of the um AI um
more than it is being done until now.
Remember the AI actu gives um the
providers the need for uh asks the
providers to uh deal with um self
assessment. It's uh only in a limited
series of cases that there is the need
for a third party assessment. These
practices are disproportionately
um
hitting on personal uh freedom of
people. Um, so when we ban the
indiscriminate use of biometric uh
cameras uh and we limit them only to
some um criminal uh prevention and
prosecution, it's important to uh be
sure that AI can be trusted to use tools
that are not in the AI act, but I must
mention them.
Welcome to the regulating AI podcast.
Join host Sanjay Puri as he explores the
dynamic and developing world of
artificial intelligence governance. Each
episode features deep dives with global
leaders at the forefront of regulating
AI responsibly, tackling the challenges
using AI can bring about head-on and
enabling balance without hindering
innovation.
Welcome to regulating AI the podcast
bringing together global voices to shape
fair responsible and inclusive AI
governance worldwide. I'm your host
Sanjay Puri and today we have the
privilege of speaking with one of the
most influential figures in air
regulation globally. our guest Brando
Benf a member of the European Parliament
representing northwest Italy and the
lead architect behind the world's first
comprehensive AI regulation the EU AI
act as co-paper on the AI act and member
of the parliamentary committee on the
international on the internal market and
consumer protection and the special
committee on artificial intelligence in
a digital age brand has spent several
years navigating the complex
intersection of technological innovation
and democratic governance. In March
2024, the European Parliament adopted
this landmark legislation with Brando
declaring, "We finally have the world's
first binding law on artificial
intelligence to reduce risk, create
opportunities, combat discrimination,
and bring transparency. Beyond this
legislation, Brando was recently
selected to co-chair the European
Parliament's AI monitoring group tasked
with overseeing the AI acts
implementation.
Brando, welcome to the Regulating AI
podcast.
>> Thank you very much,
>> Brando. Uh we have a global audience. Uh
our audience is made up of policy
leaders like you, members of Congress,
Senate, in the US, around the world.
their staff, entrepreneurs, etc. So,
we're going to explore a little bit
about the UA AI act, your journey, some
of the questions that people have, some
of the questions we have received uh
about this interview. So, uh just
briefly uh Brando, could you tell our
listeners about your background and how
you came to uh this position?
Well, I am a third term member of
European Parliament now. I've been
already there for around 11 years. Uh,
and during my second term after seven
years of work, I I've been selected to
lead this work. having been negotiating
already other legislation and working on
um uh issues related to um the digital
uh world um like the impact on uh the
labor market of digital technologies and
the copyright legislation and the impact
on um uh youth uh education. So I I
touched um the topic of innovation from
different sides and when the EU started
thinking of regulating um artificial
intelligence,
I thought it would be the good task for
me to take. Um and so I started being
part of the um um special committee on
AI that spent around one year studying
um AI uh deployment around the world
with u academics with other policy
makers with institutions and uh
businesses developing AI. And after um
that study work, we were ready to start
working on actual legislation. And
that's when we started with the AI act
which um became a a a proposal from the
European Commission and the European
Parliament started working on it. Um we
made our amendments to the text. we will
discuss uh some of the content in fact
that it's also thanks to the work of the
parliament. Um and then uh we negotiated
with the member states to reach uh the
agreement and have the law become uh a
final uh approved legislation.
So uh Brando it's been a big journey
what you have been able to achieve uh
you know getting so many member states
to kind of agree who have different in
many cases economies and things of that
nature. So really uh kudos to you and
what has been achieved and we'll talk a
little bit about uh there. So uh Brando
for our audience what are the top two
implementation priorities and where are
you seeing the two biggest readiness
gaps? Uh that was a question that came
from our audience for you?
Well, um, from the readiness point of
view, I would say that the main issue,
uh, is to accelerate education and
training on AI in our societies. I think
that all over Europe, we still lack, uh,
that kind of focus from the
institutions. Um, and the private sector
can do as much, but we need more
institutional commitment on that. Some
member states have been working on that.
I think of the Baltic states or France,
but other member states are lagging
behind. And I think that's that's very
important because we um need to um uh
make uh the understanding of of AI a
more um shared um element in society. Um
and it for the implementation side um
well uh now we just started some pieces
of the implementation. It's still
ongoing. So I would say that at the
moment the two biggest challenges is
implementing the prohibitions which were
one of the first elements to come into
place of the AI act. So some selected uh
use cases that we chose to prohibit in
Europe, for example, the emotional
recognition in workplaces and in study
places, the illimit unlimited use of um
biometric cameras and subliminal
manipulative techniques through AI. So
um implementation of the prohibitions is
at the moment one of the first
challenges for the start of the
implementation which has started in fact
only in one year one year time. So we we
are still in the first phases and in
fact the second very important challenge
is that the AI office which is the
European level AI uh supervising uh
institution
uh and the national institutions to
supervise AI act implementation in the
member states are properly installed and
are given the right means to act. This
is a very important um uh point for the
implementation of the AI act because we
are confronted with very powerful
developers, very powerful um content in
fact very powerful uh systems. uh and we
uh need the uh supervisors to have the
means to actually uh check the correct
implementation of the law.
So that's very helpful uh Brando what
you have said is some of the challenges
are you know as you said education and
training some countries you mentioned
Baltic countries France maybe a little
bit ahead
uh just briefly is there something that
can be done to bring the rest of the
countries uh towards the same uh
implementation cycle than others. Is
there something that can be done or is
something being done to bring everybody
there?
Well, I think it's a matter also of uh
strengthening the uh prioritization in
the political discourse of the um AI um
more than it is being done until now. uh
which which will become necessary for
the further implementation of the AI
act, but also with the implementation of
measures that the EU is putting in place
to accelerate the development of AI in
Europe. So the so-called AI factories,
gigafactories, accelerating
um the development of uh European AI,
this will bring more attention. But then
to be frank, you need a political class
that wants to confront itself with these
challenges. The um impact of AI, I
think, can be compared more to the
introduction of electricity rather than
uh just innovations that were extremely
transformative like internet but were
not pervasive on every aspect of life. I
think that uh uh we need uh the
political uh class and the private
sector at large to um be ready and not
only in some places but everywhere.
That's why we also need strong European
governance. Um and that's why we uh
think that it's important to have one
panuropean legislation and not risk
fragmentation among the member states.
Uh so I think you're making a point
about European governance and we're
going to touch on that uh later on.
Brando um Brando you have emphasized
that the AI act aims to build trust to
enable greater AI uptake and use.
>> Now
obviously and we'll come a little bit to
that. Can you explain to our audience?
There are some skeptics who are saying
that this might hurt innovation. We'll
talk a little bit about that. How can
regulation actually accelerate rather
than hinder AI innovation?
>> Well, uh we think that uh it's important
to uh be sure that AI can be trusted. I
give you one example I always uh use
also in debates with people that are not
uh experts. Uh do we really want doctors
to use AI systems that are not tested to
uh put forward diagnosis and therapies
for patients? I think this is an easy
example but think also of the hiring
process. Do we want really to risk
having systems that are um uh uh putting
forward discrimination against women or
non-white people because this issue of
the quality and appropriateness of data
used to train AI is one very important
aspect of the um rules of the AI act.
Also, do we want creatives to lose all
their bgainaining power and being
deprived of their creativity being
absorbed completely by the training of
the systems without any compensation?
Even in these days we see mo things
moving on this topic because there is a
lot of tension. Then we want to bring
clarity on that. We we want with the AI
act to bring clear rules for application
of copyright uh provisions and also we
want to be sure that
um uh AI content can be uh identifiable.
These are some examples on
issues where you see uh a valuedriven
approach that is based on protection of
citizens of consumers of workers. I
could give more examples. Well, uh this
is why we think we need regulation. Not
every innovation is uh good. We do not
think it's good to have um systems that
can manipulate people in a subliminal
way or that can provide for predictive
policing that is in fact discriminating
people. These are examples of what we
limit or even prohibit. So um yes more
rules will create also some bottlenecks
but we need to build an incentive
mechanism that can overcome these uh
these issues and in fact uh create a a
valuedriven humanentric
um innovation uh uh with uh AI. We think
we can do that and that this can be a
model that other parts of the world can
also adopt. In fact, now we see
especially in South America a lot of
debate ongoing on adopting similar uh
frameworks. Uh clearly and I conclude on
this we need to be sure that there are
no duplications, contradictions. So we
need also to simplify on the
bureaucratic and on the uh um
implementation uh part. Uh I give you
one example. It's it's a fact in my view
that
I see it as a as a fact that in Europe
we have issues on accessing quality data
uh for training. We have too many uh
complicated uh superpositions or rules
on this. We need to accelerate the
availability of quality data in Europe
and this is very important to innovate
uh on AI and this is something where we
will need to work in the next months but
this doesn't mean that we abandon a risk
based approach on AI like the one of the
AI act
so what you're saying is there can be a
balance I think Brando between
innovation and regulation and it it's
actually good for innovation you talked
about bureaucracy See uh one of the
questions that came in was the AI act
has created a complex governance
ecosystem with the AI office, the AI
board, the scientific panel, the
advisory forum. How can you make sure
that it doesn't become a bureaucratic
maze that stifles innovation like you
just said?
Well, it's our work to do that because
as a monitoring group of the European
Parliament, we will have to monitor that
the system works fine and its complexity
is linked to the complexity of the EU in
the sense that we have uh the member
states that are present, the commission,
the parliament does its scrutiny. So,
it's uh also linked to that. So I hope
that with more political unity of Europe
that I think it will be crucial also to
become stronger on the AI um competition
globally uh we will have more
simplification also of structures. So I
I advocate for that because I think they
are quite linked. More political unity
of Europe will mean also more
simplification of the procedures. But we
will do our best so that as as it is
today things will be um uh straight
straightforward and it doesn't create
unnecessary complications. But in fact
as I mentioned earlier one uh
implementation challenge that comes
clear uh up when we talk about um these
issues is the um
strength of the AI office itself. So we
want that structure in the European
Commission to actually do its part
effectively because it will have to um
follow um um we could say daily risks of
AI use cases uh linked to the daily life
of people like examples I already made
with the medical use or the
administration of justice or the local
institutions but also deal especially in
a more even exclusive way with the um
systemic risk of the most powerful
models because that's the other uh uh
area where the AI act deals with to
prevent um uh uh safety challenges and
risks at the higher level with the most
powerful models.
So it'll be it is something that as you
said with greater political support you
will work through that one just final uh
uh question on uh this topic and we'll
move to something else is
a lot of European companies have said
that this could disadvantage European
companies who are going up against
American and Chinese competitors who
face maybe a less regulatory burden.
There was also an effort as you know to
delay this by two years. What are your
thoughts Brandon? Uh how is it going to
disadvantage European companies in any
way?
>> Well I can say two things. One thing is
that we have uh foreseen um an
instrument for facilitating the uh
access to uh the market by new u
business uh ideas, new startups which is
the uh sandboxes that are foreseen by
the law to um uh facilitate um
experimentation and the and a clear path
towards uh uh uh putting a product into
the market for uh new players and this
is important to um reduce any uh
competitive disadvantage with the bigger
players that are already incumbent. Um
but then also I need to reiterate a very
important thing that the uh AI act
applies to um all the AI developers, AI
providers that want to put their
products into the European market which
means that we have also
uh non-European companies that will have
to do the same things as the European
ones if they want to access the European
market. So we think that no one will
renounce to the European market. That's
our strength. So if they want to enter
our market, they will need to follow
these rules. They will need to do these
um uh checks on uh systems if they are
high-risk. they will have to avoid
putting uh prohibited use cases uh
systems in in in into the market and and
clarify what is prohibited. Um so these
are provisions that will not apply only
to the Europeans but of to all the uh
businesses that want to be in our
market. So this um is important to be uh
underlined because the AI act is mainly
a product safety legislation which means
it's a it's a legislation regarding what
characteristics a product that enters
the European market needs to have which
means that it can come from anywhere
from Europe or elsewhere. We can also
have European companies that will never
have to deal with the AI act if they
simply sell high-risk AI systems
elsewhere and they don't sell them in
Europe. So it's just that we want that
what comes into Europe follows certain
rules.
So that's an important point. What
you're saying is uh European companies,
non-European companies, all companies
that want this big European market have
to follow those rules. European
companies want to sell high-risk stuff
outside Europe, EU AI act does not
apply.
>> So that's a very good point. Uh one uh
question came in from uh a non US uh
European company saying when a violation
occurs involving a non-EU company
serving European markets, what
mechanisms ensure effective enforcement,
how do you handle the jurisdictional
challenges
>> within within the EU?
Well, that's exactly the point of
ensuring that the AI office and the
national authorities work well, are well
staffed and they are uh well organized.
So this will be one important
implementation challenge for us to
follow that in the next months to uh
check if everything works uh fine
because if there is such a violation the
one of the example you just made then
the national authority
will have first to deal with it and then
if there are certain conditions it will
be uh the EU AI office dealing with with
it for uh enforcement and for uh
remedies. Um but um uh also there are
areas like the uh uh systemic risk from
uh uh uh general purpose AI models that
are especially powerful that will be um
followed only by the uh uh EU AI office
because for um certain um challenges and
enforcement needs uh it's very important
to have immediate centralization. So
directly at European level. So we built
this balance respecting subsidiarity,
the fact that we have a union of member
states, but also trying to ensure
coherence and to be honest to learn also
from the past when the European Union
had legislation that applied to the all
of the uh EU market of the 27 member
states but then the enforcement was too
much fragmented at national level. So we
are trying to do better on on this
having more um coherence and the AI
office stepping in when uh it's needed.
>> So Brandov uh one of the questions that
has come in um obviously is that the
GPAI the AI office for the GPAI can
request technical documentation and even
API source code access for evaluations.
How do you balance obviously the
auditability with IP protection and
security? Well, that's one of the main
issues to deal with when we will
implement this new part of the AI act
which was completed through a co-leative
process. the so-called code of practice
where also the developers of AI systems
were involved in the in the discussion
and in the uh decision of a final set of
uh rules that are a way of
operationalizing
obligations that are in the AI act. Um
I'm I'm sure this will still be an issue
of discussion how we can do this
balance. I think that um we um will see
uh most probably an abuse of the concept
of trade secret and of uh business
secrecy to avoid uh enough disclosure of
information. I I see that I can imagine
that's to some extent physiological we
could say. Um but I think that uh also
to avoid a form of u oligopoly forming
by having uh a few um developers of very
powerful models in fact dictating how
much transparency they can actually give
to the rest of the uh value chain of AI
to avoid that to avoid letting them
doing it on their own we need to make
these rules work uh and I know there is
a lot of attention from um everywhere
outside Europe on how we will deal with
this with the um transparency and the um
uh risk evaluation of the most powerful
models and I think it will be very
important to maintain also I would say a
global discourse on these and see how
much we can extract from these specific
um work of the EU to have some
maybe I hope some common rules at
international level of a basic minimum
level of transparency that we can all
together demand to the developers of the
most powerful AI systems. So as you said
you'll try to balance it uh to make sure
you can keep certain level of
transparency but obviously not allow
some companies to use this as a excuse
uh to do concentration.
Uh Brando, can you also walk through the
fine bands? The 7% 35 million for
prohibited practices, 3% 15 uh uh
million for other obligations and 1% 7.5
million for misleading information. How
will also this proportionality apply to
small medium enterprises? Well, I think
that we will see that uh uh in practice
in the sense that we are also
considering um uh certain um
interventions on the law to simplify uh
its application for small and
medium-sized enterprises. Um and um on
the fines side, I'm sure that we can um
provide enough proportionality with
existing legislation. But we will see.
We will see that it doesn't unfairly
targets
um in the practice the smaller realities
that um can uh uh be uh
disproportionality
disproportionately um hit by two high
fines. At the same time, if I may, we
are more worried to be sure that the
actual uh deterrence towards the most
powerful developers
um that have more market power on all
sides um actually works. So that the uh
respect for the rules will be um strong
also thanks to the deterrence provided
by existing uh fines and uh by the uh
enforcement.
>> Great. Uh Brando, the AI act also bans
certain AI practices completely. How do
you determine uh uh which AI application
should be prohibited versus regulated?
Well, if you see which ones are
prohibited, they are mostly linked to
one factor. These practices are
disproportionately
um
hitting on personal uh freedom of
people. Um so when we ban the
indiscriminate use of biometric uh
cameras uh and we limit them only to
some um criminal uh prevention and
prosecution uh but we prevent a massive
use of that technology. We want to
prevent mass surveillance. We want to
avoid the state or private actors to
actually put people under an um uh
hidden uh mass surveillance. Uh and when
we prohibit um uh predictive policing,
we want to avoid this suppression of the
rule of law and the presumption of
innocence. And so we want to preserve
freedoms so that people that have done
nothing to be uh put into um uh criminal
uh uh control or uh under scrutiny um
are not discriminated because of uh
personal characteristics. This is what
we prohibit with our prohibition of
predictive policing. We do not prohibit
the use of AI for crime prevention, for
uh um amilarating the way the police
works, but we want to avoid something
that discriminates based on personal
characteristics of people. And so as you
see these examples also if I may mention
that also the prevention of use of AI
systems to infer emotions in workplaces
and in study places. They are all having
in common that uh these are use cases
that hit strongly on personal freedoms
on the um freedom of of people. And we
think that in a democracy it's very
important that we uh deter uh this kind
of uh uses and other use cases that hit
uh on on freedom are in the high-risk uh
use cases. For example, emotional
recognition in the activity of police or
for migration are under the high-risisk.
So they are regulated. So in the end
it's it's a discretional
evaluation what to be prohibited and
what to regulate more or less strongly.
But if we want to see a criteria it's
the issue of preventing suppression of
freedoms in a way that can also be
dangerous for our democracies. So
preventing and suppressing uh freedom or
democracy I think is the criteria uh per
se. Uh Brando the big talk in AI right
now for some time has been agentic AI
agents AI agents etc.
Should certain agentic capabilities, you
know, autonomous goal pursuit,
unsupervised tool access or financial
transaction, should they serve as risk
triggers for stricter classification or
even systemic risk designation or and if
so, what minimum pre-eployment tests um
and runtime safeguard should be
mandatory in your view? Well, this is
difficult to say now because we are
still looking at the different
developments of the agentic AI, but I
would say that we need to be strict on
uh seeing where there is an actual
systemic risk of losing of human control
uh or uh manipulation of uh the
developers themselves. It's a um an area
that will need to be interpreted using
the lenses that we built inside the AI
act which is mostly linked to specific
use cases. So we look at the actual use
that a system is u devoted to but we
also look at uh uh pre um uh um
preventive uh measures before
um a model becomes a system. So we look
at um we can say um uh technological um
uh risks that we we see and this is what
we we have done with the uh systemic
risk classification. So um it might be
necessary for the agentic AI to expand
um the use of something we have been
doing very limitedly to reduce
burdens for the business but uh we
should look uh into it and I'm referring
to the use of third party conformity
assessment because mostly this is very
important to Remember the AI act uh
gives um the providers the need for uh
asks the providers to uh deal with um
self assessment. It's uh only in a
limited series of cases that there is
the need for a third party assessment.
Um
and this includes obviously there is
some third party assessment when we look
at the systemic risk in the uh general
purpose AI but probably it will be
needed also when we look at the
developments of the uh agentic AI that
for sure is uh now our area of major uh
attention for all the implications it
brings for uh the uh regulatory aspects.
No. So obviously it's something that
you're going to be looking at uh very
very carefully. Uh you have emphasized
finally uh Brandor that uh
protectingmemes small mediumsiz
enterprises through the AI acts
provisions.
Can you tell our audience just briefly
what specific measures ensure that
smaller companies can compete
effectively while meeting regulatory
requirements compared to these large
companies who have lawyers, hundreds of
lawyers and other people to deal with
this? Well, I think first of all we need
to use tools that are not in the AI act
but I must mention them that are more of
the national sphere but uh we were clear
in many instances that we support the
use of incentives
at national level that can be mainly of
the fiscal side to uh supportmemes
when they start being developed. in this
in this sector. Um in the AI act as I
mentioned uh we uh foresee the uh use of
sandboxes. In fact, we we made them
mandatory for the member states to have
sandboxes so that themes
can um be guided towards um having a um
um a a a product into the market with
the possibility to not have from the
beginning all the regulatory burden on
their shoulders. Um this means also
doing some testing that is done in uh
protected uh contexts that can uh
provide um uh uh tests for the uhmemes
without having to follow all the rules
from the beginning. This needs to be uh
further developed. To be frank, I'm a
bit um uh disappointed with the level of
development of the um sandbox ecosystem
for AI in the member states. They need
to accelerate and we are going to push
them to respect the law and not infringe
the European law and be ready for that
because some member states are already
uh prepared and are doing it. others are
lagging behind. So you see again why
it's important even for creating
instruments for facilitating
uh the uh uh uh work ofmemes
uh to have uh strong enforcement uh
mechanisms so that uh also the uh public
institutions they do their part in uh
the uh correct way. Um obviously finally
I I could mention also the push that we
have put in many instances of the law of
having more transparency on the existing
uh characteristics and risks of the uh
models that are used with fine-tuning
with adaptation by smaller uh
enterprises. Um because we do not want
um as much as possible to have a culture
of the black box of not knowing what
you're doing uh what you are dealing
with and uh uh putting all the risks in
the shoulders of the uh uh smaller
developers or even companies that do not
develop AI. they simply use it and they
see all the risks being sold to them uh
through a market uh practice. We do not
want that and we have tried to make it
possible with the AI act so that the
chain of responsibility is distributed
correctly so that it's not themes to
take the most of the burden. So a lot of
uh effort whether it's sandboxes,
transparency, education is being done so
that uh as you said the burden should
not fall uh at least majority on the
small uh businesses.
Brando there's so much more I can ask
you but uh towards the end we have this
lightning round because it'll give our
audience who have uh who have a lot of
questions for you just yes and no
answers from you. You are such so
knowledgeable about this. So ready
Brando?
>> Yes.
>> Okay. Uh Brando, should AI systems used
in democratic processes like voting
systems be subject to special regulatory
requirements beyond the current AI act?
>> Yes or no?
>> Yes.
>> Okay. Uh do you believe the current
penalties in the AI act up to 7% of
global turnover are sufficient to ensure
compliance by major tech companies?
>> Yes.
>> Okay. Should there be a and you kind of
answered this, should there be a global
AI governance body similar to the IAEA,
the International Atomic Energy
Commission?
>> Yes.
Uh,
should open-source AI development be
subject to the same regulations as
commercial AI development?
>> It's difficult to answer yes or no.
Yes, with some exceptions.
>> Okay.
>> Yes, with some exceptions.
>> Okay,
that's good. Uh, and you are allowed uh
all those answers. Uh Brenda, do you
support mandatory AI labeling for all AI
generated content, not just in
high-risisk scenarios?
>> Yes, absolutely. Yes.
>> Okay. Should individual EU member states
be allowed to implement stricter AI
regulations than EUwide standards?
>> Yes, but with limitations.
>> With limitations. Okay. U is the current
timeline for the AI act implementation 6
months for prohibited systems 12 months
for GPI realistic
that's a hard one.
>> Yes. Yes. It's it's it's okay. Yes.
>> Okay.
>> Okay. Uh should AI companies be required
to share algorithmic decision making
processes with regulators in all cases?
>> Mostly
>> mostly. Okay. U do you think the EU AI
act adequately addresses the challenge
of AI bias and discrimination?
>> Okay. Uh do you think foundational model
evaluations by third parties uh should
become mandatory for systemic risk
models?
>> To some extent? Yes.
>> Okay. Uh should watermarking uh
disclosure of AI generated content be
required beyond deep fakes? Uh Brandon?
>> Yes. Yes.
Yes.
Okay. And should energy emission
disclosures be part of GPAI
transparency?
>> Yes.
>> And finally, should there be a EUwide
safe harbor for firms that fully
implement the code of practice and
promptly self-report?
I'm not sure. Uh, it depends what it
means. So, so no for now. Then we will
see.
>> Not sure. That's okay. No worries. No
worries. Brando, thank you so much for
this comprehensive uh discussion on one
of the most
>> significant regulatory developments of
our time. You know, your work on the EUA
AI act really represents a historic
milestone, not just for Europe, but also
for global AI governance. As you had
said when the deal was reached, thanks
to the European Parliament's resilience,
the world's first horizontal legislation
on artificial intelligence will keep
European promise, ensuring that rights
and freedoms are at the center of the
development of this groundbreaking
technology. and you really have given us
a lot of information addressed every
question uh that was asked and to our
audience whether you're in Silicon
Valley, Singapore, Sao Paulo or Nairobi
the principles and challenges we
discussed today are relevant in your
work and so thank you so much uh Brando
for joining us. Thank you for taking the
time. It's been fabulous.
>> Thank you. Thank you very much. I really
enjoyed it.
[Music]
Black
hey.
[Music]
