Welcome to the Regulating AI podcast
with Sanjay Puri. AI is changing the
world faster than rules can keep up. So,
how do we protect people without killing
progress? Each week, Sanjay brings you
inside conversations with global
leaders, policy makers, and innovators
who are wrestling with that exact
question. So, if you're curious about
the future of technology and how it's
governed, you're in the right place.
Okay, good afternoon everyone. I hope
you can hear me loud and clear and
welcome to the power participation and
algorithm. It's the AI governance for
the people a side event at the OTP
global summit here in Victoria. I'm
Sanjay Puri. I'm the president of
regulating AI and we're totally honored
to be co-hosting this session with Club
D Madrid and I really want to thank all
the folks at Club D Madrid who work very
very hard to put this thing together.
Just want to give you a little uh
perspective what the next 90 minutes are
going to be like. We're going to do
three things basically. We will name the
democratic states of AI now where
algorithms are already shaping welfare,
health, policing, elections. Number two,
we are going to shift from principles to
practice. So, how do we embed oversight,
accountability, participation, and
rights into AI systems? And finally, a
road map, not just a panel, but towards
a democratic AI governance framework
that aligns with open government values
and continues beyond this summit. And
here's uh basically the format of the
afternoon. You'll hear cross- sector
views from former heads of government,
academia, government practitioners,
civil society, uh, and part of the OG.
Uh, and we'll run two fast rounds of
discussions. Uh, and then we'll open it
up for Q&A and then some crisp takeaways
uh, in a concrete next step. Our round
number one will be focused on safeguards
and trust. What immediate guard rails
are needed in public sector AI right
now? And round two will be participation
and power. How to include citizens,
youth uh meaningfully and how to keep
institutions accountable while enabling
innovation.
So and also then we'd love to hear
questions from you concise
solutionoriented.
And then finally two and three uh
closing commitments. With that, let me
welcome our truly esteemed panelists.
I'll welcome Prime Minister Mi Jama.
He's a member of Club Di Madrid and
former prime minister of Tunisia. Also
want to welcome uh Iwan Bamuji. She's
the program secretary off official
special programs presidency of Kenya and
she's also part of CDM's wide network.
And u I want to welcome Augusta Nadi. Um
she's a special advisor strategy and
communications for Southeast Development
and Commission Federal Republic of
Nigeria and also part of CDM's wide
network. And uh Alex Rosh um he's the
associate director of the center for the
governance of change for IE University.
Um and then Tim Hughes, democracy and
participation lead for the open
government partnership. I hope I got all
the names right, all the titles right.
If not, please uh let us know and we'll
make sure of that. We'll begin with you
uh Tim. Um since you're with OJP and we
want to defer and thank you for hosting
us. Um Tim, what safeguards are most
needed in your view to maintain and
build civic trust in AI enabled decision
making?
Well, um, thank you very much for having
me and thank you first of all to
Regulating AI and Club Madrid for
organizing this side event. We're so
excited to see everybody here for the
OGP summit. So at OP, our approach to
algorithms, AIS that of course they
offer such a tremendous benefit to
society, but unless we think really
seriously about their governance, they
also offer um the potential for
tremendous harms to society as well. And
particularly when we think around what's
needed to to kind of drive forwards um
innovation around algorithms and AI
often we look to resources like data
skills and capacity but actually public
trust is one of the most vital resources
that we need to maintain through this
process. So, we actually have a uh a
resource that OP develops to support our
members when they're developing reforms
around issues like algorithmic
transparency and openness um called the
open gov guide. Covers lots of other
topics as well, but includes uh a number
of recommendations around reforms,
safeguards that governments and civil
society can introduce to ensure that
algorithms and AI are governed in the
public interest. So, I thought I'd talk
through just a few of those. um a few to
uh that I've I've picked out I think is
potentially important. Um but um please
do do have a look for the for the full
list. I think it's important in this
conversation to think about the some of
the kind of underlying
um uh protections that are needed as
well. So not just immediately jumping to
thinking around AI and algorithms but
actually some of the data governance
that's needed um to to to be in place to
begin with. So of course having that
foundational level of strong of a strong
legal framework for data protection is
absolutely fundamental through all this.
I think we need to to remember that um
that element is needs to be essential at
the foundation.
On top of that, then we can layer other
reforms and particularly when we're
thinking about the open government
principles of transparency,
participation, and accountability. A few
reforms that um link to transparency are
things like requiring data processing
reports, creating registers of
algorithmic um use by government,
requiring notifications of when uh when
decisions are are subject to the use of
automated decision making or algorithms
as well. So having that first kind of
fundamental pillar of transparency
around who and kind of when um uh
algorithms since AI is being used
particularly in in the public sector.
Then the the second level or the second
kind of set of instruments in relation
to participation we can think about of
course involving the people who are
subject to those algorithms in in their
design ensuring that actually up front
in the process. We're thinking about the
potential harms that they might cause
and ways that we can we can mitigate
them. But also thinking about actually
what is the public interest in this and
not just taking that for granted but
actually having the public involved in
that conversation. we can think about um
having uh the opportunity for regular
audits and also public complaint
mechanisms to make sure that when issues
do arise. There is red address um and
opportunities for the public to uh to be
able to um to to kind of call attention
to that. And then finally the kind of
pillar of accountability.
Um there are reforms and kind of
government structures around ensuring
that there are regular impact
assessments produced. This is something
that Canada committed to actually via
OGP a few years back. Again having
redress mechanisms in place. So there's
accountability um chain as well. And
these are all different reforms, reform
areas that a number of governments and
civil society have contributed reforms
to via OGP already. And actually on our
on the panel today, we we have a number
of uh countries that have made
commitments exactly on these issues.
It's fantastic to to see colleagues from
those countries. And I'll say a bit more
about that perhaps later.
>> Well, that's very helpful. You've been
busy with many many panels. Um Yuwan
we'll turn uh to you. Um tell us how can
governments ensure meaningful citizen
participation especially from
marginalized and excluded groups uh in
the design and monitoring of AI systems.
>> Okay. First and foremost I want to thank
you for having me. Um
and I I I'm speaking as a young person
coming from a country that is very open
to AI. Uh Kenya is seeking to not only
uh be a not only take part in the
growing AI but also be a playet in the
whole of Africa when it comes to AI. But
uh we are having so many challenges and
in my context the marginalized people in
my country are usually youth, women and
of course the people living with
disability because we find that um
in most cases when we are coming up with
systems and when we are building systems
they tend not to be involved during the
the initial stages of the or or rather
during the uh the participation or
rather when we are coming up with the AI
systems.
So one of the things that we really want
uh governments to look into is the
inclusive participation
when we building frameworks.
AI is a little bit complicated if you
don't break it down to people in
languages that they do understand. So in
my context, I would really want us to
also look at uh translating languages
and having people communicate in
languages that people understand and
also let's let's talk to people about
things that they interact with directly.
If it is farmers, let's talk to them
about the system that are actually
affecting them during their farming and
in making sure that they getting the
smart funds and all that. If it is
health systems, we want to talk to
people on the benefits of using AI in
health so that they understand from the
very from the very grassroots on how
this AI is going to affect them. We had
an issue. I remember in one of the
villages in my country where we had a a
medical camp and they had this robot
that was used to like take uh samples
and scan people for cervical cancer. Not
it was not cervical cancer. It was I
think it was a robot basically. And we
had a lot of issues because people were
feeling that they're they're kind of
used to human interaction. And now when
you bring in something that is kind of
strange to them then we experience a lot
of resistance from the people. So I I
feel like when we go to the grassroots
it's good to talk to people in a
language that they understand. Another
thing we could do is when we are coming
up with AI systems let's co-design
together. In most cases you find that
you bring the marginalized people at the
very tail end and you tend to forget to
bring them on the table when we are at
the very beginning. So I would I would
urge governments to bring everybody on
board from the onset. If we are building
something, let's bring everybody on the
table from the from the first day cuz it
is easy to give somebody something that
they have taken part in building rather
than building something and then you
give people to consume. Yeah. Another
thing I would really push for
governments to do is be transparent and
accountable when it comes to these
systems because
if we understand something then we will
not critique it. We will not fight it.
But if something is forced to us and we
really don't understand how it impacts
our lives then it becomes very difficult
for you to take it in. So when it comes
to systems uh building policies uh using
it during uh in public like know when
you use AI in uh public service it's
good to make people understand the
efficiency that comes with that so that
they you face minimal resistance from
the people and I believe when we
understand what is being given to us
then it becomes very easy for us to take
part and walk the journey together and
um maybe lastly I could mention
about capacity building because um we
have very many people that come from
places that are I'd say they're not
literate and it it's difficult to to
tell them something that they do not
understand. So we need to invest. We
need to come together as civil society.
We need to come together as government.
We need to come together as
organizations that are pro AI to make
sure that we build capacity to people
from all levels of education from the
people in the villages to people that
have not interacted with a computer. We
need to sit down with them and take them
through things at their level. Yeah.
Thank you.
>> That's uh two great points you many
others but you know bring everybody on
board right at the beginning and
capacity building. Um Augusta turning to
you uh in contexts where citizens are
skeptical of institutions and there are
a lot these days. How can strategic
communication and narrative you know
framing help prevent misinformation
about AI and build trust in democratic
governance because trust is pretty low
right now.
>> Yeah, thank you very much for that. Like
you said, trust is pretty low in
government institutions. But funny
enough, in Nigeria,
when governments release press
statements and documents, you find that
people tend to ask the AI if those
things are true, funny enough.
So you see that people actually do trust
AI more than government which in a way
puts us in in a sort of unique position.
So what I would say is for the policy
making process when you're talking about
strategic communications as relates to
policym
you cannot remove the human out of it.
So if you're talking about framing AI as
a sort of or to combat misinformation
that AI may give out it's it's a is a is
a partnership. So the government cannot
remove the AI and they also can remove
the human human face. Let me give an
example. So say for instance now we want
to make a policy on say elections.
There's going to be an extensive
stakeholder engagement. The extensive
stakeholder engagement is simply so
people can claim ownership to whatever
policy document is put out at the end.
This allows people to see the process.
It makes it transparent and it allows
people to see how the policy was crafted
from beginning till the end. Where AI
comes in is after all these ideas are
collected
the AI can now refine it and can be used
as a monitoring and evaluation tool.
This way people can see AI and say oh
people can see that policy and say oh
yes I was part of this policy I was part
of that policy and even when you're
hearing that that AI2 was involved or
AI2 is used for the monment evaluation
you still have a sort of ownership for
that. So
>> it's allows you sorry I think my mic is
thank you.
So it allows you to sort of help people
build trust trust in the government
because like I said people trust AI not
in the government trust in the
government where they see that these
policies we've done very transparently
and also in the AI. So one of the things
now that my office is doing that's
southeast development commission is
we've done an extensive stakeholder
engagement in in terms of infrastructure
development asking people what do you
need at this particular point and how is
it going to impact on you. So when we're
done with all of this what we did was we
built a tool that allowed people to now
monitor the deployment of those projects
in real time. So that's an AI tool. So
you will see where people now come and
ask the AI is this happening is this
happening and it gives you real time
data because real time updates rather
because at the end of the AI works based
on data you feed it. So if you feed it
the correct information and that's the
responsibility of government or whoever
it is that wants to deploy it here. If
you fit in accurate data, accurate
information and do your stakeholder
engagement extensively, I think it
solves that trust issue. Thank you.
>> She said people uh in Nigeria trust AI
more than the government. Wow.
That's
that is something to seriously think
about. Uh while we're thinking about
that, let's uh go to Alex. Um
Alex from a academic standpoint how can
universities research centers contribute
to you know building not just technical
expertise here they teach a lot of great
people but also ethical civic and
democratic literacy around AI so that
the future leaders and citizens can
actually participate in governance.
These might not be the sexiest courses
for people to take. they want to take
machine learning and those kind of
things but these are also need to be
kind of wounded. What is your
perspective on this?
>> Sure. Thank you for the question and and
thank you to regulating AI and to the
Mad for inviting me to join this panel
and I'm very happy to be here. Uh so I
am associate director at the center for
governance of change. We are an applied
research and educational institution
based at I university in Madrid and we
study the impact of emerging and
disruptive technologies on society on
political systems on economy and
sustainability, international peace and
security and so we we coordinate
research projects and we also put
together um tailor made executive
education courses for high level public
and private decision makers. So I want
to talk a little bit about some some
examples
uh so you can understand how we we try
to have an impact on on policy. We try
to have a positive impact. We try to
make uh decision makers and not only
decision makers but the way the public
understand uh where technology is going
and what we can do right now as as
decision makers but also as citizens to
shape um the the kind of technology that
that we want for for society. So uh for
a number of years we've been
collaborating with Microsoft on a number
of projects uh all around how technology
can support democracy affirming um
excuse me how technology can support
democracy. So how how we can develop
democracy affirming technology. So this
started back in 2021
um in the framework of the summit for
democracy that President Biden has
spearheaded and we organized
venture days sort of like startup
competitions all around the world to
identify some of the best entrepreneurs
uh using technologies such as AI,
digital technologies etc. uh to promote
democratic participation to promote
privacy to promote transparency and
since then we we've been uh we've been
we've continued working on along along
this path we've had a project called AI
for democracy which focused more on on
on how AI can support democracy can
support the security of elections uh can
support participatory decision making
public participation uh that that was
mostly a research project and we are
continuing right now with uh another
research project called AI for
democratic prosperity and what we want
to do is understand how now in the age
of AI uh we can use this technology to
to promote societies that are
uh stronger uh economically but also
politically more cohesive um
and see how those two tracks can can go
together and whether they influence um
each
We've had also other more applied
research projects uh working with cities
in Latin in Latin America uh with the
Interamerican Development Bank and the
the director of that project is actually
coming to the to the summit that we're
putting together an event tomorrow that
I I invite you to join on AI
participatory audience of AI. Um and
then we we are also currently uh running
a project with the European Commission
trying to understand how the civil
servant of the future can use AI to make
uh public service delivery more
efficient. And then we also um as I
mentioned earlier put together um
executive education programs for for
leaders in in companies that want to
understand uh how technology is
transforming society. uh also for high
level uh decision makers in
international organizations. We put
together projects for executive
education programs for for the UN etc.
And um and lastly we you know we
participate I think it's very important
to to have events like this one know in
which uh people from government from
civil society academia um experts uh
share insights with with the public.
So just to quickly just briefly follow
up should it be mandatory for let's say
when you're doing an undergraduate
you know m AI machine learning or
computer science or a graduate degree in
Stanford or Oxford or whatever to have a
course on AI ethics or governance.
>> I I I believe so. Uh I think if you
study if you study anything that has to
do with technology AI, machine learning,
large world models, what have you, uh
you should also understand the impact of
of that technology, you know, and not
only focus on the technical aspects but
also on the societal
reach and and and impact of a wider
level.
>> Great. Well, we'll turn to um obviously
uh Prime Minister Prime Minister, you
know, with your background and AI is
crosswater. You know, it doesn't seem
you've heard what's happening with kids
in Nigeria, what's happening around the
world. How can democracies cooperate
internationally to you know establish
shared norms and standards? And we are
kind of living in a world where
countries are moving inwards not
outwards. So how do you kind of propose
uh and is that important?
>> Thank you. I'm happy to be with you to
discuss uh such a technical issue uh
artificial intelligence because why I'm
saying technical because uh from my
background when I was uh in another life
I was working for the aerospace industry
and we started with the noral network
that's the father of artificial
intelligence it's uh it's um
beautiful to to put it artificial
intelligence And at that time it was
really an engineering issue. Even inside
the company it was not understood by
everyone and then now it's it's more
than technical. Yes, it's still
technical. is part of many cle people
working on that engineers doctors to
develop these algorithms but it's now a
social political and no more a company
or global it's a global question and uh
I think that today we are at the stage
or at at the step or at the level uh to
leave another big revolution
uh we are quitting or at the end of of
the digital revolution and we saw how
quick it was compared with the previous
like the industrial revolution and this
one will be more transformative and more
quicker and really it's impacting all
the sites and all aspects of life. It's
not only technical but only tools uh
it's impacting our style of life, our
way of life, our work, our way to to
work. So to to to to to summarize for me
it's a premium political question more
than a technical now uh since it affects
all these aspects of life and it's
global and your question is really
pertinent because today uh we know that
we have this uh when it's global how to
manage this uh interfaces or border
compliance how we will deal with that uh
you a period which is difficult because
we know we are under pressure and
stressing the the all the organization
that we get after the second world like
UNESCO
many organization uh at the meantime we
need really a large and wide
collaboration between countries region
and different spheres of that so it's
mandatory it's one of the biggest
challenge we know that we have to manage
that Ross uh we don't we don't dream we
know that we don't we will not have
unique uh rules unique standards for
everyone but it's not a problem if we
can manage these different standards we
need rules we need standards uh to avoid
uh this uh it's more than a tool this
technology or this new way to hit
technology uh to have negative impacts
and even with the digital we saw that it
was a big opportunity to progress but in
the meantime uh it brought some
disadvantage and when we speak about
democracy let's speak at least about
election we know in many countries it
has with the disinformation with fake
news and many compacts and I can speak
about our own experience our nation
democracy in Tunisia in the last
elections in the competition the the
digital uh tools were more used for fake
news to attack than to share uh problems
and vision which is a problem but we
will not neglect that because of that we
have to pay attention and to say how to
put and to fix all of that with a frame
of rules that we have to respect. So
coming back down to the to the problem
between countries and uh and area uh I
think we have to regulate we have a
minimum uh to to regulate between
countries but we have to be sure and to
work on the consistency of this
regulation. Let's uh let's take an
example for me it's like the passport
each country has its specificity and has
its passport but it's recognized it's a
trusty to change that's on my sense the
configuration that we can imagine but
it's founded on the respect on
fundamentals
uh respect of human the respect of
citizens uh the accountability the
transparency uh the fundamental of
democratic rules that we have
instrumental respect taking into account
our specificities. But we have to create
the spaces and the platform when we can
make all this consistent
flowing uh without without problem and
uh it's the task and uh the
responsibility of the democracy to pay
attention to that. If we don't do that,
someone else will do. And you see today
the weight of this large corporate
companies and uh the interference with
the political sphere and sometimes we
don't know whether the power is under
the political or under these companies.
So it's really complex one but you have
to pay attention to work on that. and
for me uh and with the discussion you
know I'm part of a patre and we are more
than 100 previous leaders head of
governments and presidents from
democracies and we discuss this issue
daily and
we are convinced that we should go
through the existing platforms even
though there are we have many platforms
today with some trust because we have to
create this coalition of trust like uh
African Union, European Union and UNESCO
all these organizations
let's renew them and use them as a
platform to make this global consistency
and so we don't agree as well that we
have to put these rules to avoid that
this IA
be transformed on only commercial trade
or profit which is good but it's not
enough and as well will be transformed
and use it uh to oppress or mass
oppression or disinformation
and uh instead of that we think that we
have to have to respect these rules. It
should be human, citizen oriented,
globally consistent and uh rooted with
fundamentals of human and democratic
purpose. That's most important for for
me. It's a big technologic
transformation but it's bringing another
way to see things. Uh we speak about
democracy but uh even you know it will
creates opportunity but threats uh we
are uh reading that maybe in in some
business we can replace
10 and artificial how we take profit of
that and not create more cracks more
imbalances between people inside the
society but between the countries and
Again,
if it's not fair, if we don't think and
put the to
this uh the frame for to avoid derative,
it could be dangerous, but let's focus
on the opportunities the air and put
this frame and don't forget we have to
be citizen oriented
and globally consistent, respecting
and building this chain or coalition of
trust to be successful.
>> Thank you. That was uh pretty
informative and a very very important
topic. I have some follow on but I'll
come back to you. Um Tim, just uh
following on um some of the things you
talked about, you know, from your
perspective at OGP, how can open
government reforms and multistakeholder
processes be used to ensure AI
governance strengthens trust in
democratic institutions according to you
know your work.
So I think ultimately it comes down to
one of the points that was mentioned
earlier that if change is done to people
then often that leads to reductions in
trust and also the opportunity that
harms and um issues arise. Whereas if
people are involved in that change if
that change is driven by people and
their interests as well then it's much
more likely that public trust will be
maintained through that process. And I
thought I'd like to kind of illustrate
this with um actually a few commitments
that countries have made through OGP um
to date. And for those who know OGP
well, you'll know that fundamentally OJP
is about action. It's about supporting
government, civil society to come
together to agree reforms um to to to
really put into practice these
principles of transparency,
participation and accountability.
actually saw a colleague from Colombia
at the back of the room um earlier and
they've been working on this issue uh
very recently have made a commitment um
very recently through the through our
open government challenge um to
establish a multistakeholder
um forum for governing AI um in in
Colombia. Similarly in Nigeria um we
have a very similar commitment of
government and civil society
collectively agreeing to establish a
multistakeholder process for the
governance of digital transformation in
Nigeria ensuring the right people are at
the table to to make sure that that
process is happening in everyone's
interests. very similar commitments
actually a year ago from Kenya in terms
of their their digital transformation
process. Again ensuring that that was
done with academia at the table, civil
society at the table, business at the
table, all of these different
stakeholder groups ensuring that the
right knowledge, the right skills, the
right expertise was there um to guide
that process.
And um for all of the all of the sorts
of reforms I I discussed um a little bit
earlier, there are examples from Canada
to UK um to uh to New Zealand and and
others who are embedding these different
mechanisms for ensuring good governance
of technology. That's kind of ultimately
what we're talking about ensuring these
technologies which are incredibly
powerful are governed in the way that
that makes the the most of that
potential or reducing the harms. So I
think really significant opportunity. I
think uh if you attend the the the OGP
summit this week we've got a number of
sessions tackling exactly these sorts of
issues where you'll hear from some of
the countries themselves as well talking
about their experience of actually how
open government reforms are are helping
to to build and maintain public trust in
in technology and AI.
>> Thank you. A lot of good sessions as I
think you said worth attending.
one uh coming back to you. How can um
and what role can young um you know
decision makers in civil society play in
setting up governance frameworks so that
these frameworks are forwardlooking as
well as you know they are inclusive
frameworks so to speak.
>> Okay. First and foremost, I want to also
share the sentiments of my friend Austa.
It is also in Kenya where people trust
AI more than government. People will
trust civil society more than
government. So one of the major roles of
young people right now is to create
awareness because I feel like young
people in I come from a country where
like 55% of the population is that young
people and they are the highest
consumers of AI systems and so I feel
they have a role to play when it comes
to digital literacy. I personally teach
my mother everything on her phone and
she gets so mesmerized when I I tell her
you can do this, you can check please,
you can you can you can look at your
phone and it's it's going to tell you
how long you walked because sometimes
she'll come home and she'll distress.
The doctor says I need to walk for 2 km
every day and I don't know how to check.
Then I'm like open your phone let me
show you. You could actually follow your
steps on your phone and she gets
mesmerized. You think the sun came down.
So I think one of the major goals we
have as young people is to create
digital literacy. It's unfortunate that
uh we have diverse people in our in our
countries and I especially I speak for
my country Kenya. We have people that
have never seen a computer in their
lives. So we still have a long way to go
when it comes to bridging the gap
between the digital literacy and also
creating awareness on the AI and the
systems that we are creating and also
the policies that we are creating around
AI. It is difficult for you to talk
about AI to someone that is not digital
digital literate and through this now
the government has come up with a lot of
programs that are trying to get as many
people as possible to be digitally
literate. We have creation of digital
huts that are being set up in every
constituency. So this ensures that every
person in every part of the country has
a touch of what uh digital literacy
really means. And for our government
systems, we used to have like uh people
walking into government offices to get
services. But uh 2 years ago our
government went digital. So for you to
get any government service you need to
actually interact with a computer. So
through that it has forcefully or rather
pushed everybody to being uh literate or
rather interacting with someone who
helps them get services from government
through uh the digital system. So I feel
like that is something that the young
people
being the people that are very
aggressive when it comes to technology.
It's an assignment we have as young
people to make sure that everybody else
behind us is able to interact and learn
more on everything that they need to
know in the digital space. I uh the
other thing would be the ethical
oversight.
We have so many so many tools in AI that
are used even in monitoring and
evaluation. As she said when it comes to
even uh public uh service and service
delivery government, we can create tools
through the partnership of young people
and the civil society to basically audit
what the government is doing. And when
we audit uh what the government is doing
through an independent body that is a
civil society and the young people then
we gain trust from the public because
we've had a situation before where
government comes up with projects then
it's still the same government that
comes back to us to tell us the success
levels of those projects. It becomes
difficult for me to create something
then self audit myself. So when we come
together as young people and civil
society, technocrats and create systems
that actually audit what government is
doing, it becomes easy for us to
actually uh measure and even see if
whatever policies that are being put in
place by government are able to impact
in our lives directly. Uh, another thing
I'd say is, uh, partnerships and
collaborations, which I think is very
key, especially for for us who come from
countries that are still developing. The
collaborations and partnerships from
developing countries goes a long way.
We've had organizations like Microsoft,
the Ford Foundation give donations even
for computers that are specifically sent
to regions that are marginalized. So
some of these collaborations and working
together has also seen a lot of impact
in those marginalized areas and are
areas that if we they depended on the
government it would take longer for them
to see the positive impact. So we really
appreciate and part of the
collaborations is what we are having
right now because for us to get here of
course it has taken a lot of uh uh
collaborations from club Madrid from
regulating AI to make sure that we are
on the table and that we go back home
with more knowledge and more ideas on
how to make things work better. Yeah. So
thank you so much.
You know I can't resist asking u you
mentioned in your country also u young
people trust AI maybe it's a global
south phenomena it's a young you know
the population is very young
what does it say about the government
and what these young people are trusting
AI which is kind of controlled by five
companies in the world that information
is kind of controlled by them so that's
something for us to seriously to ponder
about. But while we ponder about that,
let me u ask uh Augusta, how can AI
governance frameworks integrate
communication strategies that can
counter disinformation and polarization
uh ensuring that you know citizens are
receiving accurate and trustworthy
information? It's kind of a follow on to
what I'm kind of uh getting at.
>> Yes. Yes. Yes. It is a photo. Okay. So
like I said earlier,
AI depends on the data that's that you
feed it. So regardless of how
intelligent a system is,
if you don't feed it the correct
information, then it's prone to, you
know, producing wrong information.
So,
>> so it now it's now the responsibility of
governments in this situation to make
sure that accurate information is always
available. If people have access to
accurate information and say for
whatever reason they choose to act
Grump, they choose to act tragic, they
choose to act Gemini, Gemini has access
to those accurate information. So where
we start having misinformation more
often than not is when government gives
little to no information about
particular about particular situations.
Then you tend to see civil societies
political activists or people that might
not necessarily have the best interest
put out all sorts of information. All AI
will do is to scan and produce what it
says on the internet. So how we can
combat that like I said is if we can
provide accurate information timely
accurate information. I'll give you
examples in Nigeria. Yeah, I don't know
if you know this, next year is going to
be campaign year in preparation for the
2027 elections. Now, we've already
started seeing a lot of prominent people
come out to establish that they want to
run for elections. And of course, AI is
a tool in the hands of these people. You
see false pictures, you see funny
stories coming out and all of that. And
what tends to happen is that if you
leave these things, if you're silent
about this misinformation, people take
it as truth because like I said, the
average person is going to believe AI
more than government. But if you see a
mis if you say a wrong information about
yourself and you come out with fact
evidence and say, "Oh, this is the time
stamp. I wasn't here. I wasn't there."
and bring us accurate information then
people are logical human beings at the
end of the day and they will believe
you. So it just depends if government
want to or whether if we want to cuz I'm
part of government if we want to comp
combat misinformation we must put out
accurate in a timely manner. It's very
important that it's timely so it doesn't
feel as if you're just doing damage
control. It's important that you don't
you're not reactive to things that you
preempt that this can be misconstrued
this can be mistransated
and you combat that. So you giving
accurate information that are clear that
are direct and so if anybody is just
going to AI AI you just say this is
what's happening.
>> So accurate information and timely
information I think is what you're
saying you understand. Yes. And that's
actually the the only way that we can
build trust in government institution.
Transparency. This this ties back to
transparency and accountability. So even
if the AI is going to audit you, it's
going to audit you based on what you
said you're going to do and how far you
have done it. So if you say you're going
to build a building and you have
pictures with timestamps with real life
human beings on that project site, the
AI is going to come and say yes, you're
actually building it. It's not going to
say you're not building it when you have
timestamps and accurate information
available. And even if the AI says that,
human beings can come out and say,
people involved in that in that project
can come out and say, "Oh, no, it's
actually going on." So if you if you
involve humans in the transparency
process and you ask AI to audit, I think
that's going to solve the problem.
>> Do you think it'll make governments more
accountable?
>> It's going to make government more
accountable if government know that
rather than rather than the average
because we have a freedom of information
act where everybody can write to the
government and request documents from
the government. So it's got to be able
to go through that. This brings me back
to why I said people believe AI more
than government. So you want people to
go through that whole process and
government keep saying oh we'll get back
to you we'll get back to you get back to
you they just go at charge but if all of
this information are say on the
government website the just pick the
information from where it is and just
release it to who is asking. So it costs
a lot of process. It's it makes
government sit up because then I know
that if I don't have this information on
my website and AI must answer is just
going to answer something that's maybe
off point.
>> That's pretty I think very important uh
what you just said. Um, Alex, uh, from a
research and innovation perspective,
what governance models or regulatory
experiments do you see merging globally
that could help balance? You know, the
there's always this dance between
innovation and democratic safeguards or
innovation and regulation, innovation
and you know the pull and push. What do
you think? How can that be balanced?
>> Yeah, I can I can mention a few
examples. So first for example um AI
renovator sandboxes sandboxes uh so time
limited controlled environments in which
firms or developers can experiment with
with new models uh under regulatory
supervision before these models are
released to the public to identify
um potential risks, develop mitigation
strategies. Um this this can be very
helpful. Uh for example, the EU AI act
includes regulatory sandboxes uh at the
member state level. Um second AI impact
assessments uh I think are important for
for companies develop developing AI
models for for entrepreneurs for
innovators. Um again so so it's a a
mandatory process before launching um an
AI system to identify risks from you
know risks from from different types of
nature. So it can be privacy can be
biases etc and mitigation strategies. of
ways to address um those risks and and
team actually mentioned this earlier.
Canada since 2019
uh mandates that in every single
instance when a federal agency is is
thinking about incorporating
uh an AI model that that makes decisions
takes decisions to to to to have a an an
impact assessment. And this also creates
an an audit trail that can be um taken
later to to to make sure that things are
moving the right way and things are
improving. Um and and lastly um there's
also many good examples around the world
of different uh participatory processes
like uh citizen assemblies, many
publiclix, multi- multistakeholder
engagement processes that uh make sure
that
AI regulations uh have the legitimacy
that of of of public participation that
that citizen values are fed into the the
design and the development. of of of
policies. uh I'll just mention one
example Brazil uh when when they were
putting together their AI had a very
large um participatory process in which
NOS's expert citizens in general were
able to to um to you know have their
have their say again sorry for the black
but we'll we'll have a a a session on
this tomorrow with with connected by
data on AI governance that is
participatory and and deliberative.
Thank you. Um, Prime Minister, you know,
there's a big global south
representation here in there. How can we
make sure that the input or the voice of
the global south is also there in these
governance frameworks uh to make it more
inclusive and right now it's we only
thing we hear is the US EU China EU you
know US EU China US EU China. So what do
you think? Uh because the users are
here, the producers are here. So the
users tell you the customers should be
dictating the voice because the
customers are here. Look, they're all
telling you.
>> Yes. I think if you want to speak about
the global south uh the question how to
do is larger than the question of uh
artificial intelligence that's the first
remarkable we come back to that secondly
I don't know if you consider artificial
intelligence if you consider China as a
part of the global south or not and
India as well if you consider of a
global south or not but let's
uh take the same perimeter of the global
south and the speaker I I think it's a
part of uh the transformation of the
crisis of the transformation
transformation that we are in because we
are moving from system corresponding to
decades also where uh the world was
different uh we don't have the same
political military and economic powers
now we have many emerging countries we
have certain prevalence
We have the demographic as well pressure
which is different to know here in
Europe United States we are in a big
demographic crisis in the mean time uh
in large part of Asia in Africa we have
we have growth of
of the democracy.
So what we hope is that we succeed
to uh to the transition from the old
world to the new world without damageful
large damage for crisis. That's the risk
if we are in the dialogue or the even in
a hard dialogue like we can imagine
because the interests are big. Uh I
think artificial intelligence could be
one of the tool one of the vectors that
we can use to make this uh transition
easier. Why
again maybe it's a question of big
investments in the data center in energy
producing
but when you see it's based as well on
human resources engineers and developing
uh if you take what is happening in the
United States and you make the zoo yes
it's made by United States big companies
but see the people inside
they are large part of them or part of
them are coming from the global south.
So it's a big interaction and we can use
that as really an advantage uh some uh
some uh some some advantage to help in
this big transition.
uh that's globally but if we speak about
the global south inside the global side
uh the global south we have to do things
in the right way uh we have to deal with
the different components of this global
south to be sure that we will not create
again this big gap between inside the
society but between the society which
should be based on the shading of
technology, transfer of technology, uh
capacity, uh building and as well to
focus all together to have the weight in
uh what we spoke about by the beginning
u of our meeting uh how to help to build
this global regulation and we have to do
it inside the global side. Why I said I
have to do it? I'm coming from Tunisia
and I'm from from south. So I'm I'm an
advocator of the global south. It's not
to create another power against another
but it's an opportunity to repentance
and to make more integration more
inclusive
global society more inclusive country by
country society. So this idea of the
global size for me is is a real
opportunity for all of us. It will not
happen in an easy way and I hope that we
will avoid wars because if you see the
history uh such big changes generated
wars and I I think that we have enough
wise today to avoid that but it's really
our task even to do things well and to
bring our weight and to use all uh this
uh cross competences this cross people
that we have from each side to build
this bridge and to build the new future
together which is fail and the inclusive
future of governments.
So a general question um kind of
following up any of you can answer all
of you can answer is how can we have
some uh governance frameworks that
prevent this concentration of power
because there are five companies I mean
if you thought social media is
concentration of power AI is going to be
because it takes tens and tens of
billions of investments uh which are
already being made. I mean look at the
investments that close to 2 trillion in
the next few years in data centers and
others.
But there are serious implications for
that too because we live now in a
geopolitically
world where there is this has become a
geopolitical issue. So are there any
frameworks that can be applied to
prevent concentration of problem?
Yes, you are right because even when we
listen to uh all the speakers and even
me we are speaking about we suppose that
the governments should do the
governments had the power and we are
coming from this organization where
there was a concentration of power but
it's no more true today when you see uh
the power is more under these big firms
big companies And behind them even the
press the media they have control more
than the governments and maybe in the
previous time governments were making
this uh this entrepreneur now my feeling
it's more entrepreneurs are making
governments through their influence
through this and we see that let's say
if you take the example polics and uh
even in Europe uh it as political
position and using his power to push on
side. So today that's the real thing
that we have to think about. It's not
only among countries, among governments,
it's as well how this society will be
organized. These companies uh and we
spoke about America but even in China
the difference that in China there is
some consistency balance or authority of
the political still
good. So you have this political power
who is organizing things and moderating
that and the real challenge is that and
I think that the users will have power
uh see even in politics now we are
speaking about generation see what is
happening in the world in Nepal they
were able to transform things within
economics and I think That's the
leverage that we have on this company. I
cannot I I cannot rely on any government
in the global south to push these big
players to change. No, it's it's not but
the users. Yeah. So how we think uh to
to to mobilize the social to make them
aware we can be surprised on the power
which was not existing but this
way of doing this tools this offer on
the market with this new generation
could create another leverage that we
could not imagine before which would be
and if there is a reflection is in that
direction not counting on the
governments they are not part of that
table due to it is definitely awesome.
So let's see.
Awesome. I can keep going but we do want
to get some uh questions uh from the
audience
uh if we have some otherwise I'll just
keep going because I got a zillion
question for you guys but audience
questions uh from any of you.
Okay, I'll continue on and if you have
some, please uh let us know. Um Tim,
this is really for you. I mean, we are
living in so to speak an algorithmic
governance kind of a model as we keep
moving on. How can you know democratic
institutions whether it's
parliamentarians, regulators, watchd
dogss adapt to these challenges within
this kind of an algorithmic framework?
I think this is a really interesting
question and I think I'd also link it
actually back to the the previous
question um you asked because I think
one of the ways that we can think about
government governance of these
technologies is actually expanding the
the toolbox that we have at our disposal
and particularly from the government
perspective. I think an area we often
under kind of underappreciate is the um
the power of government procurement of
technology to actually also regulate how
that technology develops. So there there
are governments at the moment signing
billions of dollars contracts with AI um
companies and actually there is a huge
amount of power uh at that point to
really determine well first of all who
you're buying these technologies from
but then on what basis um that's that's
done how they're going to how they're
going to operate but also importantly
how the data as well is kind of being
transferred from from governments and
the public sector into the hands of
private companies because that is also
handing over significantly more power um
to these companies. So really thinking
actually kind of quite imaginatively
around some of those different ways that
we can um we can have an impact on how
these technologies develop. I think of
course there's a role in building the
capacity of our existing institutions to
be able to to regulate and kind of first
of all understand these technologies
more but then to to regulate them uh
sensibly. So whether that be parliament
um or or government but then I think we
also need to look beyond that to um to
specific oversight institutions that
have can bring both the technical
expertise but also of course as we've
been discussing the governance and the
ethics expertise as well. Um so we're
not just leaving this in the hands of uh
decision makers who often do not have
access to all these different um
perspectives. I think the links to that
as we've kind of discussed quite a lot
already the role of kind of
multistakeholder approaches to this and
not just being reliant on the old ways
of making policy the old ways of doing
regulation but as we've said making sure
different interests are at the table to
be able to offer the different expertise
um that they bring. Um yeah.
>> Great. Um any questions? Well, I'll I'll
uh give an open question and any of you
can probably respond. So, if we fail to
get AI governance right, what do you
think is the greatest risk um for
democracy? And if we get it right,
what's the greatest benefit for building
trust in institutions?
Any of you?
You know I will start by some things
today. The problem is we know to get the
power the power is under the hand of who
get the information.
The governments was powerful because
they had intelligencia
interior army. Now we have this company
has more than the government
information. So we have to to pay
attention to that and
I think coming back through the
institution and through all these
platforms we have really to negotiate it
as an emergency or important issue to
regulate.
Otherwise we will leave a heavy weight
of this new technology on the democracy.
Really this couple of last year so many
elections even mature or develop a
democracy impact
of the dig digital tools.
All of us we are aware we are aware
aware of that. So you can imagine with
uh with this uh with these tools with
intelligence I saw some some
demonstrations in uh
>> some companies they produce
a cop you of your speech of your vocal
signature and making you making any
speech. So
>> I can really if it's not regulated, if
it's not structured, we can go in
another virtual world which which will
be a big threat for democracy. On the
other hand, it could be really a very
good uh time to make uh citizen
uh implied in an interactive way to
express his mind to express uh his uh
opinion.
It could be really for the environments.
You know, we are speaking about AI as a
big consumer of energy. But if you use
it in the rationalization, it could be
the the leverage for a big economy
through the smart grid, the global smart
grid. We can adapt that. So many
opportunities how we can organize
ourselves. Today we have got rules, we
have the governance and we do believe
that even though there is a big
influence of these big big business
companies, we should tie to that tied to
this democracy. We know that it's not
the best time of democracy. There is
many threats and sometimes you have
people saying that when you compare this
authority with the democracy but our
experience now from the history it's
maybe not perfect organization of
democracy but at least is less bad than
any other or it's it's better than
anything. So we have to struggle for
that. It's not easy. Again, through the
participation of the young people,
through the participation
uh of the minorities of women, of all
these actors, we can maybe give a pet to
save the democracy from the derivatives
and to use I as an inclusive as a large
democratic integration
wave or tools to succeed more in
democracy.
Okay. So,
okay. So, just also to comment on your
question,
at the heart of democracy are the
people. You remove the people from
democracy and you have a whole different
system of government. Now the danger is
where governments rely heavily on AI to
formulate policies and remove the
people. So you go to any AI tool today
and you say how can I solve healthcare
in this location? AI search for global
best practice and give you a policy
document. You've not gone to the place
that you want to solve this issue to
check what is actually the the concern
of the people. Is it really healthare?
Is it road? If it's healthcare, is it
mortality? Is it is it is it the the
birth rate? What exactly? Is it HIV? So
many issues. AI would just give you what
it can give you. You've not got the
people to actually ask their opinions.
And what's happen is that you pick up
this policy from your AI tool and you
impose it on the people. So these people
have been living their life all this
while. What they actually need at that
time is maybe an industry to create
jobs, but you've gotten a health care
policy that they don't even need. That's
not democracy in any way, shape, or
form. That's just you imposing a policy
to them. The best case scenario is
government learn to use AI as a sort of
collaborating tool to refine these
ideas. So after I've gone to these
people, after I've asked them what
exactly they need, I've created a policy
that actually solves their problem that
takes into consideration who they listen
to, what they need, the proposed impact.
I cannot go to AI and ask can you refine
this? What's the global best practice?
What are the gaps in my policy idea? How
can this be better? So, apart from the
industrial revolution that that you may
say quote unquote took jobs of people,
other technological
revol revolutions so far have just made
people more efficient. It has not
threatened the jobs of human beings
before.
So for us the developing countries what
AI can do for us is if we're projecting
to reach this amount of GDP in 50 years
with the right policies with using AI
you can cut that time down to 10 years
15 years or even lower because now you
have a tool that can look at the global
best practice do the analysis and give
you the gaps in your years and help you
make it better in a matter of minutes.
So AI is not the problem. AI is not
something we should fight against. AI is
not our enemy as government. AI is
something that in the hands of the right
people would solve our problems quickly.
Again it depends on the data it has. It
depends on how you use it. But if you
solely rely on AI, you just you just run
a government where the machines in this
case AI is now governing the people on
your behalf. And I don't think that's
anything that we want to do.
>> Well, that's a very important point um
in terms of collaboration with
government, civil society across the
board. Um speaking of that um Alex um
you know what uh risk do you foresee if
you know the research and evidence
academic research and evidence are not
adequately integrated into policym
especially when it comes to uh
governance from that perspective. Mhm.
>> So I work for a research center that
uses foresight methodologies. We seek to
understand where the future is going. So
we use foresight or some people call it
future studies and I think this is key
to avoid a big risk which is the risk of
regulatory
regulation that is reactive or
governance that is reactive. So I think
uh unfortunately what we've been seeing
lately and since since the since the
explosion so to speak of of AI is that
uh the developers the the entrepreneurs
the inventors are going much faster than
than what the what the regulators or the
policy makers can can catch up with and
and that's partly um a problem of lack
of foresight from from the point of view
of of governments. So I think it's it's
it's very important that
policy makers um develop scenarios and
and work hand in hand with people that
are at the frontier of these of these
technologies to understand uh the future
risks and and take and take the
necessary measures right now that you
know so we we do not arrive late to
regulating some of the some of the
problems that these technologies pose.
So
again u check in with anybody in the
audience any questions? Um
what from again open question for all of
you. Um
should there be I mean there have been
all kinds of conversations that there we
need a central body to kind of have a
governance framework like you have the
the international atomic energy
commission and obviously the UN and OECD
and others are there any thoughts that
there should be a a central body that
kind of governs frameworks around uh AI
What I know that UNESCO UNESCO is trying
to do this work is they are very active
and at the last session of Japan there
was presence there a large presence
there of UNESCO to connect to the people
to to attract them to to serve as a
platform to focus on that like authority
authority of of regulation. But again
this we know how things are today with
security council with auto organization
multilateral organization we we're at a
time where even uh irritated institution
are challenged and uh challenged which
is pity but it's a challenges but the
creators
of that which are supposed to to
preserve them. So the context is very
difficult today but there is many voices
everywhere in the world because we are
aware that we have that's what you say
you are saying we have to create an
authority to control that it's a problem
it's touching everywhere in the world
it's not the issue of the company of
such countries such countries or even
these big countries because we know
China will be a big player whatever it
happens today maybe it's a silent player
but it will be a big player I got the
opportunity
uh with some colleagues from President
Madrid to meet President Chishin in
2019. No one were speaking about uh
about artificial intelligence. He said
at that time in December 2019 that we
will win the technology competition and
this year we created more than 400
specialities in university in China and
you will be surprised
by the power of what they are creating
but the rest of the world we are
concerned we are involved in that we are
we believe that and we will be subjected
to that we have to get a voice and
speaking about the blood of it's one of
the challenge of the south is if we
succeed to create let's say some
governance institution global
institution for AI or
on what is connected to to AI is to make
sure that all the nations and the
population has a voice. It's the key of
the success of that not to create again
gaps or to create tricky holes where we
can follow in the future to create more
tension in the world.
>> Well,
I think we've had a fantastic uh
conversation. And I really have to thank
our panelists um three well several
ideas that cut across um at least to me
um you know that we have to make uh
democratic safeguards non-negotiable
you know uh public sector AI needs clear
legal mandates and second uh
participation must be power sharing not
performative
and you have to co-design with uh
effective comm communities uh especially
youth and marginalized groups. Um and
then you have to rebalance with
openness. Prevent uh concentration.
We've talked about that. Uh public or
private um you know collaboration is
key. Listening to I mean young to me one
of the big takeaways is young people are
listening to AI more than to the
governments. So we need open standards
and interoperability
reportings. So where do we go from here?
So that this is not just a talk fest
which is very important too. Uh we want
to create a multistakeholder road map
toward a democratic AI governance
frameworks. Uh that continues after this
summit and we will follow up and maybe
pilot one concrete participation
mechanism like a citizens panel or you
know an affected community review. Um so
and then finally aligned with some of
our peers uh who are doing some of these
uh sessions and others also map our
current safeguards to open government
values uh that have been done but um I
do want to thank on behalf of u club de
Madrid and regulating one thing I did
neglect to mention is about club de
Madrid and regulating what they are for
some of these people Club Madrid is uh
probably the largest as the prime
minister said democratic framework of
over 100 prime ministers and presidents
focused on democracy and uh freedom
really and regulating AI is a nonprofit
really focused on working and educating
policy makers.
really focusing on educating policy
makers around the world because just
assuming policy makers know AI is not
right assumption because they are
supposed to make policies and if they
are not aware of what these policies
ramifications are it would be not right
but I do want to thank uh the prime
minister uh medioma
Alex and Tim Barry uh and also for all
the attendees for leaning in. Uh we
really like all of you to give them a
big round of applause because they were
very patient
and I
thank you so much.
Thank you.
>> Thank you.
>> Thanks for tuning in to the Regulating
AI podcast with Sanjay Puri. If you
enjoy today's conversation, don't forget
to leave a comment. We'd love to hear
what you thought. Share it with someone
curious about the future of EI. And join
us next time for more stories and
insights from the leaders shaping what's
ahead right here on the Regulating EI
podcast.
