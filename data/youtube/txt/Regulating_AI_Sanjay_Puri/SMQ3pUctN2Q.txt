And the more irreversible the harm is,
the more it's appropriate to regulate.
In the very next executive order, it
talks about you can do open source, but
you really don't have to give away
proprietary information. When I think of
um AI governance, it's people, policies,
and processes. That that's generally
governance. That's how the Oxford
handbook on governance is defines
governance. I am against it because
states are sovereign entities in that
there are things that they have to take
care of for themselves. They have to be
able to run their school systems. They
have to be able to run their traffic
lights. They have to be able to run
their emergency response vehicles and
systems and AI shows up. There is one
area where as a company you get to
decide what gets in your doors and that
is procurement. And if you don't want
the bad stuff to come in, then you catch
it at procurement.
Welcome to the regulating AI podcast.
Join host Sanjay Puri as he explores the
dynamic and developing world of
artificial intelligence governance. Each
episode features deep dives with global
leaders at the forefront of regulating
AI responsibly, tackling the challenges
using AI can bring about head-on and
enabling balance without hindering
innovation.
[Music]
Welcome to regulating AI, the podcast
that brings together global voices to
shape the future of artificial
intelligence governance. I'm your host
Sanjay Puri and today we have the
privilege of speaking with someone who
sits at the fascinating intersection of
AI policy, procurement and workplace
transformation. Dr. Carrie Miller is
with us. She's a globally recognized
thought leader in AI governance and
procurement practice. She serves as the
head of AI governance and policy at the
center of inclusive change and she's
also the executive director of the AI
procurement lab. Carrie has over 25
years of experience in corporate
strategy and change management bringing
a unique perspective to the topic of AI
governance, one that really combines her
deep technical understanding with
practical implementation experience and
expertise.
Having said all of that, Carrie, welcome
to the Regulating AI podcast. It's
wonderful to have you with us today.
>> What a great day to be talking with you,
sir.
>> Yes, it is. Uh Carrie, just to give you
some perspective, we have a global
audience. These are people who are uh
policy makers, members of Congress,
Senate, policy leaders around the world.
These are people who are interested in
policy. These are people who are
interested in AI and AI experts. And as
I said, it's a global audience, but very
interested in what also happens in
Washington, where I happen to be. And we
had something happen in Washington. The
White House announced an action plan on
AI.
So given that uh we used we had an AI
executive order from the Biden
administration now 6 months into this
administration now we have what I would
say is one of the first major
pronouncements uh coming from there. So
why don't you walk our audience through
what was announced yesterday and give us
some of your opinion on how does it uh
shake out.
>> Yeah it was so it's a long time coming.
we were expecting this. Um so
fundamentally it has three pillars. Um
the first pillar is about innovation.
The second pillar is about um
infrastructure
and the third pillar is about
international diplomacy really. Um and
so the second pillar is the easiest one
I think for everybody to understand and
that is um infrastructure which you know
every country around the globe I think
is clamoring to build out their energy
supply and support AI in the best way
they can and so that was all very
expected I think what what could be
found in their data centers and um
there's a corresponding executive order
that goes along with that there are some
interesting things in that executive
order, uses of federal land to do these
things, shortening permitting processes
and kind of maybe breezing past some
usual where you would like test water
and and do things like that. But anyway,
they want to expedite getting that
infrastructure in place. So, that's the
impetus of pillar two.
Pillars one and three um are they got my
attention.
Um, and so basically I'm going to do
pillar three first because pillar one is
the zinger in my opinion.
Pillar three is about being a global
leader. Obviously every country wants to
be a global leader in AI, right?
Especially the US.
>> And so in order to do that, they want to
create their AI and they want it to be
distributed the full stack to be
distributed around the globe. And they
want global, you know, uptake on all of
that. And so there's a push in pillar
three on how to do that and to make sure
that security-wise we're doing that well
and that you know they push money into
making sure that these things are more
secure. Here's where the rub comes in
with this um this action plan that I'm
not sure I'm still digesting why or how
this is going to work. Pillar one is
about innovation and adoption. And right
out of the gate, the first couple of
bullets in pillar one are about making
foundation models um have free speech
and re removing from the NIST AI um
riskmanagement framework the word
misinformation.
So in other words, they don't want the
um foundation models to worry about
having misinformation and they want them
to not be woke and so they just want
them to be able to have free speech and
a translation for me is oh my what are
they going to do are they going to go
gro on us and say things maybe we don't
want them to say
so when I go back to a global
perspective Sanjay I want to know how
does that square with um the EUAI act
and these other global you know laws
like from a procurement perspective as
that comes through my doorway I'm
thinking that's not going to pass muster
I'm not going to adopt that it's too
risky so that's sort of a very high
level where we're at right now
>> a very high level floor that opens up to
a few questions uh Carrie obviously it's
straight pretty fresh of the press. So a
lot of it has to be you know your
perspective on it. You you mentioned the
EU AI act and
uh companies that are global have to
deal with you know different regions.
They don't operate in one region per se
and we have a lot of our listeners who
are with companies or run those kinds of
companies. There's the EUI act and then
there are several other things whether
it's in Asia, Africa, China etc.
when you look what came by you talked
about you know uh the first part
infrastructure obviously as you said
everybody wants to be number one in AI
we are going to be number one etc u but
when you look in comparing this and we
people talk about how do we harmonize it
or how do we make sure we don't have to
do this how does it compare let's take
first with the EUI
How does the AI action plan compare to
the EUAI act?
>> Yeah,
>> I mean it is not the EUI act is a
riskaware uh piece of legislation. There
are requirements and uh consequences
for not following requirements. This is
an action plan. It is um not set in law
yet. It's not even a regulation. it is a
voluntary kind of a notional directional
piece right now. There is a lot of
policy direction in there of where he
wants um everyone to head and where laws
should be um made. Um but it is not
rooted in risk awareness other than the
security piece. There's a lot of
security awareness in that. Um but
certainly not for bias mitigation and
those those other things that we've been
talking about for a long time.
So
as you said if you're a company what is
the overall perspective that hey uh just
innovate and not worry about things. Is
that the message to Germany?
>> That's yeah well expedite hurry up and
innovate and we'll worry about the other
stuff later. Yeah. Which I personally
don't think that's sustainable. I mean,
I I think that's just a recipe for
putting cars on the roads with no seat
belts, no airbags, no, you know, just no
brake pedals, no like I worry about that
>> and some of it is uh there's a
geopolitical dimension as you know
Carrie since now we are talking because
the
message that is coming out from the
White House as well as from a lot of
other people we have a lot of uh members
of Congress, Senate
governors etc. who come on our show is
that uh this has national security, it
has economic political implications with
this transformative technology. We
cannot afford to be left behind
in with some other countries who might
not share our values. So we can't have
um
regulation at this stage of the
technology that will pull us back. What
do you think uh from what is your
perspective on that?
>> I agree. Um
I was always
so we often talk about should we
regulate or not? Does it does AI require
is it special? Does it need special
regulation?
And so I part of me was always like,
well, you know, we have laws for do not
not discriminating. We have the laws
about, you know, unfair and deceptive
practices and we have some protections.
So this is a, you know, a new territory
entirely.
>> But even in what was published
starts to claw back some of that stuff.
There's there are directives in there
that says go review those things and if
they're getting in the way of
innovation, pull them back. So with
those things being pulled back now, I I
actually am more and more concerned
actually. And so that's where this has
always been part of my procurement kind
of obsession
because there is one area where as a
company you get to decide what gets in
your doors and that is procurement and
if you don't want the bad stuff to come
in then you catch it at procurement.
>> Don't want the bad stuff to come in to
catch it at procurement. We're going to
get to that. But uh just given the
timing of this uh issue,
do you think the stakes of this
technology
are so monumental
that we should uh put some of the
safeguards that we inherently have had
as a lot of members of Congress come in
and say hey Sanjay we already have uh
rules against discrimination whether
it's in housing whether it's in
employment we have a department of
labor, we have equal opportunity
commission, we have the FTC, we have the
FDA for monitoring all this. But given
so to speak the stakes that all of the
foundation company people say that uh
national security is it I mean is there
a choice that we should make in your
view? I mean it this
the stakes are high in some cases
education, health, utility, you know,
like there are in some cases.
One of the confounding things I we we
all keep running into here in the in the
US. Um I think other countries are more
consistent. We we have a level of
inconsistency.
So, for example, in the action plan, it
says we want to promote open source and
open weights. I love that. That's great.
That's a very important. There's some
risks with it, but that's fine. In the
very next executive order, it talks
about you can do open source, but you
really don't have to give away
proprietary information.
What's that? I I don't
>> probably talking about weights and stuff
like that. Yeah, but it says promote
open weights, but don't give them away.
Well, what do you think open weights?
Like I don't
>> So there's a there's just inconsistency.
So I it's so difficult to answer
questions when the the common sense and
the logic are like just
scrambled sometimes.
>> Okay. Well, we'll maybe try to move from
uh a scrambled egg to a maybe an
omelette. Um you uh a few weeks ago as
you know the uh we had this big
beautiful bill in Washington DC and
there was a provision in that bill that
there would be a 10-year moratorium on
states uh kind of uh not being allowed
to do uh you know AI legislation because
if every state you know 50 states had
different legislation it would hinder
innovation.
uh etc etc. You came out pretty strongly
against that and this comes back again
uh to that question of innovation versus
regulation. That's the kind of dilemma
we are going through at in our country
right now. Why were you against that uh
provision Karen? Um well to first of all
the u moratorum is back. Um it is
squarely in the action plan again. Um
the action plan calls for a review of
state regulations that may get in the
way of federal government. Um and it
also calls for no funding to go to
states that are doing that uh sort of
regulatory behavior. So it's back just
under a different name. Um, I am against
it because states are sovereign entities
in that there are things that they have
to take care of for themselves. They
have to be able to run their school
systems. They have to be able to run
their traffic lights. They have to be
able to run their emergency response
vehicles and systems. And AI shows up in
all of those areas. I was talking to
someone that put AI detectors on their
trash trucks to detect potholes. That's
great. But it also started picking up
homeless camps. Like you know we have to
let states do what they can do without
penalizing them. Like I think they
should be allowed to do that without the
government the federal saying don't do
anything.
So but let's just take if there are 50
states and there are you know 10 of them
that form legislation or regulation that
you know uh is important to them and you
have companies especially small
companies that are now kind of forced to
comply with them and some of these
states could have how is do you think
that would hinder innovation in any
because that's the argument that is
being made right now.
>> It it is the argument. Um and so the
exercise that we ran, I'm a member of
the um of IT E's AI policy committee and
we put uh a group of us probably about
30 of us together and we said what is
this question we keep struggling with
innovation versus regulation? When when
is it appropriate? And what we ended up
coming up with was a spectrum of when
it's appropriate. And the more
irreversible the harm is,
the more it's appropriate to regulate,
the less it re it can be, you know, the
less or the the more you can reverse it,
you shouldn't have to um regulate it. So
in other words, irreversible means
death, right? you you can't come back
from that. All right, we should pay
attention. That's weapons. That's that's
car deaths. That's things that
physically harm people. If it's means
that your SNAP benefits are going to go
away, you can't eat. Okay, so we're
moving down the spectrum a little bit,
but that's still difficult to reverse.
It takes a long time to reverse. It
might affect a lot of people. So, there
should be some regulation there. And so
you move on down the spectrum to I'm
just filling Coke bottles in a in a
manufacturing facility. We're okay. I
don't think I need to regulate that part
of it, you know. So that's the spectrum
we want to work on.
>> Not trying to beat this topic to death,
but just to final question because I
have uh guests who come here and point
to the EU. Obviously, a lot of people
point to the European Union as a great
example, but they also point some of our
a lot of members of Congress have said
we don't want to be the European Union.
When was the last time they had
X kind of a company you know look at the
state of innovation etc. there in fact a
lot of European companies are coming
here.
So
what do you say to that?
Yeah. Well, I'm a I'm a risk manager at
heart, so I'm moving to the EU now. Um,
well, I think first of all, you have to
start somewhere and you have to figure
out what's working, what's not working.
Um, I think there should be allowances
for a maturity uh scale and a curve to
come, you know, for people to come along
that curve. I think there should be some
grace and leniency and some mentorship
allowances. I think the EU went very
far. The pendulum swung very far. I
think that's an end state. Um, and I
think they know that and I think they're
they're kind of coming back a little bit
from that and and I think that's great
and fine. Um, I like where Colorado
landed. They're transparency is involved
and let's let's just check this with a
impact assessment and
>> kind of a little bit of a lighter duty.
Um, so the truth is in the middle I
would say probably for for a lot of that
stuff.
>> Okay. So somewhere in the middle is uh
what you're saying. Okay. Let's uh talk
about something that you are most most
most passionate about. you have
dedicated and that's part of the reason
we are uh having this conversation
because procurement of AI systems a very
very important critical topic and you're
going to tell us why and you've
dedicated a significant effort Kerry to
AI procurement practices why did you
choose you know to focus on them for as
a lever for AI governance you know you
could look at other approaches whether
it's algorithmic auditing or post
deployment uh monitoring etc. Tell our
audience why is this so important?
>> I um to me it is the gate of all gates.
So when when I think of um AI governance
it's people policies and processes that
that's generally governance. That's how
the Oxford handbook on governance is
defines governance. And so your people
is a strategy, right? Getting them
ready, making sure they're trained, all
that stuff. Your policies are a
strategy. Um, and you, you know, you
want to make sure that you know what
your principles are that you're
following and things like that. But
where the rubber meets the road, it it
is right there at procurement. That is
pen to paper. What do I want? What do I
need? How do I want it? How do I need
it? What are you going to give me? What
am I going to give you? So procurement
to me is like the head of the snake and
I just can't look away from it. It is it
defines
you know you set the expectations at
that moment. You set your risk you
identify your risks you assess your
risks you set your risk controls there
and and that sets the stage for how you
manage.
So it's that's why it's important to me
>> ahead of the snake. I don't know if CIOS
and CTO's have been thinking of snakes
when they've been buying AI systems, but
so we have a lot of CIOS that we have on
our show, CTO's, chief AI officers. So
they're all wondering, Kerry, why uh
what do they need to do differently when
they're buying AI systems compared to,
you know, other uh you know SAS solution
or other IT solutions? What's so
different? tell them.
>> Um, well, I think
we all know that AI is a um it's not a
deterministic system. It's not a
rule-based system. It's not going to
just do what you tell it to do. It's
going to be a little amorphous. It's a
little uh operating on its own
sometimes, especially when you get into
agents. And so understanding all of the
elements of where it could go off the
rails and that risk assessment is the
absolute most important part. So what
I've studied most is where in that
procurement process in the procurement
life cycle do you have the opportunity
to identify a risk and start to capture
the opportunity to mitigate and control.
And so that happens when you start to
identify the need. It happens when you
write a a tender or a solicitation.
That's a big tool for you um during your
assessment of vendor evaluations and you
know what they're offering you
especially during your contract and then
beyond when you do your um you know the
contract doesn't end or the procurement
doesn't end when you sign a contract.
the contract lives on, you know, until
you're ready to sunset. So that entire
process is your I call it the
procurement apparatus. So your
procurement apparatus is one of your
best AI governance tools. It's when you
operationalize
it all goes into there. And so there
should be many people involved, right?
should be program managers or business
owners and the procurement person and
legal and your syso and the people that
are monitoring the metrics when it's you
know once you sign and so on so forth
>> do you think uh you know you said it's
different than let's say traditional IT
tech software SAS systems do you think
the procurement or contract
administrators for companies
need some pressure training on how to
buy AI systems.
>> Yes. Yeah. Yeah.
>> Why is that?
>> Um because the we call it augmented
procurement. So you're going to augment
your practices where the risks are going
to show up for AI. So you're not going
to change your entire procurement
process. You still have to go get your
money and make sure you have the
authority and do your market research
and a lot of things stay the same. But
at certain points you have to do a few
extra things because the risks are more
extensive or different um and you have
to assess them and control them in a
different way than you would just a
normal IT system or a traditional one.
>> And you also said get your legal and
compliance under other people involved.
Carrie u
uh we all know I mean at least most
people know that uh AI systems chat bots
other agents and other stuff and we'll
come to some of those topics your
favorite topics later on have the
potential and these companies clearly
lay out to either hallucinate or you
know uh give answers that might not be
appropriate that has a challenge. How
should companies
during the procurement process account
for those kinds of things? Because these
vendors are saying I mean if you go to
chat GPD or cloud or it clearly says at
the bottom there's a disclaimer
let the buyer beware.
>> Yeah. Right. So the way we suggest um
handling that is in your contract. Well,
first of all, you write it into your
solicitation what your expectations are
with respect to how frequently that
would happen, metrics, you know, to
measure that and how many hallucinations
you're going to allow in a certain
period of time or the types of
hallucinations you will or won't allow.
Um so that's why your solicitation or
your tender is one of your best uh best
friends in that whole process. But from
a contract perspective
um there should be standard clauses. You
want to know what the purpose of the
solution is and the intent and mis you
know intentional misuses and things like
that. But to do a writer or a schedule
attached an addendum to the contract
that lists out not just your business
objectives or your business metrics, you
know, I'm going to uh uptime is going to
be this and it's going to accomplish
these, you know, my inventory is going
to be 30% less and things like that. But
the AI metrics, my F1 score should be
this. you know, it should not have more
than X hallucinations. I I'm going to
monitor for incidents in this way. And
then on top of that, you identify your
breach uh patterns of behavior. So if
you get close to breaching one of these
AI metrics, you have to decide I'm 80%
within that metric. I want to pause the
system. probably not. But I do want the
engineers to look at it and I want them
to give me a new mitigation. I'm 90%
within. I want a manager involved now
and I want the engineers to give me a
different mitigation. I'm 110% of that
metric. I am going to press pause. I
want the leaders involved. We got a big
issue, you know. So don't wait till
you're at 110%. Write that into the
contract so everybody's on the same page
and we don't have a fire drill.
Uh that's a great point but let me just
ask you there are three or four major
vendors at least right now of foundation
models you know take the other small
open-source vendors separately and we'll
discuss that
let's just assume most of them have the
same clauses and they basically say
Carrie you want our product here it is
uh no changes no exceptions to this
contract
and there are three of these vendors
and it is a technology that you kind of
want. So what should a company do?
>> All right. So there are variables here.
One of the variables is directly
contracting with a foundation model. Um
and then you're going to come in bring
that in and build bespoke models with
it. um that's a whole different
scenario. So your procurement is for a
you know that direct foundation model as
opposed to a procurement where you're
buying something that another company
has fine-tuned and is now selling you
this is your sales tool. It's going to
listen to all your conversations. It's
going to give you recommendations. This
is your customer care tool. It's going
to tell you if you're happy or sad on
your call.
>> Uh it's going to take notes for you. So,
I'm more in the middle of the you've
they've used a foundation model and now
they've fine-tuned it
>> so they're more accountable for what
they've done for fine-tuning and and
things like that. Um, however, on that
foundation model um scenario, you can
still do that as an interdep
departmental solution to to set yourself
up to say these are going to be my
metrics. This is what I'm going to do.
If your if your engineers are here and
they're doing that for a separate
department then that interdep
departmental agreement should be
established. Whose data is what? What
happens to that data in the end? Are you
allowed to have that data? I mean all
that sharing should be concretized in a
in an agreement.
>> So that should be interdep departmental.
That's a very good point.
>> Uh Kerry just we'll come back to the
main topic here. It just you said
something it made me think uh when cyber
security you know hacks and everything
else and ransomware became a big big
issue you started to see uh cyber
insurance start coming into play in a
big way now companies can buy that and
maybe this is the case and I don't know
is AI insurance also a possibility in
terms of uh procurement and things of
that nature if not then some of our
listeners who are entrepreneurs owners
jump into it because
uh there could be opportunity. I'm
asking you Carrie, is is that a
possibility too?
>> I mean, I'm seeing more exempting than I
am insuring.
In other words, saying, "Well, then
we're not covering that. No, we're
that's not a thing for us. We're not.
No, that's on you." I think what I would
love to see insurance agencies do is to
say, "Look, if you have a reasonable and
robust AI governance process and policy
in place, I'm seeing you train your
people and be responsible with how
you're buying your AI and you can show
me your contract terms and and you know,
put some due diligence to it. We won't
raise your general liability policy."
Um, I I think that's a possibility in
the future, but I'm not seeing a lot of
uh insurance companies jump into the
ensuring your AI products or giving you
any kind of AI insurance at this point
>> yet.
>> Not yet.
>> Is the yet is
>> I think it'll be astronomical. Yeah.
>> Yeah. Um Gary a few minutes ago you
mentioned don't let the bad stuff in you
know which is kind of like a core
principle for you.
>> Yeah.
>> And then also you mentioned before that
there are some
AI vendors who might not be as ethical
and as responsible and could be selling
AI snake oil. How can procurement teams
distinguish between uh different kind of
vendors?
Yeah, I you know sometimes when we do
procurement we will do um addestation
procurement where we just say can you
attest to that you have this in place or
that your uh governance staff uh has
this kind of experience and so you just
have them attest. Um,
>> another way to do it would be show me
the money. Okay, so I would like to see
their resume. I would like to see your
last quarter's uh test results for your
F1 score and your bias metrics and your,
you know, X Y and Z. So, can you show me
that? Better yet, if they come with a
third party that's done that
outside of them and that third party is
credible and they've signed off as an
independent, you know, non uh conflicted
party, now you're really talking about
something that is trustworthy. Um, so
those are the kinds of measures you kind
of want to see what they're working with
with your own eyes, not just an
addestation or marketing, you know,
brochure or something like that. And
then the third line of defense is a p a
pilot with stakeholders involved and and
really listening, you know, to those
stakeholders,
>> you know, have a pilot and, you know,
get the stakeholders involved. Yeah. Um
Gary, there's already substantial
guidance for AI. Well, I wouldn't say
substantial, but there's all some uh
guidance for AI procurement. You know,
the world uh economic forum has this
procurement in a box. Uh UK government
has a guideline for AI procurement and
the national AI advisory committee's
recommendations. What do you see as the
strengths and weaknesses of some of
these existing frameworks? Yeah. Um,
they all cover great sets of questions.
>> Like they all have these are things you
should ask vendors
and they're accurate. Those are all
things you should ask vendors. Um, the
weakness I find in a lot of them is they
don't go much too much further beyond
that. So in other words, if you're um
still coming along the maturity curve
and your your skills are still building
for AI, which is a lot of procurement, I
mean, we're we're still learning a lot.
You might not know why you're asking
what is the traceability of your data or
what is an F1 score? You maybe you don't
know what those questions are even
asking. And what these uh other
frameworks lack is telling you why
you're even asking that. And then
further
what's a good answer and what's a bad
answer. So you can evaluate and measure
this vendor was good and this one wasn't
and I'll give this one a 10 and this one
gets an eight. Um so those are again
they're all great questions but a little
problematic because you have to have so
much knowledge to understand a little
more depth behind that. Um, we I was the
vice chair on it e 3119. It's now
published. It's 3119 semicolon 2025.
Um, and we added rubrics. So, we have
lots of good questions too. Um, but we
did add the the explanation of why
you're asking and and provided rubrics
to say this is good, this is bad.
So, that's a little more helpful. But
there's a obviously I e likes to make
money on their standards. So, but it is
it's only like $125. So,
that's available now.
>> Um, you also uh K said that procurement
is where AI governance moves from
strategy to, you know, operation. What
are some of the at least the first three
checkpoints that every company or agency
should hit before they issue an ARFP?
Yeah, I I mean that's just a great it's
a great question because I feel like
first of all what I'm seeing in this
space I don't know if you hear people
talking about this but what we see a lot
of is the vendor shows up knocks on the
door says I have a cool thing you really
need it because it's going to save you
money save you time whatever and then
you're salivating and then it's you
pilot it and then next thing you know
you've adopted it so resisting that urge
urge. What you would commonly should do
is find a business problem that you
really actually need to solve and really
dissect that because that will tell you
is it a like did you just need to fire
someone or do you really need AI and if
you really need AI how's that data going
to come into that system because is it
good or not good. So that's like one
really important thing. Another one,
every governance framework will tell you
to do an impact assessment and you
should because everything on that impact
assessment ends up usually feeding into
the tender statement. And then lastly,
the tender u statement and how you write
up that work, how you describe it. Um,
preferably you would do a
performance-based contract. Um, so you
you know, you're kind of working with
that vendor. It's a two-way street.
Don't be unreasonable. No one's that
mature. you got to work with them. Um,
but that tender statement can be your
just your golden goose of getting what
you need and what that vendor needs from
you.
>> So the tender statement I think you're
saying is a very very critical aspect
car for doing this.
>> Yeah.
>> Carrie um there is this concept of
sovereign AI. And you talk to you listen
to Jensen Wong at uh Nvidia, he he says
every country should have its own AI.
>> Now uh Sam Alman uh you know OpenAI I
think has got a something called a
sovereign AI. There are countries that
are looking well every country wants to
have AI in some shape or form. Nobody
wants to as you said everybody wants to
be number one or in some cases they just
want to be a number. uh and the BRICS uh
nations recently they issued u their own
AI governance uh statement
from a procurement or governance
standpoint for especially for countries
around the world when you look at the
global south and others
how uh can they make sure that the
things that you just talked about from a
procurement standpoint and that talks
about their data sovereignty and you
know uh privacy as well as in many cases
cultural identity and things of that
nature those things are taken care of
because we have a global audience it's
not just uh Delaware and Washington DC
which is where uh we cover but uh so
just for them what what would be your
message for some of them
>> so when so we we were just talking about
the couple of things that you get
started with when you're doing a
procurement
that impact assessment and the
solicitation. I'm going to marry that
with the fact that you shouldn't be
doing this alone. This is a team sport.
And so when you do an impact assessment
and when you do that that tender, you
should have more people at the table
than just a procurement person. Um, and
so when you have more voices, they can
bring in, wait a minute, we need um, we
need to be culturally sensitive because
this system is going to impact these
kinds of people. Wait a minute, the law
just changed. Wait a minute, we need to
think about how um, this is going to
impact, you know, over here. And so when
you do that, you just end up with
totally better outcomes. The process
didn't change. You still buy the way you
buy. You got to go get the money. You
got to do the market research. You got
to do these steps. It's just the people
will will put into that coffee grinder,
so to speak. Do you want dark roast
today? Do you want light roast? Is it
you know,
>> it's the people in the process that
really make it um you know, the flavor
that you need it to be for wherever
you're at in the world.
>> So, the process is the same. It just
>> some of the circumstances uh change.
>> Yep. Uh that's a a good point for our
global listeners. Um Kerry, let's talk
about uh a topic which is the flavor of
the month, the week, the year uh which
is agents in Agentic AI. I that's a
topic that comes up all the time right
now.
um you have expressed concerns and I've
had uh a few guests that have come in
who are uh chief AI officers of some of
the largest cyber security companies but
they have different kinds of concerns
but u what should or firstly what are
your concerns and what should
organizations consider before deploying
a gentic AI system and I can tell you
every company either is deploying it or
is looking at least a major company's
looking at deploying it
uh tell uh them what are what is keeping
you up at night about these millions of
digital workers out there and uh what
should they be considering?
>> Yeah, I don't know that my um security
concerns would be any different than any
of your you know sisos or anybody else
like that that comes through the door. I
mean, OASP has done a great job
highlighting a lot of the things that
are um of concern on that front. That's
a lot of it. Um and so when I couple
that with knowing where the literacy
level is of procurement,
um I get really nervous because not only
do you have to in procurement do you
have to understand just general
principles of AI and ask where's the
data coming from and you know the whole
value chain. Now you have to layer on
this linkage and this compounding
complex network of agents talking to
other agents and tools and APIs and and
all of these other things with
vulnerabilities for security. Um, put
that in a box for a second. I'm going to
go back to my strategic
um planner hat that I used to wear 20
years ago when we were just doing
straight up ERP system design. Um, when
you brought an ERP system in the one of
the bins of the existence of doing that
was to map processes every day. That's
all you were doing is mapping process. I
never
>> we used to call it we used to call it
BPR by the way.
>> Yes.
>> I I mean, you know, it's just like I
never found a process that was like, oh,
perfect.
Never. And so when I think of agents
like just, oh, let it do it. you know it
it'll figure it out. Like what process
are you talking about that runs normal
and smooth every time? Like I don't know
where are you on drugs? Like I don't
know what you're talking about. So I
feel like one of the big missing
elements in agents is the the domain
professional that understands the
workflow well enough to be able to help
actually train those those domain
agents.
So they might work in low stakes and uh
for low stakes tasks that are simple you
know maybe single turn or or very few
turn um tasks but when you get into more
complex multi-turn tasks I am just like
whoa we don't have the talent and skill
sets on the domain side maybe on the IT
tech side but not on the domain side to
help couple bring together and make
those agents actually work the way you
want them to. And then you got to solve
for the security part on top of that.
That's where I'm coming from with it.
>> Well, that leads to a zillion questions
I have. But we
see if we can pair it down or I might
need a few agents to kind of ask you
those questions. But let so let me give
you an example. Well, I had u the chief
AI officer of I would say one of the
largest employment companies in the
world. They've got I don't know at least
over a million employees or so. It's a
one of the largest staffing companies in
the world. And he and I thought it was
pretty fascinating. He says everybody
who joins the company, I mean their
intention is is going to have an agent
that will follow them through their
career. Okay. So, it's a pretty cool
thing. uh you know it stays with you
etc.
Now I'm going to turn to you from a
procurement standpoint. Um and then I've
had some of the leading you know leaders
of some of the leading vendors of AI
agents and they've said we are working
on innovative pricing mechanisms. So I'm
going to add that wrinkle. We're going
to do outcomebased pricing.
We might do uh replacement employee
pricing.
So,
how are these folks I mean you're a
procurement guru. How are companies
currently buying
agents or whatever you want to software
or digital as some of these people said
they are digital workers that report to
HR and I'm so explain to me because I am
trying to figure out uh if it's outcome
based pricing who's responsible for the
outcome or the consequences of the out
sock
our audience as the procurement for some
of these things. How are how are
contracts going to be written for
outcome based promising or in some cases
it's replacement employee pricing they
said too.
>> Yeah. They're not this is not going
through procurement. This is pilot test
stuff. This is let me go to I mean it's
kind of like when Open AAI went to um oh
gosh now I can't think of their name. Um
oh I can't think of their name. Um,
sorry. Uh, I it's just not going through
procurement. It it's going straight to
the the CTO, the CIOS saying, "I've got
a great idea. You want to come along
with pilot test? You'll be the first
ones. We'll try it together." Um,
this is not a mainstream
scenario yet. Um,
>> you mean agents are not
>> agents are, but but that type of pricing
model
>> pricing. Okay. Yeah. So, let's say the
pricing is not being deployed,
>> but
>> right,
>> who are agents supposed to report to?
Uh, Carrie,
>> yeah, that's the problem that
>> I'm asking you as a procurement or who
are these people reporting to this
digital workers or whatever you want to
call them. Who are they reporting to?
>> That is the problem. Every time I start
trying to ask this question, the the
people recoil and they're like, "Well,
actually,
our pilot didn't go well and we just
didn't." So, they're they're really
piloting. They're not these aren't I'm
not finding a lot of official We're up
and running. It's an official program.
We've got 30,000 of them. Like, I'm just
not finding that anywhere
anywhere. I I'm not finding it.
So maybe they exist, but I think that I
feel like that's a hype that's
not quite mainstream yet. I I don't know
where these people are that are just
running rampant with agents all over
their because of these things like they
have major security issues and they
don't actually know how to do workflows.
So they quickly die in the pilot stage.
every one of them says hey we are either
looking at it or we are deploying it. Um
and I just think early
>> early stage yes but I mean if you talk I
mean if you listen to
uh I mean leaders of foundation
companies or others uh Salesforce for
example they've got agent force and
other stuff.
>> Yeah. So
uh it's a key part of what they're doing
and if I am a client buying let's just
say agent for there's many other things
you know there's service now and many
many others like u
what should uh procurement be looking at
kerry if you were on the procurement
side what would you suggest to them
>> so
>> because it's it's coming whether
>> it is
>> uh you it is absolutely absolutely
coming. There's just no question that it
is coming.
>> Yeah. And you're right, Salesforce and
um Service Now are two great examples um
that still I don't know that they're
going through procurement um because
those are existing, you know, solutions
that bolt on their AI and then I get a
lot of those questions. I have a
contract now. My vendor just told me
they have AI. What do I do? Um and so
that's a great example of one. Um but
the only answer is upskilling. I mean
you just have to continue to
train and learn. So at the AI
procurement lab um that's what we're
doing is building out those courses and
what do you need to know and how do you
evaluate them? And so there's some
leaderboards that you know they spiral
out of control every six months and you
got to find the next one that's
evaluating how to evaluate uh agents.
and you listen to peers and you listen
to the leaders and yeah, it's um agents
are very very hard. They're just I don't
know that we have our hands around
agents from a procurement perspective.
There's so many security issues. I need
the siss involved in in anything that
you're going to do with agents. I'm just
so nervous about them. But is someone
looking at it because it's uh it's
something uh folks like you have to take
the lead and deal with it because uh
whether they are bolting on to existing
contracts or companies selling it as a
separate it's it's coming. I mean I can
tell you it is just because nobody
remember it's the FOMO.
We no company wants to be left behind
here.
>> Yeah. and and I can't tell if it is here
or not here. Again, that's that's what
I'm trying to say. I hear a lot of we're
testing it, we're rolling it out, but
it's very early stages and nothing seems
to stick. Like I'm not hearing and our
agents doing well. I'm hearing and it
failed and so we'll try something else.
the in fact with chat GPT uh just the
other day when they rolled out GPT agent
my first reaction was to go back to
everybody I know every group and club
and client that I have all around and
say first of all go back to your AI use
policy and start recrafting it go to
your IT team and start telling them to
test it and go to your users and tell
them don't touch anything until I tell
you you can touch something. It's kind
of like when you have Salesforce and
they give you that um you can go to the
library and start adding on, you know,
apps and things. A lot of companies
don't just let you just add on stuff.
You know, that's what it felt like was
happening. I don't want chat GPT agents
scrolling through my Gmail.
Not a good idea, you know. So, let's
pause. So,
agents are Yeah. Okay,
we don't have good answers for them. I
don't even get procurement people that
understand general AI stuff, let alone
how can I tell them what a multi-turn
agent is and what tools they're calling.
It's we're at early stages of literacy
on a lot of this stuff. Yeah.
>> Wow.
>> So, I know they're not going through
procurement. They're just not
>> not going through procurement. I'm going
to ask that question next time which
will happen pretty soon uh the CIO etc
and ask them where is it going through
in terms of the buying process uh K just
the last question on agent is if let's
just say a company is implementing the
agent and let's say the agent in its
because
the agent has autonomy at least some
agents have autonomy in terms of actions
they're supposed the autonomy autonomous
agents can take action on their own. So
let's just say there is an accident
through the actions of an agent. Where
is the liability here uh on in that kind
of a process? You're a contract. You're
not a lawyer. I understand. But where is
the liability here?
>> Yeah. That I mean that because it's not
going through procurement. I don't
believe we have good answers for this
right now. I mean, in a contracted
situation, you would know who's liable
for what. You would have people in
charge. You would have, in other words,
you would have roles and
responsibilities established in a good
governance oversight situation. Um, with
some of these scenarios,
they just feel very mercurial,
very um sort of ha haphazard in certain
ways. So when they're piloted
scenarios, I'm not sure. I know there's
an organization I work with right now.
They don't have incident management set
up.
>> They just didn't think of it. They just
they're like, well, I guess if sometimes
they'll just call me, but they don't
outright say that's what you need to do.
That's what you should do. It's just I
don't know, maybe they'll just let me
know if something. So I just don't think
that there's a maturity of governance as
as strongly as you're asking for. Now
maybe there is with um some of the
organizations you're speaking to, but I
don't I work a lot with the lower end of
large and into medium-siz companies and
they're just not
they're not there.
>> There's gaps. are uh procurement
organizations that you know of are they
uh do talking about this kind of a topic
uh in your view?
>> Yeah. But here's the problem. They're
talking about this they're talking about
sustainable procurement
and they're talking about other
priorities that are given to them from
on high. So, you know, got to save
money. Oh, my headcount's gonna be
reduced because So, this is like one of
five or ten things that they're um you
know, worried about. So, it's just put
it on the list. We'll get to it.
>> Put it on the list.
>> Yeah.
>> Well, uh you know, I could go on and on,
but there's uh one other question I kind
of wanted to talk to which is also a
very topical thing and you you have uh
talked about this also, which is
synthetic data.
>> Oh. And uh you've said it can be
beneficial and it can be risky.
>> Uh how should organizations uh you know
approach synthetic data in their AI
strategies? Now keep in mind a lot of
foundation companies are now using
synthetic data to train their models
etc. And
so
what is your concern about synthetic
data?
>> Well, okay. So, let me use an HR
solution as a as a starting point for
the discussion. Um,
when we have resume data, we may say,
well, it's just I didn't have enough of
it, so I want more of it. So, you would
say, well, easily I'll just go get
synthetic data or I'll make synthetic
data. And that may be okay. However,
data principles still apply. And so
sometimes what in the research that I
was looking at, you would have, you
know, just sort of a novice data
scientist fresh out of school. They
hadn't really done much data projects on
their end. And they just think, oh, just
copy and paste and that's good enough.
And then they don't do the robustness
reviews and they don't do the, you know,
the bias reviews and and things like
that. that just gets sucked up into the
uh model and it you know comes out the
other end the way it comes out. Um so in
that case synthetic data was a really
bad idea.
But if you use it in a way that you are
applying all of your good data cleansing
and and you know monitoring and um bias
checking and and all of your robustness
stuff um then it can be a good use a
good way to make sure you get more
representativeness inside of your models
and things like that. Um now for big
foundation models to use synthetic data
for um replicating
website data and things like that.
I don't know about that. The studies
were a little light duty on that side.
Um I think we have a problem with
recursive uh information right now and I
don't think we are going to get a clear
view on what synthetic data looks like
uh going back into those recursive you
know kind of that scenario. Um but in
other isolated cases you can see where
it could be good or bad depending on the
talent using it.
>> So if you have safeguards and if you
have the right talent using it it could
be because in some cases Gary talking to
you know the experts or the users
uh in some cases like in healthcare and
others they don't have a choice but to
use they say synthetic data.
>> Yeah.
>> Um because there is
you know, a lot of privacy and other
issues that they deal with. So, and so
we'll see how uh things go. Carrie, I
could go on and on and on. We'll have to
do part two, but for our tick tock kind
of listeners, we do have at the end a
lightning round of uh questions for you.
We need one word answers. So, are you
ready?
>> I'm ready.
>> Okay. And we'll try to keep it focused
on the procurement side even though
>> sure
>> I think you can handle it all. So uh car
AI procurement centralized or
distributed decision making.
>> Uh yes
>> no no pick one centralized or
distributed. Pick one of them. you.
That's not fair because you have to tell
me what type of a business or what size
of a business it is.
>> So, it depends is what you're saying.
>> It depends on the size of your business.
Obviously, if you're large, you need
distributed. If you're smaller, you need
uh centralized.
>> Okay. I'm going to give you an easy one
and I could probably use an old uh
President Reagan phrase. So, vendor AI
claims trust or verify.
Verify.
>> Okay. Uh AI contract terms, Gary.
Standard or customized?
>> Customized.
>> Okay. Uh post deployment changes, vendor
flexibility or strict controls.
>> Uh vendor flexibility.
>> Okay. This one is an interesting one for
you. So for AI procurement expertise,
should you build it internally or hire
externally? Build or hire?
>> It depends on the size of the company.
>> Okay. Uh risk management prevention or
mitigation.
>> Mitigation.
>> Okay. AI standards voluntary or
mandatory compliance?
That's a both.
>> Okay. Uh, this is an interesting one.
You kind of touched on this. Future
procurement. Is it going to be humanled
or AI assisted?
>> AI assisted.
>> AI assisted. Okay. This one I think I'm
we'll give you an easy one. Open source
uh AI models. Is it an opportunity or a
risk?
>> Opportunity.
>> Okay.
uh data for AI training consent or fair
use?
>> Consent.
>> Okay,
we'll ask two interesting ones. Most
overrated AI risk word, hallucination or
alignment?
>> Alignment.
And the best verb for AI governance
audit, assure or operationalize?
>> The operationalize.
>> Okay, Carrie, thank you so much really
for sharing your insights. As I said, we
covered the uh new announcements from
the Trump administration. We covered
procurement, we covered agents,
synthetic data and we could have gone on
and on you know because you have the
tremendous intersection of uh you know
AI governance and also practical
implementation which gives you really a
unique perspective and you know to our
listeners Car's approach tells us uh
that effective AI governance is isn't
just about creating the right policies
it's about her favorite word of
operationalizing them through practical
mechanisms like procurement training and
organizational change management.
And also one of her other favorite
words, don't let the bad stuff in is in
a thoughtful acquisition practice which
offers you a concrete path. This is the
regulating AI podcast. I'm your host
Sanjay Puri. Until next time, keep
advocating for AI that serves humanity's
best interest. Thank you for listening.
[Music]
Hey,
[Music]
hey, hey.
[Music]
