it's really important that when you are
looking at AI systems that the that
there is a real focus on what the data
set is what the training set is right
because that is going to have a huge
impact on what information comes out
what recommendations come out of that
system welcome to the regulating AI
podcast join host Sanjay pury as he
explores the dynamic and developing
world of artificial intelligence
governance each episode features deep
Dives with global leaders at the
Forefront of regulating AI responsibly
tackling the challenges using AI can
bring about head-on and enabling balance
without hindering
Innovation welcome to the regulating AI
podcast artificial intelligence AI
stands at the Forefront of technological
Revolution so how do we regulate it
without stifling Innovation our podcast
features insights from various
perspectives from industry leaders to
government offical officials to leaders
of advocacy groups together they address
pivotal questions that are needed to
create fair and practical
legislation I'm very excited to have FAA
Patel with us today FAA serves as the
Director of the liberty and National
Security program at the Brennan Center
for justice I invited her on this show
as it is very important to get different
perspectives towards framing a
legislation and we need to get a
perspective itive on civil rights and
civil liberties welcome faisa it's an
absolute pleasure to have you on the
regulating AI podcast thanks for having
me fza can you for our audience which
comprises members of congress senate
think tanks uh member of Congress staff
and it's a global audience industry
advocacy groups can you give them a
little overview of your role sure so uh
my team uh works on um primarily on the
uses of AI in National Security Law
Enforcement and overlapping immigration
context and our basic goal is to
advocate for rules that ensure that um
AI systems used by government like all
other tools that government uses is fair
effective and accountable so those are
our primary
goals so fair respective and accountable
um so if that's the case FAA where do
you see the biggest risk uh from AI to
civil liberties um and
rights so the thing with AI as you know
is that it encompasses such a range of
different uh uses and uh so you you can
see risks in everything from housing to
employment uh education what I primarily
focus on though is the risks of you know
when the government is acting in ways
that are highly consequential for
individuals when they are
deciding uh your immigration status
whether you get a green card for example
whether your citizenship application to
the US is um is uh slowed down or uh it
is allowed to go through whether you get
arrested
because of facial recognition system
errors whether you are subject to
surveillance because some AI system
somewhere flagged your social media as
being potentially linked to violence
these are things that you know really
affect fundamental Liberty interests and
those are the things where I really
think you have really high risks from AI
I just want to say just one thing though
which is that you know it sort of feels
like the world woke up to AI with the
launch of chat GPT but in fact these
issues as you know are longstanding
we've been talking about the use of
algorithms in predictive policing for
example uh in social media monitoring in
all these different contexts for at
least a decade that I can recall so this
is kind of a new focus on an old
problem so p a new focus on an old
problem because as you said these things
have been there but they've somehow come
into our Consciousness now so how can
policy help prevent some of the things
that you talked about you know air
enabled Mass surveillance or predictive
policing systems from basically
disproportionately targeting some
marginalized groups so I think there's
sort of two sets of responses to that so
one is that you know AI is simply a part
of systems and programs right so I think
at the fundamental level we need to have
stronger rules around how government
performs its activities and its
functions um and those stronger rules
will then translate into the AI space as
well so what I'm thinking of for example
is the issue of bias right one of the
big issues in the United States is
racial bias or religious bias on the
part of law enforcement targeting black
people Latinos Muslims in the context of
counterterrorism operations and our
rules that prevent agencies from
undertaking bias operations are not
strong enough leaving AI aside the
fundamental rules are not strong enough
similarly the fundamental rules
protecting free speech in the sense of
you know when can an agency monitor what
you are saying online definitely not
strong enough across the board so I
would say step one is that those basic
rules need to be uh more robust than
they are now then when it comes to
looking at AI in particular you know
there it's obviously a multifaceted
problem I mean there's so many different
levers that you can touch on and I I I
guess I would focus on two pieces of it
so one is inputs and one is outputs
right so I think it's really important
that when you are looking at AI systems
that that there is a real focus on what
the data set is what the training set is
right because that is going to have a
huge impact on what information comes
out what recommendations come out of
that system so it's really important to
have controls around input and
for for the government to have to to ask
the right questions about what's in the
TR data which I don't think in the
current systems is is a given in in many
agencies the second thing is you have to
look at the outputs you have to be able
to examine how these systems operate in
practice and who is getting affected by
them and who is getting negatively
affected by them so I think that's one
way to sort of slice the the the
conundrum of how to how to deal with uh
regulating
AI so uh F you made couple of points if
I can uh unpack them for our listeners
one is obviously the uh current laws
need to be strengthened as you said that
we have some laws on the books keep AI
aside whether it's our civil liberties
they need to be strengthen as you said
whether it relates to you know uh
discrimination or policing or things of
that nature second you said it are
inputs and outputs the training data now
you saw uh there was an executive order
issued by the white
house uh and you talk about the input of
data the ingestion of data how how do
you control them now this is being
controlled by private companies you know
large companies small companies Etc you
are saying the government should have a
role in that is does the executive order
in your view address some of those
things so I'm not saying that the
government should have a role in what
data the company's ingesting I'm saying
that when the government deploys an AI
system right it must know that the data
the training data for that system is not
repete with bias so for example I mean
one of the you know the one of the big
sort of examples of of of training data
bias is around facial recognition right
I mean there have been many studies that
show that facial recognition
is really best at recognizing white men
right when it comes to women or people
of color it's just not very good at that
and the reason it's not very good at
that is because its training data set is
weighted heavily towards Caucasian male
faces right so that kind of skewing of a
data set has huge consequences for
people in real life and so the
government must make sure that when it
is buying an AI system it's not buying
something that has a skute underlying
data set so you're saying from a
government use to clarify that's a great
clarification whether it is let's say
for immigration policies whether it's
for Social Security whether it's from
IRS or for hard for housing policies the
government should be careful in terms of
the data that they are getting that it
is not skewed uh irresponsibly right
fisa exactly
okay um so in your view if you were to
take that further because you mentioned
uh some deep FES what constitutes
harmful manipulation versus Free Speech
uh when it comes to AI generated media
like te fakes because you did talk about
free speech um you know and now there
has been a lot of talk about deep fakes
we've had uh as you know in the primary
New Hampshire there were uh calls made
for you know some sounding like
President Biden that they should not go
to vote and many other things so what
constitutes harmful manipulation versus
free
speach that is a really hard question uh
so I think that um you know I think I
think that people who are concerned
about manipulation of media and its
impact on our politics and our
elections um will'll generally conceive
that it is very difficult to draw the
line between you know somebody who is
you know creating a fake uh video or
audio uh maliciously and somebody who's
doing that as part of you know it could
be satire it could be humor you know you
don't have to have a reason for wanting
to play around with videos right um and
I think it's very difficult to actually
regulate in this space except for a few
things so I think that um some areas
where there is more ability for the
government to regulate manipulated media
would be for example campaign ads right
because that is already an area in which
there is a lot of Regulation about what
um candidates and their campaigns can do
and can't do um another area where I
think it's possible to regulate a
manipulated media would be in the
context of um messages that are like
misleading voters about you know where
they can vot vote and you know uh the
place they can vote The Times They can
vote how they can vote like mailing
ballots you have to person things like
that I think are are more amable to
regulation given their sort of special
status uh in terms of every uh of our
democracy I also think that in sort of
regulating in this space transparency
measures are more defensible than
measures around you know removing
certain kinds of content um I think
there's there is a robust debate about
how effective it is to label something
generated by Ai and you know we all live
in a in a world where we have many many
things competing for our attention at
all times uh including you know videos
and so
I I'm not 100% sure that that that what
effect that has but that at least
provides somebody who wants to know
information about what it is that
they're seeing so I think what I would
say is like I don't think that there's
like a bright line that you can draw
between a deep Faith versus you know
something that people are just doing for
fun it often comes down to intent um and
even then I think it's really difficult
to regulate in the space because of the
complexities and because of First
Amendment Free Speech protections um so
I think there are these narrow areas
where not narrow but in there these
areas where you can
regulate and transparency is probably
the most defensible
regulation so what you're saying is a
thin line it's sometimes hard to
regulate now in uh the case of political
ads Etc the FTC has come out clearly and
uh some of these companies recently came
out with a political Bill of Rights
saying that they would be very careful
whether it's an open Ai and uh you know
Google and others uh given that we have
uh presidential elections this year we
also there about 60 countries that are
going through elections does the issue
of deep fakes concern you given uh
what's going on in the political
environment not just here but globally
also f
I mean yes obviously I mean I think the
the issue of of of manipulating media
first of all it's a longstanding issue
right like you know it's just become
easier and more widespread as more and
more tools have become available to
people and more and more people are
using them um so I think that it is
definitely an issue I I think on the
flip side it's really important uh
public education I think in this space
is really important it's important that
um that ordinary individuals who may
come across these kinds of videos or
audio or pictures or whatever have this
sort of instinctive like is that true
really and I feel like anecdotally I've
seen this a lot more in the last five or
six years you know how we're all part of
these WhatsApp chat groups right so like
people post all kinds of rubbish on
these on these uh chat groups but I've
seen more and more people like actively
pushing back like is that true like how
do you know that's true so I think
that's a responsibility on all of us and
then on us to like educate ourselves um
about what is happening in the
information environment so that we are
actually careful about what we rely on
so educating ourselves and becoming more
aware I think f is what you're saying
especially as far as the information uh
flow that is uh
concerned uh FAA moving a little bit to
more of these companies uh do you have a
view on what civil right principles
should some of these large technology
companies who are building AI systems
adhere to uh in their product design
process all
all I mean I think they should adhere to
all and I think it's important though to
sort
of I don't think we should think about
civil rights and civil liberties in the
s of physical world and in the virtual
world as being two entirely separate
things at the end of the day we want to
enjoy the same rights and freedoms in
the virtual world as we do in the real
world the question is really how do you
translate from one to the other uh so I
think that that really companies in
developing these tools need to be highly
cognizant of the diff
and civil liberties implications of
their tools that is their responsibility
to figure out that look I'm making this
let's say predictive policing tool how
could it go wrong who could it har um
and then think about you know ways to
mitigate that harm which by the way may
not always be possible there may be
tools that simply cannot be um adjusted
enough to mitigate real serious harms to
individuals so I think that's the M that
that would be sort of My overall message
I would though sort of pull out a few
things that I think are important so one
is privacy rights right um I think you
know the lesson that we've learned over
the last couple of decades in seeing you
know different kinds of tech tools being
rolled out and then suddenly I was like
oh wait a minute what about data PR
privacy and it's really late in the game
because then they are you know trying to
add things on and it doesn't work as
well as integrating principles about
limiting data collection for example in
tools in the first place the second
thing I think is that it's really
important to think about um bias I think
bias is a true line in in all of the
discussions that I've had about AI that
how do you how do you see when your tool
is biased again inputs outputs right um
and then how do you how do you how do
you account for that and I'm not sure
that we have seen
any sort
of
credible and reliable kind of um methods
for doing that but I'm not a tech person
myself I'm just a lawyer so uh maybe
they're out there but certainly when you
see the reporting that comes up over and
over again about the kinds of mistakes
that um these tools make it makes you
question whether these issues have been
addressed although everybody claims they
have been right so you're saying is uh
two key things uh FAA one is obviously
privacy and then the bias issue
so how can policy address uh algorithmic
bias and discrimination issues in AI
without stifling Innovation can that be
done well so first of all I think I kind
of uh I I sort of have a real problem
with this dichotomy with this idea that
like you know AI Innovation is here and
and discrimination is here because if an
algorithm is biased I don't care what it
does it's not it's not effective right
so if my so I don't think that you can
say that something is innovative when
incorporates bias whatever it is that
you are trying to do if it is not fair
and
objective I don't see that as an
improvement it may be faster but it's
just not working as well and I think we
need to to hold that idea in our minds
that innovation without you know
adhering to sort of basic principles is
really not valuable to us as as a human
race so I think that's the first thing I
would say um you know I mean think about
it this way right like one of the
big things I was in fashion maybe I
don't know seven eight nine 10 years ago
where these algorithms that were
designed to help judges decide who to
give bail to and who to send back to
prison and it turned out that those
algorithms were weighted in ways that
they sent black people back to prison
and denied them bail systematically at a
higher rate than white people and is
that
Innovation I I don't think so I think it
it's not an effective algorithm if it's
bias so I think that's kind of what I
would say to that so it's as you said
there it's not an either or uh option
FAA we've had uh many experts who have
come in you know people from Key
academic institutions who build large
language models who say that to create a
100% unbiased system is almost an
impossibility what are your thoughts on
that well I mean I guess a lot of it
depends on like what do you mean by bias
right uh because of course we live in a
world of bias and human beings also have
biases which they they bring to the
table whenever they make decisions um I
think it it is
a challenge for these models to be
unbiased especially as the definition of
what is bias is so contested right um so
I'm not suggesting that I think that
they're going to be 100% unbiased but I
do think that they need to be more
unbiased than they have been from what
we've seen over the last um decade or
so um in your view pra what governance
mechanisms would enable communities that
are impacted by some of these AI systems
to flag harms early
on so I think that um you know one of
the big
challenges there are a lot of challenges
for marginalized communities in sort of
addressing Ai and AI harms right um you
know generally speaking you know you're
talking about communities where their
representative groups have you a bunch
of issues to deal with not just AI
they're often under resource and then
you have these sort of like very
technical barriers right A lot of people
uh who represent you know communities of
color or or poorer
communities
um had this sort of threshold issue
about sort of addressing these harms but
it's critical that they do uh so I think
one way that I would say is that it is
important
for to build an ecosystem of these
groups and Community groups and
Grassroots Representatives that
understand the importance of AI in the
lives of the people who they they are
trying to represent the second thing I
think that's really important is this um
question of transparency right we
everybody talks about how you know AI is
a black box and you don't know what's
going on inside it but a lot of the time
you don't even know that it's affecting
you and that's one of the things I think
that is um a good development in the uh
I mean first of all transparency has
been a principle that the White House
has promoted since it it published its
blueprint for an AI Bill of Rights and
then again in President Biden's
executive order um and more recently uh
the office of budget and management
issued a memor some guidance it's draft
but it should be final soon and one of
the provisions in that guidance says
well if somebody is negatively impacted
by an AI system then they need to be
given notice of that uh I think that's a
very important step forward because only
then will you be able to start to pull
back um some uh pull back the the the
veil on the different forms of
AI so do you think uh basically uh some
of these communities that you talked
about just now they can actually work
together they can mobilize with the
private sector and Academia to prevent
some of these harms uh that we are
talking about I mean certainly I feel
like a lot of of of communities have
mobilized right and people are talking
to each other and working with each
other I from what I have seen again
limited perspective I don't know
everything um I think that the
conversation around regulating
AI is still
too centered
around
um sort of tech policy
oriented uh viewpoints uh with
fewer uh viewpoints that are reflecting
uh that are not reflecting but that are
sort of you know really representing
directly impacted communities and I
think that really needs to change and
and become more incl that that space
needs to be uh more
inclusive PHA what kind of communities
as our listeners are as I said members
of Congress they're in the
administration what kind of communities
would you recommend that they kind of
also listen to that are have been
impacted uh in your view that are not
being potentially being listened to so
to speak yeah and and just to be fair I
mean there are you know big
organizations representing you know
communities of color which is a lot of
what I'm talking about over here that
are part of the conversation I'm just
saying I think there needs to be more of
that uh just based on what I've seen in
my experience and I think when what do I
mean when I mean we do talk a lot about
impacted communities generally speaking
I think you know there's there's a
couple of ways of thinking about that so
communities that have historically been
disadvantaged within a particular
country so if you're in the United
States that would mean black and brown
communities
um often overlapping with immigrants I
think those are the the communities of
concern as far as the way I see
it so uh different commun also sorry if
I may there are also other communities
right I mean there's a whole Community
there's also like labor issues around AI
there issues around creative
professionals so certainly those are
additional issues which which uh need
consideration as well but looking at it
from the
civil rights and civil liberties lands
those are the communities I'm really
focused on oh sorry yeah go ahead no
please no it's my um there we
go uh fra in terms of what you talking
about you know the civil liberties do
you think International cooperation is
necessary from a regulatory standpoint
you see uh what the EU has done they've
obviously gone ahead uh the US is you
know it's a presidential year we don't
know what's going to happen here um but
do you think International
cooperation uh is necessary in terms of
regulatory framework for some of these
things I think it's pretty essential
actually I mean I think that and you've
seen that both the EU and the United
States have taken steps towards sort of
convergence right obviously the EU is is
further along in developing Reg ation
but if you look for example um there are
a lot of other mechanisms in place which
are sort of where you have officials
from the EU and the United States trying
to agree on sort of key definitions and
and uh ideas and principles um if you
look at you know something like um the
the nist has a document on sort of how
to sort of evaluate AI systems and it's
not a regulation but it is also a lot of
the the thinking that uh you see in the
EU um AI act that being said I mean here
we're talking about very big picture
things right uh certainly I think on the
nitty-gritty of it uh there it will be
difficult to get uh a lot of agreement
but I think alignment is something that
that is you know some that that should
be we should be striving
for um obviously we have to strive for
alignment uh as far as uh from a a US
standpoint do you think there should be
a dedicated or a specialized regulatory
body uh that'll oversee the development
and deployment especially for protection
of some of the civil liberties uh what
are what is your thought on that yeah I
think so I think it's actually really
important to have uh a regulatory body
that has sort of just a overall
oversight over um over these systems I
think one of the things that I was very
disappointed in the Biden executive
order uh was the fact that um national
security systems are Exempted and put on
a separate track uh I understand
obviously that there are special
sensitivities about national security
systems but I still think that National
Security Systems should meet the
Baseline standards that the White House
has set up for AI in general which is
you know kind of like they need to be
fair they need to be effective you know
these are things that you want from
every system particularly systems that
are uh that are uh charged with very
consequential decisions so I do think
that that's that's an important thing
that needs to be
addressed B so one of the things that
keeps uh coming up not just with our
guest but everything I'm sure you read
is uh that there is going to be a
transformation as far as jobs are
concerned um you know there's all kinds
of numbers whether if you read McKenzie
or IMF that up to 60% of White Collar
jobs um in developed economies maybe 30
40% in less developed
economies uh what are your thoughts on
that and does it do you think impact
some marginal communities a little bit
more than others or is there there what
is the consequences and should what
should be the role of regulators as far
as this massive transformation that
could be
underway so that's pretty much outside
my area of expertise um I think though
that you know and as we've seen uh over
the last um year or so as these debates
have been very front and center is that
you know the government
um has to figure out if in fact these
estimates are true and I am personally
quite skeptical that these are as true
as they seem to be especially as you see
at least the early iterations of some of
these sort of um AI tools that are
supposed to help you do basic stuff you
know kind of fail again and again there
was a a recent article I think yesterday
or the day before about the uh the Turbo
Tax chat function and how it like gave
the wrong advice a third of the time to
somebody who's trying to TA file their
taxes now I understand it's going to in
theory get better uh but I don't think
that um I I think that some of the story
about the
transformational power of AI is hype at
least in the near term um it may be true
in in 10 15 years but certainly at the
moment I think it's there's a fair
amount of hype um the second second
thing I think is that obviously if there
is a foreseeable and massive labor
disruption it would have huge
consequences for the our societies right
no matter where you live if it's 60% or
30% um those are things that it is a
government's duty to address how it will
approach and and how it will
mediate so obviously you think you're a
little skeptical about those numbers
because as you said the systems are not
up to the par but the government should
definitely be paying attention towards
that um what recommendations FAA would
you give lawmakers for protecting civil
liberties in an AI powered
world because they're also coming at it
uh remember they're not AI experts
they're not machine learning gurus right
they're dealing one day with uh uh
Ukraine another day with the issue with
Hamas and third day with border security
all in the same hour so uh an expert
like you what would you uh give them
advice in terms of uh protecting civil
rights in an AI powered world so I think
there sort of two slightly contradictory
things I want to say um so one is that
you know so far
um in the US the uh regulation of AI has
been either through soft law like
standards like the N standards and such
um or through executive order um and as
we've seen you know executive orders can
be
rescinded uh soft law can just disappear
so I think it is important for Congress
to act uh so that we have an enduring
Baseline of of applicable rules of the
road for this you know they really
shouldn't be abdicating this completely
to the executive branch I um the second
thing I think is that I think we have to
remember that AI regulation is not a
oneand done right even if you know there
is regulation coming out of Congress
which I know seems like a very long shot
possibility
um even when that gets done I think you
know we are at the beginning of the
process of regulating AI we are not in
the middle we're not even you know we
haven't even taken more than baby steps
in this direction um and we don't know
how the technology will evolve we don't
know fully what the harms are we have an
idea based on card systems and card uses
of the types of harms right but who
knows what what would come next uh and
which ways the technology will will turn
I mean if you take a look at at social
media for example and you kind of trace
the evolution of the the social media
platforms and how they have fared right
so they started out
having getting a a very um generous
Grant of immunity uh for hosting content
under Section 230 right and you know the
first few years was all you know hunky
dory everybody was connecting it was
Kumbaya uh all this love your friends
and family you know you could talk to
your high school friends and different
country and all of this and it was great
and then it wasn't right and then it
became you know the last sort of six
years I think five or six years has just
been all about like all the harms of
social media disinformation you know
teenagers all of this stuff it took a
little while for all of that to become
manifest and we've seen this in real
time right it's happened in our before
our eyes and so I think uh a little
humility in the face of new technology
is also wared that being said there are
Baseline thing Congress should act and
it should act pretty quickly um so that
the tools do not get entrenched into our
systems without some fundamental guard
rails so um as I'm in Washington we
don't do things fast we don't even do
things slow we do things very we don't
do we don't we don't
do I you said that but uh uh given that
you said that we need to act which is
absolutely right and you also made a
very excellent point that social media
it was all great as you said we found
friends we never could have ever found
uh you know our through school etc etc
um but uh obviously the EU has taken uh
much faster as you know they always are
ahead of us in as far as regulation is
concerned
um does do you also worry that maybe I
mean when you look at social media since
you brought that up our town square or
our connectivity is controlled by four
five six companies those same companies
are now exactly uh
making rapid advances because it takes a
lot of money and resources to do this
these are the same companies and data
yeah and data because they own that data
which you talked about early does that
worry you that again uh you know they'll
be in control and with AI they can
control the history they can control the
present they can control the future in
many ways any thoughts on that vaa I
mean absolutely I think you're
absolutely right I mean I think there's
a huge gatekeeper problem uh already
with with these these I forget six seven
companies that uh are also responsible
for for the rise uh in our 401K plans
and the like uh but I think there's a
huge gatekeeper problem and you know
there was a lot of um again the EU has
been much more aggressive in in taking
on these companies and has you know has
Levy pretty substantial findes on most
of them I think they finded uh Apple
earlier this week um and so antitrust is
I think definitely part of the uh
um way to
address AI um that being said I'm not an
antitrust expert so I couldn't tell you
exactly how but it feels to me that you
know that's definitely part of it I
think there's sort of you know two areas
where which are sort
of Upstream from AI but which need to be
addressed in order to address Ai and the
first one I think is privacy and data
protection which again the EU has has
you know far Advanced from the United
States and then the other one is
antitrust and and you know monopolistic
power yeah so antitrust uh is something
that you're saying is should be taken a
look at uh FAA you did drop in a point
saying that you are a lawyer so I'm
going
to uh try to throw a sort of a legal
question at you and I that'll be my last
question but I couldn't resist that so
if an AI system whether it's a large
language model or anything uh does
create does harm whether it's civil
liberties which is your area of
expertise who should be responsible the
developer of the system the implementor
or the
user because that's a question that
keeps coming up a lot and it's a great
question and the answer has to be it
depends I knew because you said you were
a lawyer
that's what the lawyers answered to me
on this but anyway but you but it is
right uh it does but that's something
that will come up or uh for us to
litigate or decide over a period of time
uh absolutely it will definitely come up
uh any last words for our listeners uh
as I said it's a global audience uh uh
something that you would like to share
with them with some of the things that
you've been doing this has been a great
conversation
yeah I mean I think you
know i' saying obviously if you're
listening to this podcast you're already
doing this but to pay attention to these
issues because they are going to have
important
ramifications uh for our lives uh you
know as a lawyer I'm also a skeptic so I
tend to read uh claims of of Earth
shattering changes with a little bit of
a grain of salt and some chili uh so
that would be the other thing I would
say um and then that third I would say I
mean I'm sure most people have already
done this like it's actually kind of fun
to play with AI and play with tools like
chat GPT or w-e and see what you can do
it is you know kind of creative in a way
as well so they are actually super
fun so be skeptical but have a little
fun and be aware that's uh faa's Last
Words thank you so much this has been
great there were so many other things I
wanted to ask uh but maybe we'll have
you over
uh another time thank you so much for
being with us by thanks
anj thanks for tuning in to the
regulating AI innovate responsibly
podcast you'll find links in the show
notes to any resources mentioned on the
show if you're enjoying our podcast
please subscribe so you'll never miss an
episode and leave us a five-star review
