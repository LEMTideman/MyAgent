Mostly government institutions should
provide you know the legal framework,
the regulatory framework for fair
competition
for the market to win out for the
journalistic organizations that have the
best ideas and can handle complicated
transitions to survive and thrive and
for the AI companies that have the best
ideas to survive and thrive. I think of
AI as it's kind of changing everything
every sort of layer of our business,
right? So I think it fundamentally like
will change search, right? And once you
change search, you've changed the whole
architecture of the internet, right? The
internet, the open web, what we access
through browsers. Open source is just
too risky, right? You take these tools,
you open source them, you put them in
the hands of individuals who could do
all kinds of damage. So there all these
things that make it hard for AI to
genuinely replace a job or somebody's
work. And there's, you know, we're
again, we're two and a half years into
this. How many companies
have really like laid off their white
collar workers and replace them with AI?
Like if you look what Instagram did to
society, right? And you look at the kind
of the insecurities and some of the it
did a lot of good and I use Instagram
and you I like to post my running photos
there. But if you look at like what it
did to the self-esteem of teenagers and
if you look at what it did to, you know,
the way we learn, the way we
communicate, the way that young people
date, the way they out in the world,
like it did a lot of harm.
Welcome to the Regulating AI podcast.
Join host Sanjay Puri as he explores the
dynamic and developing world of
artificial intelligence governance. Each
episode features deep dives with global
leaders at the forefront of regulating
AI responsibly, tackling the challenges
using AI can bring about head-on and
enabling balance without hindering
innovation.
Welcome to the regulating AI podcast
dedicated to bringing together global
voices to shape fair, responsible
and trustworthy AI policies worldwide.
I'm your host Sanjay Puri and today we
have the privilege of speaking with one
of the most influential voices at the
intersection of technology, media and
society. Joining us on the eve of the AI
for good summit where I'll be there too
in Geneva is Nicholas Thompson, CEO of
the Atlantic. Under Nicholas's
leadership, The Atlantic has reached its
higher subscri highest subscriber base
and count since its founding in 1857
while also becoming a leading voice in
the critical conversation about AI's
impact on society. Nicholas also brings
a unique perspective to our discussion
today. He was the former editor in chief
of Wired. He's been at the forefront of
technology journalism for over two
decades. And as the host of the most
interesting thing in AI podcast and
creator of a daily video series on
technological change with over two
million followers, he's interviewed
virtually every major figure in the AI
field since he began talking about AI
globally in 2017.
I could go on and on, but Nicholas,
welcome to the Regulating AI podcast.
Thanks, Andre. I'm delighted to be here
on the podcast and I look forward to
seeing you in Geneva. Absolutely. Uh
Nicholas we have a global audience uh
US, Europe, Asia. These are people who
are in the AI world, entrepreneurs,
policy makers and you know just folks
who are working building uh cool things
in AI. So um it's going to be a
fascinating conversation but you're
heading to Geneva just like I am for the
AI for good summit and there you'll be
interviewing some pretty incredible
people. Jeffrey Hinton, Yan Lakuna, you
know, some of the godfathers of AI and
also Mark PÃ±a from Salesforce. So, as
someone who has virtually interviewed
every major AI figure,
what are some of the questions you're
most eager to explore with uh these
three different perspectives and the
these are very three different
perspectives? I'm sure you understand on
AI's future. Yeah, there are three very
different voices. They're three
extremely interesting people. or three
people I've interviewed each of them
multiple times before
with with each of them I'm going to you
know bring a different set of questions
a different set of problems you know
with benny off it's really about
businesses and the speed of this
transformation he's been talking about
the number the amount of work Salesforce
that get done gets done by AI speed at
which they are creating AI agents the
way the AI agents work with humans I I
think there are a lot of lessons from
him. He's also a very important voice in
debate over climate, oceans,
environmental sustainability. Since this
is a UN AI summit, we're going to get
into those topics with Jeff Jeff Hinton.
He's one of the most articulate people
about some of the risks of AI. He has a
very deep-seated fear about what could
go wrong, some smart ideas on what could
go right as well. But I want to
understand from him
as he's watched the last couple of
years. I talked to him last year at the
same summit how his perspective has
shifted. Right? As we've seen certain
things speed up, certain things slow
down. I'm going to ask him about some
recent papers, some recent findings.
Jan is also an extremely interesting
case where he is right at the center of
Facebook and very much at the center of
open source AI which I consider
one of the
most important topics in AI the degree
to which
open-source companies openweight models
become part of the future AI ecosystem.
So I'll be asking him about that. I'll
be asking him about what has been
happening at meta and I'll be asking him
about he's always been quite skeptical
about the capabilities of large language
models particularly those built on
scaling laws and I want to ask him about
how those perceptions have shifted so
those are a little bit about what I'll
ask the three of them well we'll be
tuning in uh because uh it it's really
going to be fascinating very three
different perspectives And uh Mark
wanted to change his company's name to
agent force etc. But that we won't go
there. Uh so uh it's an agent first uh
company. U
Nicholas uh you know the Atlantic has
really thrived under your leadership
while I'm sure it's uh no surprise to
our listeners. A lot of media
organizations have struggled with AI's
disruption. Yeah. You know from your
vantage point you're leading a really
167 year old legacy institution. How
should regulatory frameworks balance
protecting legacy industries like
journalism you know which are very
critical for many many different things
while also fostering AI innovation.
Yeah,
I mean there's only
mostly they should provide mostly
government institutions should provide
you know the legal framework
the regulatory framework for fair
competition
for the market to win out for the
journalistic organizations that have the
best ideas and can handle complicated
transitions to survive and thrive and
for the AI companies that have the best
ideas to survive and thrive. That's what
you want. You want a fair market. You
want a fair fight. You want fair
competition.
There is one specific issue which you
know I've talked about and I do think is
important which is I do think that the
original sin of these AI companies and I
love these AI companies. I use them all
the time. there's an original sin in
that they went and they scraped the
entire web and in many cases they took
data sets of pirated content including
from the Atlantic and other publishers
and at the time you know they didn't
have money they didn't want to deal with
legal compliance they didn't want to
deal with all that as you know some
documents have said that legal blah blah
and so they pressed ahead and built
these models and never compensated the
creators and so that's an issue right
and so if they're building models that
compete. They're building products that
compete with journalistic organizations
as they do in some ways. And they've
built it sometimes on pirated data,
sometimes just on data that was scraped
in the dead and night. That needs to be
worked out and it doesn't need to be
worked out by the government, doesn't
need to be worked out by the courts. It
can be worked out by the media companies
and the AI companies, but it does need
to be worked out. So, there has to be a
fair exchange of value. And so that is
something that we are engaged in at the
Atlantic. We're engaged in it. We have a
deal with OpenAI. We have conversations
with many other companies. We're
involved in consortium that is part of
the lawsuit. The thing I would most like
is for the AI companies to build
products
that drive readership to media
organizations and that compensate media
organizations or creators, whether
musicians, artists, for their
contributions to the products that the
AI companies have built. That's the best
way to do it. If that is not built, then
there are other solutions which include,
you know, lawsuits or government action.
So, let's just uh go a little bit deeper
into this because you saw the recent
anthropic ruling which you noted is a
mixed message on fair use. How should
regulators reconcile this transformative
use with creator comp compensation? And
what are some of the solutions? I mean,
do you see collective bargaining by
publishers as inevitable or is there a
better market-based solution? Yeah,
that's a some really interesting really
interesting parts to that question. So,
you know, there were two cases I think
last week. One involved anthropic, one
involved meta, somewhat divergent, both
mixed bags. You know, both district
courts cases so don't really provide
full clarity. Uh in the anthropic case,
what they said is that, you know,
anthropic's use of the books that they
trained on was in fact transformative
and therefore fair use. At least for the
books they paid for, the books that they
pirated, no, that's not okay. So you
have to compensate the authors of the
books you pirated, but the books you
paid for, that's fair. In the Meta case,
the judge actually said, you know, in
this particular case, you know, Meta
wins, but mostly because the case wasn't
brought the right way. And in fact, if
you read that ruling, the judge says if
you're building an AI product that
competes
with the stuff you trained on,
as it seems is the case here, and as
certainly as seems the case in media,
the judge particularly notes, then
that's the severe problem. And so what
you there have is a complicated
question. It's a complicated question in
American law and then also just in
general ethics. If you take something,
you transform it and then you build
something that is partially but not
completely competitive what are your
obligations and in the meta case it
seemed very much the judge was saying
your obligation is to compensate the
people for the trading the anthropic
case less so but don't pirate so I don't
know what the ultimate lessons are to
your question about collective
bargaining
by publishers hard you know collective
bargaining for publishers that's hard
because of antitrust regulation um
you're not actually allowed to
you know get together and do that or
there limitations on it. So there are,
you know, there are organizations that
publishers are part of. There are trade
groups. You know, the lawsuit that we're
involved in is brought through News
Media Alliance, which is a group that we
are part of. Um, I do think that that
will be part of the solution. You know,
ultimately I think that
I hope that there's going to be a
technical solution. For example, let me
just talk about one company that, you
know, we work with. It's called PRAA.
Mhm. What they're doing is they're
building a tool to identify in an AI
search how much did different publishers
contribute to the information that was
given. Make a search what happened in
Iran today and your answer comes you 6%
from the Atlantic. Then the model would
be okay. So 6% of some revenue share
percentage let's say 50/50. So 3% of the
revenue that is generated by the AI
company on that search maybe goes back
to the Atlantic like that is a fair
model. My hope is that there's a
solution like that that works across the
market.
So what you're saying is when we look at
a perplexity they have these this
percentage answer this percentage
answer. Nicholas, these companies are
slowly veering into becoming the
operating system really to you know I'm
sure when you you you're using whatever
tool you use a lot for basic things how
is that going to move the needle in
terms of publishing and the challenges
of publishing because
it's not simple links that they're
saying okay go to Atlantic and find this
story uh that world is a little
different isn't No, the world. So I
think of AI as it's kind of changing
everything, every sort of layer of our
business, right? So I think it
fundamentally like will change search,
right? And once you change search,
you've changed the whole architecture of
the internet, right? The internet, the
open web, what we access through
browsers, you know, for the last 25
years or the last gez almost 30 years
has been, you know, mediated by Google,
which you go to Google, search for
something, then you go out. Now you'll
just search for something. It would just
answer it, right? And so that will
denigrate the rest of the web, right?
The rest of the web could
shrink. It could go to zero. Who knows
what's going to happen? But certainly
the rest of the web will become less
important a thing, right? And browsers
will become less important. So that
matters to the publishing industry
because that's how we get a lot of our
revenue. People go to the Atlantic. Now,
some people will still go to the
Atlantic. You'll type in
theatlantic.com. You'll go into a
newsletter. You'll go through social
media. There are many ways you will get
there. Some people will still go in
through Google. Some will go in through
perplexity links, right? So there will
be a whole different ecosystem for how
people find us. So that's part of what's
going on. Then there will be a whole
different method by which publishers
create content, right? Some people will
use it for writing. We don't do it at
the Atlantic, but people do use it for
research, for thinking. You know, these
tools make us so much smarter. It should
make, you know, journalism and the
content produced by publishers much
smarter. So, we should be able to
produce more content in better ways by
having the best people working with the
best tools.
Right? I just wrote a book. Book is
coming out. It's about running. I used
AI all the time. Never to write
anything, not one word, but to think
through things, right? And to help me
understand complicated concepts. So,
it's changing the ecosystem by which we
find things. It's going to change the
ecosystems by which we read things. We
will have AI tools. We will send out
agents to the web to get us information
to summarize us to find the facts we
want. It'll change the means of
production. So, you're kind of changing
every step along the way. So, as a CEO,
I have to figure out how to position my
company to succeed on all those
different fronts as best I can.
Recognizing that no one can really see
like we're two and a half years since
Chad GPT launched. No one can really see
where this is going.
Just to follow up, uh Nicholas, I'm just
thinking, is there a generational issue
here too? If you're a 16-year-old,
15year-old, 17year-old or a 14y old and
you're just coming off on chat GPT or
take claude or whatever you want to do
and you're getting that information and
that's all you have gotten. You don't
know Atlantic. You don't know any of
these other things and you grow up in
that environment. How does I mean I know
it's hard to figure out but I see what
some of these young people you know on
their mobile. Is that a possibility?
Well, I mean it's really interesting,
right? We we we've kind of gone through
it with social media, right? Where
people go through and
young people read less than they did in
the previous generation. They read fewer
books. Um, there's still plenty and
there's still plenty of young people who
subscribe to The Atlantic and love The
Atlantic.
I wonder sometimes
I kind of think that the effect on young
people of AI will be less bad for
publications like us than social media.
I mean, if AI ends up creating these
sort of false fake worlds inside of
social media that are infinitely
attractive, maybe. But like the Atlantic
thrives when people are curious about
the world, when they're, you know,
educated, when they, you know, love
words, when they love complicated
thoughts and AI, you know, AI makes us
all smarter, right? It it deepens our
curiosity. It is an amazing tool for
trying to learn more about the world. So
maybe young people who grow up in AI
will actually be more likely to be
Atlantic subscribers. I don't know. Um,
I'm gonna I'm gonna I'm gonna bet on AI
making the next generation
incredibly smart and I'm going to bet
that that's good for increasing our
readership.
Okay. Well, you are an optimist and so
am I and I hope uh that happens. It is
definitely making us smarter even though
there are some people who say it's less
but you have talked about and you know I
I'm I live in Washington DC and we just
uh are going through this uh big
beautiful bill which had this uh
uh state uh piece of regulation which
you saw the proposal and you called a
real I I I think you called it a really
bad idea for regulating AI. So
now I interview a lot of members of
Congress and Senate and governors on
this show. Uh their issue is that we
need some time to get federal regulation
in but 10 years is way too much. There
was a issue that we uh I think Senator
Blackburn wanted it for 5 years etc etc.
Your thoughts on you just don't think we
should leave the states to do what they
need to do? I mean, this specific piece
of legislation was insane, right? And it
said no state legislation on AI for 10
years.
I mean, come on. Like, we're a
federalist country. Like, I understand
the argument that it is hard for a big
company to maneuver when you have to
deal with different regulations in 50
different states. And I understand that
it is hard when you have some states
like California that regulate you one
way and states like Texas or Vermont
regulate you in different ways. Hard
stuff. But it's not the role of the
federal government to say the states can
regulate on everything but they can't
regulate on AI.
Secondly,
that is particularly not the case
because it's not like the federal
government is regulating on AI. If the
federal government I would be slightly
partially a little bit more sympathetic
if there was going to be a set of
rational rules Congress was going to
pass and they want to preempt all state
legislation. So they say, "Hey, we're
introducing a national AI bill. It will
do X, Y, and Z, and we are preempting
state legislation." That is a more
logical position than, "Nah, you know
what? Just screw the states no state
rulings." So, I thought that bill was
terrible. Not that I agree with all the
state rulings. Some of the states are
have terrible regulation ideas, but in
general, I was very much against it. I
was glad that was stripped from Trump's
budget bill.
So, yeah, that happened. uh yesterday.
So um
Nicholas in your podcast you know the
most interesting thing in AI it's given
you deep insights into you know how AI
leaders think about regulation. What's
the biggest disconnect you have seen?
Now as I said you're going to talk to
some incredible three of the most
incredible people uh at the AI for good.
What's the disconnect you see between AI
developers or foundation companies and
what they want from regulation and what
policy makers are actually proposing in
some ways?
That's a hard question. I think maybe
I'll answer it in three ways like
what the I think what developers want,
right? You want individuals,
they want fair competition, they want
fair rules. I think they probably want
an ecosystem where there's lots of
competition which you would get through
enforcing antitrust by
you know creating rules around data
portability where you would use the
government to create public systems that
developers and academics can access like
that's something I believe in strongly.
I think that's what developers want. I
think developers want a diverse
community of lots of people building
lots of tools that can be shared in the
optimal ways and where you don't have
lock in network effects and just a few
big winners. I think the large tech
companies, you know, believe a little
bit of the opposite, which is they, you
know, they do think the world would be
safer if there are just a few big
winners. And, you know, it's not a
coincidence that it would be helpful to
them as well. And so, they're in favor
of legislation that sort of smooths
their path to to to that for good, for
good and for ill. Policy makers, I
think, for the most part,
a little bit focused the wrong way.
Okay, they're focused on
a lot of the conversation is around how
to mitigate the biggest harms, which is
legitimate, you know, but I don't I
think that's not the right way to do it.
Like what we should be doing from a
regulatory position right now is set up
markets so they're maximally
competitive, so that they're well
sourced, so the government is using and
creating tools and incentivizing
like the best work. If the goal is
you know the best, safest, most powerful
AI built in this country. You know what
you want are clear rules government
support um across the board.
So clear rules across the board. Um
what do you think of the EUI act? I mean
I have uh you know obviously I've talked
to lawmakers here and say we are never
doing that. Generally there's a big
consensus here. We're never doing that.
Yeah. You know,
in general, I'm skeptical. I think the
EU has shot itself in the foot through
overregulation, right? I was startup
founder. I had a company, an AI company
trying to create positive social media
experiences. We didn't even operate in
Europe, right? We just couldn't handle
GDPR, right? We didn't like our lawyer
said nobody under 13 and no Europeans,
right? And
that's, you know, why are there no
giant AI companies in Europe. Well,
number of reasons. One, immigration.
Two, market size. You know, three,
regulation. And so, in general, I'm
skeptical of the EU's approach to
regulation. On the EU AI act, I actually
don't think it was quite as ownorous as
previous regulations. I thought they
drew smart lines. I thought they were
relatively contained in what they
demanded. So, I'm not as critical. I'm
not I'm no expert on the EU AI act and I
haven't had a company that's had to
navigate it. Um but I think they I think
they did a better job. I do think that
there is a concerted effort in Europe
right now to not regulate themselves out
of the game in AI.
Yeah.
uh because we talked to a lot of uh
European companies and some of them well
a lot of them want to uh come to the US
for a lot of reasons funding regulations
etc. Nicholas uh there is this whole
debate open source closed source I mean
you know meta is uh open source um
mistral has gone open source um um where
what are your thoughts on this it's it's
interesting I sometimes think of this as
the issue where my views have shifted
the most in the last two years you know
I know that two two years ago I believed
open source is just too risky right you
take these tools tools, you open source
them, you put them in the hands of
individuals who could do all kinds of
damage.
Now, I've changed my mind and I've
changed my mind for a couple reasons.
One is I haven't seen that damage. I do
believe that actually like the best way
to counter bad AI is good AI and so
putting tools in the hand of good civic
organizations is absolutely essential. I
have found you some of the people I've
talked to have the highest commitment to
helping shape AI for the greater good
are working in open source and I don't
fully trust the big companies. So I'm
actually pretty pro- open source at this
point. Uh pretty open source AI at this
point.
Well, also add Deep Seek and those
things to the mix because whether we
open source or not, they've pushed it
out. Even Alibaba is pushing it out on
open source. That's one of the greatest
ironies of AI today is that you know
China the great closed system is pushing
out the open source um open source AI. I
do think on this, you know, the the
China US question, this is something
where I also had strong views where
going back to your previous note. I
think that there's a
there's a
misperception
that the US and China are locked in this
AI arms race and that one country will
kind of cross some kind of a line first.
Either the US will or China will. And if
China does it then suddenly they will
dominate the world. And it is true that
AI will affect national productivity. It
is true that you know country will be
better off if the AI companies inside
its borders are better off. It is not
true that there is that one specific
line. And it is not true that if it's
crossed by an American company, you
know, suddenly a United States will have
a massive national security advantage.
AI is too complex. There are too many
different vectors. There are too many
different forms of AI. There is no
single threshold. And I think that the
perception which is pushed by all kinds
of people in this debate,
there's a line that can be crossed and
that the US better get there first. I
think has been very damaging. Has led to
a lot of bad thinking and um bad policy
proposals.
Well, again I am in Washington so that
you know there is this whole thing uh in
terms of chip exports and sovereign AI.
Do you think we should be restricting
exports of chips to China since you
brought this issue up? You know I'm not
against
I wouldn't be an absolutist against chip
exports, right? I mean you do want
it's very hard to separate chips that
can be used for AI for foundational
models and chips that can be used for
military. You know you do want to make
sure that American technology is not
being used in Chinese military
technology. There are all kinds of
complex
trade espionage issues involved in this
in general.
I do think that the chip export ban you
supported by the Biden administration,
supported by Trump administration, has
been
not as effective
as they hoped. It has not slowed down
China as much as advocates of the ban
hoped. We've seen this in Deepseek.
We've seen this in other Chinese
advances. It is in fact probably helped
Huawei more than any other company. So
there has been a side effect. So it has
not worked as intended and I also think
that as a general principle
the United States and China should be
sharing more information right they
should be sharing best practices they
should be sharing an understanding of
where each other's AI is going so that
you know if humanity has a shared
interest in protecting against super
powerful AI right if we are really you
know if there is a chance as I think
there is that AI could become become a
existential threat to humanity. Like
China and US better be cooperating on
this and
I would like there to be more exchange
of ideas between the US and China, more
collaboration.
Um so that's a long way of saying
I think the bans as put into effect have
not been effective. I think they've been
a little misguided, but I'm certainly no
absolutist and I certainly understand
where some of the people with support of
the bands are coming from.
Yeah. I mean, right now there is no
appetite in this town for uh doing
anything else uh besides the ban. Um
another thing that you talked about
which is something I u focus a lot on is
this job apocalypse
that is uh you know uh Dario has talked
a lot about it especially you know even
in the past few days and there's been
that debate between Jensen and Dario
what are your views on this and then is
there a rule role for government
regulation in this uh so I
tell our listeners what do you think
about this whole situation well on this
you know the Daario the CEO of Anthropic
has said
I can't remember the exact stat but
right like 50% of all white collar work
will be wiped out in three years um and
Jensen said that's nonsense um
I'm more on this particular debate I'm
more on Jensen's side like there's no
doubt that AI is has a risk to all kinds
of white collar work, right?
But one of the things that I think is
true is that it's very easy to imagine
why AI can wipe out somebody else's job.
Extremely hard to think about why AI can
wipe out your own job. Now, why is that?
Well, with your own job, you recognize
just how messy it is. recognize that
like your job does involve some rope
processing, but it also involves like
doing this other complicated thing
that's sort of hard to explain to a
machine that involves talking to this
other person and using this other team,
right? Or it involves this thing that
involves this comp complicated
regulatory step that AI would never be
allowed into, right? There's all these
re or involves this thing that actually
involves like real humanto human
connection. So there all these things
that make it hard for AI to genuinely
replace a job or somebody's work. And
there's, you know, we're again, we're
two and a half years into this. How many
companies
have really laid off their white collar
workers and replace them with AI? Like
it's just not happening. And it's not
happening because AI is a great tool for
making individuals more efficient, but
it's not like a great replacement tool.
So I think
you know that over time yes it will take
away some jobs it will replace some
people's work it's clearly having a huge
effect on um computer science computer
programmers but I don't think we're
heading towards um the job apocalypse to
the second part of your question
yeah this is where the government should
play a big role in this right the
government should know that
you
There will be changes, right? This I'm
trying to like have like a nuanced line
where I am worried about the pace of
change. I am worried about jobs
changing. I don't think there's a job
apocalypse.
The government's role is to prepare
society for more churn and more change
with AI and to make sure that it's
setting up job retraining that it is
figuring out the right way to
incentivize educational institutions to
you know provide secondary training for
people who have lost their jobs because
of AI or who are in industries that are
changed because of AI. like the
government, you know, it should be using
government resources to basically help
us figure out how to plan and how to get
through. It should be, you know, funding
work programs for the kind of people who
are most likely to be replaced because
you don't want chaos. And if AI does end
up really changing certain professions,
you could end up having chaos. So I do I
think that the government also should
probably fund this through a tax on this
is something that I do agree with
Abdario's a tax on the AI companies. If
there are massive profits from the AI
companies it can be redistributed into
funds that help industries that are you
know upset by AI and people who lose
their work because of AI. Like that
seems like a rational proposal. So the
government should be playing a role in
making sure that society as resilient as
possible for the change that's coming.
So government should play a role. Maybe
a percentage of the revenues of these uh
big AI companies should uh be there for
potential retraining, reskilling. I
don't know if you saw uh Microsoft
announced a layoff uh I think today or
yesterday, 9,000 people. So it's
actually hitting the people who are kind
of the most in this industry, the
software workers per se. Um and
obviously you know uh that's something
that's uh pretty important especially if
you are now a new graduate trying to get
a job and you you know it was given if
you got a STEM degree or a tech degree
uh you know that was an easy path but
maybe not as much uh Nicholas. Yeah, I
do think there is some some concerning
data on sort of the unemployment rate of
you know 25 year olds and
one of the things I worry about I worry
about whole professions being wiped out.
I worry a little bit about that. I worry
more about you know the first rung of
the ladder being wiped out. And so if
you look at my profession, the one I
most know, journalism, you know,
traditionally you would go in and you
would start your career. You go to
finish college, you become a sports
reporter. You, you know, you write about
the base the AAA baseball team. You
know, eventually you move up the chain
and you write more and more complex
things as you go.
Um, and you know those early jobs will
be replaced by AI. And I think that's
true in a number of professions. So
that's going to make it harder. And then
the interesting question is okay so that
makes it harder. Does it mean that it
then pushes young people to be
unemployed or does it push them to start
building the new structures for you know
the new parts of society and the new
companies and like I think a lot of them
you'll see a lot of entrepreneurial
energy from them. So I worry about it
but I also think there's some upside.
Okay. Um Nicholas the other thing that
uh you have discussed also has been the
AI's capability to diagnose medical
conditions better than humans. I don't
know if you saw Microsoft said it's uh
recently.
Sorry to keep bringing up some of these
stories but their uh AI tools diagnose
uh patients I think like four times
better uh than you know actual
physicians.
What is uh is there how you know when
you look at inner cities, rural areas
where you really can't get I mean it's
really hard to for them to get
physicians in there. Is there a role for
AI you know especially GPS general
practitioners etc. I mean now uh your
and my phone can basically do sorry with
due respect to all the GPS that I know
but they can do a lot of what GPS can do
but what are the regulatory frameworks
that could handle a scenario like this
where AI is outperforming humans in some
critical decisions? I mean if that's a
that's an amazing question and something
we'll have to cope with so or deal with.
First off, it's, you know, like AI in
medicine is great, right? And so it's
great for lots of things. Um,
the problem with AI is it can it can
hallucinate, makes mistakes, BS's, but
there are lots of situations in medicine
where that's okay, right? And like I
find AI an extremely useful thing.
Family member who's going through a
series of complicated procedures.
Two years ago, I would have had to like
get in the queue and call a doctor. I
would have called my friend who's a
doctor. Now I just sort of go to you my
model of choice and ask it right very
useful providing information helping
understand it right like my son has
something weird going on with his foot I
take a photograph okay here's what's
going on like this is how you treat it
at home right my at home treatment has
gotten much better right like I'm
dealing with something in my ankle
describe it don't need to go to a doctor
I just need my ankle to hurt a little
bit less okay this is how you do it
right and so incredibly useful for that
the Microsoft paper is you more
complicated. It's like actually real
medicine, real problems. And I'm I'm
curious like how this paper is vetted,
right? When whenever a company puts out
a paper has like a great finding,
you have to like let it sit and settle
for a few weeks and wait till the
doctor's professionals have looked at
it. Right? In this particular paper,
it's
very smart mechanism for having a
mixture of AI agents communicating,
diagnosing, comparing against real
doctors. The doctors in the study
weren't allowed to use the internet. So,
there's like a little bias in it. Um,
but it does suggest that there is a form
of diagnosis that will be very helpful.
I think in medicine
for diagnosis,
you know, what we're going to want for
the foreseeable future is humans who
work with really great AI models. And I
think that whoever can build
the sort of the most sophisticated, most
trusted AI model to be used by doctors
in a hospital setting and the doctors
become experts in it and they are able
to kind of check their own judgments,
you know, use the model to feed in
information. I think it will make and
then the doctors you know convey it back
to the patient and the doctors are
involved in the places where the model
shouldn't be involved. I think that will
be a huge benefit and will allow
medicine to be much faster allow tele
medicine to be much more robust. I think
it will have you know wonderful
wonderful impacts.
Will it drive
doctors and GPS out of business? I doubt
it. You know the demand for medicine
versus the supply of doctors. it's so
mismatched that having, you know,
doctors be able to move faster, be more
effective, more efficient, I think will
will be a would just be a huge plus.
Just to just take it one step further,
any thoughts on how AI is being used for
companionship, behavioral
uh things, you know, from uh depression,
etc. And there have been results uh you
know, the former surgeon journal said
loneliness is an epidemic.
Can AI be a solution for something of
that nature?
This is one of the hardest ones because
yes, it can. Um,
and there will be a real
there real market opportunities for
companies to build AI companions who are
very useful, right? and help people who
are depressed who are lonely and even
people who aren't depressed but just
want you know need a need to talk to a
model about something or other right and
I you know I go to a model and ask like
complicated questions all the time it's
not a companion but it's very useful to
me
so that's good
but there's also a real risk that
the companies that do this are going to
make so much honey and there's going to
be, you know, so much honey available
for them that they're going to end up
building something that is actually
destructive to us where,
you know, they suck us into a fake world
and we lose some of our human to human
interactions. And you can imagine in my
ultimate dystopic fear,
you know, a new social media platform
that is built and is like populated by
perfectly beautiful, perfectly
communicable, you know, men and women,
you know, of your your choice and your
preference who infinitely distract us
and take us out of the real world. And
so
I
I see real danger here. Um,
I I I if I could maybe wave a magic wand
and make it go away, of course I
wouldn't do that because there's so much
good, right? There's real good that can
come from having an AI bot that can talk
to you about your problems and they can
be, you know, be a friend for you there.
There's just
the danger of creating something,
you know, like a real Westworld. The
danger of that is is quite high.
Yeah, when AI meets metavor wars,
imagine. Yeah, I mean it's it's
you know a lot of people are afraid of a
lot of AI outcomes. You know I mentioned
the sort of destruction of humanity and
you know there AI experts and Jeff
Hinton talks extremely intelligently
about it. Yosua Benjio you know what
happens if AI is misaligned with our
values? What happens if you know the
most powerful AI has a desire to cause a
certain amount of harm? like could they
build a bioirus? Like I do worry about
that, but I worry more about
if you look what Instagram did to
society, right? And you look at the kind
of the insecurities and some of the it
did a lot of good and I use Instagram
and you I like post my running photos
there. But if you look at like what it
did to the self-esteem of teenagers and
if you look at what it did to, you know,
the way we learn, the way we
communicate, the way that young people
date, the way they out in the world,
like it did a lot of harm, right? Yeah.
And that seems unambiguous right now.
And
AI could just be so much worse. And so
we have to be
we have to be ready for that.
We'll have to be ready for that. Uh
Nicholas, finally, you talk to such
amazing people, which you do all the
time. You're getting ready to talk to
them.
Are there some people that have, you
know, maybe inspired your thinking on
AI? I'm now talking specifically or
shaped your thinking in AI. For our
audience, can you talk uh about that so
they can follow them, listen to them?
Yeah,
there there many many many many.
I'll pick a few. Just a couple. I'll
pick a couple. Um, so there's Audrey
Tom, who I think is one of the great
thinkers of AI. She's the former digital
minister of Taiwan. And some of my
thinking on open source has been
influenced a lot by by Audrey and
Audrey's view that
there's a vertical race in AI which is
the big companies trying to reach
maximally powerful AI, right? And then
there's a horizontal race which is like
individual civic organizations trying to
build the the right tools in AI. And so
what you need to have happen is you need
to have enough civic organizations,
enough good-hearted people, enough
people, you know, really building
human values into AI. And then if the
horizontal race goes as quickly as the
vertical race, then you know, we'll end
up with an aligned AI. I think that's
important. So I'll give a shout out to
Audrey and then I'll give a second shout
out which is the Vatican actually you
know and like if you had asked me at the
beginning of this I would have been
quite skeptical that
um I would have thought that the view of
the church would be to kind of reject AI
and to sort of say it's you it's an
artificial creation and creates false
gods. But like one of the best papers I
read last year was the Vatican's paper
on AI and it was a extremely smart essay
saying look you know this is a creation
of mankind. It's part of us. There is a
risk that we will create false idols.
There is a risk that it will lead to
more income inequality. There's a risk
that it will lead to violations of
ethics. But here are some ways of
thinking about it. Here's how it can be
good. Here's how it can increase our you
know quest for meaning. So if I were to
recommend one thing for the listeners to
read, it would be uh it would be that
document. Yeah. Fantastic. Uh great uh
comments on that. We generally end the
podcast
for our listeners who are hooked on to
Tik Tok and others. Just to do a quick
lightning round, you give us one word
answers. You ready, Nicholas? You're
good to go. Let's fire away. Okay. One
word answer. So AI regulation urgent or
premature
urgent
or premature. It's hard because it's not
really either, but one word urgent. If I
have to choose either or I'm going
urgent. Okay. Uh I think I know the
answer to this. I think you kind of
answer it. But open source AI
democratizing or dangerous? Democ
democratizing. Yeah. Uh do you think
global AI governance is it achievable or
idealistic? Achievable.
Um
okay let's ask something that's related
to you. Content licing licensing for AI
mandatory or voluntary? Mandatory.
AI safety research adequate or
insufficient? Insufficient.
And then future of AI optimistic or
concerned? Optimistic.
Awesome. Nicholas, thank you really for
sharing your invaluable perspective with
the regulating AI community. Oh, so much
fun Sanjay. This is really great. I
enjoyed all this. This is a wonderful
conversation. You asked terrific
questions and we got into some good
stuff. Yeah, it was uh really really uh
fabulous. You really gave us some great
perspective. you know, the symbiotic
relationship between AI companies and
content creators. Uh, you know, rather
than purely extractive ones, you know,
uh, that was pretty fantastic. And as
you head to Geneva, you'll be continuing
the Atlantic's long tradition of
bringing critical conversations to the
public square. So, really appreciate you
being here. Thank you so much, uh,
Nicholas. Really appreciate it. Great.
Thank you so much, Sanjay. It was a real
pleasure to be here.
[Music]
Hey,
[Music]
hey,
hey.
[Music]
