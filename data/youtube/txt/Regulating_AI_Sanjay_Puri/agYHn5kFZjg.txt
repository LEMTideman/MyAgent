making sure we don't, you know, we got
to measure two or three times and cut
once because we don't want to cut the
wrong way. That maybe we should just
take some time to see how this plays out
a little bit before we decide to to
regulate or at least regulate um and
really put a significant regulatory
infrastructure.
>> Welcome to the regulating AI podcast
with Sanjay Puri. AI is changing the
world faster than rules can keep up. So,
how do we protect people without killing
progress? Each week, Sanjay brings you
inside conversations with global
leaders, policy makers, and innovators
who are wrestling with that exact
question. So, if you're curious about
the future of technology and how it's
governed, you're in the right place.
Joining us on the podcast today is Mike
Hil, Attorney General of Nebraska. With
extensive experience in law and public
service, he's been at the forefront of
shaping policy that balances innovation
with accountability.
His perspective on governance and the
role of states in regulating AI is sure
to add great depth to this conversation.
>> Attorney General Hilters, welcome to the
regulating AI podcast.
>> Thank you for having me, Sanjay. I look
forward to the conversation today. Just
briefly can you explain uh to our
audience what does an AG in a state do
that would be to a good beginning. Sure.
A state and it depends on the state sanj
there and in fact there are more than 50
there are 50 states but there actually
are more than 50 uh AGs in the country.
Guam has one um some of the territories
have one but gener and they're all
different but generally speaking the
attorney general in a given state
certainly in Nebraska is the chief law
enforcement officer of the state. So
they are usually tasked as we are in
Nebraska with criminal enforcement
responsibilities, prosecution
responsibilities, the chief lawyer for
the state when the state gets sued
maybe. Um also very frequently certainly
in Nebraska big part of our
responsibilities we are the kind of the
chief consumer watchdog in the state. So
if companies, whether they're tech or
otherwise, are misleading customers or
defrauding customers or scamming
customers, we're usually the front line
there. And then we do a lot of advice
and guidance to various state agencies.
And we usually handle a lot of
constitutional issues. So there's more
to our portfolio than just that, but
sort of the top lawyer in the state is
the way I describe it. the top lawyer in
the state and I think uh this role is
becoming at least from the past few
years I've seen more and more visible as
a lot of issues keep coming up which we
will discuss. uh AG you've had a
remarkable journey as I said uh in my
beginning from entrepreneur to
legislative leader to chief law
enforcement officer with a vast diverse
background and now you generated this
real focus on AI generated uh
exploitation as a priority issue
how has your background brought you to
this uh perspective and how did you
recognize this as an emerging threat
that really needed uh immediate
attention
>> now it's a great question Sanjay
probably different different threads
kind of coales into one part of my
background is just an entrep as an
entrepreneur and for your listeners who
are founders it's one of the toughest
jobs that there is and I think the
defining characteristic of most founders
are there that they are nimble and they
are just laser focused on solving
problems as a former speaker as a
speaker of the Nebraska legislature and
as a former senator um being able to
work and listen and sort of like
collaborate I think it was a big part of
what I did day-to-day. So, that was
another part of my background that
helped me get to this point. I was an IP
lawyer in the past. So, I've got sort of
a background of thinking about tech
issues um in emerging technologies. And
then being the attorney general and as I
mentioned, part of my role is to oversee
a criminal prosecution unit. I really
saw sort of the dangers and evils of
human trafficking firsthand. Uh the
dangers and evils of CESAM firsthand.
And you start to put all those things
together, the desire to solve problems,
the desire to protect children, protect
Nebraskans, seeing this emerging
technology, and just and saying, "Hey,
we've got to we really have to act and
we have to act now." There's almost a
moral imperative to do so. All those
things kind of came together and we the
good news is we have a lot of other very
committed public servants who saw the
same problem and building a large
coalition I think led from that.
So for our audience who might not be as
aware of this issue, AG, can you help uh
our listeners understand the scope of
the AI child exploitation problem? What
what specific capabilities of AI
technology make it particularly
dangerous for children?
>> Oh, it's a great question. So let me try
to describe it kind of comparing preAI
to the under AI. PreAI, I mean, CESAM is
is frankly it's terrible material. It's
evil. It's very exploitative. In a
pre-AII world, generally speaking, CSAM
is tied to a specifically exploited
child. Um, it's it wasn't it's not easy
without AI tools to sort of create
lifelike seam material that's that's not
tied to a child. And so, in a preAI
world, you're looking at very directly
exploiting one specific potentially
known um child. um maybe the volume is
is large or can be large sad very sad to
say but maybe not um at the level that
we might see in an AI world. So that's
kind of the preAI world. Certainly
prosecuting those cases can be
difficult. We put a lot of resources
across the state into prosecuting those
cases. Um but they typically have known
victims and we can actually do a lot um
in that in that context. In the AI world
there's some key differences. Certainly
the material might be similar but as I
mentioned in an AI world you may
actually have um non the the images
themselves may not be directly tied but
certainly are derived from because these
models are trained on actual images of
real children. Um, but also the volume
is so is so high and so it makes it very
difficult for criminal law enforcement
officials, whether it's my office or our
local sheriffs or county attorneys, to
really be able to sift through some of
these um some of these CESAM materials
at such a when it's with the with the
tools that we have had when it's at such
a high volume. And so one of the things
we did in the Nebraska legislature is
actually we actually advocated for
helped introduce a bill to help expand
our tools and really make it this type
of AI generated CESAM unlawful to ensure
that our law enforcement officials have
the tools to be able to hold these types
of people accountable.
So uh AG you're saying the speed and the
scale at which AI does this makes it
really really difficult because you have
limited resources to do this and you
said Nebraska passed a uh bill I think
you're talking about LB 383 which
prohibits uh AI generated CES just walk
our audience through this because there
might be uh your colleagues listening in
around the country who are looking at
this or are looking at and
uh in countries elsewhere. What is this
uh bill about?
>> Yeah, so great question. I really
appreciate the opportunity to talk about
this. So the other this I should have
said the speed and scale but also the
laws are different uh when they apply
differently in an ai context. So without
LB383,
our previous law really was designed to
meet the moment that we've had over the
last several decades. In other words,
this preAI world that I described, we
actually have a known victim or a victim
that can be identified. You that is what
really the our criminal laws were were
designed to do. The idea of having a um
you know AI generated sea sand where
it's not immediately tied back to a
child a specific child although as I
mentioned with these these models are
certainly trained on child images. Um
the laws need to catch up these these
specific laws need to catch up. So some
of the concern that we had in Nebraska
was that unless we modify a criminal
statute in order to cover CSAM AI
generated CSAM then without that it
would might make it more difficult for
us to actually prosecute these these
individuals which then have all sorts of
downstream implications for our ability
to even investigate these things. If you
don't have an ultimate criminal statute
it could be hard to investigate. So what
we did was just catch our criminal law
up with this new AI reality and
hopefully it's a model for other states
or or other uh your listeners in other
countries to look at their own laws and
say hey are have our penal laws our our
criminal code have they caught up with
this technology and LB383 I think is a
really good example if they haven't they
can use that as a model to start
thinking about how they could update
their own laws in order to cover this
particular instance.
So that's uh very helpful for our
listeners especially overseas. You
touched on a a point which was brought
up to us by one of our listeners and
said you know AI technology AG is
evolving so rapidly. I mean if we did
this show maybe 6 months from now I'd be
asking probably about something
completely different but legal
frameworks as you very well know take
time to develop. How do we bridge this
gap? This has been asked by one of our
members here audience members. Well,
it's an amazing question because
honestly the AI technology is maybe the
most exciting technology in my time.
Now, once we have AI in place, who knows
what that what kind of inventions and
innovations we'll see in 10 or 15 years.
Still waiting for my, you know, my
Jetson Jetson's flying car and
teleportation, but it's incredibly
exciting. And to your point, Sanjay,
you're exactly right. It may be the most
the fastest moving technology I've seen
in my lifetime. I mean, it wasn't maybe
even a year ago, we hadn't even heard of
of DeepSeek and its its models out of
China. Um, any on any given day, you're
seeing a new model come out, leaprogging
an old model, you're seeing new
capabilities. It's very it's incredible.
And so, everyone will sort of approach
this question from a different
perspective and may reach a slightly
different answer. I'll just tell you
Sanjay how how I've evaluated up to this
point and that is really trying to when
you're trying to balance innovation and
regulation in this context I think I air
on the side of ensuring that we have
more innovation and not putting too much
drag via regulation um on this this
early stage of developing the models and
I say that for a few different reasons
one reason is that I think we are in a
really significant competi global
competition
By by all accounts um China in
particular is just sort of on the heels
of the United States in terms of the
model development. Certainly the US with
Nvidia has been on the forefront of the
chip development. But I think it's
critically important at least here in
the United States and I think in the
free world in order for the AI stack to
be that race to be won by the United
States and that the AI stack really be
top to bottom be an American stack. And
I think hopefully you know we are never
in a hot war may hopefully we're not in
any sort of like global conflict but
certainly I think ensuring that the
predominant technology and you know how
these techn technological battles play
out. I mean ever since the VHS beta I
mean people understand once you have a
predominant technology that is the one
that get that has really the whole
position to be adopted by others and I
and that's where the investment
resources go that's where the
development resources go and so I think
it's really important I think for the
American technology stack or western
technology stack I guess even if you
were to expand it beyond the United
States is the predominant one in order
to do that with this we are literally
sprinting against China to see who wins
and I think if you put too much drag on
that regular regy structure, you will
increase the likelihood that you will
lose that race. So at this stage, my
view has been that I think we ought to
be awfully careful about putting too
much regulation, especially on such a
fastmoving technology um in in a way
that might really inhibit our progress.
The other part of that is that I think
at I think if you look at our history
Sanjay in other emerging technology
areas we don't exactly have the greatest
history when we try to be very
prescriptive about our regulations of
actually hitting the mark. Let me give
you one example that I'm dealing with as
attorney general just today and that is
online internet access to certain sites
for children. So there was a statute
passed federally called Kappa, Child
Online Privacy Protection Act. And that
at the time it sort of set this uh age
threshold to viewing certain content and
getting and meeting parental consent to
get onto websites at under 13. And that
really set sort of that was the
regulatory framework that we still are
living under today. And I think the data
is in when it comes to social media that
that is was a bad decision. that was the
wrong decision. That we have 13, 14, 15,
16 year old boys and girls, girls in
particular, who have had really been
harmed by a lot of this online content.
And that if we were to redo the
regulatory structure today, maybe we
would have come out with a different an
actual different structure. And the
problem is once a regulation or a law is
in place, it becomes very difficult to
change. Not impossible, but very
difficult. And that's certainly true at
the federal level. So I just think
between those two things, the need to
innovate and iterate quickly to win this
particular race. And secondly, making
sure we don't, you know, we got to
measure two or three times and cut once
because we don't want to cut the wrong
way that maybe we should just take some
time to see how this plays out a little
bit before we decide to to regulate or
at least regulate um and really put a
significant regulatory infrastructure in
place. So that's how I've come out on
that particular question. Of course, the
devil's in the details, Sanjay.
So that leads to several great pivot
points. Uh AG, one of them was uh
recently we had the big beautiful bill
which uh tax bill which had a potential
provision to ban state regulation for 10
years or so. It did not go through and
there are still people who say that we
need something of that nature because
there are states many states that are
considering whether you look at
Connecticut, California etc.
You have said you come out on the side
of innovation. We are in a geopolitical
world where innovation is going to drive
so much benefits for our country.
How do you view uh the federal state uh
because it we could end up with
patchwork of uh laws
those some of those states and I've had
uh some of them governors and others
here saying hey we can't wait forever
for the federal government to get its
act together. So your perspective on
this AG?
>> Well, as you mentioned, I did not
support I actually thought on balance
that having the prohibition actually
made a better public policy sense. Let
me take a step back and just explain to
your your viewers and listeners sort of
my philosophy on this particular
question in general and then why I I
came out the position that I did. In
general, I am a states rights person. So
the United States for those listeners
outside of um outside of the US we are a
federate we're a country with 50
sovereign states one federal government
our constitution gives the states a
significant amount of power. I'm a
jealous protector of that power. I think
states are are truly are the laboratory
of democracy. I want to ensure that the
power is closest to the people and I'd
rather in Nebraska that decisions are
made that impact Nebraskans that those
decisions are made by Nebraskans who
ideally are politically accountable to
the to the electorate. I also am very
sympathetic to those who are frustrated
with Congress acting or really not
acting on a whole host of really
difficult policy issues facing the
United States. So coming into this
discussion, my sort of priors as it were
would be yeah, let's let the states
innovate. I I don't think that that that
is not where I came out on this
particular question. Let me just give
you a couple of reasons why that the
first reason is a little bit of a bias
towards ensuring that we have a national
standard that you the federal government
in the United States under under the
constitution has a limited set of
powers. For those that your listeners
outside of the US, they may be like
really seems like they have a lot of
power. But the truth is under the
Constitution, they have a limited set.
But one of those powers which is right
there in the text is that they have the
power to regulate interstate commerce.
And one of the places where you really
need federal regulation is is the means
of commerce across states. And so think
about there's a long history in this in
this country of of the federal
government regulating the the means of
commerce. So for instance for uh
railroads. So railroad gauges can differ
in size. You don't want to have one
state have a certain size of a gauge
that's different from another. Adds
friction and drag to the process. Same
thing with uh semi-truckss driving on on
the highways, the interstate highways.
There's we don't want states mandating
different sizes of semi-trucks. So if
you go from Nebraska into Iowa, they've
got to get out and make some changes. So
there is actually a pretty strong
argument that for the means of commerce,
we should have a federal standard. I
also think Sanjay in this particular
instance that I don't the states I've
seen some of the data points that I've
seen in the technological environment
have states some states have really
gotten very aggressive and I think have
been captured by very um extreme
interest some mo most often I think on
the progressive side where they have
made I think maybe some values-based
determinations as to how they want to
regulate things like the tech industry
that I think are inconsistent with how I
would like to see some of these
particular uh means of commerce be
regulated. So for instance, I'll give
you a small example. Um and the problem
by the way is not just the patchwork,
but it is one state really dictating to
the others. And so uh for instance, when
the FCC a couple years ago, decided that
they didn't want to have a net
neutrality that they got rid of net
neutrality. Remember, you may remember
that some states including Nebraska, but
in particular, California, really wanted
to dictate their own uh net neutrality
standard across the United States. And
we've seen we don't want one state to
dictate nationally. And by the way, one
I don't think these companies are going
to have patchwork states. So they'll
probably comply with the most
restrictive state that they and just
have that as the national standard.
We've also seen states like California
and other contexts actually put forward
pretty pretty aggressive I think very
short-sighted policies um in non-tech
areas in particular. And so I just on
balance I could see those who say hey
let's let the states innovate. But I
think on balance I think the the
importance of innovate winning the
innovation race in AI the risk that some
states might really get involved in a
way on an emerging technology maybe they
don't fully understand or maybe can see
sort of around the corner on maybe could
really restrict our ability to develop
this uh technology as fast and as well
as we thought we can and maybe make some
decisions like I mentioned before with
Kappa that we might really come to
regret in two or three years as this
technology unfolds. you know uh social
media and some of these things. How
should we hold major tech companies
accountable while encouraging innovation
because the same we see the same movie
happening again in AI a little bit where
you have because of the intense cost uh
in this whole equation. you see four,
five, six companies that are going to
dominate uh this sphere and AI might be
even more significant in our daily lives
in our healthcare and everything else
than even social media. So, how should
we do that?
>> It's a great question and and by my
previous comments, I want to make sure
your listeners and viewers understand
that I do not I do not trust a total
free-for-all for a lot of these big tech
companies. We've in Nebraska have been
really leading the fight against several
of these large companies in the social
media context. And our our lived
experience here in Nebraska is that a
lot of these companies if you just let
them go to the free market that they
will do a lot of things that will be
very harmful to children. We've seen
that with a major lawsuit that we filed
against Tik Tok or Meta um that they
will they may uh unfortunately use their
power for particular political or
partisan or ideological ends. Um they
may suppress free speech. They may they
may um or suppress speech. They may
amplify certain ideological voices. So I
do look at it with a very sort of a
little bit of a jaded eye for some of
these large tech companies. And I do
think it's very important for us to be
very thoughtful about ensuring that we
don't you know end up in a world in
which we have four, five, six, whatever
the number might be Sanjay of really
unstoppable tech companies that eclipse
the power of all of the major regulators
where it's the state attorney general or
even the United States Department of
Justice. A couple so I don't have the I
don't have the perfect answer to that
but let me let me give you at least a
couple starting points. I certainly
think one one set of tools already
exists in our hands whether it's the
state or federal government and that is
consumer protection. I mean we're
starting to see some things uh with AI
psychosis AI um AI prompted psychosis. I
think there's that's been in the news a
little bit lately. Certainly we want a
AI companies to protect privacy. There's
robust privacy protections around the
country. um we want to make sure that
they're telling uh customers and users
of those software that they the truth
and so if they say one thing of how
they're going to use their data uh they
better do that and not actually use
their data for other types of purposes.
I do think also we have maybe some
structural analoges that we can pull
from from other other um technology
areas that we could start to use to
think about it uh how to regulate an AI
because I do think they have to be
structural changes if we get to that
regulatory point. So, for instance, in
the social media context, the data tells
us that, you know, really kids 16 or
younger shouldn't be using it. That's
where we see a lot of the mental health
problems. And so, states like Nebraska
have passed laws saying, "Hey, look, you
got to have an age verification." Some
of those have been challenged. But the
point is is that's a structural change.
Now, I'm not advocating and saying you
have to be 18 to use AI. But my point is
I think we have to be um focused on the
structural in particular because of the
intellect or the um technical complexity
of these issues. I think we have to look
at structural really sort of robust
fundamental regulatory changes that are
or regulations that just that are kind
of a really strong baseline that no
matter whatever the innovation is on AI
over the next five or seven years kind
of don't become rapidly scale now or
stale the issue that then part of the
reason I've advocated for pausing a
little bit Sanjay is we don't know what
those are
>> are colleagues of yours or you know
other policy leaders not just in the US
and the rest of the world aware of
what's happening at such a fast pace.
That's the one worry that I have is
making sure that leaders know because
you can only regulate if you know what
you're regulating. That's one. And then
you're also dealing with these companies
who have such massive resources to put
these companies do a lot of good too. I
mean we in the United States have
benefited from a lot of the innovations
these companies do but there has to be a
balance. So any thoughts on the
education awareness of policy leaders
and the resources underresourced policy
leaders over resourced tech companies
this applies if you're a policy maker if
you're a student if you're a kid if you
are in a job today I try to tell
everyone AI AI AI learn as much as you
possibly can to protect yourself against
the future if you're if you're in a job
right now you want to make sure that you
have that job you continue to remain
valuable to your company. Learn AI
tools. If you're in school and you're
thinking about what your future is,
think about what AI might disrupt sooner
than later and make sure that you're
thinking about that as you make your
decisions. It is absolutely true as well
for policy makers. I think it's
enormously enormously important. I try
to tell people all the time, we had
technological disruptions in my
lifetime. I was born in 1978. I remember
when the internet came online. I
remember when Y2K happened. I remember
people thinking that, oh gosh, the
internet's going to do all these amazing
things. we'll have that Jetson's flying
car. It has been incredibly disruptive
over time. I mean, if you compare 1999
to what we have in 2025, I mean, the
world has changed. But I do not think
that the internet, as powerful as it's
been and as important to productivity as
it has been, will really hold a candle
to the changes that we we will see and
have from AI. And so, I just there's you
just got to keep talking about it. And
some people just won't fully engage. And
I think it's a missed opportunity. Um,
more than anything, Sanjay, I think we
should look at the opportunities here.
By the way, I think a lot of it's
threat. We think about the threats. We
think about the downside.
>> AG, you said you're the chief law
enforcement officer. From a law
enforcement standpoint, are there any
unique challenges in prosecuting AI
generated cases compared to traditional
crimes? I
>> mean, especially how powerful these
models have gotten. I mean, a lot of the
CESAM material can, you know, look like
a a real victim. I mean again there are
children victimized through use of the
models to create the the particular um
the particular uh picture but or the cam
but I think um that makes it difficult
and I think the volume combined with the
fact that you may not have you don't
know whether or not you have a victim a
specific victim you can go and interview
and and talk to um right at the outset.
So I do think I do think those present
some unique challenges in the law
enforcement context. Of course, we see
in other parts of our world in the
consumer protection and which also
touches on law enforcement, the impact
of AI when it comes to scam and fraud.
And one of the things we've seen maybe
an exponential rise in are the use of
really brazen actors using AI tools to
defraud people. I mean, the stories of a
grandmother getting a call from a voice
that sounds like her granddaughter who
says that she's in a jail and needs
$1,000 sent via Bitcoin. I mean, these
are extraordinarily powerful tools. Um
and so we see that a lot and
unfortunately uh people are using these
AI tools to really def fraud and scam uh
people around our state certainly.
>> Ag should individuals have a right to
sue when AI systems cause them harm
primarily around the issues of deep fake
or privacy violations.
>> We have data privacy protections in the
United States certainly GDPR in Europe.
Uh there there are a lot of strong
privacy protections. Those should apply
whether we're in a nonAI world or in an
AI world. I think some things like
consumer protection also apply in a
non-AI world versus an AI world. I think
AI companies have to be honest to their
customers just like non-AI companies
have to be honest to customers. I think
there's another set of problem legal
questions that we're still still sorting
through what the answer is. So think
about intellectual property. What
happens if an AI uh AI creates something
new that would fall under the copyright?
Who owns that? What about a patent? Who
owns that? How do you deal with
co-inventorship issues? And so I think
these are really the really important
but also fascinating legal questions
that we are going to be having to
grapple with for the next two or three
years. But yes, I think consumers
absolutely ought to have the same kinds
of tools that they have today. The real
question I think Sanjay for you and then
your your questioner is over the next
three years depending on where AI goes.
Are we going to need to expand those
tools? Are there new things that we
haven't thought about? I mean, think
data privacy. I mean, HIPPA was a has
been a thing for a long time. Protection
for your for your global listeners,
protection to your p your private
information as a patient, as a medical
patient that's protecting the United
States. The idea of data privacy and
data security is is a relatively in the
history of the at least our country is a
relatively new phenomenon and really
kind of really took off with the advent
of the internet and and use of computer.
And so if you would have asked someone
80 years ago about data privacy, they
would have looked at you and sort of
like thought you were crazy and from the
future. But um so let's see what I think
we need to be open-minded about the
world's going to look look like. But
let's start with some first principles
that we know work. Um we know have
worked and let's apply those and start
there. I don't think consumers are
defenseless nor should I do I think that
they should be.
>> Agentic AI it's everywhere. They you
know these are autonomous systems that
can act on behalf of individuals
organizations. How does it impact any
risk that we have to regulate against?
Because I had the chief VI officer of
one of the largest cyber security
company in the world and he says one of
his nightmares is rogue agents that you
know can go rogue internally within a
company etc. So I mean my so uh and this
is one of the largest uh cyber security
companies in the world. So when you look
at agents um do you think from a uh law
enforcement or regulation perspective
anything that comes to your mind that
worries you?
>> Let me start with I think the innovative
potential of agents. I mean, I think I
think when harnessed correctly and as
we're just going to continue to see new
and new use cases, you know, every day
and it's pretty exciting to see. I mean,
the ability of use of an having an uh
agentic architecture or system for your
own organization is I hate the word game
changer. It's a phrase that we use in
the US a lot. Seems very cliche. It
feels like but it feels like using that
here unells the power of agents. So, I
think I think it's an extraordinarily
exciting technology. Having said that,
uh whether it's rogue or broken or sort
of um an agent that doesn't work as
designed, there are absolute major
concerns because what you're doing is
you're taking the ability to scale scale
good things in the context of innovation
or a company trying to be more
productive. But in this case, you also
can scale really bad things and you can
scale them very quickly. And so maybe
that's an in broken architecture inside
of a system that um that wres havoc. So
the c the the person you were talking
about within their own organization but
also in the hands of male malevolent
actors who want to scale scams or want
to be able to scale fishing attacks or
uh you know intrusions into data
repositories to be able to get people's
information. So I I certainly do think
that there's real risks there. I do
think as I said before kind of my
framework of looking at these things I
think we want to be a little soft touch
on the regulation. I think people need
to be awfully awfully careful and
thoughtful and as they put together
their own agents for their organization.
Um, so I do think they need to be
careful. I also think like some of our
tools probably do work. I think if
you've got our legal tools, so if you
have if you have uh if you are using a
system and building agents for your own
organization, it goes haywire. Well, if
it's gone haywire because the company,
the vendor didn't give you what they
promised, well, you've got some legal
protection there. you've got the
opportunity to breach a contract, maybe
there's a fraud suit. Um, we have some
some similar tools that people are using
agents to be able to whether attack um
or or or you know violate someone's
privacy. We have law enforcement and
other tools. I really think it's it is
um it remains a little bit to be seen
exactly how those unfold. To some
degree, some of this is not a difference
in kind, it's a difference in volume.
Um, but I do think um, as rapidly as
this has been developing, in the next
six months or a year, my answer might be
slightly different. I might say, "Oh my
gosh, these these agents are really out
of control. We need to think through
something structurally just to kind of
rein them in." But I don't think we're
at that point yet. But everyone should
be cautious, whether you're building a
company, running an organization, or in
a world where you think your systems are
exposed to malevolent agents.
>> AG, I live in Washington, DC. uh here
the two parties uh can't even agree if
the sun is out in many cases and you
built a bipartisan coalition of 54 AS
for uh the CESAM uh issue that you had.
think when you take the politics out of
it and you just look at it, you say,
"Hey, let's let's actually help protect
kids um and and uh and applying some
limited regulation to help really make
sure that this particular use of AI is
curtailed. I think people really rallied
around that and I think it's a
reflection of the fact that actually at
the end of the day, most people want the
same things. People want whether you're
Republican or Democrat or otherwise, you
want kids to be protected." Um, and so I
think it really kind of hit the trifecta
of of, you know, hitting an issue that
people were passionate about, AI, they
wanted to do something, but also really
helping protect kids, help protect help
support law enforcement. Um, so I think
that was there was that there wasn't any
other magic to it. I certainly think
though as people think through these
really difficult problems, sitting down
really understanding the issue, um, AI
is extraordinarily complicated. The idea
that you could pick this up with a
briefing book in four hours, I think is
probably missing the mark. And I think
really as much as possible given the
demands in our time, immersing ourselves
in these issues, really trying to
understand the pros and cons of these
things, reasoning from first principles,
and then listening to experts, listening
to trusted voices and other
stakeholders. I think we'll get to the
right result. And I think it could be
bipartisan. I think it really needs to
be because I think ultimately we want
something that's durable and smart and
lasting. And I think the way to get
there is by doing at least some of the
things that I just talked about. So
hopefully our policy makers in DC can
can do that. I've I I've got hope that
they will. Certainly, the issue is
extraordinarily critical for us to get
right. We've got to win the AI race.
We've got to get any regulation right.
And so, put we're putting a lot of trust
in them that they'll do it. Um and
hopefully that's what we'll see.
>> Well, watching what other states,
specifically Colorado, California doing,
watching what Washington is doing, and
just staying on top of uh technology, uh
that I think is pretty important.
Okay. Federal or state leadership on AI
regulation?
>> Federal.
>> Okay. Innovation or safety first?
We're going to give you some tricky
ones. AJ
>> innovation.
>> Okay. Voluntary industry standards or
mandatory regulations?
>> This feels like a definition where I
have to answer one or the other, but I
can't say something else. Um,
>> well, you can say something else, too.
>> I think it depends. Probably a little
bit of a mix of both. Honestly, I think
there's going to be places where we will
absolutely want mandatory and then I
think others are voluntary. I think what
would be nice also early would be
voluntary. Um, that might ultimately we
see which ones really matter and then we
can maybe bake those as mandatory later.
So, I I would say on those two different
I would that's what I would say on
those. I think it's a mix.
>> Okay. AI liability is it on companies or
on users? I depending on the issue both
absolutely I think I think there are
instances where users can um can use the
tool in a way that could create
liability for themselves just like they
can on think about X if you get on X and
you defame somebody it's not X's fault
that you defame somebody it's your fault
that you defame somebody but I certainly
think that there's also liability for
some of these core issues on the
companies themselves
>> okay uh global AI governance is it
possible or is it a pipe dream
>> I think it's a I think It's a pipe
dream.
>> I think it's a pipe dream.
>> Okay. Um, is AI in criminal justice is
it a promise or a peril?
>> You say that again. AI criminal justice.
>> A use of artificial intelligence in
criminal justice. Is it is there is it
an opportunity or is that a problem? Do
you think?
>> Oh, uh, using AI and criminal justice is
a huge opportunity. It's a huge
opportunity on both sides on the on the
actual law enforcement um the
investigation side but I think on the
rehabilitative side on the actual uh
custody side so that that's three sides
so I guess I said both the three I think
it's an enormous opportunity and in fact
I think it's an enormous opportunity for
almost every aspect of of government.
>> Wow. Finally, your confidence level in
current AI governance standards on a
scale of 1 to 10.
>> Oh my gosh. Five TBD. I mean, I think uh
look, I mean, I think we I think the
current standards are are working for as
of today, but I but it's hard to say. I
mean, we look we could look back at
three years and I could and I could be
wrong
>> for everything. Almost everything.
>> That's right. That's right.
>> That's so true. That is so true. Uh AG,
you're really it's been fantastic to
have you uh on the podcast. Your
leadership really around child AI safety
shows what's possible. You know, when we
put protecting the vulnerable first
while we still embrace innovation and
your work really demonstrates that
effective AI governance requires
collaboration, as you said, across party
lines and between state and federal and
amongst diverse stakeholders and so
thank you for joining us and for your
continued leadership. And to our
listeners, as AG has shown, AI
regulation is not just a technical
challenge. It's a moral imperative.
Thank you so much for being on the
regulating podcast.
>> It was honor Sanjay. Thank you so much.
It was a great conversation. I really
appreciate you and all your listeners
and viewers.
>> Thanks for tuning in to the regulating
AI podcast with Sanjay Kuri. If you
enjoy today's conversation, don't forget
to leave a comment. We'd love to hear
what you thought. Share it with someone
curious about the future of EI and join
us next time for more stories and
insights from the leaders shaping what's
ahead right here on the Regulating EI
podcast.
