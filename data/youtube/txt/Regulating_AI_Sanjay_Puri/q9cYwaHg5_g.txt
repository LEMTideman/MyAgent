Human centered AI means that we design
the tools around the human and not force
a human to learn a a novel modality. The
EU AI act is not regulating technology
as such but the usage of technology. I
believe that many jobs will be affected
by uh uh AI in the future. I don't think
so much that many jobs will really
disappear as job as in their do job
description. I think they will be
transformed but of course productivity
will raise will be arisen and this also
means you need less people for the same
amount of work.
Welcome to the regulating AI podcast.
Join host Sanjay Puri as he explores the
dynamic and developing world of
artificial intelligence governance. Each
episode features deep dives with global
leaders at the forefront of regulating
AI responsibly, tackling the challenges
using AI can bring about head-on and
enabling balance without hindering
innovation.
Welcome to another episode of the
Regulating AI podcast where we bring
together diverse voices from around the
globe to discuss the future of AI
regulation. Today we have a
distinguished guest with us, Professor
Antonio Krueger. Professor Krueger is
the CEO of the German Research Center
for Artificial Intelligence, DFKI, and
the head of the cognitive assistance
department at DFKI. He's also a full
professor of computer science at Sarland
University, leading the media technology
lab. His work sits at the fascinating
intersection of artificial intelligence
and human computer interaction, focused
on ensuring that AI developments are
human- centered and beneficial to
society. We are thrilled to have him
here to share his insights on AI
regulation, human- centered AI, and the
future of AI applications and more.
Welcome, Professor Krueger.
Yeah, thank you for having me.
Wonderful. Um, Antonio, we uh have a
global audience of people who are policy
makers, legislators,
uh CEOs of
company enthusiasts around the world. So
could you tell them uh a little bit
about your role at the German Research
Center for Artificial Intelligence and
your work at the Sarland University just
to inform them? Yeah, I'm glad to do so.
So um the German research center for
artificial intelligence is an
institution that exists for more than 30
years now and it sits actually on the
intersection of um basic research and
applications and the transfer of basic
AI research into uh applications of
course in particular with a focus on uh
German economy small and medium-sized
enterprises also the large companies of
course and uh and it is of course also
uh one of the leading institutions in
Germany that educates in AI. So we have
lots of PhD students, lots of master and
bachelor students that uh work with us
and do their research often in a context
uh of uh companies actually so with
company data and I personally have a a
background in AI and uh uh and in human
computer interaction and uh um I've
started more than 10 years ago at DFKI
and was responsible actually to build up
one of DF FKI's living lab actually a
lab on future retail which is a
fascinating topic that was at that time
you know a couple of years into the
first iPhone you know uh and uh and it
uh and I've worked there for a while and
then since 2019 now I'm actually
responsible for um the technical and
scientific uh strategy and direction of
DFKI. DFKI now is
u a large institution in Germany. It has
over a thousand researchers now and is
present in seven regions actually not
only at Saland uh in Saland University
but also at several other universities.
Wow. So a pretty large uh research
institution uh that is out there uh
especially given the critical nature of
AI. Uh Antonio your research focuses on
the intersection of AI and human
computer interaction. Can you explain to
our audience why this intersection is
important and so critical? Yeah, it's a
I think it's a very important uh and
very interesting fascinating research
field also because if you uh think about
classical human computer interaction. So
the way how you would very agonomically
use a touchcreen or a mouse and and a
keyboard to uh issue commands in a
computer. Uh we see actually a shift in
the way how we interact with computers.
We have more and more kind of highlevel
tasks that we give computers. For
example, you know, if you just see the
very recent development in generative AI
even in a complex natural language, you
know, and uh and the question now is do
computer exactly do what we want them to
do on such an abstract level? You know,
if you control a mouse, you see your
pointer, you know exactly, you know,
what to do and where to click and so on.
But of course if you issue abstract task
like saying yeah please plan my next uh
uh holidays in Italy for example then
the question is how can we ensure that
the machine is really following our
intent how can we ensure that machines
actually follow our ethical guidelines
for example you know how do we ensure
that we know what the machine is doing
you know and it's not kind of overriding
certain uh important uh preferences that
we have for example. Yeah. And uh and
what you see is actually that in the
interaction with these complex system we
move more and more from a direct control
task to an oversight task. So actually
and this is a new role for role for us
as humans you know in human computer
interaction and uh but it's an important
shift that we see now a paradigm shift
even and uh and the interaction
paradigms are not 100% set and clear at
this point and um and that is actually
what I'm in particular interested in.
So, uh, Antonio, uh, for our listeners,
what does human- centered AI mean to
you?
Yeah, human- centered AI means to me
that as all other tools that humans have
invented, you know, they are an end to
their their means to an end, you know,
and uh, and this end actually is human-
centered. So it means we are developing
AI tools that are meant to support
humans actually in their task actually
to lead to better lives for humans and
um and this also means that in all our
research efforts you know we have this
in mind and uh design our system design
even our research agenda towards that
goal that these systems support humans.
they are perfectly I think this is
perfectly okay also to do research
without humans in mind you know this is
perfectly okay but that's not the kind
of research that we do with a AI systems
you know we are interested in AI systems
that are tools uh and support humans
highly complex tools also tools that act
partially autonomously of course this
then requires additional
sorts how to do this so that they end up
still being tools you know um but I
think this is what we mean by human
centered artificial intelligence
so uh Antonio just to uh follow up on
your perspective these days I mean for
average person the chat box is you know
whether it's chat GPT
anthropic any of those uh Gemini etc
that's their interaction
But now lately there have been a lot of
noises some stumbles about variables uh
about you know the pin the rabbit etc.
What are your thoughts on that because
that's a paradigm shift at least that's
what people are saying there's a
paradigm shift now you are a pioneer in
human- centered u AI I would love to
understand what do you think uh is
wearables people say moving away from
the computer etc what are your thoughts
for our audience on that topic so I
think actually that uh if you um if you
see the earned a predominant interaction
paradigm which is touch basically you
know so it's not keyboard and mouse
anymore for quite some years it's touch
all most of the devices that we interact
with computer devices use a touch
interface so phones also smartwatches
and so on you
know and and still voice is somehow
under represented you know if you
compare this to yum interaction which I
would say 90% is basically voice
interaction
as is this discussion that we are having
currently you know and and the question
is why is this you know one is of course
that uh speech natural language is very
complex it provides very it's very
powerful also because it can convey very
abstract concepts in a very short amount
of time you know it's very ambi so there
are many interpretations to it and um
and what's exciting actually with the
newest generation of AI models is that
voice as an interaction modality is
getting more and more useful you know
and will be integrated into uh a future
uh devices for sure. Mhm. The devices
that you mentioned are I would say first
attempts to do so. They might be not
very successful attempts at the moment.
That's actually my view. But I think
they will eventually succeed because
voice is such an important modality to
humans. Again to come back to human
centered AI, human- centered AI means
that we design the tools around the
human and not force a human to learn uh
uh uh novel modalities you know uh like
touch is such a novel modality for human
at least when it comes to interaction
with devices you know uh so that I
believe that actually uh the current
development will lead to much more voice
interaction. Uh we've seen recent
developments in terms of interaction
speed turnover speeds. You know this is
important improvement because we know
that if you have to wait you know for a
system to respond to your voice commands
you know more than let's say 100
milliseconds or so then uh this will
hinder actually the interaction. So this
is good news. On the other hand I still
believe you know that voice is not the
only modality you know. So we still need
screen we will still need screens you
know we will make use of graphical
information visual information it's so
much powerful the bandwidth is much
bigger and so on and uh but we are at an
exciting exciting point in time where I
believe that in the next 5 to 10 years
there will be novel device concepts that
rely much more on natural language than
uh former device concepts. Yeah. So uh
Antonio to follow up uh as you know uh
open AI uh Google deep mind have
announced and several others
multimodality of uh uh working with
their whether you call it chat box or
whatever it is it's you know voice it's
uh images it's videos etc. Uh so
the paradigm is shifting but for uh you
know for normal people who are basically
keying it in their phone or computers
what if you uh as a uh pioneer in you
know uh human- centered uh interaction
what is your vision for a ideal human
machine in partnership in AI
so I believe that actually uh um
multimodality is the key. So we will use
many modalities in the future. So not
only voice, not only touch but also uh
other modalities like for example um
physiological information from uh our
body. So one interesting observation
regardless of the AI models is that
computers have moved towards us. You
know they started maybe 50 60 years ago
in the large uh uh mainframe computer.
You know there were own buildings built
around computers. We still have those.
They're in the cloud. And then they
moved on our desktops and from our
desktops on our body on our wrist for
example or you remember the glasses you
know glasses are also if you if we think
about uh development there you know and
the next step and I think this is
invible and uh comes with a lot of
additional challenges but might be very
beneficial is also hardware that goes
into our body to a certain extent you
know so that measures vital function s
you know and all this will be used
actually to make interaction with
computers as seamless and as easy as
possible. I still believe though that um
again human- centered you know that
actually uh control uh uh comes from the
humans. So I believe voice will play an
important role. But this voice will be
the information that comes from our
voice commands and from the voice
dialogue with the system will be
augmented with additional information
that comes from other sensors also from
our body you know and this will make uh
interaction much more easy less
ambiguous and uh and more efficient
actually.
So are you kind of alluding to things
like neural link where we are inserting
chips in our brains and things like that
uh using that that kind of technology
Antonio. So I think um I find this
fascinating. Uh I believe if you if I
come back actually to my human centered
view now we enter if you think about
adding uh uh enhancing for example your
cognitive abilities and so on there
there is of course an ethical debate
whether this would be really human-
centered in a way you know so the
question of course is what is human what
does human mean you know right and I
guess different cultures have different
views on this you know I think in Europe
we we are maybe a little bit more
conservative here. So people would maybe
say okay health functions monitoring of
health functions you know it it might be
okay but a neurolink that maybe uh
alters your cognitive abilities is maybe
too much you know I personally would not
add a neural link to my brain you know
but of course you know this is a little
bit also a cultural and personal uh uh
preference to a certain extent and I
believe society will move forward. I I
don't believe that we will see many
actually neural link implants you know
uh in the near future beside of course
medical application I think for that
they are great you know there's no
question about it uh but of course who
knows what happens in 40 50 years you
know when these kind of
things cultural interest and so on shift
over time you know so so we'll see it's
fascinating that we the research is
definitely Fascinating for sure. Well,
you talked about being in Europe, uh
Europe being a little more conservative.
There is a a saying that we uh some
people in the US say that um Europe is a
regulatory superpower, US is a
innovation superpower, uh etc. Uh I want
to uh you know get your opinion. The EU
recently well it's gone through many
stages but on the 21st of May it finally
uh passed the EU AI act. What give us
give our audience you are right in the
center uh you know leading a huge
research institution in Germany uh from
what we understand Germany and France
had something to do with tweaking uh the
laws uh for some reasons but uh tell us
your view uh about the EU AI act to our
listeners.
So I personally think that it's good to
think about regulation, you know. So I
also welcome uh this podcast, your
podcast that puts this into the center
of a large discussion. I think it's
important because um uh
regulation on the one hand and I
understand also the concern being in
innovator myself you know um of course
regulation always kind of slows slow has
the potential to slow down innovation
yeah but on the other hand uh I think
the risks also associated to AI are of
such a nature that it's good to think
about certain uh rail guards,
guidelines, you know, and also rules
that apply to the use and to the
development of AI which then again also
helps to provide level playing fields in
a certain way and give also a certain
assurance to players in that field,
commercial players that they allowed
actually to uh uh benefit from their
investments into a field because what
would be catastrophic actually is that
we all develop and uh companies invest
lots of money into a piece of technology
that then is uh um completely uh
forbidden and overregulated. So I think
it's a good idea to uh to start uh with
these kind of regulations. I think CU uh
uh did a uh of course as usual time it
took a lot of time you mentioned several
iterations you know many stakeholders
that's the way how it works in the EU
sometimes this is also too slow I have
to admit but in the end I think it's a
good compromise we have uh the EU AI act
is not regulating technology as such but
the usage of technology and I think this
is not uh something new. You know, we
have many application areas especially
in the medical domain but also in the
mobility domain where we already have
regulation of usage and rightfully so.
Yeah. And uh now the UAI act does
something similar for um the usage of
AI. We have different kind of risk
classes, risk categories and depending
on these risk categories other different
rules apply. You know in the lowest risk
category basically no rules apply.
Highest risk category is basically uh is
a category where AI the use of AI is
forbidden completely at least for civil
uh uh applications and then you have
middle uh risk categories that uh
require certain amount of transparency
documentation and so on. I think this
makes sense and um the other important
part is also to uh remain flexible in
the way how you can adapt those rules.
We know AI is moving fast you know and
uh and the framework has certain aspect
that NXS and so on that can be adapted
faster than the whole framework itself.
I think this is also a good idea but in
the end we will see you know it's a it's
a little bit u of course risky
undertaking from the European Union my
feeling is that um given the large size
of the EU and also the good core ideas
that this is something that others will
adopt to a certain extent also in the US
I'm pretty sure
so uh just as Uh one aside if you think
the EUA act is slow but think about the
US we are not even close to getting any
regulation we are in a presidential
election year so that's uh I am in DC
and I can tell you slow is our middle
word here but uh coming to uh the EU AI
act
u you are in Germany leading uh this
large uh research
institution is is there a worry for you
uh a twofold things uh Antonio that it
is going to inhibit uh companies uh you
know startups or companies at all uh
from that standpoint that's one quick
question for you yeah I think there is a
risk you know one would be naive to say
that uh regulation does not pose risks
you know it's of course uh there is the
risk that actually investments are not
made you know um I agree
On the other hand, I believe that in
particular for Europe that has a
different economic uh uh structure as
for example the US, you know, in Europe
we have many midsize, smalls size uh uh
enterprises that are often familyowned
for a couple of generation now and uh
that are market leaders in their niche.
Yeah. technological market leaders. And
I think for Europe, it's important that
these uh uh small companies that don't
have enormous uh uh abilities to invest
into AI, that they are still able to
benefit from AI, that they're able to uh
augment their products, you know, with
AI services, with AI technology to be
able to compete also uh uh in the next
uh uh uh decades, you know, because if
they are not able to uh include AI into
their product, I think this will be very
hard and very difficult to still stay on
top you know. So this is important and
for them it's uh uh these regulations at
least help them to make safe investments
you know and to now be able to say okay
now we know how the rules are and now we
are able to invest and uh and we are
sure that our products will have a
market you know that they will not be uh
uh excluded from certain markets. Yeah.
So there is some level of
predictability, consistency for these
companies. I think that's what you're
saying which is very very helpful.
Uh should the world have some level of
harmonization of regulations? I mean if
you have patchwork of US having one, EU
having another, China is doing its own
thing, god knows uh you know African
Union is working on it.
Uh I understand there is AI nationalism
and we'll touch on that a little bit but
uh should there be some kind of a
harmonization of AI regulation?
So I'm absolutely convinced that we need
a kind of u international uh uh
agreements actually on uh how AI should
be regulated and I myself I'm part of a
of OECD process you know um that looks
at rules for AI. I'm part of the bleach
uh safety AI safety report. This is very
important actually and it's actually
good news that for example uh in this AI
safety report there has been just the
interim report being issued. You know
there was in Seoul now a mini summit.
There will be a larger summit on AI and
safety in uh this fall in Paris and and
the good news is actually that more than
30 nations including also China and
others you know are part of this uh uh
initiative you know and I believe this
is at least a starting point you know AI
and safety it's clear that AI has many
kind of safety threats you know and uh
it's good that we have an international
that they're international initiatives
and that hopefully leads then to
international agreements you know how to
uh uh deal with those threats yeah and
build on that I guess also um the more
general questions how to regulate AI
might at least lead so you know these
initiatives might lead to a minimum set
you know of internationally globally
accepted requirements for AI systems you
know and I think this is a a laudable
goal to achieve and it's uh important to
work on this. Yes. So you are saying
that there should be some consistency uh
Antonio in terms of uh the framework uh
for regulation. Um in your view Antonio
you've talked about being part of this
uh safety institute whether it's in UK's
and now in Seoul and I'm moving to
Paris. what are your biggest concerns uh
for AI if you were to tell our listeners
what worries you? What keeps you up at
night about AI? So actually I think the
the uh the biggest concerns are uh the
ones that are related to um the massive
scale of um uh uh fake information that
can be distributed. you know the um uh
strong biases that can be introduced by
AI systems you know and again those are
all things that are not 100% new to uh
uh to us in terms of uh in the internet
is full actually of these uh uh threats
in a way but of course modern AI models
allowed to scale these uh uh attacks and
also scale this misinformation in a way
that we haven't seen before. You know,
and this is something that uh uh worries
me, you know. Um I also believe
that again you know following a human-
centered AI approach it's important to
me that AI is still used as a tool and
not used to basically tool humans
actually you know and change humans and
uh and there is a risk actually that the
as with many tools human tools you know
in the hand of wrong people you know uh
of course uh the the potential actually
of harm and damage is pretty high and
and therefore I'm I'm glad that actually
for example in this AI safety process
you know many nations came together and
first now we have identifi identified
the different uh threats you know
associated to AI and also uh we are
discussing technological but also at a
certain point of course also regulatory
means you know to uh counteract
M so I mean you touched upon some key
things as you said biases um some uh
deep fakes which is a big concern as we
have an election in this country and
there's elections in many many other
countries do you have uh some
suggestions as to uh so let's let's
address the topic of deep fakes in the
US we've talked about watermarking and
some other uh techn technologies even
though they are not 100% uh successful.
Uh then there is the issue as you talked
about with biases. Um and then finally
uh Antonio the issue is about privacy
also because of uh data. Uh so when you
look at some of these issues uh your
suggestions, ideas, thoughts on some how
to tackle these very big uh or when you
go to these uh very exclusive things in
Seoul or in uh in UK etc. What are some
of the solutions being proposed for
these kinds of things? So I think there
will be not one solution actually but we
need actually a full uh uh uh breadth
actually of different approaches. One of
course are technological uh uh
solutions. So it's of course it's a
little bit a red race. We know this
actually as it has been always with
cyber attacks you know but it is uh um
there is a fair chance that we can use
technology actually to prevent most of
the damage. Yeah. So this is one thing
watermarking at least for images I think
and uh works fine and it will uh uh we
already seeing it the big tech companies
basically have agreed actually to
introduce watermarks in nearly all kind
of uh um images that are generated
through AI and so on. I think this is
very useful and very helpful. It's also
in their own best interest because if
you think about um you don't want to
train
on on data that has been generated by AI
models you know at least you want to
know about this if you use this data you
know so that's the question uh where
does the new data come from and so on
and what happens if you feed data back
into uh um AI models you know so that's
one thing I believe uh the other thing
is of course also education. This is
very important, you know, we have to
educate uh um and and this the problem
is since these developments are very
fast, you know, and we're moving really
on a a very de dynamic field and
education usually is much slower, you
know, we need to make sure actually that
people understand, you know, that they
understand that uh how what AI is able
to do in what scale, you know, AI is
able to do it. We have to we we need
regulation because without regulation we
cannot uh uh enforce laws you know we
don't have laws we would need standards
I think this is very important for safe
uh u AI systems for transparent AI
systems AI systems that are able that
can be scrutinized that can be explained
and uh this is important because this
will then allow to audit AI systems, you
know, and uh and and I envision actually
at a certain point
uh a world where we have fully audited
AI systems so we know what they're doing
and uh and everything else is not safe
basically. Yeah, it's like building your
own car, you know, uh out of your garage
and going on the road. I think they are
there might be some countries including
in the US or some areas where this is
allowed but in Europe it's definitely
not allowed and I think it's also good
that's not allowed you know so something
similar actually for AI systems future
AI system is very desirable in my
opinion um so what you're suggesting um
Antonio and I want to just follow up
because I talked to a lot of these uh
leaders is some kind of an audit
mechanism to audit some of these uh
systems. Now, Antonio, large publicly
traded companies have at least uh
they're set up so to speak these audit
boards or ethics boards etc. What are
your thoughts in terms of something like
that? I mean you're when you talk about
auditing are you talking about auditing
these foundation models? Are you talking
about the application of these
foundation models or the use of it or
all of it?
Yeah, I think uh uh first of all I uh I
think it's good that uh uh many also uh
AI companies have ethic boards to
basically uh raise the awareness
actually of the responsibility. I
remember when I studied computer science
in the 80s, you know, uh uh ethical
concerns
were never addressed actually during my
studies. Yeah. And this has changed uh
uh fortunately and also it's important
that this has changed. you know computer
scientists people that uh work in AI
data scientists that are part of
building large AI systems have a huge
responsibility nowadays you know and it
it and and this is something they need
to be aware of and it's good to have
actually bodies within companies but
also within institutions universities
that basically keep the awareness level
uh very high in this respect on the
other hand I don't think this is enough.
This is uh my personal opinion. I uh
believe that we also need kind of uh
neutral auditing in a way because
companies always have of course a
certain and that's perfectly fine but of
course they are set out to earn money
actually you know and make money and
they might come into uh conflicts you
know in terms of economic pressure and
so on. So I believe having uh neutral
bodies that do this auditing is also
important and we will see in the
European Union such institutions will be
actually installed. Uh they are not
there yet but they will come for sure. I
believe that also other countries will
do this. The question now is what to
audit and the honest answer is we don't
know exactly yet. So research still has
to be done to understand exactly what we
can audit and what should be audited.
Yeah. But I believe that so we should
start actually in the use cases. I think
this is the easiest thing to do. I'm not
so much uh a fan of saying we should
audit now foundational models for
example that that are base technology.
you know uh I I won't say that this will
not happen at a certain point in time
but at the moment I think it's not very
useful you know we don't even know
exactly what to look for you so I think
it's much more useful at the moment to
think in terms of applications there are
sensible applications applications that
potentially can cause harm you know and
make sure that we audit those and I
think step by step this will maybe then
also lead to a better understanding how
we can audit AI technology in general.
Um, but at the moment we are not there
yet in my opinion to really be able to
say how to do this in a sensitive
manner. Yeah. So Antonio to summarize
what you're saying is we need to audit.
We still don't know yet what to audit
but your focus is going to be more on
applications and in the EU there are
going to be these uh entities that will
be providing third-party audits as per
the EU AI act and I what you're saying
is that's very very important. U Antonio
we've covered uh you know we talked
about uh biases we've talked about some
of the ethical implications etc. I've
had uh uh guests from uh Europe from
smaller countries not as big as Germany
etc. And some of them well some of the
larger ones including France also have
expressed this there is a worry and I
want your view that uh these large
language models are getting trained on
English language uh they are all Silicon
Valley based uh getting trained on the
internet. Is there a worry that some of
the culture the language of smaller
countries larger countries whether it is
uh Finland or some African regions etc
that might get erased in this whole
process absolutely I think this is a
valid worry and it should be addressed
you know uh it's clear already now
actually the large foundation models
from in particular you know from US
companies
they are much better u in providing
answers and uh uh advice in English than
for example in a small language like
Finnish for example you know um and I
think it's important for
uh and therefore there is the need for
room for a variety of foundation models
that have been trained and also
specialized on smaller languages we have
for example at DFKI we just recently
uh uh finished a project where we used
actually uh one of the open- source
models that from Mistral AI which is a
French-based uh AI company. uh uh the
and and we um uh um retrained the model
with uh additional data from uh French
corpora, from German corpora, from
Italian corpora and the results improved
enormously in these languages. So there
is also the possibility that we take one
of the existing models that are mainly
of course trained in English and we add
data that is maybe not publicly
available for example from EU archives
you know or from archives from uh from
uh public media companies from a certain
country and uh and achieve very
comparable levels you know of
performance in small languages you know
I think this is very important
And we need to be uh uh very attentive,
you know, to uh to cultural uh um to
cultural issues in these foundation
models. It's also one threat that's
mentioned actually in the AI safety
report.
Wonderful. So you are working on uh some
of these things because uh I know some
of our Finnish guests have said that
they are working on uh their language uh
and others which I think is very very
critical to keep the culture and the
language I think otherwise uh it's you
know you lose a lot from history not
just for that culture but for the rest
of the world. Um sorry go ahead Anton.
No. Yeah, I completely agree. And what
is also important is once we have these
multicultural foundational models, they
will be uh much better. They will in if
those collaborate, you know, there's
this large approach on multi- aent
systems. Now, you know, it's a very
important topic in research. It turns
out that if you have multiple instances
of foundation models that work together
on one problem, the results are better
than having just one uh foundation model
work on that problem on its own. You
know, and if you ex extrapolate this,
you know, this would you could expect
that different uh foundation models with
different cultural backgrounds that work
together, you know, to solve a problem,
they might even uh produce better
results than the uh copied instance of
multiple of a of one foundation model
that maybe only trained on English data.
So I think there are also practical
reasons that you want to have a
diversity there you know in the in the
foundation models to improve the
results. I think you make a excellent
point on that. Uh Antonio you are uh in
a research and an academic institution.
I want to touch the topic of jobs. U
there have been you know there are two
aspects to it. On one side people say
you know peu companies like open AI and
others are paying like a million dollars
for highly skilled uh some of your PhD
students who are listening can probably
get that kind of money but then we have
uh the world economic forum McKenzie IMF
saying that 60% in developed countries
about 30 to
60% displacement of workforce could
happen. Now you are teaching students
uh which you have a sense of
responsibility to these students that
you teach them hopefully they get
livelihood etc. What are your thoughts?
I mean
u firstly there is you know this talk
that there is a scarcity of AI talent
then there is this talk that there is
going to be huge displacement. Talk to
our listeners as a leader a thought
leader in uh research and academic as to
what should they be thinking. lawmakers
here are trying to figure out hey uh 60%
people will be without jobs what can
they do yeah I think uh um first of all
although I'm not an expert in labor
market of course you know I have to make
this small disclaimer but I have an
opinion I think I've seen this McKenzie
report for example I think there is a
slight um I think uh overestimate ation,
how quick actually AI will be integrated
into our processes, you know, and there
are many examples from former
technological breakthroughs and the time
it took actually to bring those
breakthrough really to full uh uh uh
exploitation into society into uh uh
labor processes. So that I'm a little
bit skeptical. I don't believe this will
happen in a couple of years. I I
remember I think the Mckenzie report
mentions 2030 as a goal. I think it will
take longer. This is my opinion.
Nevertheless, I believe that many jobs
will be affected by uh uh AI in the
future. I don't think so much that many
jobs will really disappear as job as in
their do job description. I think they
will be transformed. But of course
productivity will raise will be risen
and this also means you need less people
for the same amount of work. You know
for many western society this is rather
good news in my opinion because as you
mentioned we are lacking actually uh uh
talent and even worse we are lacking
young people in general. You know we
have a
demographic catastrophe coming around
the corner. At least western country and
also China we know this also China has
this problem. uh and uh for example in
Germany we are currently pressing to
bring AI into administration because
many jobs in in German
administration are the positions are
open and they they're not able to find
people you know to do this you know and
so there is a big chance actually that
we and also in a way an obligation to
exploit AI to its full potential in
particular in administration
to be able to maintain the service level
within our societies uh also in 5 to 10
years you know so but still I think
there will be uh to a certain extent
changes in the labor market also huge
changes they might take a little bit
longer than studies suggest
but uh uh but there will be an impact in
particular on white collar worker which
have been more or less uh in the past
not so much the target of uh uh of large
uh uh job changes and transformation.
So what you're saying is transformation
will come but maybe it'll be later than
what most people are predicting because
uh it'll take a little longer to get
integrated. But what you're also I think
very important point you're making is
that this could be beneficial especially
to western societies even Japan look
look at the demographic challenges that
they are facing or like you said China
where this could potentially help with
some of the demographic challenges that
are being faced but uh jobs will get
transformed uh productivity will be
raised so those are uh uh excellent
points uh Antonio for our listeners who
are not as familiar with Germany, you
know, people who are in the US or uh
Asia etc. We have a lot of listeners
around the world. Give a brief idea of
the AI ecosystem in Germany. I mean we
are familiar with Alfalpa and a bunch of
other companies but I have sure there is
lot more to the German AI ecosystem
besides uh some of these companies. So
it would be really helpful to uh us if
not to them to me for sure. Sure. Yeah.
No. So, as you might know, research on
AI has a long tradition in Germany and
we have a couple of very excellent uh uh
locations, you know, for uh um basic
academic research. In fact, actually the
German government has funded uh besides
DFKI uh five uh so-called AI competence
centers that uh um um uh that since a
couple of years are basically get
additional funding. There is around uh
and they are a little bit regionally
distributed in Germany. uh around those
centers um AI ecosystems have started to
uh uh to flourish you know and and to be
honest I'm uh of course we have the
problem uh of
uh investment money venture capital in
Europe in general it's getting a little
bit better we uh we we now managed to
get the first rounds actually of uh also
in Germany but also France is very good
actually the first rounds, investment
rounds covered. When it comes to uh the
large scaling rounds, we still lack
behind, you know, I
believe. But if you look at uh cities uh
like Berlin, they have a very vibrant AI
ecosystem. If you look at cities like
Munich that have around the technical
university of Munich a very good concept
how to build up startups and also DFKI
has a long tradition of uh uh uh
developing startups uh and actually
that's one of our also missions you know
transfer missions to allow our employees
after a couple of years uh as DFKI
researchers to take their knowledge and
uh uh and try their own luck in uh in in
their own funded companies. I think this
is very important and and this is
something also special I guess in
Germany that we have I mentioned those
small and medium-sized enterprises you
know and lots of innovation happens in
this companies in Germany and of course
you know uh the challenge here is other
than the US where everything is pretty
public in a sense that you know there is
an idea and then you have investors
immediately and and then ideas are
scaled up quickly, you know. Often in
Germany, innovation happened behind
closed doors, you know, and even some
companies in Germany, they don't even
file patents because they're afraid that
those ideas are then copied. So, they
rather have the advantage of the early
mover, you know, for a certain way, you
know, and uh and they're not so much
interested in patterns. So it's it's
interesting you know to see how this
ecosystem now kind of adopts AI and AI
technology. I think those are the
pecularities actually of the German and
maybe also the European AI ecosystem.
But uh Antonio from everything that I've
read and I've talked to guests the
talent is tremendous in Germany in
France I mean all over Europe. uh in
some cases unfortunately that we uh the
US has been the beneficiary of that
talent to be very frank with you but uh
with companies like Mistral ALF Alpa and
others we are starting to see now uh
whether and I'm hoping that that as you
said that funding ecosystem etc begins
because uh I think it's not just for the
US but I think for the rest of the world
we need many many different pockets of
AI excellence happening around the world
because it is going to be very important
to democratize that and I wanted to ask
you that question. Does that worry you?
because I know that I have a lot of
senators, congressmen come in here and
one of the big worries for them is uh
the monopoly uh
of AI in a few companies because right
now we are struggling with the monopoly
of social media with a few companies and
the last thing we want is the same thing
to happen. Is that a concern for you or
in Europe or anything like that? I think
there is a clear advantage at the moment
especially in the US you know regarding
the technology not so much about how you
know about the the the general
architectures that are used those are
basically well known and everybody uses
more or less the same but of course in
the engineering and in the doing you
know and how the data is handled because
uh the big uh American companies they
have this advantage that they were able
actually to experiment on the data you
know and build these models you know uh
in the last couple of years a head start
this would not have been even possible
in in Europe uh uh uh uh one and a half
years ago to build such a large language
model because of lacking in uh financial
uh capabilities but also because of
lacking uh computational uh
capabilities. Yeah, this is getting
better now. I'm not so super pessimistic
regarding the monopoly and the main
reason is that AI models are piece of
technology. They're not so much a
platform service. Uh it's not a
platform economy. Although of course the
the large American companies try to
integrate this into their platforms. You
know we see with Mestri for example uh
the open- source model that you can do
many things with that model already. you
know, of course, it has to be adapted to
certain use cases uh used uh uh with
data from certain domains and so on, but
uh and so I'm not so pessimistic uh uh
there. I believe my feeling is that uh
we have a trend that goes more into the
direction that large AI models,
foundational models will be rather part
of operating systems in the future. You
know, then uh and this means nobody is
going to pay a lot for them in the end.
You know, maybe maybe the costs to
operate them those have to go down for
sure. But uh it's not like that uh there
is uh uh there will be a monopoly of one
uh uh technological provider or only a
few. I think we will see much more uh
foundation models coming. Now we have
now the enormous trend towards um uh
foundation models that include data from
real world interaction. You know sensor
information, robot interaction and so
on. We will see several models appear
there. So I think there will be a
variety of models. I rather believe that
commercialization will take place in the
applications in the domain and not so
much at the technological core. Yeah.
But we will see. Yeah. Yeah. Well, I'm
glad that you're not worried because I
can tell you the lawmakers here are uh
concerned because of what happened with
social media. Of course, I understand
this. Yes. Yeah. Uh Antonio uh I have uh
I could talk to you for hours because I
have so many other questions but uh
we'll need to get you back again here
but towards the end we have a few
lightning round questions. These are
either
or in your case we'll make an exception.
It can be both. So we'll just ask you a
few questions relating to that to get
some idea of your thought process. So
let's just uh go with the lightning
round of questions. Uh Antonio uh would
you like transparency or privacy?
So I think both is important. Okay. Uh
national AI policies or international AI
frameworks? International AI frameworks.
Okay. Ethical AI boards or government
regulation?
I tend more towards governmental
regulations. But we also need the the
boards for sure. Okay. Uh do you want
algorithmic transparency or data
transparency?
I think they are like really difficult
to tell. I think both are important but
I would tend more towards data
transparency but uh uh auditing
algorithms might be also a viable way
actually. That's a that's a tough one.
Uh Antonio, is AI a greater risk or
opportunity for society? Opportunity of
course. Wonderful. Uh should we tax uh
AI companies more or provide them
incentives?
So I think at the moment it's more
incentives actually. Okay. Um last one
for you. Should we criminalize advanced
deep fakes or counter them with
authentication tech?
We need definitely both.
I agree with you. Um so Antonio, for our
audience, I mean you've been just such
an incredible guest. Uh tell them
looking ahead, what are your hopes and
concerns for the future of AI? What role
should regulation play in shaping that
future? Especially uh to our lawmakers,
legislators here, to the European
members of parliament who are listening.
Yeah, I very much hope that actually we
will be able to uh uh deliver on the
vision of human centered AI as we
discussed today. I think we need uh
rules and regulations to do so. But I
also uh strongly believe that um uh most
of AI researchers and most of people who
are in the AI business share this
vision, you know, and of course there
are people uh that use AI as tools to do
harm. And we uh and my big hope is
actually that we will be able to
mitigate actually those risks and that
uh um that AI will uh will help us
actually to deliver on the promise of a
democratic and
uh more human- centered uh uh use of
technology and uh and I hope that we
will do a better job actually than we
did with social media actually the
internet you know this is actually the
chance
Absolutely. Thank you so much, Antonio,
for sharing your valuable insights uh
with us today. You know, your dedication
to human- centered AI and your work at
the intersection of AI and human
computer interaction are really
inspiring. And as we navigate the
complexities of AI regulation, your
perspectives will undoubtedly help shape
a more democratic, fair, and equitable
future for AI technology. And to all our
listeners, thank you for tuning in for
this episode of Regulating AI. Stay
tuned for more conversations with
leading experts and lawmakers as we
continue to explore the critical issues
surrounding AI regulation. Until next
time, stay informed and engaged. Thank
you so much, Antonio. This was uh
fabulous. As I said, we need to get you
back because I had so many questions
that I needed to ask. Absolutely. Yeah.
Thank you very much. Thank you.
[Music]
