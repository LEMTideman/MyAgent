to raise the salience of the issue at a
time when the intersection between
science and technology with national
security, public policy and our media
landscape is going to be one of the
defining features of US governance. I
strongly believe that the path forward
for sound guard rails for AI is going to
be industry specific. It's going to look
different in education than it does in
healthcare than it does in financial
services as it should. When I think
about the ability to do to do AI, I
think of it as a nexus of three major
assets. One is data. You you you
literally need the training material.
Second is compute, right? Which to a
certain extent is really becoming a
question of energy. And then the third
is is talent really is the ability of to
construct the algorithms necessary to
advance these LLMs. Ultimately, the
United States is not going to win by
trying to play keep away from China.
We're going to win by running faster
than China. and we're gonna win by
recognizing that the 21st century is
going to be a competition between two
operating systems.
Welcome to the regulating AI podcast.
Join host Sanjay Puri as he explores the
dynamic and developing world of
artificial intelligence governance. Each
episode features deep dives with global
leaders at the forefront of regulating
AI responsibly, tackling the challenges
using AI can bring about head-on and
enabling balance without hindering
innovation.
[Music]
Welcome to regulating AI the podcast
where we explore the intersection of
policy innovation and responsible AI
development. I'm your host Sanjay Puri
and today we have a fascinating guest
who made history by being the first US
congressman to deliver a speech written
by artificial intelligence on the US
House floor. Please welcome Congressman
Jake Arinclaus from Massachusetts fourth
district. Congressman, your background
spends military service, local
government, business, and now national
politics, and you've taken a bold step
in demonstrating AI's capabilities right
in Congress. Thank you so much for
joining us today.
Thanks for having me on. Looking forward
to the conversation.
Wonderful. Uh, Congressman, we have a
global audience, uh, obviously US
lawmakers, staff, policy makers,
entrepreneurs, and then in Europe as
well as in Asia and some in Latin
America too. So let's start with your
historic uh chat GPT written speech.
What motivated you to use AI for a
congressional address? Um congressman
to raise the salience of the issue at a
time when the intersection between
science and technology with national
security public policy and our media
landscape is going to be one of the
defining features of US governance.
So uh Jake the whole perspective was
that let's really uh bring this to
attention especially for your colleagues
right in terms of what it can do so that
people do understand that
for my colleagues yes but actually
more so for industry leaders I strongly
believe that the path forward for sound
guard rails for AI is going to be
industry specific. It's going to look
different in education than it does in
healthcare than it does in financial
services as it should. And the best way
to adopt sound policy for AI, as I think
is the case for any new technology, is
for subject matter experts within
industry to engage and uh to volley back
and forth problems, ideas, and
solutions, and then to organically come
up with uh the guardrails that they want
to see in place, and then to interface
with public policy makers about those.
That's a much better way than top- down
one-sizefits-all dictats from
Washington.
Well, uh, I think you made some great
points. So, if I can just follow up on a
couple of those points. Uh, Jake, EU
passed its, uh, EU AI act, which is a
fairly comprehensive
u bill that goes across. It's a
riskbased system. What you are proposing
is a more industry or vertical specific
uh, uh, situation. uh why do you think
that would be better again for our
listeners than the something
comprehensive across the board?
I strongly disagree with how the
European Union is approaching AI and
indeed with a lot of technology. The EU
seems to be aspiring to be the regulator
and chief of the world and yet has
become a desert of innovation for much
of this technology and if it's not
careful it's going to be totally left in
the dust on coming up with the
groundbreaking science and technology
that defines the 21st century. I do not
think the United States should be
following in the EU's template. Um what
I believe is that we should have an
outcomesbased rather than a
technologybased regulatory regime. So
what do I mean by that?
Mhm. What I mean is that instead of
regulating AI or regulating SQL or R or
C++ or any other technology, we should
define crisply and clearly in a tech
agnostic manner what are the outcomes
that we think are acceptable and what
are the outcomes that we don't think are
acceptable. So I'll give you two
examples to make this real. both in
healthcare. If a biotech company is
using AI to look in higher dimensional
space about protein folding
possibilities to come up with new
targets for drugs,
that's great. I hope they do that. I
hope they do more of it. And the FDA
isn't going to ask, well, you know, what
were the GPUs that you were using on
this program? They're going to say, is
it safe in phase one? Is it effective in
phase two? Isn't it is it safe and
effective in phase three? It's an
outcomesbased approach. Similarly,
within Medicare under CMS, if United
Health Group is using AI to proactively
deny prior authorization requests for
needed care, that's a tort. That's not
acceptable. A health insurance company
can't proactively deny requests without
clinical basis. Whether they're using AI
or they're using, you know, a customer
service hotline, to me as a policy
maker, it's unacceptable either way. And
the technology is secondary to the
outcome.
No. So, uh, that's a great input. uh you
made several comments. We have a lot of
listeners from uh Europe. Uh what you're
saying is Europe could end up being the
desert of innovation. I need to uh
remember that line. That's a pretty cool
line. Uh but just coming back to this,
I've spoken to a lot of your colleagues
uh on this show. They say we already
have a lot of laws in place. FDA does a
lot of uh AI approvals. We have FAA and
other things. So is your perspective we
just need some additional laws for areas
that are not being covered? Uh you know
whether it's the FTC or things of that
nature. Jake, what would you suggest?
I'm in no rush to pass any type of
general AI law at the federal level. In
fact, I'm not even really sure what that
would look like. That doesn't mean that
we don't need any new laws in general,
though. And I'm happy to give a couple
of specific examples. So
please
first there is a bill that would
basically create a public cloud for
access by universities by small
companies by nonprofits by civil society
in order to tap into the compute
necessary to build large language
models. I think that's a public good
that the federal government should be
providing. We do not want uh these
corporate walled gardens where only open
AAI or Facebook or Google can do the
kind of high-powered compute that is
necessary to train new LLMs. And having
a public infrastructure
that people can hook into for a modest
fee, I think is a is a public good
that's likely to expedite innovation. So
we should do that and that's small
dollars given the potential ROI. The
other thing that we need to do is amend
section 230. This is the 1996 law that
immunizes social media platforms for any
liability regarding third party content
posted on their platforms. And in 1996,
that law made sense. It was actually it
was a good idea. It's been called the 26
words that gave birth to the internet
because it shielded
online entrepreneurs from uh bad faith
lawsuits. The world has changed. Okay,
mission accomplished. The internet was
born. Uh but now 30 years later, these
uh major internet platforms have become
the wealthiest, most powerful
corporations in history, and they are
attentionfracking our kids. They're
making them miserable by exploiting
their attention spans to sell their
eyeballs to the highest bidding
advertiser. We need to crack down. We
need to say, "Hey, it's not acceptable
if you are platforming cyber harassment,
bullying, intimate privacy violations,
defamation, liable, things that are
already tors. You actually have to have
skin in the game." Now, these
corporations will come back and they'll
cry foul about the First Amendment, and
it's nonsense. We have the First
Amendment. It's doing great.
TV broadcasters and radio journalists
and print journalists have wide latitude
to criticize anybody they want, me
included, with no issues of retribution.
These social media platforms are not
trying to defend the First Amendment.
They're trying to defend their narrowly
vested exception to the law under
section 230. And I don't understand why
they should get special treatment that
journalists the world over don't get.
Yeah. So basically what you're saying is
that two areas. One is uh democratizing
access which is what you're saying you
know small dollars and second is section
uh this 230 repeal of that and there's a
bill in the senate as you know uh that
talks about it. Um you touched on
something also uh which is fairly
important. Uh our social media is kind
of dominated Jake by five six companies
our the message that goes to the
children uh our town halls and right now
we're in the danger of the same thing
happening in AI you know because it
costs a lot of money those foundation
models etc. What can Congress do? I mean
you to make sure now obviously there's
this whole issue of open source, closed
source, etc. But what is there a role
for you or US Congress to make sure we
are not in this? Because if you thought
social media was bad, AI is going to be
you know 10 times as much. So what can
US Congress do towards that?
It's a it's a superb question. I would
not claim a monopoly on the answer. So,
first I think the
tighter controls around section 230 and
you'd mentioned legislation. I have led
bipartisan legislation in the House
along with Ashley Henson of Iowa called
the Intimate Privacy Protection Act and
that curb section 230 protections unless
these platforms can demonstrate that
they are taking uh that they have a a
due process to prevent in particular uh
deep fake pornography being targeted
against one young women on their
platforms. And this is an example of
where we need a new law based on AI.
Because
obviously it's always been theoretically
possible to create graphic content
without somebody's consent. But because
of AI, because of these notification
apps, it's now at a scale that creates
really a difference of of principle as
opposed to just a a new area on on the
continuum. And I'm I'm worried this is
going to ruin kids lives. We're going to
see a situation where where the lives of
young women and actually young men too
are going to be ruined by this. these
social media platforms don't care. They
just legally don't have to care and they
need to they need to be responsible. So
one, we've got to put those bounds in
place. Number two is when I think about
the ability to do to do AI, I think of
it as a nexus of three major assets. One
is data. You you you literally need the
training material. Second is compute,
right? Which to a certain extent is
really becoming a question of energy. uh
uh and then the third is is talent
really is the ability of to construct
the algorithms necessary uh to advance
these LLMs and while Amazon and Meta and
Google and Facebook all have different
products and markets and use cases at
the strategic level to me they've all
kind of started to merge towards the
same thing which is that the three of
them are all just warehouses of those
three things they're all warehouses of
data compute and talent and so the way
that I think we democratize the ability
to innovate with AI is to think about
how we democratize across those three
asset classes data compute and talent
public cloud is one element of that with
the compute
data through the open source effort I
think is the other and then the
algorithmic development I actually think
that's going to happen organically
because we're seeing that the algorithms
and the ability to evolve these LLM is
becoming further and further
commoditized
so uh that's an excellent point that uh
there are three aspects of it and you
know with uh data open source uh with
compute uh you know giving shared access
and then talent obviously uh Google just
announced I think a couple of days ago
that 25% of their programming or coding
is now being done by AI
and Sanjay what we have to watch out for
is this aqua hire phenomenon meant to
skirt antitrust laws because if you
think about what is a
well in this day and age in in in
something as intangible
as an AI startup.
25 people just by virtue of like all
connecting on LinkedIn and deciding that
they're going to announce a company
together probably right off the bat have
a hund00 million valuation, right? Like
no exaggeration. If it's the right 25
people, heck, if it's the right five
people and they just decide that they're
going to come up with a name together
and announce a new venture right off the
bat, probably $100 million valuation.
And I'm not I'm actually not I'm not
throwing shade on them. Good for them.
If they have that kind of market value
based on their talents and what they've
done previously, rock on. What I do have
a problem with though is if one of the
big companies then Aqua hires them to
prevent any type of uh competition and
functionally just hires people through
an acquisition and and
skirts or I should say acquires it
through hiring to be clear and skirts
FTC purview because of it. that I think
is something that we have to watch out
for because it's how the big guys are
going to gobble up everybody else.
Uh so I presume you're uh talking about
there are three specific examples with
inflection uh the acquisition well aqua
hire because uh the CEO moved over the
employees got left uh behind and the
Microsoft paid off and then you
character AI with Google and then you
had with Amazon. what role uh I mean is
this FTC's perview uh I mean they're
looking at it etc because obviously they
have found these companies seem to have
found something because now every one of
them is doing it uh is there a loophole
or something that they are looking at
I don't want to comment on specific
instances cuz
well I'm say general Aqua Harris just
general Aqua Harris
but this is firmly within the remit of
of DOJ and FTC they are going have to
though. I think what what is incumbent
upon the federal government in this area
though is clear and predictable and
consistent rules of the road. Rule bylaw
or regulation by enforcement is not
acceptable. It's going to chill
investment and create uncertainty for
entrepreneurs. We want to be the AI hub
of the world. We want people starting
new ideas and we want them getting
acquired by the way because those
liquidity events then create a cascade
for the next entrepreneurs. So I love
it. I want all of it. But I I am very
skeptical though of the big companies
trying to protect their moes by stamping
out anybody else building a castle.
Uh good points. Uh good points. Jake, uh
just uh if we can just shift a little
bit to national security. You've got a
tremendous background in there. You also
sit on the select committee on China. So
uh couple of uh things in there because
that's become you know AI uh to be very
frank with you uh Jake has become a
national security issue. It's become a
geopolitical issue. Tell our listeners
how does your experience on the select
committee uh for strategic competition
with China inform your views on AI
regulation?
I agree that it's a national security
issue. There's so many areas that we can
dig into here. Let me pick a few out and
be specific about them. So, one is
energy. As most of our listeners, I
think, will understand better than I do,
a lot of AI functionally, is at this
point an energy play, right? We're
seeing nuclear power getting
bootstrapped by uh by AI companies, and
that's terrific. Um, what I think the
United States needs to do is build on
the Advance Act. So, we passed the
Advance Act, this Congress, one of the
rare bright spots of an otherwise
relatively dysfunctional congressional
term. What the Advance Act does is it uh
makes the Nuclear Regulatory Commission
a uh have to not just think about the
safety of nuclear which of course is
vital but also how to promote nuclear
power in America. It also creates
regulatory certainty and and uh uh
responsiveness for fusion as well as
fision power. This is really exciting
because we have now created a regulatory
regime whereby fision and fusion could
potentially scale up dramatically in the
United States as a share of our utility
uh of our utility grid. We're we're
we're too low. we should aim to build a
thousand nuclear fision or fusion power
plants uh over the next decade or two.
Uh the Chinese are doing it and they're
not just doing it for themselves,
they're exporting it.
And when you pair nuclear power with,
you know, desalination plants or data
centers, what you do is you become the
vital lynchpin resource for everything
else a developed society wants to do.
That's a tremendous amount of leverage
that we should not be yielding to our
pacing adversary. The United States
needs to become a clean energy
powerhouse. I think fusion and vision
are the keystone of that aspiration and
we have to get so good at building these
modular plants the way Gates is trying
to do out in Wyoming that we cannot just
do it at scale domestically but export
the the capabilities overseas. That's a
tall order. I have utmost confidence in
our ability to do it though if we get
public private alignment and there's
some things that we can do with
department of energy to accelerate that.
Um number two is uh we have got to put a
demand signal into the marketplace for
embedding AI in robotics. This is to me
the uh the near-term critical element.
Unmanned aerial and unmanned maritime
systems need to be able to swarm, sense,
surveil and strike with the uh synergy
of hardware, software and artificial
intelligence. And we are at the very
very beginning of that journey. The best
way to expedite that journey is for the
Department of Defense to slap several
billion dollars on the table and say you
build it, we buy it. And they have
grudgingly gotten there with the
replicator program which is for drones.
But at this point, and I've said this
directly to DoD, that replicator program
is a PowerPoint slide. They have not put
money behind it. They need to get
serious about buying these things. And
then we got to test it in the feedback
loop of real war uh in in Ukraine. Uh
and then get ready to deploy the
maritime systems paired with the aerial
systems in the Indoacific. Uh the
Indopacific is very different than
Afghanistan and Iraq where the US
military over the last two decades has
learned how to fight. This place is full
of water. It's big and it's going to
need a lot of dispersed decentralized
autonomous systems that are again able
to both operate individually but then
also flock together, swarm, surveil,
strike uh and then disperse again.
That's going to be how we beat the
Chinese out the Indoacific.
So uh you pointed two things for our
listeners. One is obviously energy is
critical and you said fusion and u
probably micro uh nuclear uh you know uh
opportunities. Uh that would be one and
the second thing you talked about is
robotics and unmanned systems uh being
very very critical. Um and robotics uh
is really coming of age. Yeah, I'm sure
you know this Jake where the confluence
of AI and robotics is really really
changing. Now the obviously the issue is
the Chinese have also made some
tremendous advances in uh robotics and
it's not just us thinking of that. So
from a
on the select committee uh Jake uh we've
obviously uh put down several
restrictions on uh export of uh certain
categories of chips to you know China
and certain other countries. What are
your thoughts? I mean uh do you think
this is going to kind of let's say our
adversaries hold them back or what else
can be done for us to keep us ahead of
the curve here?
Ultimately the United States is not
going to win by trying to play keep away
from China. We're going to win by
running faster than China and we're
going to win by recognizing that the
21st century is going to be a
competition between two operating
systems. The US operating system and the
CCP operating system. And operating
systems like Android and iPhone are
about who wants to build on top of that
uh of that hardware. Meaning who wants
to build on top of US military security
guarantees and freedom of navigation
guarantees and our diplomacy and our
soft power and our culture and our
economic exchange versus who wants to
build on top of the Belt and Road and
the CCP's
use of its uh naval bases and and forces
in the South China Sea and elsewhere.
And right now we are uh in a fierce
competition in the global south between
the operating systems. There is too much
emphasis in Congress about the way that
we win is by trying to mildly degrade
the the CCP operating system by
preventing chip exports or impairing
telecom exports or impairing outbound
investment. And you know what in in
isolated specific examples maybe that's
the wise thing to do. I supported the
president's October 23, for example,
semiconductor export controls. But we
are kidding ourselves if we think that's
how we win. The Chinese have 1.4 billion
people. Most of their students are
scoring higher in math and science than
our students are. We think that we're
going to win in a science and technology
race in the 21st century merely by some
isolated export controls. Absolutely
not. Let's get serious here. The way we
win is by creating a worldclass science
and education enterprise. and we and
through robust and mutually beneficial
terms of trade with the global south and
with our allies, we should have joined
the Trans-Pacific Partnership because
you know who's now leading the biggest
trade partnership in Asia Pacific?
China.
We're not at the table. We're on the
menu for them. uh we should be uh
re-upping AGOA, our our uh economic
partnership with Africa as it comes up
for reauthorization in Congress and
figuring out how we can deepen those uh
trade ties and development ties and
investment ties there because the
Chinese come to Africa and they build
power plants and train stations. We got
to be out there providing real tangible
economic value as well and access to our
markets is part of that. So, uh we we
will win by doing what America does
best. free enterprise trade and a
rules-based international order. We
should not try to win by aping the CCP's
myopic mercantalistic approach.
So uh continue out innovating, continue
working with the global uh south is what
you're saying and bring people into our
uh value system I think is what you're
saying. Uh
and it's good for the US economy. There
has been a lot of claims that somehow
trade is bad for the US economy. It just
doesn't stack up in the economic
numbers. Now, if we are trading with
people who are cheating and the Chinese
have been cheating under WTO rules, then
yes, that's not acceptable. We need we
need to level the playing field and I
support legislation to level the playing
field against China for environmental or
labor labor or IP or country of origin
uh malfeasants that is that is
undermining the terms of trade. But in
general, trade makes both parties better
off and it gives our entrepreneurs
bigger markets and it makes us invest
more and it also makes us more
productive and efficient. And I think
we've got to double down on that core
strength. Um recognizing that we have to
prepare Americans to succeed in this
economy and there's myriad ways to do
that beyond I think what was an overly
limited approach in the early in the 90s
and early 2000s.
No. Uh those are very important points.
Um Jake, we obviously have an election
coming up in a few days and then you're
going to have a new Congress. Uh you
said we're you're against obviously
comprehensive uh you know legislation
but you're focused on some industry
sector whether it's deep fakes or things
like that. What is your feeling in the
new Congress? Do you think we're going
to have some uh whether industry
specific or issue specific whether it's
deep fakes etc uh kind of legislation
moving forward
for AI?
Yeah. or AI.
I worry that
Congress will do the kneejerk
thing, which is to stack export controls
on top of one another
and make it seem like we're hurting
China, when in fact what we're doing is
empowering Huawei and other Chinese
companies, SMIC, to own those domestic
markets by themselves and thereby get
the kind of production and econ economic
scales that they need to go down the
production cost curve and and embed
their own influence and metrology into
those new industries which is a major
source of US soft power. So I would I
would be cautious of those and like I
said specific isolated examples where we
think we have outsized leverage. Okay,
I'm on board and again the president's
export control order I thought did that.
I think it's worth noting that the
reason the president had the leverage in
that export control order was because of
ASML, a Dutch company that builds
lithography machines and has probably
the most globalized supply chain of any
product in the history of mankind. And
so it's ironic to me that we are taking
a protectionist stance by leveraging the
power of one of the most globalized
companies in the history of the world
and the success story of global supply
chains. The reason we have the leverage
of ASML is because of terms of trade and
free exchange. And we have to recognize
that we win by our network position, not
by a zero- sum approach to uh exchange.
What I think we could also do, the deep
fake issue we discussed, that's
bipartisan. I've launched that bill and
we're going to uh attempt to kickstart
and galvanize support for it in this
next Congress and and gain co-sponsors
from both parties, particularly focus on
parents of kids in Congress. I'm the
youngest parent in the Democratic
caucus. And I don't want my kids growing
up in a world of just toxicity and
trash. I don't want them to learn about
America through algorithms that amplify
the worst amongst us. I want them to
learn about America through the ideas
that represent the best of us. And these
platforms are uh part of the problem
right now.
Uh those are uh very important points.
Uh Jake uh AI is moving very very
rapidly. As you know when Chachiri came
out we've had now multimodal we have
agents etc. How does uh Congress or
regulation keep pace or how do you have
regular updates to AI regulation? I mean
that's the one question I get from your
colleagues a lot. How do we keep up to
date because things will change in 6
months or a year?
It's a fool's errand to try to think
that we're going to regulate in pace
with the development of LLMs or with
even the use cases of LLMs. I mean,
there's a a booming industry of
entrepreneurs, investors who are going
to figure out how we embed agents into
knowledge work. And I think we're going
to see things that are hard for us to
predict. Just like if you were sitting
here in 1992 talking about, well, I
think web 1.0 is going to do this or
that. I mean, we would have gotten it
wrong. And by the way, Washington would
have gotten it wrong, too. What were the
two kind of critical things that got us
to uh the ability to do AI at the level
it is right now? Well, one of them is
GPUs, which came from video game
semiconductors in the 1990s. And the
other is the LLM transformer model,
which came from translation services in
the early 2010s. If you had told a
Washington policy maker in either of
those eras, hey, I think video games are
strategic, or hey, I think translation
services are strategic, you would have
been laughed out of the room. So policy
makers should not have the conceit that
somehow we're going to predict where AI
is going years from now, months from
now. What we should do is be very clear
about the tors and the standards that we
expect from any private sector
enterprise. I don't care if you're using
blockchain or AI or if you're using good
oldfashioned SQL or if you're
handwriting it. It doesn't matter. This
stuff is illegal. That stuff is not
illegal. This is the outcomes that we're
driving towards. And entrepreneurs can
innovate within those sandboxes.
Yeah. So, uh trying to stay uh
legislation to update with technology
progress as you as you said is a fool's
errand. Uh Jake, I have a zillion
questions and I could keep going. We
need to get you back again. But at the
end we have basically a very simple
lightning round. One word answers. Uh uh
so we want to just ask you a few
questions on that. Are you ready?
I'm a politician so I reserve the right
to use 10 words where one world will do.
But
absolutely. And you can also plead the
fifth.
Okay. Uh Jake more important for AI
innovation or safety?
I I don't I don't think I don't I don't
accept the premise of the bifurcation
there.
Okay. Uh, I forgot who I'm talking to.
Uh, okay. Biggest AI threat, China or
big tech?
Uh,
yeah. Again, I just think the world is
more complicated than that. I mean, I
What is Tik Tok? Is Tik Tok China or big
tech? I guess it's both, right? And it's
a huge threat to the ideological
formation of our youth and to the spread
of disinformation. So, it's just
Okay. Um, I think this one I'll be able
to get an answer from you. AI regulation
should be federal or state based.
Uh
yeah, I don't in the public policy
realm, I don't I guess I don't I don't
deal in one word answers. Again, it's
just specific cases, right? If we're
talking about section 230, that's got to
be federal. If we're talking about some
banking or insurance issues, that may be
state where they tend to have wider
remit. If it's education, maybe it's
local.
Time will tell, but it's got to happen
organically and there has to be tight
feedback loops with reality. It can't
just be a one-izefits-all top down
approach.
Okay. Uh
do you think current AI regulations are
they sufficient or lacking?
I think we need to update our laws for
just the reality of of what 2024 looks
like and you know deep fakes and abuses
by health insurance companies and all of
these things. Um I don't support sort of
a one-sizefits-all AI bill though in
Washington. And I don't think that would
be appropriate and I would be worried
about what lawmakers would try to stuff
in there.
Okay. Finally, open- source AI or
proprietary AI?
I'd bend towards open source.
Open source. Okay. Finally, uh Jake,
based on your uh experience in so many
areas. What's one concrete action for
our listeners, whether they're AI
developers, policy makers, or concerned
citizens that they can take to promote
responsible AI development? promote
local news. One of the great casualties
of the last 15 years of the dominance of
uh big tech has been the collapse of
local news and that has I think maybe
chief amongst all of the various
ailments in our democracy caused a
decline in civic and social trust. When
I first ran for city council 10 years
ago, we had a a local newspaper and that
reporter was at city council meetings
and was holding me to account and
holding the mayor to account and it's
gone. It's gone now. Yeah,
I I see a world in which AI as opposed
to being part of the problem by covering
the internet with pink slime can be part
of the solution by helping to support
local news and local journalists. And so
I would encourage people to uh to build
in that space recognizing how hard it
is, how hard the revenue streams are to
create in that space. Build there,
you'll do a tremendous amount of good.
So promote and read local news. I think
that's what Jake is saying. that'll uh
really create value for our democracy,
for our social fabric. So, thank you
Jake for really sharing your insights on
AI regulation and policy. You know, your
unique perspective as both a techsavvy
legislator and the first to use AI
generated content in Congress really
offers us uh you know valuable insights
into the future of AI governance. And to
our listeners, remember that shaping AI
policy is a collective responsibility
that requires engaged citizens like all
of us. So join us next week for another
episode for regulating AI where we
continue exploring the path towards
ethical and innovative AI development.
Thank you so much Jake. Uh what a uh
incredible session. Uh thank you.
[Music]
