there are two truths that we have one is
we don't actually finally know how they
work we can't trace from point A to
conclusion how this model get gets the
answer uh the second is every now and
then these models hallucinate AI experts
predict in about 2 to 3 years we're
going to have text to complicated
programming so you imagine a world where
a billion people walking around and then
with a few prompts from their phone they
can write a complicated software program
that then goes out into the world and
does stuff for you AI that can destroy
the world the defense department has
weapons that can launch automatically uh
over 60 countries sat on to about the
responsible use of AI when it comes to
controlling automated
weapons welcome to the regulating AI
podcast join host Sanjay purri as he
explores the dynamic and developing
world of artificial intelligence
governance each episode featur is deep
Dives with global leaders at the
Forefront of regulating AI responsibly
tackling the challenges using AI can
bring about head-on and enabling balance
without hindering
[Music]
Innovation welcome to the regulating a
podcast where we bring div wore Global
voices to discuss creating fair and
Equitable AI regulation today we have
the privilege of Hosting congressman
tedl who represents California's 36th
congressional district as the co-chair
of The house's bipartisan task force on
artificial intelligence Congressman Lou
has been at the Forefront of efforts to
create fair and Equitable AI regulation
we are thrilled to have him here to
share his insights and perspectives on
this crucial topic Congressman Lou
welcome to the regulating air
podcast thank you sanay honored to be on
the podcast wonderful uh Congressman Lou
just to give you some perspective we
have a global audience we get over a
million viewed uh it's made up of policy
makers think tanks uh CEOs of companies
uh AI offici so uh they have all
anxiously waiting to hear from you and
several have sent questions in
anticipation knowing the great leader
you are so uh Congressman to begin with
as the co-chair of The house's
bipartisan task force on artificial
intelligence what do you consider to be
the most pressing challenges in
regulating AI
technology and let me first thank
speaker Johnson leader Jeff for creating
their bipartison house task force on AI
I'm honored to co-chair the task force
my counterpart is Congressman Jay oberoi
out of uh Southern California and we
have had a number of meetings already
there's 24 members of the task force 12
Democrats 12 Republicans and we're in
the process now of gathering information
on AI in a number of different fields
and areas and our main mission is to
come up with with a report by the end of
the year on what kinds of AI we might
want to regulate and how we might want
to go about doing so well uh Congressman
firstly uh congratulations um and I
think uh speaks to the leaders and we've
been lucky enough to have a lot of your
colleagues on the show including
congressman oberau who was a great guest
too um Congressman uh you have uh you
know uh put forward several bills in
Congress so let's talk a few of them
because they're very very important
uh let's first talk about the block
nuclear launch by autonomous artificial
intelligence act and I'm talking about
it given uh the current state of the
world we are in um it aims to prevent AI
from making decisions to launch nuclear
weapons without human control can you
explain just the motivation behind this
bill and the potential risk that you're
trying to mitigate sure uh one reason
that all of a sudden there are podcasts
in AI now and why everyone is looking at
this issue is because of a new change in
AI technology that basically hit the
world less than two years ago and it's
these large language models you can call
them Transformer models you can call
them neuron networks but essentially
open AI disrupted the world when they
released chat GPT
worldwide with these large language
models there are two truths that we have
one is we don't actually firly know how
they work we can't trace from point A to
conclusion how this model get gets the
answer uh it is basically too many
calculations being done at once with too
many different sort of uh inputs and
data that we can't explain it uh the
second is every now and then these
models
hallucinate so it will give you a
perfectly uh English accurate answer
that is totally Bonkers false so when
you have these two facts might be okay
if you're like asking questions about
poetry or about writing essay for you
and there's some mistakes we can deal
with that but there are use cases where
you can't have that happen so you can't
for example every now and then have a m
of hallucinate if it's filling medical
prescriptions it's got to be a th%
correct every time right that's the same
in the field of nuclear weapons you
can't have it every now and then
hallucinate and so our bill is very
simple it basically says uh you always
have to have a human in a loop we're
never ever going to let AI launch a
nuclear weapon by
itself well that I think is a very
important uh perspective as I said
Congressman L given what's happening uh
in the nuclear field we've seen some
kind of pronouncements from Russia and
others uh this leads me to a following
question uh Congressman uh the current
buzz word in the world of AI is agents
and super agents can can you give uh
because it kind of relates to a little
bit about this bill that you talked
about can you give our audience your
thoughts on this uh because that's like
become like the Holy Grail these days I
want people to understand how fast AI
has moved just in the last two years so
when the first models came out it was
large a texttext platform you would ask
it questions and it would return to uh
answers to you in text in less than two
years now you can do text to video you
can also do video to text where the AI
will summarize a video of 15 minutes and
tell you what's in that video now we
have text to basic programming so
there's some applications where uh the
AI will write basic programs for you AI
experts predict in about two to three
years we're going to have text to
complicated programming so you imagine a
world where a billion people are walking
around and then with a few prompts from
their phone they can write a complicated
software program that goes out into the
world and does stuff for you that is
something I don't even know what it's
going to look like it is both
simultaneously amazing and alarming at
the same time but we're entering a Brave
New World and when you have all these AI
agents in the world doing stuff uh
things can get very messy and very
complicated it could also be quite
wonderful I don't think we really going
to know until it starts to happen but
eventually we're going to get to that
step because of how quickly AI is
advancing so uh AI is advancing very
fast uh agents are obviously something
all these organizations are working
towards uh congressman is that something
that your task force is also going to
look at yes we're going to look at a
variety of issues uh including some of
the predictions of where AI goes in the
next few years so our task force isn't
just charged with looking at AI just
what's it doing this year but also what
we think might happen in the upcoming
few years and then when we talk about
agents it is sort of interesting I think
it's still going to be a relatively
defined use cases because let's say you
just want AI to do a very simple task
such as for example move a pile of
bricks uh that I have in a corner of my
house uh to you know the fence 15 feet
away that is enormously complicated and
there's a lot that has to happen for
that very simple action to occur so I
think we're sort of uh very far away
from AI doing that versus if you have ai
agent that can go ahead and for example
you know book all your travel
reservations for you in the next couple
days so I think the use cases are still
going to be very important and where we
have agents and where we don't have
agents well that's very helpful um
Congressman you also co-sponsored the
federal artificial intelligence risk
management act which would require all
federal agencies and V vendors to follow
the nest AI risk management framework
uh talk about the benefits of adapting
this framework for audience and how can
it build trust in the government's use
of AI this has done a good job putting
out a risk management framework uh they
are contining to work at it and they're
going to be Contin to make revisions to
it especially with uh the large language
models that have come into society
recently this risk management framework
has been adopted by a number of both
private sector and public sector
agencies we're trying to get more
adoption of it and get the federal
government uh to adopt this framework
after all it was a federal agency they
came up with it and so our hope is we
can get all federal agencies to apply
the this risk management framework which
really I think causes people in the
agency to think about AI to think about
their risks and then think about how to
mitigate it uh you talked uh Congressman
about how uh you know private sector has
also come in towards this
uh can you talk about the importance of
collaboration between the public and the
private sectors and Def you know
developing effective AI risk management
practices well let me put it this way uh
there are going to be hundreds of
millions of use cases for AI there is no
way Congress can regulate every one of
those use cases so in the first instance
we're just going to have to have the
private sector do the right thing they
just need to do the right thing and test
their products make sure their products
aren't biased make sure they don't
deploy products that could be harmful
now if they don't do the right thing
then Congress can still take action even
if we haven't passed a specific law on
it we could for example have hearings
asking them why they didn't do the right
thing we could uh write letters we can
ask for investigations so there are
things we can do to try to incentivize
the private sector to do the right thing
but the best I think that could happen
for society is if all these companies
really took their time to make sure that
their product was safe and not harmful
before they deployed it uh to you know
have responsibility Congressman uh we've
had a lot of your colleagues uh on our
show we've been lucky enough to do that
so uh wanted to just get your views
obviously AI as you mentioned is moving
so very fast you know the llms came out
and there is multimodal as you said you
know video graphics agent Etc how does
regulation keep Pace with something that
you don't even know what's going to
happen I mean and you talked a little
bit about this but just for our audience
uh that's a big concern for them so I'll
tell you how I think about it I think of
two large bodies of AI you got a large
ocean of AI and then this small pond of
AI so to me a large ocean of AI is all
the AI we in government don't care about
so if you're smart refrigerator for
example is making ice cubes incorrectly
we really don't care about that so in
the small part of AI is the AI we might
want to care about it and to me there's
at least three buckets the first is AI
that can destroy the world so we've
talked about nuclear weapons the defense
department has what weapons that can
launch automatically and um the state
department actually has put out now a
document that they've got uh over 60
countries sat on to about the
responsible use of AI when it comes to
controlling automated weapons so we've
got that category right AI that can
destroy the world right the second is
going to be AI That's not going to
destroy the world but could kill you
individually so when your cell phone
malfunctions it's not going 45 miles per
hour but there's a lot of AI it turns
out in moving objects Planes Trains
Automobiles and we make sure that it's
going to have these neuron networks and
large larage models that we've got
Federal regulators and state Regulators
who can be more attuned to Unique
aspects of AI and really be able to
regulate them effectively and correctly
and the last bucket is the hardest which
is AI That's not necessar going to kill
you but has some sort of harm to society
so we wouldn't for example want an AI
software program that uh helps large
companies hire people that is biased or
discriminatory we wouldn't want an AI
program that is helping you know banks
give out loans for that also to be
buyers so discriminatory and um it's
harder to try to sort of address each of
those use cases and figure out ways to
reduce the risk and I put also into that
bucket the unfair monetization of AI
right now the creative economy doesn't
have really a lot of rules of the road
when it comes to Ai and so we have to
figure out what those rules of the road
uh should be well that's very helpful so
for our listeners uh Congressman says
he's only interested in the small pond
not the big Ocean and the small pond is
made up of three things something that
can destroy the world something that can
kill you cars planes and something that
can harm you whether it's discrimination
hiring Etc that's a a very very uh good
summary Congressman uh you also have
your health AI act which you know aims
to explore how Genna can improve patient
care which is supposed to be the Holy G
Healthcare is supposed to be the holy
gra of this through grants you talked
about grants to universities nonprofits
and government agencies can you
elaborate on the potential applications
and the challenges for AI and Healthcare
I'm very excited about AI helping with
Innovations in the healthc care field we
know that AI uh has now folded all 200
some million uh proteins human proteins
know to humankind and given that out to
medical researchers we know that AI is
going to likely make um drugs uh easy
here in terms of which uh drugs might
work out in future which might not work
out it's going to have uh quicker uh
ways to uh in uh make medical more
efficient for example when helping
doctors uh take notes uh and helping um
a lot of efficiencies in the medical
field at the same time how we discussed
earlier AI can hallucinate and at a very
basic level we don't actually know how
these neuron networks work we can't have
AI right hallucinate in use cases where
you can never make a mistake so again
right you don't want AI to fill medical
prescriptions every now and then it
hallucinates you might think of other
use cases in medical field where we
can't have that happen where the AI has
to be correct 1,000% of the time now I
want to know there's different kinds of
AI right so when IBM pioneered you know
deep blue and they beat the number one
chess expert in the world that was a
different of AI that was not a neuron
Network large language model so there
are some AI systems that are much more
closed much more constrained and so when
we talk about AI I think we have to
think about what AI we talking about as
applied in medical field if you have an
expert medical AI system that might be
more okay uh in certain use cases than
for example an unconstraint neuron
Network where we fundamentally don't
know what's going on uh we've had a lot
of Health experts also come in uh
Congressman they talk about the
potential of AI to reduce Health
inequity where you know equal access is
not available especially when you go to
rural areas you go to inner cities Etc
so obviously there is that big potential
also of AI and Healthcare any thoughts
on that I do it raises a host of very
interesting issues uh for
example there are some applic
where you can use your cell phone and
let's say take a picture of your skin
and there might be AI applications I can
tell you if you might have something
that might look like uh skin cancer not
everyone in the world has access to a
dermatologist uh there are people who
may have to drive very far to see a
dermatologist this could be quite
helpful at the same time I've also been
told these applications May in fact be
worse for people who have darker skin in
terms of accuracy so what do you do with
that do you still deploy it uh do you
try and make it so that you don't have
these biases I don't know rais this very
interesting philosophical questions or
maybe you deploy it with a disclaimer
saying that that you know it's less
accurate people with darker skin uh but
fundamentally the principle is there are
going to be applications where people
can use AI in Far Away remote areas as
long as they have you know access to uh
for example the internet or or some sort
of connectivity or if they can take you
know a train model with them to an area
that doesn't have connectivity uh but uh
it does have the capability to give
people access to medical information in
potentially Medical Care in a way uh
that they could not have had access a
few decades ago no I think that makes a
lot of sense um you uh congressman
obviously uh come from a area which has
a large creative uh uh economy I mean um
Hollywood other production you have some
very large production houses and there's
obviously been some concerns when you
look at Sora and other stuff uh and
Hollywood unions and artists have
concerned about AI training on artists
work and churning out some cheap
imitations as well as infringing on
First Amendment rights uh what are your
thoughts so what will Congress do about
something like that so we're definitely
looking at those issues uh in terms of
the intellectual property field there's
also a number of court cases right now
uh that are litigating different aspects
of this issue so I think Congress is
going to see what happens with those
court cases and we're also working on
various bills that will try to put down
rules of the road it is challenging
we're still trying to gather data and
even Within uh this field there's large
disagreement on what's a way to monetize
this so I think it remains to be seen
what's going to happen but I think we
all agree there's got to be rules of the
road and I think the extremes are not
going to happen I don't think you're
going to have a a case where no one gets
any monetization I don't think members
of want to see that happen I think the
question is how do we monetize what does
that look
like no that makes a lot of sense uh
Congressman generally in trying to uh
you know Advance uh AI legislation how
can and you've done a great job but how
do you balance uh you know Innovation
and Implement safety standards to
protect individuals and Society
especially in this current environment
that we are in so in terms of innovation
I'm a big believer in investments in
government that can provide research
funding uh year after year after year
with without having to have a profit and
government has been instrumental for
example and helping to uh kick off the
amazing um bioscience industry we have
in the United States because of all the
Decades of government research uh that
went into this our educational
institutions as well and also in terms
of AI a government have put in a
signific amount of funding uh to working
on a lot of these different issues are
precursors to what helped really these
large language models to now sort of
come into fruition and so I think we
need to continue to uh invest uh in
Government funding and research and then
research at our institutions of higher
education and I think we can get bipar
and support for that at the same time we
have to put in guard rails I don't think
anyone likes how social media for
example turned out and I think there's
bipar and consensus that we don't want
to repeat that again and so again that's
one of the purpos of this task force is
to hear from their different
stakeholders and to take input and then
to S print out a road map on what areas
of AI we should regulate and how we
should go about doing
so uh we had the director of NSF uh Dr
punch also on our show and he talked
about how AI especially my concern was
in rural areas and community colleges
Etc so there's a big initiative and we
are really glad of doing that uh let me
just add add
something so what we have now is a
situation where if you want to work on
these Frontier models at The Cutting
Edge of AI you need access to these
really really um large systems right uh
you need the compute power uh you need
uh access to facilities that only a
handful of private sector companies
control so imagine a world where if you
were a physicist working on you know
Cutting Edge physics and every particle
accelerator was owned by one of you know
five priv private sector companies we
might have some issues with that uh and
so that's what we have right now in
terms of AI and so if you're a a
government uh employee or if you work at
a university or a community college and
you want to work on this basically you
have to hope that one of these private
sector companies allows you to do that
and gives you access right uh so we're
trying to figure out well how do we make
it so that we actually have an ability
for government and Academia to actually
access this compute power and these
kinds of facilities one way is to
actually build it and so there actually
is um precedence for this uh what
happened and you know Al Gore actually
did lead the effort on this he actually
led a bill that provided a huge amount
of money to set up basically
supercomputing centers and um one for
example at the University Al Nori they
got a cray supercomputer because of that
federal law and so we might want to
think about something like that so that
government doesn't have to depend at one
of these five private or six or however
many private sector companies to
actually donate uh their facility or
their compute power so uh that leads me
to the question is the task force uh
because a lot of concerns has been
expressed about this Con consolidation
of power in AI I know the FTC has
recently started looking at it is uh we
don't want the social media experiment
where the Town Hall in some ways or
whatever the social media is controlled
by four or five companies will the task
force look at how things are now getting
Consolidated if you see as you say it's
very expensive it's like making a drug
is a billion dollars making an llm
Foundation model is almost like a
billion dollars and there's literally on
your hand you can count on these so is
the Task Force going to look at
that that's a great question and so what
I've been lobbying uh for uh is for the
report we come out with to say you know
version 1.0 because my view is it's not
as if Congress is going to do this one
task force you for one year and then say
we're done with this uh this is such a
um widespread fast moving complicated
area that I think it's really going to
be something that Congress is going to
look at for many years and we might do
you know some bills here or there every
year or every few months to try to you
know address certain aspects of AI but
um certainly uh the issue you raised is
something that I imagine we would in
fact look at at some point I think it's
a little early to tell because you do in
fact have a lot of folks who are now
interested in investing all kinds of AI
so I'm not sure we know what this world
looks like in two or three years and you
also have right other countries who are
putting in huge amounts of money to
string together you know 30,000 really
expensive computer chips uh so we're not
exactly sure exactly what this world is
going to look like uh in in in a few
years but I imagine if it is in fact
Consolidated and only very small handful
of companies uh then Congress might take
a look at that but I think what more
likely happened is the department
Justice Anti-Trust division we'll look
at that first okay uh Congressman UCLA
one of the best universities as part of
uh your District along with many other
great institutions uh McKenzie IMF all
predict uh major disruption in
employment are in our future are going
up to 60% Etc um what are your thoughts
uh is that something the task force is
going to look at and I know
uh we I had this discussion with many
members but I want to hear your thoughts
and the disruption coming ahead of us
there is absolutely going to be
disruption in the labor force my view is
we just don't know where that's going to
occur and if you look at technological
advances throughout human history net
net you actually end up having more jobs
but there going to be jobs are going to
be eliminated there'll be jobs that
going to be created I think it's really
hard to know what that's going to look
like I liken it to the 100 day weather
forecast and I'll give you an example uh
people have been predicting for years uh
that you know AI is going to replace
Radiologists well guess what it turns
out there's a shortage of Radiologists
right now and AI has in fact not
replaced Radiologists because it is
quite complicated as what they do but
what AI has done is there are now
programs that make radiologist more
efficient uh so when radiologist is
given let's say 50 scans from 50
different patients um they are not going
to know before they look at these scans
which patients might actually need an
urgent look at their scan as opposed to
another patient who could you know wait
a while before their scan is looked at
well there's now applications that will
prioritize and say Hey you might want to
look at these seven scans first and then
these ones a little bit later um and
then let me give you the analogy of the
word processor so none of us I think
very few people actually uh know how to
actually write a word processor and
program it and create one but it didn't
really matter because the whole world
one day got a word processor let's say
it's Microsoft Word and then we're like
oh wow it does spell check it can do
automatic page numbering it can let you
do uh fonts and all sorts of cool things
and then over time we started to see
less secretaries but you know who it
really helped it helped folks that have
weaknesses with spelling right it took
that weakness off the table so I think
what AI is going to do is actually help
a lot of non stem folks it's going to
help a lot of folks who don't have a lot
of uh technical degrees or technical
knowledge it's going to give them an
amazing ability to do very technical
things and uh that I think is going to
result in lots of innovation and lots of
amazing inventions and developments but
it's very unclear right now exactly who
AI is going to uh make more efficient
and and help create new jobs and what
areas AI is going to start reducing
jobs that's a very good point uh
Congressman just taking you back onto
Health uh mental health is one of our
leading crisis according to the surgeon
Journal loneliness is another huge
crisis uh there have been now some AI BS
that help with loneliness and others
there's Le replica and others we've got
20 million followers Etc uh your
thoughts on use of AI for some something
that is U such an important thing and
obviously from a regulatory standpoint
obviously there's all kinds of issues
but uh any thoughts on
that it's hard for me to answer that
because I'm not a psychologist or
psychiatrist I would be concerned
because of the hallucination problem of
large language models and also because
at very fundamental level we don't
actually know how they work now on the
other hand um a lot of the medical field
actually lot of fields uh were based on
data and um there's ability to actually
get data here if you can have um some of
these applications one way to do it is
say look we're going to try to make it
as safe as possible and we to try to put
these guarden rails on it and then want
to collect some data and if it turns out
that on average it's sort of helping
people that might be something versus if
it shows well you know it's helping
people and then for 10% of the folks it
goes off the rails you know helps helps
him commit suicide that might be another
problem and so um it's hard for me to
know without sort of seeing any data at
the same time there's this issue of well
do you really want to gather data if it
actually is harming people in their
process so it's a very complicated issue
uh I'd like to speak to some
psychologist psychiatrists and those in
mental health counseling field first um
but it is an interesting issue you
rais Congressman um want to talk a
little bit about how ionizing AI
regulations as you know the EU passed
the uh their AI act uh the US is working
on this China is doing their thing India
is doing their thing your thoughts uh
should there be some kind of
harmonization or we should all uh do our
own thing uh so to speak one of the
things that lawmakers do is we
plagiarize so what we'll do is we'll
look at what other jurisdictions have
done and if it works out well we might
copy it if it's a disaster we're not
going to copy it if it's something in
between we look at you know what worked
well and what did not and so I do think
uh it's um not a bad thing that Europe
went first and so I think we're going to
look at well how how is it turning out
and I think um it's something for the
world to watch and to learn
from uh Congressman we are now uh in the
tick of uh well we're going to be in the
tick of an election season France has
just announced its election UK India
just had the elections the there's a
conversation about deep fakes uh and
some of those things any uh thoughts
concerns is the Task Force looking at uh
some of these things for our elections
for our democracy we did we did have a
hearing on elections and deep fakes
there is a private sector initiative to
basically put watermarks on videos and
images and so on uh there was also
testimony at the hearing that that also
poses some technical challenges and you
know it could be haed so it's a
complicated issue I think it's hard for
Congress to pass any sweeping laws on
this issue before the elections which
are in five months I think the best
thing we can do at this point is to try
inoculate the American people and say
hey look there are things known as deep
fakes if you see a video on the internet
don't immediately believe it's true uh
take a pause and think about it and do
some double-checking if you see an image
uh that you think you know is sort of
out of whack or is troubling maybe it's
not true you might just want to do some
double-checking and if you see you know
something in your social media fee
that's particularly um uh explosive or
uh really uh out of the world two days
before the election you might just want
to pause and consider hey is that deep
fake and I think the best way is to let
people know there are deep fakes out
there and that you know the account
you're reading on Twitter or on Facebook
may be powered by AI rather than a human
being that's true that is true uh
Congressman just final uh quick uh
questions and then I know how busy you
are uh quick thoughts open source or
close Source your
views open source uh has helped Academia
and helped
um government as well and really help
Advance the field in Computing
technology as well as AI so I generally
support open source uh now if you get
really Advanced Frontier models and you
have open source models that basically
can tell people you know how to create
the next virus that's going to start a
pandemic um wouldn't have to think about
that and think about are there ways to
mitigate that
issue wonderful congressman thank you so
much uh this has been uh a fantastic
session there were so many other things
that I wanted to ask you I really uh
hope that we can have you back again on
behalf of our entire regulating AI team
really uh I want to thank you for taking
the time uh such a wealth of knowledge
that you have your commitment to
ensuring that AI technology is developed
and deployed responsibly is truly
commendable and to our listeners we hope
this conversation has shed light on the
complex challenges and opportunities
surrounding AI regulations so until next
time keep exploring and keep questioning
thank you so much Congressman this has
been
fantastic thank you sanj really
appreciate it
[Music]
