uh if I take um an example of U AI being
used for instance in recruiting um where
people apply for positions and if you
have an AI that um decides who will be
advanced in the recruiting process and
who will be denied the key aspects of AI
systems that make it particularly
challenging are one that um the kinds of
data that are used to train these
systems uh attack the AI in ways to get
it to produce outputs that it wasn't
designed to produce so how do you
balance Innovation versus
regulation welcome to the regulating AI
podcast join host Sanjay pury as he
explores the dynamic and developing
world of artificial intelligence
governance each episode features deep
Dives with global leaders at the
Forefront of regulating AI responsibly
tackling the challenges using AI can
bring about head-on and enabling balance
without hindering innovation
[Music]
welcome to the regulating AI podcast
artificial intelligence AI stands at the
Forefront of technological Revolution so
how do we regulate it without stifling
Innovation our podcast features insights
from various perspectives from industry
leaders to government officials to
advocacy groups and academics together
they address pivotal questions that are
needed to create fair and practical
legislation
today we are honored to have with us
Professor Ramaya Krishnan he's the dean
of Hines College of information systems
and public policy at the carnagi melan
University where he also directs a
university-wide center called The Block
Center for technology and Society he's
also the WW Cooper and Ruth of Cooper
professor of management science and
information systems he currently serves
on the national advisory committee to
the president and the White House and
he's a fellow of several prestigious
organizations including informs and
Trias thank you for joining us today
Professor Krishnan thank you Sanjay
thank you for the
opportunity wonderful uh Professor
Krishnan as I said we have a global
audience uh members of Congress uh
Senators Think Tank staff industry uh
they would be very interested to know
obviously uh your extensive background
given your EXT iive background in
Academia and policy what sparked your
interest in AI regulation and also I
want to let our listeners know before
you answer that you're speaking on
behalf of carnegi melan University and
not uh for anybody else so Professor uh
thank you Sanjay I you know um I've I've
been trained in uh engineering and
technology and as you know AI uh has
been around since the mid-50s in fact
kaniki melon is one of the birthplaces
of innovation in AI herb Simon was at
that dmouth meeting when they even jined
came up with that term um when I was a
PhD student was when I first got
introduced to uh artificial intelligence
so it a different generation of
artificial intelligence it was the
expert systems generation of artificial
intelligence when I was at the
University of Texas um and right from
then on uh I've been I've had an abiding
interest in thinking about the ways in
which uh artificial intelligence
optimization these different
methodologies how can they help make
consequential decision making uh be
better and over these years what's
happened is that um AI has become such a
major transformative technology going
far beyond the capabilities that existed
in the in the 0s when I was a graduate
student to where we are at today where
we see not only the traditional
predictive kinds of artificial
intelligence but you see the generative
uh approaches to artificial intelligence
and many tools that for the first time
have made AI available to the common lay
individual to actually engage and
interact with like the tools like Gemini
and and Chad GPT so when you have this
kind of transformative
technology uh along with that Innovation
comes great opportunity but also come
potential downsides and risks uh and so
this issue of governance issue of
Regulation um and what public policy
should be doing both to advance the pace
of Discovery uh and gender Innovation
but do so in a responsible way um began
early began in the mid 80s has continued
but then uh on on account of the
transformative role that AI is playing
uh is certainly something I'm uh you
know honored to be able to contribute to
uh the policy discussion that's uh
ongoing
today um you talked uh Professor just
now that uh you know it has great uh
potential great opportunities but also
has great risks um there have been all
kinds of polls studies done that the
general public is concerned so for our
audience in your view what do you see as
the biggest risk from artificial
intelligence that need to be regulated I
mean I I mean if I think
let me use one example of an opportunity
and one of a risk um for those members
of your audience that have that have
children uh you've probably seen KH
academy uh and the ways in which kids
learn uh using you know originally the
the videos from KH Academy KH Academy
has a new um service or product kigo
which basically combines the power of
generative artificial intelligence with
this learning content to actually help
kids at every level of the ability
distribution to become better Learners
to understand to be better writers
better understanding of History better
uh understanding of algebra my own kids
who are much older now used KH Academy
in the old version but if I see the uh
the power of AI for education and making
it accessible making it available both
to teachers as well as to individual
student students I think that's one of
the examples of the power and promise of
AI now but where is where are the
potential risks uh if I take um an
example of U AI being used for instance
in recruiting um where people apply for
positions and if you have an AI that um
decides who will be advanced in the
recruiting process and who will be
denied uh I think you're going to see uh
the potential risks that arise from uh
not having um an AI that is governed
properly imposing very significant costs
on the individual and Society especially
when something called a type two error
happens which is when an AI is used it
either can commit errors of omission or
commission that is it includes people
that should not have been included uh in
the interview process and that cost is
born by the firm but if it excludes
people that should have been included
that cost is Bor by the individual and
by Society so this is an example of uh
harm that is being caused and I can give
you example similarly in health in um in
in issues of uh law enforcement um so on
so forth but I think the examples all
illustrate the question of errors that
the AI could commit and who Bears the
cost of those errors and what harm is
caused and therefore when we think about
governance we need to ensure the guard
rails are put in place taking these
costs and harms into
overcome so um you made two points uh uh
Krishan one was the opportunity as you
just talked about Khan Academy and kigo
uh giving probably Equity education
equity for across anybody if you're a
kid in a rural area inner city area you
have now access in some some folks call
it personalized education personalized
tutor whatever you want to call it but
there is and some people are saying
there could be Health Equity potential
too but then uh and we'll come back to
that but then you also now talked about
variety of Risk by Omission or
commission that happened now we've had
many uh Regulators Congress members of
Congress ATC that come in what are some
of the key challenges in regulating a
you talked about the errors and of
omission and commission especially if
you want to keep uh fairness and equity
in mind so I and I think this is very
clearly a challenging exercise I think
the questions of how to measure evaluate
uh and monitor AI systems is uh still
very much a topic that requires research
that requires advancements in our
capability to better better understand
how to do this well just to lay that on
the table it's not like we know exactly
what to do and then it's only a matter
of figuring out how to put it to work um
so with that with that said I mean for
instance we have the nest having stood
up a AI safety Institute uh with very
much this in mind uh to have a public
private uh set of discussions where the
private sector the public sector
Academia Civil Society can all sort of
have discussions around what the issues
are that need to be addressed and the
key aspects of AI systems that make it
particularly challenging are one that um
the kinds of data that are used to train
these systems uh particularly we're
talking about uh AI by the way as you
know is a broad term in particular I'm
focusing on um these large machine
learning based systems um and those
systems are so dependent on the data
that go into them so issues of
understanding what went into the AI so
we I I think of this as nutrition labels
you know so when you when you buy a a
bottle of juice in a grocery store it
tells you you know all the stuff that
went what are the ingredients and it
also tells you how much sugar how much
protein how much fat Etc right uh and if
it's good for you so I think it would be
good to have the equivalent of nutrition
labels uh for AI and that's challenging
because today even the quote unquote
open access AI models from from meta
from Mistral from FAL from uh uh the
Technology Innovation Institute in Abu
Dhabi which are quote unquote the open
source um vendors um they don't tell you
what exactly are the data that their U
Foundation model or large language model
was trained on and of course open Ai and
G and Google and anthropic don't either
so we don't know they provide a a high
level description using what's called a
system card or a data card or a model
card but you don't have complete clear
data about what clear information about
what went into the AI and that's why you
have these lawsuits of the sort the way
have New York Times suing open AI uh and
we can delve into you know some of these
issues so issues of ownership issues of
Ip is the data biased or not is there um
are there concerns about adversarial
poisoning of the data to ensure that
that it will behave the way it is
supposed to and these are all data
related exercises that we need to have
an understanding of the second piece is
once you've trained the model how do we
know that the model will behave uh in
ways that um that will produce outputs
as expected the for instance again using
generative AI as an example we know that
it's a next token predict prediction
type of engine and it does so
probabilistically which means it's a
stochastic system that's why if you go
to one of these chat gpts or anthropic
in fact I did this with Claude 3 the
other day plot 3 is considered
state-ofthe-art I put my name in it
would be interesting to put your name in
and see what it produces and see if it's
accurate or not it gets many of the
larger themes right but it did have
errors so for instance it said my PhD
was from the University of Pittsburgh or
it had errors uh that were factual
errors so one kind of uh issue on the
output side is evaluating so how do we
evaluate an AI on multiple Dimensions
one of those Dimensions is you know is
it accurate another dimension is does it
produce toxic content another dimension
is is it biased or does stereotyping Etc
um so evaluating the outputs of an AI
and then going farther to ask the
question can
adversaries um attack the AI in ways to
get it to produce outputs that it wasn't
designed to produce so for instance
suppose I said can I tell me how to
build a bomb uh Chad GPT will say no
politely decline that request but as
work has been shown at kigi melon you
could actually create something called a
suffix attack that can effectively
provide that same prompt but then
produce a lot of um additional suffixes
after tell me how to build a palm which
actually can break the guard rail that
has been put in place and Chad GPT and
it's to be fair every one of the large
language models in fact this is a
systemic risk that exists across these
models will comply with a toxic request
so so this is now an issue of uh you
know is it safe with regard to uh the
guard rails that have been put in place
and then finally when you actually
deploy it and field test it with users
when errors are committed who Bears the
cost of those harms like I was telling
you earlier about the type one type two
errors so to summarize if you think of
three key phases how do we evaluate the
model intrinsically how do we know what
data went into it what outputs come out
of it how well does it do second can we
red team these models to understand how
well they perform in adversarial
conditions and then third we when we
field test the models um and apply them
uh get them to actually be used remember
most times AI models are not used in and
of themselves they are part of a system
so the harm that is caused is not caused
just by the model it's caused by the
system by which I mean it could be
people processes and AI models in place
so I'm giving you a sense for the
complexity of uh of evaluating them and
certifying them as being reliable and
safe that's why I think there's a lot
work that needs to be done it's not like
there hasn't been work there has been
but there is more that needs to be done
to build a science of uh measurement and
evaluation uh to ensure you you have uh
the capability to um assess safety and
reliability so Christian what you said
is there are three aspects one is the
data second is obviously you know the
measurement and third is where do you
assess the risk in terms of the de Vel
oper the Builder and the implementer and
those would be the three things um
couple of questions when are uh well
there were many uh when they knew you
were coming was one of the questions was
uh and this is really a member of uh
Congress kind of question
is how do you balance Innovation versus
regulation we want we are an innovation
economy and uh you know we are that's
the one question is how do you balance
that part and the second question
related to that that came for you was
that AI is a constantly evolving
technology look at what's just recently
happened Jensen Wong has now talked
about a new chip we've got multimodal
we've got agents you know and next week
there'll be something else you got Sora
Etc how does regulation
keep p with that so those are two one of
well there are many others but two that
I wanted they want to let me take them
sort of in in reverse order um so with
regard to the the three steps that I
laid out I think it's important to
recognize that so much of what we need
to do with AI is going to be in the
context of use that's why when I said
field testing of users uh what I do in
healthcare is very different from what I
want to do with recruiting very
different from what I want to do an
autonomous driving so context matters
right um and um with regard to um
keeping uh a pace with the rapid um the
idea is not to regulate
technology um per se because it it's
changing in in many cases like the
recruiting example that I gave you to
begin with OR the healthcare example AI
might be a means to an end so if you
regulate the outcome meaning if if you
think about something like the fa Credit
Reporting Act it's about giving people
loans uh or giving people credit and
there is an existing regulation pre AI
that that exist that might that type of
sectoral Regulation might be perfectly
reasonable in these
verticals uh where AI happens to be a
means to an end just because you're
using AI doesn't mean that that
particular context or use case or
application does not need to be um
overseen and governed and regulated it
will be uh AI just happens to be an
intervention that is used uh to decide
who gets a loan who doesn't get a loan
and you want to make sure that that is
done in a fair unbiased effective uh and
efficient manner so there are multiple
Dimensions to this so um so to your to
your question about um you know the
rapid pace of change um
indeed that's why it's not about saying
you know let's regulate the technology
per se but think about the context of
use now certainly the intrinsic
evaluation of the model step that first
step that I talked about um that will uh
take into account the nature of the
model the model and the technology
because how you evaluate uh a
multimodal um and multilingual uh AI
model uh is going to be different
especially if it takes for instance
pictures as prompts or audio as promps
or video as prompts versus just textual
prompts it's going to be different um
but nevertheless uh I think these three
steps that I laid out of Model EV
intrinsic model evaluation red teaming
and uh field testing keeping in mind
context matters uh I think is a is a
reasonable approach uh now with regard
to the B balancing Point uh of balancing
Innovation and regulation um I think um
at one level You could argue this is a
false dichotomy um that it's not as you
know if it's one or the other because
you could if you think about the
distinction between model development
and deployment and then what kinds of
due diligence can be done predeployment
and what needs to be in place post
deployment
it's a fair argument to make that if you
require um a level of due diligence that
prevents people from
deploying you know the balance if
anything is how much work do you need to
do predeployment and how much do you
have to do to recognize problems that
arise when you deploy both with regard
to incident reporting as in you know
these kinds of Errors happened
these let if at one level you could draw
a parallel with information security so
imagine a software vendor um creating a
piece of software um say let's say pick
um Microsoft Os or something like that
in before AI I went ahead and Rel I did
some software testing I did validation I
did um qual quality assurance and then I
release it so the testing and quality
assurance work that I do prior to
release is work I do pre-employment then
I go ahead and release it when I release
it I I I might find that there are bugs
that people encounter people discover uh
these have to be identified reported uh
and then I have to have a mechanism to
try and Patch them and push patches out
I might need mechanisms like the bug
Bounty program so that I can identify
bugs before they become broadly known to
malicious attackers that might use these
bugs to take advantage of them Etc right
so we have an existing model from cyber
security of what work needs to be done
predeployment and then what
infrastructure needs to be put in place
post deployment by infrastructure I mean
things like the CT the computer
emergency response team that basically
keeps track of these reported
vulnerabilities does forensic analysis
of them risk tiers these vulnerabilities
lets the Upstream software developers
know what the problems are so that they
can be fixed now let's take that and now
say what is the AI analogy of that okay
what I just described was for software
and cyber SEC is there an analogy now
some of it is analogous some of it is
different but as a as a structure or as
a framework I could imagine that you
want to do model evaluation and red
teeming and field testing prior to to uh
deployment but in some way tit rated or
calibrated to the risk tier of the AI
application that you're deploying in
other words if it's a a Netflix
recommendation
system if I recommend a wrong movie to
you not such a big deal it's not super
consequential but on the other hand I
could imagine that if it was a a healthc
care uh diagnos
application um that that's a much higher
bar um so the level of due diligence
that you need to do with regard to model
evaluation with regard to Red teaming
with regard to field testing and doing
impact analysis of harms that might be
caused because of errors in the AI like
in that recruiting example um that bar
and in fact the EU AI act actually
formalizes it by sort of saying you know
AI applications are have these tiers
that are the unacceptable tier the
highrisk tier the medium risk tier and
The Limited risk tier and for each of
these tiers um there is a level of um
obligation on the model developer to do
this due diligence now that said post
this due diligence I'm going to deploy
and then there is this issue of incident
reporting figuring out what the errors
and vulnerabilities are and how I might
need a
like an AI
CT um to actually keep track of what
these problems are that arise upon
deployment and try and assess them uh
risk tier them and then have the model
developers fix equivalent of patches for
them and in this in this close loop kind
of way we move to a safer more secure AI
ecosystem so um if we can do this I
think we also have in inovation
happening remember there two kinds of
innovation one kind of innovation is new
kind of models being created of the sort
that you mentioned you know there a SORA
then Gemini with a million token context
window Etc right but there's also
innovation in how to do measurement and
evaluation of AI models which that
Innovation might lead to an entire new
industry for certifying AI models so
much like the the with financial
statements
um when you had the generally accepted
accounting principles that created a
whole industry of auditing companies
right like the Deo and the pwcs ETC I
could imagine that there is innovation
happening and will need to happen in
measurement and evaluation of AI systems
how to monitor them at um at deployment
time at run time Etc and that I think is
going to be new capability that also is
a kind of Innovation that's why I'm
saying it's it's not regulation versus
uh Innovation I think the regulation
might require Innovation as well um
because of the needs of these kinds of
models I know it's been a long answer
but I hope that gives you a flavor yeah
uh for uh the set of issues that are
relevant no it does um I want to pick up
on two points uh that you mentioned one
is you mentioned the eui act very
briefly uh as you know Parliament just
approved it and in the next couple of
years you're going to see hopefully the
implementation what are your thoughts on
International collaboration for AI
regulation considering that AI is a a
global uh technology
Christian yeah and and and I think this
is without a doubt a really
important um uh question um both for
American firms that are going to uh do
business in Europe and uh this idea of
global
harmonization uh of um standards uh of
the approaches is is important now I
think might if I might take a moment to
say you mentioned that we are an
innovation oriented uh the US
indeed but if you think of what are the
three big drivers of policy um it's one
is the mark you know how do you promote
markets and Innovation the other is
human rights and the third is states
rights so you would argue that the US
typically has been a proponent of Market
Le Innovation model it's not that the US
doesn't care about human rights or
states rights it does but Innovation and
markets have been the primary driver um
and then on the the Europeans have been
a human rights focused uh policy regime
and going back to the GDP R for privacy
the Digital Services act the digital
markets act um you know dma DSA and gdpr
and then the Chinese have been more of a
states rights uh based model and as you
know they passed um um a directive on
generative AI in September of last year
actually even predating the EU AI act
right so if you think about these
different models um and what it then
means for um on the on the ground what
it might likely mean um it's interesting
to see at least in Europe and in several
parts of Asia I was in uh in various
parts of Asia late in December last year
and then I was in Davos and uh as well
as in other um uh locations in Europe
earlier this year um the AI risk
management framework that has been
created by Nest has found broad
acceptance nist of course is our
National Institute of SES and technology
so so think about that framework of how
to think about risk management in AI one
kind of harmonization that's happened is
this broad acceptance of uh AI RMF
that's the first thing the second is I
think there is Broad consensus around
this risk tiering type approach that the
that the Europeans have adopted which is
this
unacceptable um uh high risk medium risk
limited risk now countries May differ on
what they put in what bucket uh but by
and large there seems to be
um convergence around a risk steering
type of approach uh a third piece and I
think you'll see some version of the
Brussels kind of effect that happened
with gdpr uh as you know gdpr led to uh
what what happens in
California and then many firms pretty
much adopted because you know from a
cost of compliance perspective the EU
requires it requires you to comply with
the EU AI act as long as not only if you
do business in Europe but as long as
European EU citizens have the potential
to use your services uh you have to
comply so I think the the reach is Broad
and it's a large enough market that I
suspect that um the once rul making
happens right you're right to point out
what's passed as the act that it's going
to take 18 months uh or so for rule
making to happen but I suspect that that
rule making uh will have Broad
uh impact not only uh in Europe but also
in the US and and in Asia um much like
GDP uh had so I think you're going to
see harmonization come about in two ways
one is this AI RMF uh being um broadly
uh supported the second is the impact of
the AI act uh which by the way the
Europeans pulled back from an earlier
version to promote quote unquote more
room for Innovation that's itself an
interesting um move by the by the
Europeans and then the last point I'll
make is the emergence of I ISO standards
um so that's the third part of the
puzzle I the i42 iso 42,000 I think is a
family of Standards around AI so I think
the combination of those uh is likely
what is going to um what you're going to
see on the ground that firms are going
to start uh
complying with and building teams within
their organizations that understand U
these Technologies the last point I'll
make is that the AI safety Institute of
Nest has created something called a
crada which is uh a Consortium and
almost all the major tech companies but
also largely the downstream deployment
companies are part of that Consortium so
you're hearing all these voices um in
these consortia and I think through that
public private Consulting model that
nist has uh does so well you know the AI
RMF has wide adoption why because it
came out of a public private
consultation process so I think through
these efforts I think um that's I I
suspect that there will be bumps in the
road as there always are but I suspect
that this is going to be the large uh
framework so you're saying uh Christian
basically three the nist RMF uh eui Act
and the i e which will somewhere come
together in some shape or form to give
companies and others some standard and I
think you'll have that and then in the
markets that they operate the sectoral
regulation remember I talked about yeah
sector specific regulation that will
also you know whether are you doing
healthare AI are you doing you know that
will drive this too right uh one other
question that that uh came uh for you
Krishnan was that Washington Post
recently published an article that said
Silicon Valley is pricing academics out
of AI research Fifi Lee from Stanford is
pushing for the government to fund
research through the create act what are
your thoughts on this you are sitting
right in carnegi at the key point of
academics I mean um what are your
thoughts on this so I I I I think um um
you know Professor F Lee I think um uh
is right and I think the Washington Post
is right as well in the following sense
that um if you think about this
generation of Transformer architecture
driven Foundation models the big inputs
are uh very large amounts of
data very significant compute
resources um and then very talented
people right those are the three inputs
that go into and if you look at the five
or so major companies that uh have
developed the closed um large language
models they all happen to be us
companies in the main um though there
are some interesting startups that are
in the open source space that we can
talk about um but they all have the
resources to create these uh uh the
infrastructure the compute
infrastructure the data
infrastructure um to be able to build
these models so if you are a if you're
an academic at kanagi melon or at the
University of Texas or Stanford or MIT
um you don't have access to these GPU
clusters that that are required um and
so one of the things that was a
recommendation from our committee but
also from other uh committees has been
the establishment of What's called the N
uh the national AI research resource
um you know because if you think about
the reason for why the US has been at
the Forefront of innovation has been
that it has democratized Innovation
meaning that there's wide participation
in The Innovation process universities
are a key um uh element of that uh key
input into that process along with small
and mediumsized Enterprises now if the
barriers to Innovation are you need to
have you know um a very large
200 GPU cluster uh and that and the p
and the pricing of these things are
north of $100
million um then there are very few
universities that are in fact I know of
none that have the capacity to provide
the computer sources that say a meta or
uh a Google or an Amazon or a Microsoft
slop AI have right um so if you think
about um this uh situation that has come
about what happens is that
universities find that their very top
faculty May either be lost to Industry I
say lost because oftentimes they when
they go there they're not publishing
they're not uh if you look at even uh
the early work on Transformer
architectures vasan's paper 2017 was
published and has been transformative
but if you look at the more recent um uh
Innovations from open Ai and Google
they've stopped publishing it because
they see this as a big um competitive
race to win and therefore there isn't
the advancement of science universities
have historically played that role
because they had the capacity to publish
and had incentives to do so but because
they of these barriers and that's the
pricing out if you will um they are
unable to participate in the science
that's why most of the University
projects have been
open-source efforts that are focused
more on taking the foundation models and
then fine-tuning them to create um
Downstream applications versus the
foundation models itself um let me pause
there because there some there are some
interesting potential um developments
particularly with small language models
which are showing promise which might
change the equation that I just outlined
but the existing equation certainly is
one where unless you have very large
compute and data
resources um you're not able to do the
more foundational work uh that these
companies are able to support and I
think long run that's not good for the
us and not good for the the society or
the world short run you might say hey
these are all American firms it's good
for us yes but long run I think you want
a more democratized
process no yeah uh we had the uh
director of NSF uh Dr punch also and he
talked about how they are creating these
clusters AI clusters around the country
and you also talked about near um and I
think uh in that article they said
Stanford has I think like nine or
something gpus and meta is going to have
3500 gpus so how does a St I mean we
talking about Stanford or carneg how do
you kind of compete
taking what you just said on the open
source uh Krishan there is a debate uh
about open source closed Source people
say hey uh open source you know and uh
Mark Zuckerberg has said he's going to
well he's open sourcing CL U you know
llama 3 he's going to even open- Source
AGI to a certain extent there are people
who say it could get into the wrong
hands the weights and stuff like that
you your thoughts on this
so so so Sanjay one I just want to make
a quick Point um punch and NSF are doing
an amazing job with n I do think that I
would urge Congress um to fund NSF at a
much higher level um because I think
those resources are required to create
these digital public goods if you think
of near it's an example of a public good
it's a digital public good that we need
which is become going to be a key input
to allowing for greater participation
and engagement in this more democra
democratized process for um for AI uh
for AI Innovation that we've just talked
about now talking about open source um I
think the ntia which is a part of
Commerce actually has a an RFI uh on
open source models with uh with weights
um which is what you asking about um my
my own uh uh uh sense here speaking just
as as an individual as at Kani melon and
not wearing any policy hat um is that I
think net net uh open source um is going
to be uh a very
important um um piece of uh the pie so
to speak in terms of what we should be
doing um and if you think about open
source in general it's generated
trillion dollars of in Innovation and
value creation uh by
getting
um know this is a great example I mean
this it's a great phrase to use is
democratizing innovation what does that
mean right so what it means the capacity
for individuals small businesses others
to both take what has been created but
then contribute back and through that
crowd process uh Drive the quality of
the Innovation and you and you actually
are are seeing some amazing go go to
hugging phase and look at the
leaderboard uh and look at uh all the
different um open- Source models that
are out there including one from China
if you look at um uh
01 by the way it's led by Kaiu Lee who's
a Kani melan Alam um they are number two
or number three on the hugging phase
leaderboard um so I think um the the
Capac capacity to drive Innovation
through open source I think is on the on
the plus side question is are there
malicious uh uses of the technology at
one level you could say that for any
kind of Technology but the examples that
are often provided like somebody is able
to build a bomb or make uh um you know
get access to content about building a
bomb I mean the question there is would
they have been able to do so anyway with
what is already on the Internet is um
and is the big point of friction not um
collecting that information that a chat
bot gives you but actually getting
access to the physical materials the lab
in other words where is the friction
right so if you think about these
malicious aspects one aspect is what can
you do in the physical world with
information that you gain the other is
and perhaps this one uh is a is a point
of concern which is can somebody
maliciously launch cyber attacks can
they develop uh man manipulable
information that can manipulate
electorates during elections I mean
these are all very valid uh concerns um
and the and the question is can that be
done only with open source or can they
be done also with uh the existing um
models that are out there I mean for
instance deep fakes are constant are are
an example that are um uh referenc could
you do a deep fake uh with
Photoshop um I mean which is which
predates uh gen and Di and uh so it's
not the case that there aren't malicious
use cases please don't get me wrong I
it's not that I'm downplaying the
potential risks but taking both the
benefit side of the equation and the
cost side of the equation um I do think
that there is value in open- sourcing
these models and by having the of
weights made available it allows for a
level of fine-tuning and further
customization that would not be possible
if the weights were not made available
so that and um unless I see something
you know profoundly different uh that
would be where I I would that would be
where my position would be so the
benefits of Open Source outweigh uh
potential downside of that uh Krishnan
yeah um
Krishnan do we need a separate
regulatory body a lot of our guests come
in and say hey look at uh nuclear or
look at the FDA is there a need for a
body whether it's a global or something
to regulate AI in your very I've gone
back and forth on this to be honest uh I
can convince myself on some is that yes
it does and and one reason for why it
does and like these things right there
isn't a black or white answers like not
zero or one because there are you can at
the end of it I'll tell you what the
consensus of our members of con Congress
is but I won't give you the answer right
now please no no I think the the the
argument in in favor has been that by
having a single point of contact UM
there are issues of how do you resource
these this agency how do you attract
talent to this agency how do you get
intentionality and focus and then can
you have one organization in the US that
actually represents and can uh engage
with Global Partners um those are all on
the pro side um the the alternative
model would be do we already have uh
this
capability um except that it might be
distributed it might not be just in one
place and you want uh to have more of a
coordination uh model versus creating a
brand new um agency the these are sort
of and I'm laying out two Alternatives
that that might be in between uh in
between models and like I said I um yeah
I could go I could go back and and and
forth convincing myself on one day that
this is this is the better model versus
that's a better model so um I don't I
don't have a this is model to use and
here is why uh this is superior on all
counts kind of
answer well I we've had many guests who
come in and say yes we need we don't uh
the consensus I'll tell you for members
of Congress even the ones who want it is
it's very difficult in this current
political environment to create another
bureaucracy it's going to be almost uh
according well another in some cases
there a bureaucracy in some cases
whatever is it's going to be very very
difficult because lot of them say the
same thing we already have you know we
have the FDA we have the FTC we have the
Department of Justice on and on and on
we have the National Labor uh Relations
Board Etc so we'll see one other
question that came but sanj the quick
point on that is by having all of that I
agree that that was my point that you
have all of that but coordinating those
is a challenge as well and and who will
represent us as a single voice um in in
globally or internationally is also a
fair point yeah uh I I agree with you uh
I'm just telling you about the political
reality I don't deny that I don't yeah
uh the other question that has come in
uh for you Krishan is that there are a
lot of job displacement and societal
upheaval uh that are being talked about
whether you look at McKenzie you look at
IMF Etc you know numbers up to 60% or
30% or whatever these are massive
numbers you are working with students
and telling them hey go we're teaching
you go out into this
Workforce what is your message
given this are this is the question
given all this news that you're saying
what should we and what should the
government be doing from a regulatory
standpoint for something is there is the
government should be doing anything yeah
I I think there is work that the
government should do but uh here is my
point of view on this so the the study
that I'd like to use is the open AI
study that um was done by a colleague of
mine Daniel Rock um where they basically
say uh 80% of the jobs uh will have at
least 19 20% of their uh tasks impacted
or exposed to the AI and I'll come to
what what exposed means um and then
maybe 29 30% of the tasks have a much
larger proportion uh of their task
exposed to the AI right and I we could
go back and look at the exact numbers
but the argument is that uh that as AI
develops there could be a very
significant number of tasks that might
be exposed I think the question of does
exposure translate into job losses uh is
the fundamental question and nobody
knows um so my my view on this is that
we need considerable situational
awareness for individual leader for
leaders for policy makers for Business
Leaders to understand how this change is
what what is happening right with regard
to um is this
technology substituting is it
augmenting uh are new jobs being created
or new roles being created that didn't
exist previously I think there's a whole
collection of things that are likely
going to happen uh over the next 3 to 5
years and rather than speculate as to
what might happen I'd like for us to
build the situational awareness
capability so for instance having almost
an observatory that monitors uh job
postings that monitors um uh the kinds
of skills being demanded um so that we
have an understand understanding of what
the labor market how that is changing
right that is one the second piece is
that we need to help individuals some in
some jobs let me give you two examples
from in the past when the automated
teller machine came out everybody
predicted that that was the end of uh
tellers and Banks it turns out we have
more tellers today in Banks than we had
when the automated teller machine came
out however they don't do the same
debits and credits that the old uh
teller did so while they are called
tellers the skill set that they employ
is a very different skill set than the
debit credit uh work that they did
previously right so I think it's really
important to understand um how the skill
sets that are going to be required is
are going to evolve number one the other
counter example I'll give you is if you
remember in the old days driving on a
highway or a Tollway used to get a a
little ticket from a toll operator uh
when you entered and you gave the ticket
and you paid for the toll when you
exited Nobody Does that job is gone it's
completely substituted right so the
issue really is will the
technology evolve to a point where it's
only going to change it can do some of
the tasks associated with the job at the
level of reliability that the task
demands and if so does it then change
the nature of the occupation or the job
like the teller example or is it going
to be like the toll operator setting
where it displaces and substitutes that
substitution in the F in the other case
it was actually
transformation um so which of these will
happen well there are going to be some
jobs that are going to be substituted
without a doubt and so I think it
behooves the government to have
situational awareness as to who may be
affected and providing those individuals
with information about
what kinds of uh occupations are there
that are close and proximate to the
skills that they have what upskilling
and new training can they obtain how
might they actually get the resources
meaning money to pay for that upskilling
retra should there be like an individual
training account like an individual
retirement account um that we need to
provide people with and can we provide
individuals with knowledge of what
occupations they should be put
potentially seeking to get themselves
ready for I think that's work to be done
and much like with individual workers
being informed in this way and here I
think unions can play a role I think um
not for-profits can play a role
governments can play a role uh
universities community colleges you know
I think we need this Collective action
uh driven by data that's why situational
awareness comes in and we have a project
called the workforce supply chain
initiative at the Block Center that uh
that I lead that does this work to
support transitions because I think for
people who are affected we need to help
them transition from the occupation
they're in to occupations they could
potentially move to an interesting and
an open question is if you're 60 years
old um and you have this kind of impact
uh with regard to the occupation that
you're in where it's being entirely
substituted out what is the best thing
that the government can do for you um in
terms of upskilling you and training you
versus if you 25 because you have
another 40 years ahead of you versus you
have another um you know 10 years ahead
of you uh in terms of career that is so
I think there are some really
challenging and open questions for us as
a society that policy makers will
contend with that Business Leaders will
contend with and people like you and I
have to contend with uh as we think
about what the impact is but I don't
think it's a pat answer as in okay this
many jobs are going to be lost um I
don't think anybody knows I think
there's a lot of speculation therefore
I'd really like more Fast Response
capability uh to be built ahead of time
that is datadriven that can intervene as
changes happen rather than wait for the
change to happen like it did in the past
you know I'm I live in Pittsburgh we had
the steel industry uh uh you know go
away in the late 70s and there was a
humongous amount of pain uh that was
born by individuals um here if we know
what is coming and can at least use data
to drive that decision making can we
help workers uh who are likely going to
be impacted while being hopeful and
optimistic that there may be new jobs
created there may be new opportunities
that might be coming to the table as
well so that would be my uh my uh
response to your question those are
excellent points so you have situational
awareness that's very important we data
driven keep a track of what job losses
are happening what new jobs are being
created by Ai and the government you
know you talked about the you know the
toll person if a person's job gets
displaced the government should be ready
ahead of time in preparing uh them
whether working through unions and
Industry and others in doing that is
what you suggesting those are uh
excellent points because uh you know uh
it's not just economic you talked about
Pittsburgh and you know you go down to
Ohio and other places those are societal
impacts too it's when you you know lose
a job it has ripple effect a whole
family and an entire Society gets
impacted so we need to learn from the
changes the transitions that have
happened before and that's why bringing
those people early on in this
conversation and what we do in our
podcast Krishna is we are bringing in
people from manufacturing we are
bringing in people from community
colleges because they all need to have
that understanding
because as I said it should not be where
they say hey it's the two course that
make decisions and then they are the as
they call it the fly over people that
are there everybody flies over them and
nobody think of them but you've given
some great great recommendations
Krishnan I could go on and on and on uh
we'll need to have you back but final
comments for our listeners you've been
just fantastic I've taken you in so many
different directions but some final
comments for our listeners no thank you
again I think this has been a phenomenal
uh conversation thank you for such a
engaging um uh conversation and a set of
really important questions like you like
you noted um that and we covered ground
ranging from technology to um AI safety
all the way to Workforce um so I'm
really looking forward to uh coming back
and or and learning more about where um
how these changes come about and how we
might best work together um to help
Society thank you so much uh krisan this
has been really really uh great we've
gained some valuable insights into the
complexities of AI regulation and the
importance of fostering fairness and
equity in this rapidly evolving field
and your expertise and experiences have
been very very valuable so for our
guests please stay tuned for more
thought-provoking discussions on the
intersection of Technology policy and
Society thank you so much Krishan thank
you again the honor is entirely mine uh
have a good afternoon
[Music]
[Music]
