AI has made everything more complicated
you throw deep F into the mix right
where no it sounds like it's R your boss
calling you and you can actually have a
conversation with your boss it's really
solv like the boss is your boss and he
seems to know so much that surely it's
going to be him and then he tells you to
do something very stupid and your
company gets in
trouble welcome to the regulating AI
podcast join host Sanjay pury as he
explores the dynamic and developing
world of artificial intellig
governance each episode features deep
Dives with global leaders at the
Forefront of regulating AI responsibly
tackling the challenges using AI can
bring about head-on and enabling balance
without hindering
Innovation welcome to the regulating AI
podcast artificial intelligence AI
stands at the Forefront of technological
Revolution so how do we regulate it
without stifling Innovation our podcast
features insights from various
perspectives we've had industry leaders
to government officials to leaders of
advocacy groups and academics together
they address pivotal questions that are
needed to create a fair and practical
legislation for AI I'm very excited to
have Professor Norman Sade with us today
he's a professor of computer science at
the carnegi melon University and he's
also the co-founder and co-director of
the Privacy engineering program I
invited him on this show as it is very
important to get many different
perspectives towards framing AI
legislation and we needed to get a
perspective from an expert on privacy
and someone who's also been an
entrepreneur and a leading academic for
this transformative technology welcome
Norman it's an absolute pleasure to have
you on the regulating AI podcast well
really glad to be here thank you for
having me wonderful Norman uh can you
just uh give a brief background about
your uh experience with computer science
and uh at carnegi as well as what led
you to focus on privacy engineering for
our audience I will do my very best so
as you pointed out I'm a computer
Scientist by training and I've been a fa
with K melons for a long time at this
point a lot of my work over the years
has actually been in AI uh but I was
invited at some point in the late 90s to
work as a chief scientist of a new
initiative dealing with cyber security
and privacy and e-commerce and there I
was forced to expand my Horizon I found
it really interesting to learn about
those varas that was not very active at
the time and so when I came back to car
melon full time in uh in 2000 I decided
that uh ders secur and privacy were
going to be a big part of what I wanted
to work on so I've been active in this
space ever since uh I'm known among
other things for pioner ing the use of
AI technology in support of privacy
enhancing Technologies which when I
started was viewed as being potentially
crazy but I think over the years I've
shown that without AI it's actually very
hard to make privacy word because of the
usability challenges that you've got
nobody had the time to read privacy
policies nobody has the time to engage
with all the privacy setting are being
offered to them or required by
regulations and so if you don't have
some form of AI available to support
people in taking advantage of these of
these uh of these rights of this
information of these settings then they
will not be able to effectively take
advantage of them so that's certainly an
area that have been very active also
well known for having done a lot of work
on modeling people's privacy
expectations and processes developing
what we refer to as privacy assistant
technology answer privacy questions that
people might have developing technology
also to nudge people more attention to
privacy decisions that they have to make
and get them to engage with those cities
that otherwise they might be tempted to
ignore because privacy tends to be uh
something that people are confronted
with in a context where their priorities
are entirely different tasks like
downloading a mobile app on their phone
or trying to uh meet a quarterly uh
quota if they're salese or what have you
so those are some of things that I've
done and um as you pointed out a dozen
years ago through conversations with
industry uh we're very interested in the
work that we're doing in privacy uh we
decided PR to start uh what was and uh
what was the first program in privacy
engineering recognizing the fact that it
was a very big need for people who
didn't just understand privacy but also
understood technology people could
really serve as a link between the
sofware engineering side of the world
and the legal side of the world and all
sorts of other roles within the
organization that need to be involved if
you want to make privacy a reality as
you develop as you design develop and
and uh and deploy our products and so
this this program has been running now
for over 10 years uh I think it's viewed
as the gold standard in the space and uh
uh we we're now also offering a cant
program in this area so those are some
of things that I'm doing and obviously
most recently uh with the popularity of
AI we've been looking more and more at
well how do we teach governance to all
these PR Engineers because that's
something that they will be asked to
work on uh many companies have come to
realize that those privacy Engineers are
probably among the very best people to
Le some of these AI governance efforts
that many companies now have initiated
because they understand many of the
different aspects that are required
you're going to make this happen so
that's also very much something that we
teach for instance I'm teaching right
now this semester a new course on a
governance that's uh uh very popular not
just among our privacy engineering
students but actually we have phds in
robotics taking the course as well as
students from our business school so
it's a lot of fun to have such a diverse
group of students in the same class
working together with them obviously
working with industry also on those
types of problems that's not sure what I
do these days and that may have been a
longer answer any youly I'm not sure oh
well that's very very helpful Norman
because what you're telling our audience
um and as I said it's a very diverse
audience that when it comes to
implementation of AI it's not just
machine learning deep learning and bits
and bites and data
Sciences uh and this is for our industry
leaders also there is this aspect of
privacy and there is this aspect of
governance for companies who are going
to implement it who uh do not want to be
in a situation where there's legal and
other ramifications you're saying a lot
of factors kind of go into it right
Norman that's correct and uh it's really
about bringing all the right actors into
these prophecies uh that's that's the
key to success if you just read our
legal you m up with expectations that
are unrealistic and that may not even
find their way into the actual software
that you're going to develop and you
know you just with software Engineers
you're going to end up with things that
are ignoring most critical issues and so
at the end of the day what a European I
see what European eii governance uh you
need to have OB legal compliance risk
management you need to have the eii
engineers the machine learning Engineers
but you need to also have the software
Engineers the software Architects you
need to have the uxui designers the
security Engineers the product managers
obviously so there's a number of
different roles and uh when we talk
about AI governance or when we talk
about data governance in a privacy
context we are talking about processes
uh and obviously organization structures
and roles and workflows that are
intended to orchestrate all these
different troles as they need be brought
into these processes so that you assure
that all these different perspectives
have be brought have been brought to
bear and have been taken to C in the
design the deployment of of these
products and continue to remain involved
after you deploy the product so all
these governance processes we've seen
this in privacy in the context of what
people refer today as data governance
which s this in security by the way as
well so the security governance data
governance thei governance needs this
these processes are actually extremely
close and have to be viewed uh you know
as processes that need to be integrating
none of those processes should be
thought about as you know existing in a
vacuum when a company thinks to do about
the governance they've got to think
about how do I integrate those issues
into my existing processes is into my
existing organizational structures how
do I ensure that I document all these
things as I you know basically extends
the types of activities and the set of
considerations that I'm thinking about
as I develop these new products uh as I
design these new products develop them
and and deploy them eventually F them
out here so for our listeners many of
them happen to be Chief AI officers a
interdisciplinary approach is what Dr
Professor Norman is suggesting has given
us a fantastic overview of the many many
different disciplines that really need
to be brought to uh thank you uh
professor professor as AI continues to
evolve what do you see as some of the
biggest privacy challenges we face oh
they they're huge right and uh even with
thei privacy is far from being easy uh
privacy de governing uh so you know
there are regulations that were
introduced start years ago gdpr for
instance in Europe has had a big impact
not just in Europe but worldwide and
you've got so many companies that still
struggle today in terms of making sure
that what they're doing their products
their services their business processes
are in fact compliant with these
regulations and obviously AI adds a
completely new layer of complexity on
top of that uh why there are many
different facets to this there is a
cultural shock right so as someone who
studied AI way back when in machine
learning and has actually worked in this
space for many years I canest to the
fact that for many many years and in in
fact even still today data if you're a
machine learning person is viewed as an
asset and for good reasons so the more
data you can collect the better you feel
about yourself proba say is all about
data minimization it's about looking at
data as B liability liability because if
something goes wrong with that data and
you are not necessarily supposed to B
down to that data you're going to get in
a much in much bigger trouble then if
you had said well I no longer need this
data I'm going to dispose of it I'm
going to delete it and so that's already
a culture Clash I know obviously uh when
you look at privacy you've got uh the
idea that basically present in many
regulations around the world not just
gdpr but you look at regulations in
California and elsewhere around the
country
and in other countries as well there is
the idea that if you're going to be
collecting data you've got to specify
the purpose which you're going to be
collecting that data right so
historically we've had people especially
here in the US whose job has been to
collect as much data as possible you've
got data Brokers and uh most of the data
they've collected was collected in a
framework that we have extremely loose
in terms of purpose for which most of
the time dat are might have been
collected for one purpose and then
somehow it was recycled and sold to
various entities for entirely different
purposes and so all that has to be
brought under control regulations like
the Privacy regulation we have today are
aiming to do that in an context it's
even more challenging because now we're
talking about basically training
foundational model using you know data
that's coming from a variety of
different sources what do we know about
that that data what do we know about the
conditions under which this data were
acquired do we even have the right to
use this data do we you know even if we
were to go back to People Who provided
us with this data or would we go about
you know specifying the par purpose for
which this data is going to be used
given the fact that these foundational
models are in principle being made
available to support applications across
such a broad of of of of domains so
those are examples of challenges
obviously you know deep figes uh and all
these other uh you know uh issues that
make the headlines are making obiously
privacy an even bigger challenge within
that context as well so you've got all
sorts of different uh issues you've got
the the notion that comes from privacy
actually that under gdpr dig General
data protection regulation coming from
Europe you have a right to object to
automated decisions you have the right
to say when the decision was made you
know by Ani algorithm or some other
algorithm I'm not quite satisfied that
this was done properly I would like a
human being to review this data and make
a decision manually and obviously one of
the big strengths and the pry of AI is
that we can automate so many of these
decisions right is going to allow people
to ask systematically uh you know to
have their decisions be reviewed what
does that mean you know can we do this
at scale how do we support that so all
sorts of challenges and I'm going to
stop here but I could go on as you can
tell Norman you pointed out that data
can most people think of data as an
asset data can be a liability with all
these data Brokers uh that are going on
um and then you talked about some of
these uh legislations like gdpr and CCPA
do you think we need new privacy
regulations for AI or you think we can
tweak existing regulations like gdpr and
the CCP the California act what is your
view on that nor well I I think there's
certainly a need to regulate AI right
your question is obviously in the col so
is gdpr enough or do we need
more there are clearly some PR issues
that were not fully anticipated in gdpr
gdpr is was a great step in the right
direction so is CCPA and California and
other regulations uh there's always uh
an interesting there's a fine line that
you have to work as you start regulating
and and Europeans have been willing to
go a bit farther than than for instance
people here in the US where we've tended
to be perhaps a little too cautious
dealing with regulation uh and so I am
absolutely convinced that there are some
areas where we want to go beyond GPR
when it comes to privacy I think there's
also a part as I've mentioned earlier
where all these government issues really
start coming together and so it's no
longer is this a privacy issue is this
an AI issue uh at the end of the day
both of those uh areas of governance if
you will are driven by ethical
considerations right considerations of
fairness agency right uh and
transparency and so on so uh for
instance transparency is a very big deal
in pris we've got pricey policy that no
one reads right but uh you know you take
transparency to the next level and now
it's about being able to understand
machine learning models so it's about uh
explainability and interpretability and
and so on and so is that falling under
privacy is that falling under AI it's
clear that some amount of that is
already included in a regulation like
gdpr but at the same time gdpr was not
really fully appreciating I believe the
challenges that we fac with today and so
we're seeing some of those challenges
now being captured in the form of the
new regulation that's going to be coming
out of Europe very soon which is the EU
AI act where there are additional
requirements when it comes to
transparency and obviously the Europe is
is trying to sort of build on its
success uh with gdpr is saying well
we're going to continue taking the vi in
this space and and you can tell that
even when it comes to privacy and maybe
not but privacy maybe it's just all
these ethical configurations that
probably the better way to think about
this but clearly the the new
requirements are being produced
requirements are also being further
clarified so there's a ton of very
aspirational uh elements to these rules
and regulations including gdpr right as
I said gdpr was passed in May of of what
became came into force in of 2018 we're
still less wondering how to interpret
some elements of gdpr and this will most
likely continue to evolve over time it's
all about best practices so the same
step we can do today were not the that
we're able to do five years ago and the
things that we might be able to do five
years from now thanks to new privacy
enhancing Technologies for instance
maybe things that today seem to be
farfetched so there are new technologies
becoming available homomorphic
encryption obviously differential
privacy these technologies have gained
interuption and immaturity over the past
years and our most that they going to
continue are becoming more mature and uh
there will also be packaged in a way
that it's easier to expect would be
easier to expect a variety of companies
to start using these Technologies while
today perhaps only the most mature and
most advanced able to do so so yes I
expect to see things evolving over time
that's going to be reflected I believe
in regulations as well as
interpretations of these regulations so
there will be some tweaking whether it's
a UA I act the gdpr and also What
legislation if any uh happens here in
the US we're in an election here uh
Norman uh when we talk about privacy uh
and its implications and average well
most people would say facial recognition
technology is probably one of the prime
example of AI with privacy implications
what are your thoughts on regulating its
development and use so I I I believe
that there's clearly Ru for some
regulation in this space you don't want
to over regulate I mean these are
extremely powerful
Technologies um and U you know as as a
as an aside we've done a lot of research
to understand how people feel about
deployment of of these Technologies so
one experiment that we ran it took us a
very very long time to be able to do
this but we when we talk about facial
recognition uh we tend to bundle a bunch
of different things obviously there's
recogn in someone uh but there's also
the fact that computer vision algorithms
today can recognize a lot more than who
that person is including facial
expressions being able to make
inferences about whether someone might
be depressed or not whether they're
healthy or not how obviously how excited
they are when they look at a product
marketers obviously love those kind of
things there's the ability to see uh you
know what you're doing there's the
ability to to just Eng do many different
things and we'll continue to innovate in
that space and so uh we spent uh um a
lot of efforts right to understand how
people felt about all these different
scenarios uh we've actually published a
paper that actually got an award for on
public policy in that space showing that
uh people's perception of this
Technologies is very diverse uh and the
technologies that interestingly
you hear the most about today are the
technologies that at least in our study
uh people showed uh I wouldn't say the
greatest level of Comer because that
would be that that would be going
entirely in the wrong direction but they
were the least concerned about on a
scale of also other scenarios so
surveillance many people have run
accustom to the IDE that there's
probably some surveillance that place
there and then when I'm saying most
people I mean probably 60% people right
so there's still 40% of people who are
not super super comfortable with that
when you start talking about using this
technology to uh measure the
productivity of people at work or to
make Health predictions about people or
to make some additional
differences people are feeling a lot
less comfortable about those scenarios
so there's a whole range of scenarios to
be considered it's clear the fact that
different people have different
perspectives and depending on how you
phrase your questions you're going to
get very different answers if you phrase
a question without surveillance and you
make it sound like without this
surveillance are people Security will be
at risk you're going to get a lot of
people think we should deploy this
technology I would like to be safe on
the other hand if you you know emphasize
the creepy side of these Technologies
it's going to get very
different so IDE I think a good part of
this has to do with narrowing down the
purpose for which these Technologies are
being deployed being very transparent
about these things they're clearly
Secret
scenarios right when when you when you
clear you know immigration com here you
know through the airport and the F you
probably want that technology it's
probably there to protect us but hey
quickly right you're going to get on a
slippery slow where all of the sudden
these Technologies might be used other
purposes and right now there's very
little in terms of ability to
effectively communicate with some so you
might notice a camera MH might even
notice a sign that says this area is
under camera surveillance but that
doesn't tell you whether this is using
facial recognition or not doesn't tell
you what this that might be shared with
doesn't it's only for your security or
whether that data might be recycled and
then sold to other people for other
purposes but so there's going to be a
need I think to be uh you know much
clearer about what's going on giving
people the ability to you know access
this information at some level not that
you would want to read every every sign
and you know every camera that you pass
in front of this is by the way one
reason why I believe there's a need for
AI but in my in my mind and I've
developed this technology it's actually
deployed today in my mind what you need
is a little app on your phone right that
discovers all these things around you
and those new preferences and in terms
of what you would want to be alerted
about scenarios that perhaps you would
not be expecting scenarios that you find
you know uh you know that you're
uncomfortable with and perhaps even
communicate propy propenes to M have so
that you op out to obtain those
scenarios that you might potentially
feel comfortable with that has to best
be done in the background most of the
time there is no way we can steale this
or human brains just don't have the
ability to keep up with the number of
cameras that are that are you know out
there and the fact that these cameras
may be needed for a variative scenario
dealing with security but they also supp
scenarios of people are feeling lot less
comfortable and they would really like
to have some agency as some ability to
control these scenarios I think there's
a need for more more regulation within
that space so what you're saying is the
nus is uh we need Clarity on people will
give different answers based on the
newus whether it's for health purposes
for the security purposes uh we need to
get the public engaged in this process
uh Norman is what you're saying uh and
some of it is for our own good important
to understand that all these ethical
issues that we're talking about they you
can come up with the nicest possible
definition this has to be grounded in h
will feel right Notions of fairness you
know Notions of privacy all these these
principles are fundamentally grounded in
the way we feel as individuals and asy
right that really key and so you know
one the nice things that I see for
instance in in the
N Management framework and other
Frameworks that are emerging is you know
this recognition that we need involve
all the stakeholders we need to
understand how they feel about this
right and you know that's somewhat
aspirational today no question but
ultimately that's what we need to aim
that's what we need to aim and I didn't
mean too you no no but that's an
important point that we need to get all
the
stakeholders uh involved uh Norman
speaking of uh stakeholders how can uh
the policy makers were trying to frame
legislation how do they strike a balance
normal between fostering Innovation that
keeps us safe uh produces revolutionary
medicine um and also protects
individuals privacy rights in uh AI well
I I wish I had the final answer to that
question uh so I think what we're saying
here is is a number of efforts are going
in the right direction uh recognizing
the fact that there's probably no way of
ever doing this perfectly uh I like the
fact that you know there is uh at least
you
a good amount of recognition for the
need of for AI governance right uh I
like the fact that there are some
regulations that are coming out in some
places faster than than in others um I
you know there are clearly some car outs
for small organizations even the EU AI
act right has some special provision to
deal with startups and ensure that uh
there there that these new regulations
don't H Innovation too much
ideally will or not is still TBD there's
no question that governance favors the
larger more mature organizations because
to put these processes in place is
extremely demanding uh one of the things
that n does if you look at their AI risk
management framework is they've
introduced this notion of profile which
is basically the idea that you know
we're going to expect you to try to do
this but we also recognize by the
different organizations might have
different levels of resources available
to them if have levels of
sophistication and um and uh you know
please try to your best and and uh and
you know as you mature you know try to
keep on raising the bar I think there's
you know that element to this um there's
going to be a need
for for for um it's never going to be
the case that the laws are going to do a
perfect job right and so if you regulate
too hard then you constrain people too
much you're going to lose a t in terms
natural for Innovation and so at the end
of the day organizations will have to
take responsibility for they're doing
and they're going to have to look at
these Frameworks like the N Management
framework which have to through for
improvement still today and and at this
knows that they're working very hard at
this uh and they're going to have to ask
themselves you know how good of a job am
I doing and what are potential defs that
I might be missing where should I put
more effort what are the worst case
scenarios I should really make sure I V
is this functionality really needed
would I po actually drop it because
there's just you know this huge kind of
forms that I'm opening if I start going
down this path um regulations will not
solve problems and will not give answers
to companies on on every question that
they're going to run into and so there
will always be need for organizations
that take responsibility for they're
doing and think a little beyond what
these regulations require because these
regulations even if they look are very
ominous to some uh there's still
extremely look and turns out so
organizations also need to take
responsibility it's can't just be
regulations because that can't cover
everything um that leads me to ask you
there's a growing debate around data
ownership in the in context of AI what's
your perspective on this issue um nor
well I ideally uh you know you own you
own your data right and idea you know
that uh you know you have control over
how that data can be used and uh and
perhaps your some right to be
compensated for the way that data can be
used that that's a nice principle uh you
know what does it take to implement that
in practice how realistic is that uh
there will be limits to how far we can
go so there will be a need to reconcile
you know those ideas with you know
practical considerations I think and and
where you know how we do that exactly
I'm not completely sure that that's uh I
think one topic is you part it out uh
there are you know a number of
interesting perspectives to to to be
taken into account and I'm not in a
position right now to make a uh you know
a a a specific suggestion I think we'll
have to see how you know again bringing
all the the productors the different
perspectives we have to see where we
land on that but it's a certainly an
interesting question we talked to a
little bit about uh you know
globalization and in terms of AI should
regulations apply to AI globally or
should they be tailored regionally we've
talked about the EU UK safety China is
doing its own thing the US is doing
things what are your thoughts on that
well obviously right uh these are Global
issues um and um you know ideally would
Converge on some you know uh Global
framework at some level whether we can
do that or not uh I think people will
generally agree on the high level
principles but the devil's in the
details right expecting people to agree
on this in the context of AI I would not
be super optimistic if you look at the
state of privacy right everybody agrees
on on on the high level principles and
at the same time we have a very
fragmented landscape in terms of all the
laws that you find in different
countries and so are expecting people to
converge tomorrow on on common
regulation
that would be fantastic because it would
certainly make it easier for companies
and innovators they would not have to
look at you know tens and tens of
different laws that might actually apply
uh so that what going be an ideal or
situation short of doing that it's
extremely important to recognize the
fact that in AI in software there a huge
relies on third party software and third
party data and short of having you know
regulations that apply everywhere we
going to have to make sure that we
review right the the the the software
that we use the library that we use the
data that we use and that uh you know we
move into a framework where there more
and more documentation about the context
within which that data was collected the
type of conern that was obtained the the
the guarantee that were offered and uh
you want to make sure that you're only
ingesting and consuming data and using
libraries that are consistent with you
know your own commitment to customers
that's only you know a principle that's
part for instance of the general data
protection regulation in your when you
as a data controller which is you know
the entity that takes responsibility for
collecting your data as you take you
know some uh as you collect some data as
you process some data you take
responsibility for everything that
happens Upstream in your in your in your
value chain or Downstream in your value
chain and uh I think the same will have
to apply so there will be a need for
standards at least to document those
things there will be a need for
taxonomies right what taxonomies of
purposes right that that's a very simple
what taxonomies of data taxonomy the the
kind of things that you can do for how
long you can retain that data at what
level that data has to be stored and
those these types of things that has to
be extended to AI as well and so I think
that that's some an area where perhaps
there could be some agreements
internationally you know even if at the
end of the day the laws are different in
different count could agree on some
common standards at that level I think
that would be tremendous and that's
would already be progress so agree on
some common standards uh uh Norman
Norman just you know as far as nuclear
weapons are concerned there's a separate
body that exists you could even say for
Health Care medicines you have FTA do
you think there should be a specialized
regulatory body dedicated to seeing
overseeing AI development and deployment
are you you're talking here from a
military standpoint no I'm talking just
uh think of you have FDA overseeing the
approval of
medicines um I think a government agency
should there be a regulatory separate
government agency to oversee the
development and deployment especially of
large language models or some of these
things like ATI so this is certainly the
path that Europe is taking with the eui
ACT right they've got this risk-based
classification falling in a high risk
category there's an expectation and even
you know some those slightly lower risk
categories there's an expectation that
you're going to file some data and
you're going to do some assessments uh
with with regulatory agencies um so um
it would probably make sense u mean
there are different ways of doing this I
mean you could say that you know
organizations have to conduct these
things and if they get audited they've
got to be able to show that they they've
got the processes or you could actually
force them to submit these things
there's suddenly you know an issue of
you know being able to make sure that
they didn't do the auditing after they
got in
trouble but you know you've got uh you
know uh electrical electronic
certificates and things of that nature
that could easily be generated to prove
those things without necessarily
submitting them to agencies um so
I think could go either way probably and
make it
work here I think we need to make sure
that organizations have to document the
processes that they've gone through as
they designed develop and deploy these
AI products uh that's the key from our
perspective if they've got questions it
would be good for them I think you have
someone that they could go to and say
you know this is what we've done we're
not entirely sure can you confirm that
we're okay you know that that would be
nice perhaps from the perspective
organization the question is you know
what incentive does the agency at the
other end I have to say yes rather than
always saying no and that uh you know
that's an interesting game and I'm not
sure that I know exactly you know what
the the correct balance is here but
certainly a governance is about forcing
organizations to document their
processes and to be able to show that
they were documenting this that they
thought carefully about each one of
these issues
uh and and that's that's really actually
where we are right now in our fing so
regulations requiring that documentation
are not bad I believe um regulations
perhaps in the case of the most
sensitive systems to that that require
you to have these Ved at some level or
to show that at least you've got through
a battery of tests right you reported
the results that would be very good and
then perhaps you know having an arable
process when agency is supposed to
collect this information and
occasionally you know do some spot
checking there have a question as to you
know obviously resources that are
available to do these things uh look to
do at regulation in the C pracy
Regulators don't have the resources to
do this that scale right so it's going
to be spot checking initially and
perhaps one day we'll have tools to to
make process and the government will
check your AI model will give you stop
of approval and you'll be all clear but
I'm not sure that I see that happening
anytime soon we don't know yet but maybe
there could be some standards and
governance stuff um Norman just to uh
shift very briefly to cyber security you
obviously spent a lot of time uh even as
an entrepreneur in that how is the
landscape of cyber security evolved with
the integration of AI Technologies for
our users to know AI has made everything
more difficult uh right so uh you you
you you mentioned my company one sec
technology we uh you know uh basically
develop what ended up being the defa to
sty today for training people not to
fall for fishing attacks and sending
them fake fishing email and and then if
they fell for those emails they would
say hey this is what you should have
seen you know please take this training
it's going to help you do a better job
next time and uh you know why am I
talking about that because when you look
at security today with or without AI uh
at the end of the day 90 to 95% of all
the secur incidents can be traced back
to you not making the right decision uh
and often this is actually the formal do
fishing email so the headlines keep on
changing today it's all about PR
someware and this and that at the end of
the day that PR someware got there
because someone clicked on the link in a
fishing email and so what happens with
AI is that we've got the ability to know
ultimate those attacks at at a scale
that we're never able to to to to reach
before and but what I mean by automate
is not just sending a bunch of emails
but personalizing those emails or you
know basically tailoring the text that
you use in those emails according to a
number of different factors and doing
this at scale so this is terrified right
uh and and uh and you know doesn't
matter how much you train people I mean
you can significantly reduce the chance
that people for for these things but his
email are becoming increasingly
sophisticated and uh and it's at AR race
and so AI has made everything more
complicated you throw deep things face
into the mix right where no it sounds
like it's really your boss calling you
and and you can actually have a
conversation with your boss it's really
sound like the voice is your boss and he
seems to know so much that surely it's
going to be him and then he tells you to
do something very stupid and your
company gets in trouble those scenarios
are you know very real uh these things
have actually already occurred as far as
I know and we're lucky to see more of
them so it's a it's it's a world where
it's going to be extremely difficult for
us to operate we're going to have to
raise the bar in terms of training for
everyone the Technologies can only go so
far are detecting deep takes I mean
we've seen progress in that area but
hoping that you're going to be able to
do that perfectly in illusion there will
always be another level that the bad
guys will be able to to aim for and that
will defeat whatever you know defense
people have come up with up to that
point in time the deputy National
Security adviser for cyber and newberger
she said basically that cyber security
she sees a lot of promise and a lot of
peril uh on both sides um which is kind
of what you are also talking about
Norman and obviously we live in a world
where um you know people have many
different access abilities that kind of
leads me to this question um Norman that
what do you think of open sourcing of uh
some of these large like language models
like uh companies like meta and mistr
and others have done it does give uh in
some cases theyve even disclosed the
weights Etc it does give people maybe
who are not friendly to us in some ways
or some individuals who have you know
not the best intentions access to these
Technologies uh but people say it's also
leads to a lot of innovation you are in
academic area so your thoughts on that
not well as as a security person right
uh security through obscurity is
generally
frontal uh and so in in general the
general wisdom in this space uh is that
openness is better uh may want to
combine that with balti programs for
people to report issues that they see
it's clear that the bad guys right or
adversaries you know from National
Security perspective organ organized
crime you know at the other end of the
spectrum or sometime it's the same it's
it's you know sometimes it's all the
same it's clear that they'll be able to
take advantage of that you know when we
talk about AI governance and we're
talking about submitting foundational
models to you know a battery of tests
and and and
requirements uh this doesn't mean that
the bad guys cannot develop their own
foundational models and then basically
uh publish them on or offer them as
services in the dark web uh this will
clearly happen uh and uh uh nevertheless
I think that uh
transparency right and Security will be
better served if we move towards more
open systems keeping in mind you know
commercial considerations so you know
perhaps disclosing all the weights it's
not something that everybody can afford
to do uh and I I am not entirely sure
what the right solution is there but
certainly a good amount of openness
tends historically to be beneficial from
a situation standpoint enabling everyone
including you know random PhD students
who got nothing else to do one evening
to look at these thing and say h I found
something really funny here and have a
mechanisms to which they can report
these things and uh that definitely
increase the chance that um you know
we're going to be able to address those
issues while they're found so more uh
towards openness U for Innovation for
transparency uh Norman uh being
respectful of your time I mean we we
need to bring you back
again because there's so many other
topics I wanted to uh talk to you about
but uh you know thank you for sharing
your V was expertise with us today is
there anything else you'd like to tell
our audience you know as I've told you
it's a global audience some points as
lawmakers work towards regulating it uh
think tanks Etc if you can share a last
few words for our audience nor well I
think you an exciting time to be working
in this space uh there are no guarantees
uh I mean technology has obviously been
a driver of economic growth for the past
few decades it will continue I believe
to to to be a major driver for economic
growth but at the same time it's
important that we as a society and as
individuals be mindful of the potential
perils and try to set up uh you know
guard rails and mechanisms to ensure
that U as many of the worst case
scenarios are less likely to materialize
so basically innovate responsibility
Seas thought opportunities but be
careful of the Guard Wills thank you
Norman that's uh very very helpful and
very very informative for our members
your vast experience we'd love to uh
bring you back uh thank you for taking
the time than PK you for having
me thanks for tuning in to the
regulating AI innovate responsibly
podcast you'll find links in the show
notes to any resources mentioned on the
show if you're enjoying our podcast
please subscribe so you'll never miss an
episode and leave us a five-star review
okay
