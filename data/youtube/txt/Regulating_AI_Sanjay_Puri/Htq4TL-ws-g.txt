It's very important to us to uh
consolidate to build in a normative
national international level a kind of
constitutional digital pact for the
artificial intelligence era age. It is
so important this this fundament this
new fundamental right because uh if we
forgot the relevance of of this
fundamental right we can convert the
rule of law into a rule of algorithm and
that can't happen there is a false
dilemma between regulating and
innovation I don't think I I can't see
things that way I think that uh uh we
must innovate but never innovate
that when that cost is fundamental
rights.
>> Welcome to the regulating AI podcast.
Join host Sanjay Pury as he explores the
dynamic and developing world of
artificial intelligence governance. Each
episode features deep dives with global
leaders at the forefront of regulating
AI responsibly, tackling the challenges
using AI can bring about head-on and
enabling balance without hindering
innovation.
[Music]
Welcome to regulating AI, the podcast
that brings together global diverse
voices to shape fair and responsible AI
regulation worldwide. I am your host and
today we have a fantastic guest. A guest
that we met at the AI for good summit in
Geneva a week and a half ago and we had
to have a conversation with her u
because she's got some amazing things to
talk to us about and that person that
I'm talking about is professor Raquel
Rida Castro. She's a distinguished
constitutional law scholar and vice
president of ANCOM which is Portugal's
national communications authority.
Uh Rquel brings a unique perspective to
our discussion combining deep
constitutional expertise with practical
regulatory experience. She holds a PhD
in law from the faculty of law at the
University of Lisbon where she also
serves as an assistant professor and
leads courses on constitutional justice
and law
and she has a unique background which
combines journalism, academia and
regulation that provides her with really
invaluable insights into how AI
governance intersects with fundamental
rights, democratic processes and media
freedom. Raquel, welcome to the
regulating AI podcast.
>> Hi, what a magnificent introduction did
you make?
>> Thank you so much.
>> Wow. Much deserved. I actually uh for
our listeners uh you shrunk it down to
maybe 10% of what really is her very
distinguished career. Raquel, we have a
global audience. uh this is an audience
of policy leaders uh you know members of
Congress and ministers their staff uh
entrepreneurs and others
so uh from their perspective
uh we want to talk uh about various
things but let's start talking about the
EUI act which you're very familiar with
which represents a really landmark
moment in global AI regulation from a
constitutional law perspective, what are
the most significant
uh challenges this act poses
particularly on fundamental rights
protection?
Well, I think we can uh speak of a kind
of artificial intelligencedriven
uh revolution.
Um because uh uh artificial intelligence
raises
a lot of questions and um and he has um
there are constitutional challenges that
we must face and must try to to to to
speak of them. And the question is uh
artificial intelligence um demands a
profound transformation of the
structures and principles of the
constitutional law such as separation of
powers for example or the rule of law or
even the protection of fundamental
rights. Well, for example, Portugal and
as any um member state of the European
Union are a social democratic uh rule of
law state, but and that is a concept
that it is the most developed topics for
the constitutional doctrine, but it is
also a concern of international uh human
rights law and it has um a concept of
universal validity. If you for example
check the list suggested by Venice
Commission uh identifying uh rule of law
state uh you can easily conclude that
the use of artificial intelligence
uh currently doesn't meet that
requirements and that is uh uh there is
something that we must face. So what I
say is it's very important to us to uh
consolidate to build in a normative
national international level a kind of a
constitutional digital pact for the
artificial intelligence era age uh and
that is uh some kind of translating into
a digital social democratic rule of
state law rule of law state. So uh first
of all we must uh consolidate the
traditional identities the
constitutional identities because uh
ultimately the constitution is our last
uh defense
>> and also the last safeguard. Secondly,
we must uh uh consolidate and define the
new fundamental rights because there are
new fundamental rights that came from
artificial intelligence. For example, uh
we can see for example the rights the
fundamental right to explainability and
that is a very important uh uh
fundamental right or the right to a um a
human oversight.
Mhm.
>> And in some cases we we have to to
consolidate the right to a human
decision because that is very important
and of course the right for example to
demand the disconnection of a harmful
artificial intelligence system. We think
it's very basic but we have to write
them. And the um
third question that I think that is very
important is to um consolidate the
principle of legality in this digital
context because all the public
administrations are going to use
artificial intelligence and they are
going to use artificial intelligence to
make decisions that uh with a widespread
impact in fundamental rights and in
other constitutional protection. values.
So we must ensure that uh the use of
artificial intelligence is clearly um
rule uh regulated
u the limits of that use and uh some
kind of the existence of mechanisms of
accountability and effective mechanisms
of auditing. So in summary, I think it's
very important now to um
guarantee that no digital powers, no
digital power public or private make
decisions that impact the legal sphere
of citizens
uh without a clear basis without
transparency rules and um without uh
mechanisms of accountability. And that
is very even if those decisions are made
through artificial intelligence or
algorithms. And that is very important.
And um I think if we think for example
the the right to explainability
it is so important this this fundament
this new fundamental right because uh if
we forgot the relevance of of this
fundamental right we can convert the
rule of law into a rule of algorithm and
that can't happen because um that
happens when uh we allow machines to
make decisions
uh for us and but we don't understand
how they reach those decisions. So
every I know that the the most the part
of the doctrine says that for example
the hayak the artificial intelligence
hack from European Union doesn't
contemplate the strong and the generic
right to explainability but the question
is uh um we must not uh um we must we
must um
I importance and say that um
If if we um we we need to make answers
and we need to we make to ask questions
the questions we want and we need to
receive the answers that u that I can't
that I can understand why the algorithm
reached a certain result in a concrete
case and that is a very important Um in
this perspective of the use of
administration by public administration,
you know, um
for example, or or for example, there's
another way of saying that u um we must
uh we should use the public procurement
rules because uh we could guarantee not
only the systems but also the public
administration
That way we can guarantee that there are
compliance with the requirements of
artificial intelligence act. Uh because
the legislature
um obliging the entity the contracting
entities to um demand to award the
proposals to um to guarantee some kind
of aspects. um they can reach an
indirect uh um uh result of that uh
compliance. And so in the use of um by
the the public administration there is a
lot of things to to to think and to
reflect and um and I think it's we are
only in the beginning you know um for
example in Portugal these are those kind
of of
topics that I'm talking about they are
rather new you know um because we have
to review all the administrative codes
and uh so
um that is very important.
>> So uh you covered quite a bit of ground
uh recurl just to uh follow up on a
several points there. uh the EU AI act
is basically you know categorizes AI
systems by risk levels. Uh from a you
know from a constitutional perspective
do you think this riskbased approach
adequately protects fundamental
fundamental rights particularly for
vulnerable populations?
>> That's the million-dollar question
I think. Well, I think um you know um
artificial intelligence has a brutal
impact on fundamental rights especially
the generative intelligence the the
general purpose artificial intelligence
the agentics well they raises questions
in cyber security privacy and data
protection copyright etc. Uh for
example, in data protection um and uh
privacy, the the use the the the
traditional techniques we use to protect
fundamental rights are not uh
they are offer limited protection just
like uh that anonymization or
differential privacy. Um so uh we spend
so many time uh we doctrine the courts
and so uh building and uh uh creating a
self-informationational
self-determination
um since the Google Spain ruling you
know 2014
the European Court of Justice um and
just when we thought that the build the
build the building was strong artificial
intelligence threw us to ground zero.
You know, uh how can you Sanjac, how can
you exercise your rights to be forgotten
in a artificial intelligence chatbot or
how can you um control your footprint
in in Chachet or Jiminy AI any kind of
this chat uh chatbot from artificial
intelligence. How can you uh for
example, how can you demand safeguards
for selfexpression or access to
information if you don't know the
sources?
uh if you don't know um which criteria
is it is used to uh pre-reside some
contents that you receive or for example
how can you know if
that chatbot
um
uh are is using some kind of
disinformation campaign you know you
can't uh
All these freedoms, all these rights
uh are um
are affected by artificial intelligence
and it's very difficult to to say that
the high act uh can effectively
guarantee the protection of fundamental
right. I know that um
everybody says that high act is a
um some kind of
excessive burden for companies and well
but that's not correct. I I don't agree
with that perspective because one thing
is bureaucracy and bureaucracy is not
regulation. you know there's a t then
then there's a trend in confusing those
concepts and um it doesn't make sense
first the high
um
and it's not a a valorative neutral
choice uh choose a riskbased regulation
and that means that um there is no it
dispenses prior intervent vention of a
regulator strictto or senso
um and only the high-risk systems
uh have some rules because the others
and there are risking the others
um are only subject to codes of conduct
and they are volunteer. So um
how can you say that this is too much
regulation and I think also that uh it
depends I think too much in
self-certification
self-regulation.
So the the the choice that uh the
European legislature made was precisely
to um prevent hindering innovation and
uh I know it's a difficult task to to
find the hot mode balance between
innovation and the protection of
fundamental rights but um I think it's
all going to depend on several factors
like uh how European Union is going to
implement artificial intelligence act
because European Commission there is
some kind of
how can I say fluctuating fluctuation
between the official speech um about an
alleged uh regulation relief because uh
we have that speech but at the same time
we see that the European Commission is
always producing guidelines and uh
surveys and so on uh and important
producing important documents to uh
guaranteed implement mentation of the
the the of the HI act. So uh it depends
a lot on the on those on those kind of
guidelines and also and this is a very
important question in the national
legislative hacks because although it's
regulation
um it needs implementation in the
national laws uh and of course
there's a huge challenge because there
are a lot of regulations now digital
regulations as you you know, you have a
digital service act, DSA, you have GDPR,
you have
GMA, you have Okay, so those regulations
must be combined
in a very uh clever way, you know. Um,
and it's not very easy. It's not easy
because um they can, for example, GDPR
complement Hayak. So you can't have uh
uh for example data protection authority
or artificial intelligence authority or
a digital service coordinator uh and
each one applies and
guaranteed enforcement of each
regulation. It's very important to have
a transversal and comprehensive
regulation um um enforcement of these
regulations. So um I think it all
depends also in the way the regulators
will understand a subtle distinction and
that is between what is legally required
what is ethically desired and what is
technically feasible and that's a very
important dist decision because uh there
are different ways of for example of the
hatics in the regulation and ethics is
not the same as law.
And uh if something is ethically re um
uh how can I say regulated it's not um
it's not an enforceable regulation
and as I said before only the risk
systems are subject to for to
enforceable rules in binding rules the
others not they are only subject to
alternative regulatory instruments as
soft law code of conduct and um ethics
uh is very important of course because
um
but um ethics are not functional
equivalent to law. They complement each
other. Well, some some authors uh
compared a lot of codes of haptics and
codes of conduct. Of course there are
consensus in some teams but if we look
closer we understand that there are
there are different interpretations of
the same principles ethical principles.
So um it's very important to make this
distinction and it's very important that
the future because we don't have yet uh
we will have um
next August 2nd we hope we will know the
regulators of uh IE the supervision of
market authorities
uh but it's very important to to have
this um this distinction and the way the
regulators will implement this
distinction because it's different when
what we um want to law regulate and what
we want to ethics regulate and it's a
different kind of regulation and it's I
think it's very important
>> so Raquel uh I mean you talked about the
difference between you
the ethical rules which might don't have
a legal basis and you know the rules
that are there and you you basically
said there's a big difference between
having rules implementing it and you're
concerned about that let me just um
push back a little bit to you today in
the world there are basically three AI
centers there is the European Union
there is the American American and
there's the Chinese so to speak these
are the large ones I mean there are
other many other countries who are doing
some incredible work uh the perception
at least around the world maybe outside
the EU but in talking to a lot of people
even in Europe like the former pre uh
prime minister of Italy who wrote this
huge piece of work that talked about
what some of the challenges are is that
maybe The EU is focusing a lot on
regulation and not on innovation. That's
why some of the European companies leave
and come to the US or go somewhere else.
And this is a very fastm moving
technology
which you know really needs a lot of
leeway. Just two days ago
uh in Washington DC which is where I am
uh the White House the President Trump
released a set of executive orders that
basically said we are our interest is to
unleash the power of AI. We are going to
not hold it back. We're going to give it
from a data center from energy from um
permitting and other things because we
want to have a dominant role in this
technology and we're going to export uh
this to our allies etc. which is a
different message that comes from uh the
European Union. Uh
what is your uh perspective? Obviously
you you believe that even the EU what it
has done is not enough or if what it is
has said needs to be implemented but
that's the the question that I'm trying
to figure out that comes up quite a bit
Raquel.
Well, I think uh there are different but
it's tradition of the Europeans versus
the Americans. there is a different way
of um facing uh um this challenge. For
example, um it started with GDPR, not
with high act because GDPR was the first
digital regulation was the first step to
um to this European regulation. And it
was obvious, it was evident that the
United States has a different
uh way of interpreting of understanding
the relation between freedoms and um and
rights and other kind of values. So um
as you know there were a lot of problems
between European and and Americans
because of the ruling.
Uh so um I think um artificial
intelligence hacked European hacked uh
there's nothing new in that you know um
well Uh I think somebody said I think
that there was a scholar that said that
uh regulation it's what makes Europe
great again. I think it's a
it's the
>> well Americans say that America
innovates and Europe regulates. Uh
that's a little so just uh anyway. Yes.
>> Yes. So I think it's very important
because there there is a false dilemma
between regulating and innovation. I
don't think I I can't see things that
way. I think that uh uh we must innovate
but never innovate
>> uh when that cost is fundamental rights.
Um
when we speak of a trustworthy
artificial intelligence, we are saying
that we can uh um
uh we can trust the artificial
intelligence and that is much that is
much more important that uh uh than any
kind of innovation that don't have that
concern. So I don't believe in any kind
of artificial intelligence innovation
that don't care about fundamental
rights. You know for example the
European uh high act uh of course there
are
there is a generic concern about
fundamental rights but uh um it doesn't
elaborate on them don't densify on them.
So um when they say that there is a
dilemma between the European approach
and the the the American approach well I
I don't see that as a dilemma first
because of what I said before because I
the artificial the high European act is
a regulation is a riskbased regulation
and that's that is not
how can I say hard law regulation you
know uh for that's it and um of course
on the other way we can speak of
a kind of uh Washington effect when um
the the administration the Trump
administration was elected well there
are
two
main topics two main facts that we can
say that there is a kind of Washington
effect. First was the third draft of the
code of conduct for general proposed
artificial intelligence. Well, uh it was
clearly different from the interior the
second draft. Um and it raises the third
draft. It's not because the European
Commission published last week um the
final draft uh but um about the third
draft it raises a lot of questions of
fundamental rights and second the
withdraw from the artificial
intelligence liability directive. It was
very it was a very important step uh in
European politics to um to to react to
some uh to that Washington effect, you
know. So, uh if this Washington effect
is going to make more uh or are going to
produce another
uh another results, I don't know. I
think it all depends on um on on those
factor that I I told you before. The way
the European Commission will implement
the the for example the guidelines or uh
for high-risk systems that are not yet
known. uh and of course the national
legis legislative acts um that uh the
Europeans member states must must
produce. So I don't think there is a
dilemma between innovation and inventor.
I don't believe in that you know I think
uh innovation must um not be a harmful
innovation to fundamental rights.
And if you see you have high risk, you
have medium risk, you have limited risk.
Okay, in the in the categorization, the
European categorization.
So, uh to the medium risk, well, but
there is risk anyway. To the medium risk
systems, there are only codes of
conduct. Anything else?
So
um I see the hayak in another
perspective. I see that as I said before
I think he trusts too much in
self-certification
and um well let's see how it is going to
be implemented
next
two years next two years is going to be
very important.
>> Yeah. uh Raquel some American companies
uh large ones who you know maybe uh who
are hyperscalers etc have said that they
might hold back the release of some of
the their products in Europe because of
either the uncertainty or the questions
around that what will be the
implications within the well there are
financial implications for these
companies but there is and implications
for the AI ecosystem within Europe too.
If some of these companies say, "Hey, um
I don't think it's too high risk for me
to be uh releasing my products here."
>> Well, uh the main percalers are
American, right?
>> Yep. All of them.
>> All of them. So, uh there's obviously
it is going to be very problematic. Uh
but um I must say that um European Union
is uh working in some kind of uh how can
I say it some kind of um
sovereignity, digital sovereignity.
Uh and um of course they are promoting
uh those kind of
economy products. But
uh you must see that uh for in this
regulatory contest it's very difficult
to
uh understand that our data is not
controlled by by the European Union for
example or the data centers um for
example uh are not subject to the same
rules that are the same digital
services. Um I understand those that
kind of uh speech but um what can I say
about that? Well only that um latency is
a new coin and uh but I think not
everyone has already noticed that.
Yeah. And I I also um used to say that
uh uh
We we we face the problem of net
neutrality and u the build of um some
kind of a fair internet.
But uh the latency raises other
questions. for example, maybe uh neutral
temporal
to to um how can I say uh temporal
neutral right you know um well but I
think um I I always
thought about that but I don't have any
specific answer to that only the well
the notion the the I'm aware of the
importance of the latency and the and
the impact it will have in all economies
and why are the all the states and the
companies investing in latency. I
understand that. But I also know that
latencies can be a a vector of
discrimination and uh um
problems with fundamental rights. Okay.
So, uh as a constitutionalist, I always
um say that uh I must we must be
concerned with fundamental rights. Of
course, we must find hot balance between
uh fostering the innovation and uh not
um
raising questions to the fundamental
rights. I don't know if I well I try to
run away from your question.
>> No problem.
>> I did it.
>> Yeah. I think it's very it's a very it's
a very
>> very important question but I don't have
the answer no.
>> Okay. Well, maybe you have an answer to
this uh question. Um is you know the EU
AI office uh is going to have
significant supervisory powers. what uh
uh the uh European Union AI office it'll
have pretty significant very important
uh supervisory
regulatory powers. What are there
safeguards or constitutional safeguards
that uh will prevent uh regulatory
overreach by this office?
>> Well, that's a very
>> this is a question a lot of people want
to know. Uh
>> there's a very that is a very specific
question that I and I I wrote about that
question a lot. Well, because it's a
very technical question. We have a
problem.
>> Well, Sanja, we have a great we have a
huge problem because
>> uh because of the limits of the primacy
of the the the principle of primacy of
the European law. Well uh the European
Court of Justice
um the understanding is that when there
is a regulation the jurisdiction passes
to European Court of Justice which means
the all those regulation we are talking
about the SEA
GDPR are about uh fundamental rights and
that's the core of the constitutions. So
if the jurisdiction passes to European
Court of Justice, what is going to
happen to the constitutional courts?
Well, and you could say something like,
well, they disappear.
they are going to
have a marginal
well uh the problem is the
um the current citizen don't have access
to the European Court of Justice
and he barely can uh go to the European
Court of Human Rights. So the problem
here is that digital regulation are uh
raising specific questions of
constitutional justice and the way to uh
effectively
protect fundamental rights.
So we will have I think not now but
maybe in two years or three we are going
to have problems collision between the
European law and the national law you
know and there is no solution there is
no no answer uh that we can uh apply
without problems so I think it's very
important to understand that if the
jurisdiction passes of fundamental
rights passes to European Court of
Justice. Uh the European citizen
uh doesn't have direct assess you know
only uh
after if the courts if the national
courts because the dialogue is between
national courts and the the court of
justice. So uh that is another problem
when I started this interview saying
that we are uh assisting a
constitutional revolution.
Uh and that was one of the aspects
because we have to think we have to
redefine the constitutional justice also
and the administrative justice.
Um and that is very very important and
very urgent you know but um we are still
in the beginning.
>> Yeah. Uh we are all in the very
beginning. Um finally uh Raquel and then
we'll get to the lightning round. Um
there were a bunch of leaders uh
business leaders and others who said now
obviously it didn't happen that there
should be a two-year moratorum on uh the
EU AI act because you know it'll hinder
innovation etc etc. Do you did you agree
with them that there should have been a
two-year moratorum in the implementation
of that? No.
>> No. Look s look the uh I think
the issues
bought by artificial angelisters are
even more sensitive. Well let let me
tell you the example of the hologram of
Jesus Jesus Christ that was used in the
church in Switzerland. Well,
it is very dangerous, you know, because
uh it raises well, we can say, "Oh,
that's good because it's a way of um uh
speaking directly to Jesus Christ and
there is innovation." Okay. But it
raises questions of authenticity and
manipulation.
And we can think of political
manipulation, religious manipulation
and it is increasingly sensitive and uh
so and that is not going to wait two
years. You know we must hack now.
>> Yeah
>> we must hack now.
>> We must act now. Uh so finally we will
act towards uh this lightning round of
questions at the end. We basically to
make it a little interesting for our
listeners just one word answer from you.
These are just a few questions uh Raquel
for you. You ready?
>> Yeah.
>> Okay. And this is your view. Is the EU
AI act a success or is it a compromise?
>> Depends. Let's see. Let's wait and see.
>> Okay.
Okay. Uh AI regulation should it be
global or should it be regional?
>> Well, both. I think it must be both. We
can't have one uh uh only one
perspective of that regulation.
>> Okay. Is the Brussels effect is it
enduring or is that temporary? Is it
going to happen where Europe pardon? Go
ahead. I think it's going to happen, but
it also depends on the effect of the
Washington effect.
>> Washington effect versus the Brussels
effect. Uh
>> yeah,
>> that'll be uh very important. Uh and
this is something you've spoken a lot
about algorithmic transparency. Is it
essential or is it impossible?
Well, I think it must be there must be a
a level of transparency that
it's obvious that can be obvious and and
we have the right to know uh if a public
administration use algorithmic how uh my
situation is defined by the algorithm
and I must understand the criteria.
>> Yeah.
Yeah.
uh AI governance democratic or
technocratic?
Uh
well both I think must it must combine
both perspectives because uh technoc you
said technocratic it was
well because there must be scientific
>> right we must because uh um but there is
there must also be uh um
demands
frequentization
And uh sometimes the democratic process
doesn't
is slower you know is slower than the
innovation and uh we must reach a
compromise between both.
>> Okay. Finally um AI is future. Are you
optimistic or are you concerned?
>> AI is not future is present you know.
>> Okay. AI is present. Are you optimistic
or are you concerned? Completely
optimistic. Very optimistic.
>> Completely optimistic. Fantastic. Wow.
We are optimistic too and we are
optimistic about this conversation. Kel,
thank you really for sharing such
profound insights, you know, on the
constitutional dimensions of AI
regulation especially the EUA act which
as it navigates the complex terrain
between innovation and fundamental
rights protection and regulation. It's
been really incredible to hear your
perspective because sometimes we don't
get that uh and how do you protect
democratic values, human dignity
um so you know the questions that you
raised um really make us all think um
and to our audience of policy AI policy
leaders uh the constitutional lens that
Raquel bring brings to these discussions
is essential for developing ing truly
comprehensive AI governance frameworks.
Um, so thank you Raquel. Thank you to
our listeners. Uh, at regulating AI, we
believe that diverse voices and rigorous
debate are essential for developing fair
democratic AI governance principles. So
until next time to our listeners, thank
you so much.
>> Thank you so much. This has been
fantastic. Thank you for being on the
podcast.
[Music]
Black.
Black.
[Music]
