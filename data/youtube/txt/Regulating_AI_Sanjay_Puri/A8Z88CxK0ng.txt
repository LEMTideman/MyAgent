One thing I think the action plan
doesn't resolve. That's key to the
question you asked is where to strike
that balance. Where to put the threshold
for let's say semiconductors that the
commerce department won't allow American
manufacturers to export to let's say
China. I'm not sure there is yet a kind
of definitive national security view on
whether open source in this space can be
misused without the other pieces of the
technology in a way that makes it
absolutely wrong or absolutely fine with
respect to national security. But this
action plan picks up on that and
indicates that federal AI funding should
be withheld from states whose laws whose
regulatory environment is deemed to
counter the purpose of those grants.
This is one like a lot of things in a
strategic level document where I think
implementation will really matter
because there's a narrow and there's a
broad reading of that piece of the
action plan.
Welcome to the regulating AI podcast.
Join host Sanjay Pury as he explores the
dynamic and developing world of
artificial intelligence governance. Each
episode features deep dives with global
leaders at the forefront of regulating
AI responsibly, tackling the challenges
using AI can bring about head-on and
enabling balance without hindering
innovation.
Welcome to regulating AI, the podcast
that brings together global voices to
shape innovative AI governance
worldwide. I'm your host Sanjay Puri and
today we are diving deep into one of the
most significant shifts in US AI policy
in recent history and to analyze that we
have a truly unique perspective on some
of these questions. I'm thrilled to
welcome Joshua Gelser partner at Wilmer
H. He focuses on AI safest cyber
security and national security related
litigation. But what also makes Joshua's
perspective extraordinary is his recent
tenure at the highest levels of
government. Until January 2025, Joshua
served as a deputy assistant to the
president, deputy White House counsel
and legal adviser to the National
Security Council. Before that, he also
held senior roles including deputy
homeland security adviser. Joshua,
welcome to Regulating AI.
>> Thanks so much for the invitation.
excited to get to join you.
>> Awesome. Uh Joshua, we have a global
audience. We have uh you know policy
leaders, members of Congress, Senate and
other leaders as well as from policy
leaders around the world or
entrepreneurs etc. hold this in it. Uh
the AI action plan was uh introduced uh
last week u by the Trump administration.
Um and the plan uh spans innovation
infrastructure as well as internal
security from uh what I have gone
through that
in your view what's the thought line or
the through line that you see that
connects these three pillars
>> you're right that it covers a lot I
think the through line is the notion of
supporting the US private sector at home
and abroad so it's the US private sector
sector's version of AI that dominates
the global marketplace.
>> So it's the US private sector u that
dominates uh the marketplace from that
standpoint. Um Joshua you mentioned
u that the plan stopped short of staking
out a position on fair use and training
data and that's a very important aspect
because there was some conversation that
uh that some of this is fair use and
there have been some legal cases in the
past. What should policymakers and
courts watch out for next on that
aspect? Now, I love that you went there
first because for the lawyers, this is a
fascinating fascinating issue in in AI.
And in the past month or so, we've seen
three district judges, three federal
judges tackle this issue with two of
them concluding that more or less fair
use did protect AI model developers in
using copyrighted information,
copyrighted materials for AI model
training. And one finding that it
didn't. And there was some question as
to whether for all of its scope the AI
action plan would stake out a view on
this legal issue. It didn't though.
President Trump in his speech in his
remarks announcing the action plan and
three accompany executive orders he did
tackle this issue and he seemed to side
with the model developers and suggesting
a lack of feasibility for every
copyright holder to be rewarded. In
other words, he seemed to lean towards
the fair use side. But remarks from a
president in passing are not the same as
case law from the federal courts and
lawyers will need to watch carefully the
percolating cases especially as they go
up on appeal.
>> Yeah. So it's going to be interesting as
we watch but it's an one of the more
important things that happens u Joshua
one of the key things that was well one
of the many things that important one
that's been talked about is this whole
issue of power land and permitting. Uh
so uh you know it talked about how to
speed up uh data center bills, grid
upgrades, um permitting uh use of uh
data centers and government land etc.
What is your view? You have a view on
this in terms of how do we speed this up
without obviously compromising on uh
security or own community concerns.
The United States starts in essence from
a very privileged position here. There
is a lot of land in the United States
and especially given some of the novel
energy sources that the AI action plan
specifically encourages for
consideration. There's the potential for
a lot of energy that hasn't been built
out into into the sort of infrastructure
upgrades that for example China has
built out to power its AI development.
So I think you've described it well. The
action plan does at least two things. It
says with respect to any land in the
United States, the government is charged
with making it a less cumbersome, less
burdensome, altogether faster process to
get the permits needed to turn that land
into something actually usable for the
sort of data centers needed for model
training, model maintenance. Beyond
that, the action plan tries to
accelerate an initiative that began
under the prior administration, which is
making certain federal ants available to
the US private sector. Now, there are
things that get sacrificed, including,
for example, a commitment to clean
energy or some of the environmental
considerations, but that's where this
action plan strikes the balance in favor
of get that land available, put it in
play, let the infrastructure grow on it.
So we're going to build on that front
and see how uh we can get it done
quickly. Uh one of the other aspects uh
is the issue of uh you know that
contemplates NISK guidelines and
evidentiary standards to counter
synthetic media which is relates to some
of the whole issue of deep fakes uh
which is obviously growing in many ways.
Where do you think will courts and
agency realistically uh adopt first?
It it it does seem like at least
voluntary standards needs to evolve with
the technology here because in some ways
I think a lot of commentators maybe
including me are surprised that there
hasn't been more more of a challenge
posed by deep fakes by synthetic media
that purports not to be synthetic
instead purports to be legitimate or
organic and tries to confuse the
American people and other people as to
who made it or who said what or whether
the person portrayed in a video really
said whatever it looks like he or she
might be saying. And so this is going to
be a source of confusion,
disinformation, potentially real public
safety and national security challenges
for years to come. I do think it's
important that the AI action plan puts
down a marker that there is at least a
role for government in setting out what
voluntary standards look like to try to
keep pace with or maybe it's catch up to
that evolving issue.
>> Yeah. So it's going to be something
we'll have to keep an eye on. Uh Joshua,
you had a lot of experience with CEUS
and export controls and this is
something this plan has talked about. It
emphasizes strengthening semiconductor
export controls, preventing technology
transfer to adversaries.
In for our listeners who might not be
experts in CEUS, very few people are or
some of these how effective are these
tools and what are their limitations?
Can export controls really maintain
technological advantages? I mean you
have uh you know people like Jensen Wong
from Nvidia saying hey it's going to be
innovation not these uh restrictions.
Other people say we need uh I mean you
know there's two sides to this. Where do
you come out on?
>> There's definitely an enforcement
challenge here. I think even uh even
anyone in still in government as I used
to be would acknowledge that enforcement
in all areas of course is imperfect but
maybe especially imperfect here where
spotting these sorts of evasions of
export control can be quite challenging.
Now I think what government would say
next is but even imperfect enforcement
so long as it's there deters bad
behavior raises costs because when
enforcement does pick up on evasion on
unlawful activity it can oppose some
really significant penalties and one
does still see the Trump administration
uh engaging in enforcement actions with
respect to export control. One thing I
think the action plan doesn't resolve
that's key to the question you asked is
where to strike that balance. Where to
put the threshold for let's say
semiconductors that the commerce
department won't allow American
manufacturers to export to let's say
China because the action plan says flood
the global marketplace with US developed
AI products and do export control but it
doesn't say when one ends and the other
begins.
Yeah, and you know we it the plan talked
about building an AI global alliance
Joshua. However, we you know while we
emphasize American dominance
uh and then obviously we have these
security uh issues. Can the US uh
effectively lead international AI
governance while we also prioritize
national dominance? I mean it's a
It's an interesting uh dilemma here.
>> It's very it's very hard. I think some
of the the commentators uh were quite
surprised by the emphasis on
multilateral fora international bodies
even UN opaces as places to kind of
foster global norms in this space and
even build the sort of alliance that the
action plan anticipates and calls for.
That said, when you have as much of the
frontier technology as the United States
has, it does give some power, some
ability to bring others to one side if
one puts in the work, does the diplomacy
called for in the action plan to stake
out those global norms. The other, I
think, and this goes to the the the the
last exchange you and I had about where
exactly one thing ends and another
begins, who's in and who's out of the
alliance that the action plan refers to.
That matters a lot and that's where a
lot of the debate really has been. Not
that there should be some information
sharing, some quite a bit of exporting
of the technology even its most
sophisticated forms, but to which
recipient countries either you know
because other recipients pose a risk
themselves or because there's a risk
that hostile actors will reach the
technology in those destinations.
>> Yeah. And as you said that list can
change over a period of time. uh as we
have seen uh the one other thing uh
Joshua you know obviously in the big uh
beautiful bill they tried to put a
moratorum on the you know states uh for
10 years but that somehow fell apart but
the plan al this plan suggests limiting
federal funding to states uh with
burdensome AI regulations
how do you view federal state dynamics
uh in AI governance I mean what's the
appropriate division of authority in
your view
>> it's It's a fascinating issue that has
gone from kind of the fringes of AI
debate and discussion to really at the
center in a pretty short period of time
because this idea of federal
preeemption, a 10-year moratorum went
from something being discussed in think
tank papers to almost becoming federal
law in just just a couple of months. So,
as you say, this action plan picks up on
that and indicates that federal AI
funding should be withheld from states
whose laws, whose regulatory environment
is deemed to counter the purpose of
those grants. This is one like a lot of
things in a strategic level document
where I think implementation will really
matter because there's a narrow and
there's a broad reading of that piece of
the action plan. The narrow reading
says, look, don't waste federal grant
money. If you're going to pour it into a
state whose legal landscape is such that
it does less to foster AI innovation
than it would elsewhere, well, that
might well be a kind of reasonable
almost uh universal approach to good
grant making. On the other hand, if what
it means is use federal grant money as a
cudgel, as a way to try to dissuade
states from passing certain laws or even
get them to revoke to to uh unenact laws
already on the the books. Well, that's
quite different. It raises some
complicated constitutional legal
challenges potentially and it's a much
more muscular attempt at a much more
muscular posture from the federal
government with respect to a domain that
has belonged to the states thus far
because there isn't federal law taking
up that space.
>> But what about states that already have
enacted some of those laws? Um Joshua,
>> so I think the the grant uh provision of
the action plan that you referenced
would if read in its stronger form
suggest that money should be withheld.
AI related discretionary grants should
be withheld from those states. And you
know there's a world in which some of
those states might choose to challenge
that including the notion that it
violates what sometimes called the
anti-comandeering constitutional
provision. federal government can't make
states the enactors of federal policy. I
think the most natural way to preempt
state law in any area is to actually
fill it with federal law. And one thing
that this action plan doesn't call for,
though it could ultimately become a
prelude to is more comprehensive federal
legislation in this area. Part of what
made the the debate around the 10-year
moratorum of preeemption so interesting
is that it was a call to preempt state
law with nothing, with no federal law,
just to leave the space ungoverned. If
there were instead a push to preempt
state law with actual federal law that
might call for transparency or other
things picked up uh from current state
law models, you might find that
different stakeholders actually have a
different view of the merits and
demmerits of that proposal.
>> Yeah. because uh wasn't there uh I think
Senator Blackburn talked about uh
compromise with five years. There was uh
all kinds of numbers that were thrown
around to give enough time. But anyway,
we that's going to be an interesting
thing to see. Joshua, the other thing um
that was interesting for especially
folks uh who are building these systems
is the whole open-source closed model.
The plan strongly advocates for an
open-source AI development. Now you work
on national security uh and have worked
on national security and you know from a
competitive perspective what are the
tradeoffs of this approach? It's a
really interesting one because the the
action plans call sort of emphasis on on
open source I think picks up in picks up
on some strands in the the California
dialogue that the tech community
dialogue that clearly have been imported
into this administration including some
really leading figures in this space.
the same time it's a fissure. It's a
divide among leading tech companies with
with some really believing that closed
uh closed model weights closed not open
source uh not only helps protect the
special sauce the intellectual property
and essence of of model development but
to your point exactly helps guard
against potential misuse distortion
exploitation of what's otherwise shared.
I'm not sure there is yet a kind of
definitive national security view on
whether open-source in this space can be
misused without the other pieces of the
technology in a way that makes it
absolutely wrong or absolutely fine with
respect to national security. But I do
think it's one of those dimensions as
with many others in the AI space that
needs to keep being re-evaluated as this
technology evolves. This is definitely a
thumb on the scale from this
administration, thus from the executive
branch in favor of the open wage.
>> Yeah. Well, that's uh going to be very
interesting to watch. Uh finally,
Joshua, you know, the AI action plan uh
it seemed like it was framed uh kind of
the US AI policy primarily through the
lens of competition with China stating,
you know, whoever has the largest AI
ecosystem will set the global AI
standards. I mean do you agree with this
uh competitive framing? What are the
implications of viewing AI governance
primarily through a national security
lens?
>> It it it goes to the heart of of the
action plan's framing because I think
the action plan both explicitly and
maybe even more so implicitly. It does
make an economic argument good for
American companies if American companies
can build out their infrastructure,
innovate and sell to a global
marketplace. But it is also making just
as you say a national security argument
national argument that says it's worth
the risk of exposing frontier models
closed um model weights to even at least
potentially global rivals if if that
technology can become the global
standard can become essentially you know
irreversible irreplaceable and that's
one of the accompanying EEOs tries to
take that forward with the idea of
making available to the world full
stacks kind of the AI suit to nuts, if
you will, in a way that's American. Um,
I think these are the this is a vision
of how to win in national security terms
the AI race that has its proponents but
also has its attractors from those who'd
be more cautious who would say there's a
period of time in which America has an
advantage and what the private sector
should do is ensure that that advantage
gets utilized and have the innovation to
maintain it rather than risk it becoming
available to the likes of China. I don't
think that debate is over yet because
there's so much left up for
implementation because there will be for
example debates over the thresholds the
cut offs for well which particular chips
are export controlled or not or what
particular things can AI model
developers in the US sell to the world
and where in the world this debate it
this debate will keep recurring and
probably should keep recurring at that
level of implementation.
Just as a final point, I don't know
Joshua if you saw the the Chinese PM I
think uh yesterday or day before said
that we need a global regul A AI
regulatory body and they talked about a
global uh perspective on AI which was
very interesting right after the uh AI
action plan was announced. This was in
Shanghai for a uh AI conference. So it
is interesting uh you know that these
conversations are happening. The EU has
done its piece with the EU AI act. Now
we have our uh the you know the AI
innovation act. Now the the Chinese are
saying so it's as they say may you live
in interesting times. We're going to uh
we definitely doing that. And Joshua
thanks so much uh for your perspective.
We'll keep uh checking up with you
because this is just uh chapter one in
this uh whole evolution. So, thanks so
much for taking the time to be with us.
>> Thank you. Really enjoyed the
conversation.
>> Thank you.
[Music]
