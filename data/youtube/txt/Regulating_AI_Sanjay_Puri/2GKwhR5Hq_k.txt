These issues, whether it's AI or
climate, these are global issues and we
have to make sure that countries are
working together to [music] address
these issues, which is really hard in
this day and age with all the conflict
and sometimes the ego of some of our
leaders.
>> Welcome to the regulating AI podcast
[music] with Sanjay Puri. AI is changing
the world faster than rules can keep up.
So, how do we protect people without
killing progress? Each week, Sanjay
brings you inside conversations with
global leaders, policy makers, and
innovators who are wrestling with that
exact [music] question. So, if you're
curious about the future of technology
and how it's governed, you're in the
right place.
Joining us today is none other than
Senator Scott [music] Weiner of
California, a leading voice on
technology policy and one of the [music]
key lawmakers shaping how the world
thinks about AI, digital rights and
innovation governance.
>> Senator, welcome to the Regulating AI
podcast.
>> Thank you for having me. Just to set the
context a little bit, Senator, you have
talked about how your mom used to fold
newsletters in a tiny synagogue and your
parents met in a Lutheran church [music]
and you know your family flood programs
and experienced a lot of anti-semitism
and have built community institutions.
So when you think about AI catastrophic
risk, you know, bioweapons,
mass casualties and other, you know,
biases and other uh things of that
nature, does the family history of
existential threats make you approach
this, so to speak, hypothetical risk
differently than critics who say, "Hey,
we should wait for demonstrated harms."
Senator,
>> yeah, thank you for having me. You know
my yeah my family history is my family
like so many people in different parts
of the world came to this country
fleeing violence and repression and to
find opportunity. They came from Russia
and Eastern Europe. Uh Jews fleeing
begrums where they would like burn down
our villages and kill people. uh and
they came here to make lives uh for
themselves which is one of the reasons I
am so uh pro- uh immigrant uh because
when I see immigrants coming here today
from Central America or Venezuela or uh
from South Asia or wherever else um I
see my own family uh in those families
you know early on in my life as um as a
Jew living in an extremely non-Jewish
area with lots of anti-semitism uh as a
closeted gay kid gay teen during the a
mass die off of gay men during the worst
of HIV AIDS. I learned early on that,
you know, government uh is not just
about the small things and about, you
know, are you happy or unhappy. It's it
could be a matter of life and death. Uh
particularly for communities uh that are
underrepresented, that are marginalized
and so forth. And so early on, I learned
that you have to know what's happening
in government. You have to care. And so
that's really guided my policym
particularly in protecting civil rights
uh of so many different uh communities
and and so forth. Um I've also learned
that government has a solemn
responsibility
uh to try to make people's lives better
and more affordable and also to protect
people's health and safety. Uh and so
when it comes to AI, AI is it's
incredibly powerful fastmoving
technology. it has the uh possibility
and I think I hope the likelihood of
making people's lives better, curing
diseases that we thought were incurable,
helping us uh resolve uh climate change,
fighting wildfires or preventing
wildfires and or reducing the damage
from wildfires uh and so on and so
forth. There's so many areas where AI
absolutely can improve people's lives
and benefit humanity. But as with any
powerful technology, there are also
risks. Uh and we know that those risks
come in various forms. There's the
catastrophic risks that that we were
focused on the last two years around uh
you know uh targeting the grid or the
banking system or chemical, biological,
nuclear weapons and so forth. Um cyber
crimes uh mass cyber crimes. Um and then
other risks like deep fakes, risks to
employment, uh uh without any kind of
real plan for what's going to happen to
the folks who are displaced and so on
and so forth. And so we need to try to
understand those risks and get ahead of
them. Not to eliminate risk. Life is
about risk. Can't eliminate it. But if
we can reduce the risk, we should do
that. And historically with technology,
we've just ignored the risks as a
society and as a government with we
still don't have a national data privacy
law in the US. Uh we still don't have a
national social media law. We don't have
a deep fakes law. We don't have a net
neutrality law. We've just let it flow
with benefits and with harms. And so AI
is so powerful and so fast moving. Let's
try to get ahead of those risks.
Let's talk about California per se,
which is uh where you are and some of
this stuff is happening. And you've
repeatedly said if any state can do it,
California can. And you cite
California's leadership on data privacy,
net neutrality, and emission standards.
But there are some critics who say that
California exceptionalism, that 12% of
Americans shouldn't set policy for the
other 88%. And sometimes companies don't
always comply with California standards
nationwide. So what makes you confident
that California can set the template uh
senator for national AI policy when
Congress sometimes explicitly refuses to
act?
>> Yeah. And because Congress has failed to
act in certain areas, um areas around
climate change, areas around technology
policy and so forth, California takes on
an outsized role. Uh California is by
far the largest state. Uh we are
depending on the day either the fourth
or fifth largest economy in the world.
Uh and so even with you know we're 12%
of the US or a little more than that but
we we always punch way above our weight
class culturally in terms of uh
Hollywood and uh economically and in
terms of Silicon Valley and agricultural
sector. We are a powerhouse and when we
act uh people pay attention and we often
uh set a standard and we've done that
for many many years around auto emission
standards uh and uh it's happening now
around climate policy and technology
policy and and that's okay and again
ideally we would have amazing policy
coming out of Congress and I don't want
to diss Congress too much. Congress
under President Biden and Nancy Pelosi
and Chuck Schumer actually produced a
lot of great policy before Trump took
office. He's now trying to dismantle
everything. So, Congress is capable of
acting, but there are certain areas
where Congress has really struggled to
act. And so, California has a
responsibility to lead because we're in
a position to do so.
>> Senator, you had two bills and again, we
have a global audience, so I'm going to
try to simplify. One was SB 1047 which
was a liability bill uh with penalties
up to I think 30% of training costs and
then SB53 is a transparency bill with
penalties capped at 1 million and again
for our global audience there were two
bills that senator had proposed one went
through legislation and got vetoed and
the second one got approved. Some might
say that you, you know, uh, capilitated
to industry pressure. Others might say
transparency is smarter than
prescriptive mandates. Which is, uh,
more important according to you for our
listeners?
>> Well, the actual reason is that bills
can't become a law without the
governor's signature. And so, the first
time we went with a liability approach
and almost the entirety of industry
opposed the bill. you know, ranging from
not all of the large tech companies, but
the most of them, the investors and VCs.
We had a number of startups that
supported the bill, but a lot of the
startups opposed the bill. So, there was
just very broad-based opposition, and
there was also enormous support for the
bill. Uh, so uh, as the governor stated
in his veto message, SP 1047 created its
own weather system and it did. uh and it
played a very important role that it
elevated this issue of safety in AI
innovation and how can you both support
innovation and safety uh and it was a
long overdue conversation and and it was
very productive ultimately the governor
vetoed the bill uh and the governor then
as part of that veto set up a
three-person working group uh with folks
who had diverse opinions on SB 1047 and
asked that working group to produce
produced recommendations. And so we then
worked with those recommendations. We
kept some of the elements of the first
bill, whistleblower protections, very
strong whistleblower protections, uh
creating a public cloud called CalPM
compute to try to democratize access to
compute. And then we incorporated the
key elements of the governor's working
group uh report which focused instead of
liability on transparency to require uh
AI labs uh to uh say whether they have
safety protocols and if they don't they
have to say it and they can no longer uh
claim that they're taking safety
seriously and then if they do which I
think they largely do disclose what they
are so the public can see and so there's
that level of transpar arency and
accountability. Obviously, I supported
and continued to support the first
approach, but the governor vetoed it.
And so, we ended up passing a a strong
bill that sets a strong standard that
the nation is paying attention to. Uh,
and I'm proud of the work uh that we
did. Uh, and we were able to get the
governor to sign it. And the, you know,
Anthropic came out in support of the
bill. The other uh tech companies did
not. So they they didn't love the bill.
Um but they we were able to navigate
this. So we had, you know, enough
support and support from the governor uh
that we were able to get the bill signed
into law. And so I don't is it a
capitulation to industry? No, absolutely
not. Industry uh the most of industry
would have preferred that this all go
away. They don't want anything. Uh so
clear they prefer 53 to 1047. uh but it
wasn't because of industry that that
happened. It was because of the governor
vetoing the first bill. So obviously you
have to try a different approach.
>> Yeah. And as you said the country is now
paying attention uh to this uh Senator
Senator uh the US Senate voted 991
against Ted Cruz's 10ear moratorium on
state AI laws and you have said it's one
of the most irresponsible
things that you ever seen. Now there are
policy experts that say that federal
regulation might be better than a
patchwork of state laws. Now uh as you
are running for Congress um also and if
you make it and Democrats control both
chambers of Congress, would you support
federal AI legislation that preempts uh
California laws?
>> Yeah, let's first of all let's be clear
that Congress has failed to act on
technology regulation under both
Democrats and Republicans. uh it's been
a bipartisan uh failure and I agree
philosophically if we can enact strong
federal regulation that that's not just
lip service but strong and real and
impactful that is preferable to having
potential variation at the state level.
I've been clear about that from the
beginning. Um so in California we passed
our state privacy law data privacy law
and we're very proud of that. uh and
there have been efforts to preempt it
with uh federal regulation. Those have
all failed. But you know, the concern is
that it could be weaker regulation and
weaker enforcement. So when it comes to
federal preeemption of state efforts,
I'm very cautious about that um because
a the federal law could be weaker, b the
federal law could go uninforced, and c
if you pass a reasonable federal law
that preempts state laws and then a few
years later it it gets, let's say,
weakened, right? like a different
government comes in place and weakens it
and then you have a weak law with
preeemption. So I'm cautious and a bit
skeptical of preeemption, you know,
unless you have an ironclad guarantee
that there's going to be a really strong
government law with strong enforcement.
Uh so that's my take on it. And uh you
know, if I'm in Congress and clearly
we're going to, you know, uh tech policy
is something that's important to me and
important to a lot of people. And you
know sometimes I want to be clear
sometimes uh regulating tech and safety
gets pitted against innovation as if the
two are inconsistent. So if you're in
favor of safety, you're you're somehow
against innovation and vice versa. A
large swath of people and a large swath
of people in tech are in the middle.
They want strong innovation and they
also want uh reasonable protections uh
for the public. And that's where I am. I
I am proud that San Francisco is the
beating heart of AI innovation. I want
that to continue. I think it's amazing.
Uh and I also want to make sure that
we're being responsible about it.
>> Senator, you talked about that where AI
could, you know, cause massive economic
displacement and we starting to see some
of that that the speed of implementation
is faster uh than we've ever seen. You
regularly mention 500,000 Californians
whose jobs who are truckers, Uber
drivers, delivery workers through
autonomous vehicles, etc. could be
replaced by AI at some time in the
future. But neither SB 1047 nor SB53
addressed uh labor displacement, worker
retraining, or AI taxing, AI profits, or
safety nets. What was the reason you
didn't want this bill to be addressing
some of those uh issues at all? when
when you're talking about a big like
when I I do a lot of housing work,
you're never going to do a housing bill
that covers every single aspect of
housing. That's just not how or or we're
doing a health care bill that covers
every single aspect of healthare. It's
not how legislation works, nor should it
work that way because then the
individual pieces aren't going to get
the attention they deserve. Uh so SP
104753 addressed one specific aspect of
AI risk specifically catastrophic risks.
Over the last few years there have been
a number of bills in the legislature to
address deep fakes, deep fake revenge
porn, deep deep fake election fraud. Um
there have been uh bills uh to address
chat bots like chat bots that try to get
kids to kill themselves for example. And
there there have been bills to uh try to
address um issues around energy and
water uh and data centers. So there have
been you know it it's not it's all
handled specifically. So AI uh workforce
risk is a really critical issue and uh
and I think we are still I don't think
anyone has the solution to it because we
know that new technology has always
changed work and eliminated jobs and
created different kinds of jobs. uh back
to the beginning of humanity. Uh but the
difference now and you sort of mentioned
this in terms of the fastmoving pace is
that historically when like the printing
press came around I I I would need to
study this but I'm going to speculate
that when the printing press came around
it probably took a very long time to
have mass job changes decades maybe a
century because the world just moved at
a slower pace then. And so you have a
long period of gradual change even like
the personal computer that came out when
I was a teenager uh in the 80s and I
still remember the my uh Atari uh
computer that I had uh I was so proud of
my Atari for I think 400 or 800 I can't
remember which I wish I kept it I could
have like donated it to the Smithsonian
but it took like a few decades for the
personal computer to have really really
uh big impact. Same with the iPhone. I
mean it was shorter but the iPhone it
took like a long period of time. So now
we're seeing with AI development it's it
is so fast and we're seeing very fast
impacts on jobs and that is you know
it's not about banning technology or
anything like that but it is how do we
deal with that because we're not our
society is not very good at that kind of
adaptation fast adaptation uh and I
worry that you're going to see big
classes of jobs be eliminated overnight.
It's an exaggeration, but you know,
period over period of months or a few
years. And you're going to see a lot of
people who are thrown out of work and
who have either no other options or only
other options to take massive pay cuts.
And that will have huge impacts on
society uh economically
um politically when people get are
desperate and and feel abandoned you
know grifters like Donald Trump can come
to power and so we have to make sure
that we are not just abandoning people
and if it becomes a situation where you
have a tiny group of people who are now
becoming you know billionaires or in
Elon Musk's case I because is he now
going to be a trillionaire, you know,
with that scam he's pulling at Tesla?
You know, he like that. You have a small
group of people who are, you know, uh,
flying around the world with President
Trump and going to his gilded ballroom
and going to Saudi Arabia and doing all
the things and then you have a huge
swath of people who are eating cat food
in the gutter. That's not a good result
for society. uh and uh you know we have
to grapple with that and we're and these
fights are going to play out and
sometimes they're going to be like the
uh the polar opposite. we need to like
ban this technology or we need to just
let it run, you know,
completely rough shot. And there has to
be an approach where we allow technology
to evolve and innovation to happen in
ways that improve people's lives without
people being upended in that kind of
massive way. Um, and I don't pretend to
have all the solutions to it. And I've
heard very few people who do. Some
people have said we should tax robots uh
to create basic income. Um I also I will
say that this is beyond economics for
humanity like there's that old saying
like the idle hands or the devil's
workshop and sometimes those old sayings
are very wise. I don't know that human
beings were really designed to just like
lounge around all day and when people
have like are just don't have meaning in
life uh and don't have you know and
whether it's raising a kid or working or
what you know just have that kind of
meaning that's when people can get
sucked into wormholes on the internet
when addiction can happen so I I it it
is so complicated and um but we have to
resolve it
>> and we are starting to see job losses.
Uh I mean talk about young people coming
out of colleges are really having a hard
time. Uh Senator, just one final point.
Do you think the federal government or
the state government has a role to play
in this kind of a situation with these
job losses that might be coming down?
>> The federal government, let's be clear,
the federal government has more tools
economically to bring to bear. Congress
has much more flexibility in terms of
taxation and spending than state
governments do because state governments
we have to balance their budget. Um
Congress has just dramatically more
latitude
in terms of as the economy restructures
around AI. How do we restructure
government's response to it? But I know
right now this Congress and this
president that that's not going to
happen. you know, they did reject the
horrible preeemption, although they're
trying to pass it again. Um, you know, I
think Trump, Donald Trump does not care
about people. He He would for him it's
not a big deal if people are eating cat
food in a gutter. Like, that's not a big
deal for him because he's a he's a
psychopath who does not care about
people. Uh, and so we need to have a
government that actually is people
focused and and and cares about people's
future.
Uh Senator just to switch to the you
know the European Union has the EU AI
act and their act uh focuses on
deployers and high-risk applications
across all AI systems. You focused on
developers and frontier models who got
it right uh senator
>> you know I don't know I think there
there are a lot of it's a tough issue.
Yeah, we focused on certain size
thresholds and it is true that a smaller
model can be you know riskier and a
large model may not be uh risky
depending um and so it's always hard to
try to to to determine uh with the
smaller models I think what we were
focused on you know developing a large
frontier model takes huge huge resources
and so while like a small startup could
do that it's much more likely to be a
large lab Um and so for the small
models, what we wanted to be cognizant
of uh was making sure we're not, you
know, harming startups ability uh to
innovate uh and not you know and so that
that's why we made that choice. Um was
it the right choice? I think it was a
reasonable choice. Uh I understand
people can differ and and you know that
policym is an evolving process. You can
always change things, add, take away,
modify. Uh and that's the beauty of uh
legislation. nothing is set in stone.
Senator, for our listeners who want to
understand your so to speak your
regulatory philosophy, you uh you want
to deregulate housing construction,
streamline permitting and you know uh
from that perspective, but you also want
for AI, you want oversight and safety
protocols and transparency requirements.
What would you say is your regulatory
philosophy?
>> Yeah, I I would uh dispute that
characterization. I'm not in favor of
deregulating
uh housing um deregulating housing. I'm
in favor of having the correct uh and
optimal level of regulation of housing.
So, you know, in the in my approach, I
want us to have h we have a housing
shortage and it shouldn't take five or
10 years to get housing approved. I want
to have faster, more predictable
approval processes where we set the
rules ahead of time and if you meet
those rules, you get your permit and it
doesn't become politicized. We're still
going to have building codes and safety
rules and uh and zoning. Uh I think Z I
think we should zone for more housing,
uh more density, more apartment
buildings, not just single family homes.
We should allow for both. Um so that's
not getting, for example, rid of zoning,
it's just changing the zoning. So I
think we've been too restrictive on our
regulation of housing. And so I want to
have um still have good regulation but
less restrictive so we can build more
homes. With AI, it's the opposite.
Whereas housing we overregulated with
with technology we've at times
underregulated. In other words, often
having zero regulation whatsoever. And
so I want to make sure I don't want to
overregulate technology because we want
people to be able to build and innovate
and and all that. But I also don't want
to have like no regulation whatsoever
even if there's a health and safety
risk. So for all my philosophy in
general is we should have reasonable
regulation that benefits the public
without impeding the ability of people
whether technologists or homebuilders to
build and create things that improve the
world.
>> So reasonable regulation I think is what
the philosophy is to that helps people.
Senator finally we do have a lightning
round of questions for our Tik Tok
oriented audience. So just quickly one
word or one sentence answers. Uh and
you've done this a zillion times,
Senator. I watched uh your interview. So
let's go.
>> Should AI companies be allowed to train
on copyrighted data without permission?
Yes or no?
>> Okay. [music]
Is open source more dangerous or less
dangerous than closed source models?
>> Uh neither. Hopefully, you're in
Congress in 2027. Will you introduce a
federal version of SB53?
>> Um, I I don't know. Uh, TBD, the
technology policy is something I am
interested in, will continue to be
engaged in. What specific bill I might
introduce? I can't predict yet.
>> Name one thing, the EU, the European
Union AI act that got it right that you
got wrong.
>> I think, you know, we focus on
transparency and I think that's really
uh important. Um there are you know
certainly good things and less good
things about the EU act and I know
they're making some changes uh now as I
understand that because we want to make
sure that we don't overregulate. I'm not
criticizing the EU. Um there have been
some aspects where maybe the EU went
[music] a little bit beyond uh where I
think we should go uh in terms of
promoting uh innovation while we also
protect [music] public health and
safety. for our global audience. The
toughest part of getting an AI [music]
law passed in Sacramento
>> um intense lobbying by the uh large tech
companies and the large investors. Um
[music] that is the the hardest uh the
hardest piece.
>> The hardest piece. Okay. Finally, AI
liability be on the companies or should
it be on the users? It depends if a
model is dangerous and and this is
existing liability law. If a model
allows or facilitates something really
harmful to happen uh there could be
liability there. Uh there's [music] also
at the application level if someone
takes a model and uses it for something
terrible [music] there's liability there
as well. So I think it can it can be
either. For the policy leaders who are
listening to you around the world, is
there a message that you would want to
give because a lot of them know you. You
don't know them but these are people in
countries around the world because we
talk to a lot of them. Is there a
message you would like to give to Yeah,
that these issues whether it's AI or
climate, these are global issues and we
have to make sure that countries are
working [music] together to address
these issues which is really hard in
this day and age with all the conflict
[music] and sometimes the ego of some of
our leaders first and foremost uh our
own leader in the US but certainly other
leaders as well. [music] Uh and we uh we
have to find ways to have global
solutions. [music]
So, we're working hard in California,
uh, and we're struggling at times at the
federal level, but we have to move
towards global solutions to some of
these truly global problems.
>> At 6'7 in being the tallest legislator,
it does help when because people are
looking up to you. Uh, so Senator, thank
you so very much and look forward to
having you back again. Thank you so
much.
>> Thank you for having me.
>> Thanks for tuning in to the Regulating
EI podcast [music] with Sanjay Puri. If
you enjoyed today's conversation, don't
forget to leave a comment. We'd love to
hear what you thought. Share it with
someone curious about the future of AI.
And join us next time for more stories
and insights from the leaders shaping
what's ahead right here on the
Regulating AI podcast.
