I think some of the biggest takeaways is
that aiming to remove bias and aiming to
Center Equity does not mean compromising
on what the product looks like instead
doing those things actually makes your
product better and builds more
trust welcome to the regulating AI
podcast join host Sanjay pury as he
explores the dynamic and developing
world of artificial intelligence
governance each episode features deep
Dives with global leaders at the
Forefront of regulating AI responsibly
tackling the challenges using AI can
bring about head-on and enabling balance
without hindering
[Music]
Innovation welcome to the regulating AI
podcast artificial intelligence AI
stands at the Forefront of technological
Revolution so how do we regulate it
without stifling Innovation our podcast
features insights from various
perspectives we've had industry leaders
to government officials to advocacy
group leaders together they address
pivotal questions that are needed to
create a practical and fair
legislation I'm very excited and honored
to have Professor rashan Ray with us
today Dr Ray is a professor of Sociology
at the University of Maryland as the
founding executive director of the lab
for Applied social science research re
has help developed a virtual reality
training program for law enforcement and
led implicit bias trainings with
thousands of police officers military
personnel and employees at companies and
organizations I invited him on this show
as it is very important to get many
different perspectives towards framing
AI legislation and we absolutely need to
get the perspective from an expert in
bias especially with police and military
and its impact on AI regulations welcome
rashan it's an absolute pleasure to have
you on the regulating AI podcast thank
you so much I'm really excited about
this important
conversation rashan uh as I mentioned
our audience is global uh members of
Congress staff uh think tanks industry
can you please uh tell them a little bit
about yourself and your very important
work yeah sure so as you mentioned uh
one of my roles is being a professor at
the University of Maryland where I've
been for over a decade uh in the
department of sociology and you
mentioned my work on policing and
virtual reality which we'll get into a
lot I've also had the opportunity to be
a senior fellow at the Brookings
institution where I've taken a lot of
the research that I've done and actually
aim to scale it up to provide policy
prescriptions and solutions that are
impacting not only people in in the
United States but people around the
world uh my most recent role is with the
American institutes for research helping
to lead its Equity initiative which is
an over $100 million fund to address
systemic inequality in local communities
so all of my research pretty much
focuses on racial and social inequality
and how I ended up getting to policing
and technology and virtual reality is
really a t path of following research
outcomes while I was primarily concerned
with what was happening in local
communities centered with uh family
structure centered with health outcomes
and also center with upper Mobility
through education it started recognizing
the ways that individuals in local
communities were not only policed
potentially by law enforcement but even
surveilled by some of their own
neighbors and that led me to start
looking at police Ing and surveillance
and how that impacts Health outcomes and
then what I started realizing is there
was a huge gap in people who study
policing but they actually don't
interact with law enforcement and as a
person who calls from the law
enforcement and military family I found
that a bit surprising and off-putting so
I wanted to make sure that we are
working directly with the individuals
who hold often times uh the most ability
and the most power to impact us every
day which includes law enforcement and
that led to us eventually developing
this virtual reality training program
that we'll be talking
about rashan uh you talked a lot about
some very important topics and we're
going to really dive deep into it but as
maybe a little bit of a techie a techie
junkie uh recently there have been some
tremendous advances you've just seen
Apple just announce its uh new product
um meta has uh now it seems like game on
as far as virtual reality um uh is
concerned does that excite you does it
help with what you're trying to do
because the immersive experience is a
lot lot more with some of these products
right yeah most definitely I mean it it
does excite me I think that often times
more competition can create better
products I know meta in particular has
been out in front in a lot of ways I
mean from not only the Oculus glasses
which uh brandan Irby was actually a
student at the University of Maryland
when he first started to develop the
Oculus glasses but also the Rayband and
the Rayband stories which are
essentially sunglasses or glasses that
people can actually have on and they can
record things I mean the advancements in
technology that I've seen from these
companies from working with Google from
working with meta from being
correspondences with Amazon I mean
people kind of have no idea what's
coming and for me it's exciting the
biggest thing that I always talk about
with these companies though is the
importance of how we think about who is
sitting at the table when these
decisions are being made how we think
about how these products are going to be
dispersed through local communities and
whether or not local communities
fundamentally understand what's coming
and and can play a role in what is
ultimately in their backyard but I mean
as far as me I think all of the
technology is super exciting and I
always think about how can we take a
product and actually use it for social
good and that's part of what we aim to
do with our virtual reality training
program for police
uh rashan final question on this our
companies whether it's an apple meta Etc
are they open to collaborating on what
is very very important work that you're
doing obviously they have big markets
for gaming and all those other things
but what you're talking about might not
not have the ROI for gaming but it has a
way more Roi from a social standpoint
are they open to some of these things I
think the companies are open um I think
we saw during the pandemic uh
particularly in investment in the
diversity equity and inclusion space But
even since then I think a lot of that
work is now housed in their policy areas
and their policy shops and thinking
about legislation and thinking about
Equitable legislation and thinking about
uh how we think about randomized
controls control trials how we think
about uh beta and Alpha products and
being ready to go about so I do see that
they are thinking consciously of these
particular issues and of course that
becomes very very important because the
return on investment is one of the big
things that they think about but we
should also be thinking about equity and
ensuring that these companies are
leading way and I found uh that I think
they do a much better job than people
think they do well that's great to hear
uh rashan how does your work in using
virtual reality for implicit bias
aligned with the goal of democratizing
AI can you tell our audience a little
bit about that yeah sure so what we did
uh probably going back seven or eight
years ago I developed um an implicit buy
it's really a diversity training
training program for companies for
universities for organizations like law
enforcement and what I started noticing
was that we really didn't have an
evaluation tool by which to know the
impact that had been done and as a
researcher that's extremely important
it's not about checking a box is whether
or not we actually see attitudinal and
behavioral change that then led me to
start looking at police training and
what I noticed with police training were
a couple of things first was that they
were overwhelmingly training in what I
found to be archade techn technological
settings for example if people grew up
or were coming of age in the 80s and
they played Nintendo and they played
duck hunt that was kind of what law
enforcement was still using which I just
found fascinating in the years that we
were in I said there's no way that this
is looking realistic that someone is
sitting at a computer punching a button
and seeing as though how a person is
responding to a screen and so we wanted
to develop an upgrade for that the big
thing that we did was we aim to focus on
social interactions as a sociologist I
focus on what's normative and not
extremes which was the second part of
what I noticed with law enforcement law
enforcement typically trains to the
extreme which can be okay when we start
talking about um overtime the
normalization of mass shootings to
something happening where where there's
a hostage situation them training for
the extremes can prevent Mass violence
we get that but on a regular basis often
times they're interacting with someone
at a traffic stop or they are
interacting with someone in public so we
created uh these social interactions
that law enforcement encounters every
single day traffic stop suspicious
person at a bus stop a mental health
call a domestic violence call a robbery
at a store and then we varied the race
and gender of the person that they
encountered so that we will be able to
to discern from a research standpoint
that if an officer or a group of
officers responded differently that it
was primarily due to the race and gender
of the person or the setting and not
necessarily another factor that people
talk about so part of the background of
this was that we collaborated with
computer scientists we collaborated with
engineers and we put everybody in a room
and we took our strengths and we came up
with a tool that allowed us to do this
because the third thing about this often
times the advances in technology and law
enforcement are housed in large police
departments the smaller to midsize
departments are the ones that are left
out there are 18,000 over 18,000 police
departments in the US most of them are
relatively small they don't look like
NYPD or a large city instead they kind
of look like in the Heat of the Night
it's you know 10 to 20 to 50 police
officers in a particular department and
we wanted to to develop a tool that was
mobile that they could set up in a
relatively small space that was
relatively affordable where they could
be able to access advances in technology
and not uh necessarily be behind the
curve so rashan was there resistance
from uh them in terms of applying this
technology tell our users what was your
experience because must not have been
that easy saying hey here uh I've got
something for you to uh try so tell our
users uh listeners a little bit about
that yeah most definitely was their
resistance Massive Resistance um a lot
of the resistance the way they I always
think about it is ration there was a
perception that as researchers we'd be
collecting data and would show that
their bias and then if there was an
incident in the real world that they
would then uh go out and be held
accountable for that and and part of
that was just the realism by which we
brought to the virtual reality space
when people put on virtual reality
goggles they're immerse into a virtual
world and algorithm is responding to the
offices in real time that's dictated by
what they say uh how strongly they say
it and their distance from the VR
character so there was a lot of
resistance there was some police
departments who simply did not want to
participate there were some police
officers who did not want to participate
and so we had to figure out strategies
by which to start working with them and
I think I think still to this day there
are a lot of barriers but at the lab for
applyed social science research we were
much more successful than other places
and what we realized is that we could
start incentivizing police departments
and police officers to participate now
people here incentivizing what do we
mean by that well these law enforcement
officers are subject matter experts they
know a whole lot more than most people
do about how to interact with someone
and then we also realized that within
police departments there were a lack of
resources centered around certain types
of trainings centered around community
policing and especially centered around
officer mental health so we were able to
provide some grant funding for police
departments to participate and then in
exchange the grant funding went toward
these underserved programs that were
going on but yeah I mean make no mistake
I could I mean we could spend all our
time talking about the difficulties that
we had and I think for people who have
started up companies or done something
Innovative they've always faced hurdles
and the people who've been a able to
overcome it are the ones who are able to
tell the stories about what's going on I
mentioned earlier about my law
enforcement military family I lean on
that a lot
my great uncle was the first black chief
of police in my hometown I have another
Uncle who's a police officer his son uh
my first cousin is a police officer my
granddad served in two war wars Purple
Heart bronze star presidential
Commendation my mom got into the West
Point as a black woman in the 70s in the
late 70s so telling that story and that
history would help me to connect with
police officers that I understand and I
empathize with them and then we had a
really diverse team of people what I
realized is that based on just my own
identity and representation I I didn't
always have to be the person out front
to communicate with people there were
other people on our team who were part
of that and I think the diversity of our
team across race and gender and
ethnicity was extremely important for us
connecting with law enforcement for them
saying that we have their best interest
at heart um and that we just want to
move forward in an equitable way well
that's very helpful to know uh rashan
ran um how do we get the public uh
engaged when it comes to some of these
applications like uh implicit bias
training especially when it comes to AI
I mean do you see a role for Community
input in shaping some of these policies
most definitely I think that Community
input is essential and I think that that
hasn't happened enough um I think what
it should look like is whenever there's
some new technology to be deployed let's
go to San Diego for example where San
Diego is claiming to be the first kind
of smart fully smart functional
technological City there are lot of
products that are surveiling people from
the sky to the ground that the public
may or may not be aware of there need to
be just homegrown Community meetings
there needs to be information
disseminated on social media and then
there need to be opportunities to get
before lawmakers who are allowing this
to come in I think one major issue is on
the communication front with the
community so that they are aware of
what's going on and I don't think that
that's happening enough it's definitely
not happening enough on the sampling
side that even we get to the deployment
of Technology the technology needs to be
tested to that theith that's embedded
within the technology is not biased and
one thing I know is that if the
technology is not tested in a diverse
way you will get biased towards one side
so for example when we were priming the
algorithm in terms of interacting with
law enforcement we had to ensure that we
had a diverse group of police officers
across the country across age experience
gender race and rank why was that
important because if you're only
selecting officers from the East Coast
well one thing I know being a southerner
is that on the East Coast you might
could cuss in a police officer and they
don't think twice about it but you cuss
in the South you cuss in Arkansas you
cuss in Tennessee they're gonna be upset
and they're going to react differently
and so now the algorithm is going to be
primed that way but the other issue that
happens with technology is often times
these Technologies are being tested on
individuals who ultimately are not going
to utilize them so it was important to
include police officers in what we do
rather than say just having students or
having people who you're just bringing
in to test the technology and I think
that tech companies are starting to
realize that that they have a standard
to raise up to and it's important to
educate the community about what their
expectations should be for this
technology and then finally I think the
community needs to ask what they're
going to get for it are they simply
going to be surveilled more or are they
going to actually get something that's
going to help keep their Community safer
that's going to bring more resources to
the community it's going to bring more
jobs and ultimately make their Community
a better place to
live so uh from a community standpoint
we understand that they absolutely I
agree with you and there's lot more
going on in terms of that but in terms
of uh democratizing AI uh how can
legislation ensure that all law
enforcement agencies regardless as you
mentioned there are some everything is
not NYPD or LAPD size or budget they
have access to effective we training for
implicit bias because this is a very
critical issue yeah most definitely I
mean I think the first thing is Dei is
essential it's one of those topics that
has been weaponized in a lot of
different ways being in the spaces that
I've been in it's always been around
it's about inclusion it's about all the
steps are people sitting at the table
are they treated the same are they
allowed to get to the same place based
on their history and then are they
included in decision making it's similar
to what Shirley Chisum and John Lewis
have always said when Shirley Chisum
would say if they don't give you a seat
at the table bring a folding chair John
Lewis would say Don't just put me at the
table allow me to actually see what's
being prepared and participate in that
process whether than you just serving me
up a meal that I don't get the chance to
partake in and Bill parcel as a football
fan he would say if you want me to cook
you got to let me pict the groceries I
mean all of these analogies are
important about how we think about Dei
and so it's it's it's imperative because
often times the technology is being
deployed in a way that's not Equitable
for example we know that there have been
facial recognition software programs
that have done a horrible job at being
able to predict people's faces it's led
to people who did not commit a crime
being arrested and being incarcerated
and being convicted of crimes it's also
allowed then that means people who
ultimately did the crime oftentimes they
got away so we need to be clear about
that there was uh facial recognition
software that was just misclassifying
sear groups of people say like black
women because there weren't enough in
the sample by which to even start with
to be able to read uh their face their
hair different sorts of body movements
and then one of the best studies I think
about is a study that couldn't tell the
difference between or the technology
that couldn't tell the difference
between criminals politicians and
members of the Patriots and the are not
some of the same people I mean it should
have been able to tell the difference
there so we see how that plays out I
think part of thinking about this then
is we have to rely on academic standards
if I'm publishing an article and I've
published a lot of them there is a
certain statistical threshold that has
to take place that law that lawmakers
should enforce we don't expect all
lawmakers to know technology like we do
or know about algorithms or AI like we
do but we do expect for them to know how
to gather the information
and how to get experts to the table the
other thing I think that lawmakers
really have to rely on the AI Bill of
Rights which was developed um in large
part by the leadership of Dr alra Nelson
um who was sitting in the White House
technology uh Council and I think that
that's something that also has to happen
there's been some
bipartisan um algorithmic bias acts that
are extremely important to come into
play about the thresholds around
confidence intervals in terms of how we
think about the ESS or the viability of
this technology and then finally we need
to assure that say if we're talking
about law enforcement that if this
technology is going to be used that it
is not the end all Beall on how
decisions are being made about people U
being arrested or even being
incarcerated because we know that
algorithms are also used as a way to
determine risk and to determine who
should be led out on parole who should
be held on Bond and so forth and so on
and be unfortunate reality is that if
tech companies continue to look the way
they look demographically that our
algorithms will continue to Simply
replicate the inequality that exists in
society instead of being something that
can be so much better for society and I
think that's where we're trying to get
to so um rashan you raised some
uh uh important points that I want to
just follow up and before I forget some
of them so one thing is you talked about
the tech companies and you know how they
are training a lot of this data it's
basically what's on the uh the internet
Etc and you saw recently what has
happened with some uh with a Google
release product that has come out Etc
so what suggestions the one question
would be and you touched on this what
suggestions and are do you have for some
of these uh tech companies who are
training this data uh that that's
question number one and then I have one
more about the legislation the
algorithmic bias legislation the bill
that you talked about so if you can just
address what can tech companies do
because they are listening to you here
right now I think it's two sides for
companies on one hand it's who's
actually developing the products and of
course they talk about a pipeline issue
yeah but see there are content creators
and people are creating algorithms every
single day who may not have degrees from
where we have degrees from but they are
content expert and they are experts in
this area identify them find them
through your networks and include them
in the process they are people who can
actually help on the side of developing
the products on the other side is who is
actually um on the side of who is being
tested uh who the products are actually
being tested on we need to ensure that
there is diversity in a host of ways to
ensure that when the technology is
applied that it is being applied in
similar ways for different groups of
people people particular in a global
Contex and I think that becomes
extremely important and I think
centering those two things I'll say that
I've been impressed in particular with
meta in terms of their approach to this
on their policy unit in terms of uh
approaching it in this way and trying to
have a very diverse group of people at
the table to help inform some of these
decisions as they go for
it so you uh two points you made uh for
our listeners is one is when you you're
creating it have a diverse group right
there who can help with the content and
when you're deploying it also make sure
you get the voices of a diverse
community that is doing that but you
also touched on a a point that has come
up by many listeners is make sure you
keep a global perspective because rashan
this should not a lot of our listeners
from overseas have said they should not
just become an American English thing
because the rest of the world is not
just English there's culture there is
history out there so you touched on some
three very important points for our
listeners in the tech industry uh rashan
you also talked about this algorithmic
bias Bill we are in an election here and
I'm not looking for you to make
predictions but uh it's there are
certain things and we have over 100
bills in Congress as you very well know
that address many many different topics
uh as as far as this algorithmic bias
Bill do you think uh in we've had many
members of congress senate come in and
say we that it's in this year we can't
have a comprehensive AI bill but we'll
have separate separate things in there
would you like to see this algorithmic
bias will go through uh this or you
would want it to be part of a bigger uh
comprehensive AI Bill uh or you it
doesn't matter to you yeah no I think
it's important to think about what the
legislation looks like I think part of
what lawmakers are trying to do is
they're trying to take pieces of how
artificial intelligence impacts society
and come up with best practices for that
I do think with the AI Bill of Rights
that there is a guiding document that
should be applicable in this particular
case but at the same time there are
different ways that we might think about
the use of AI either it's its benefits
or it's or its cons in terms of thinking
about um say Workforce Development and
the way algorithms are used to take
applications and decide who rise who
Rises on the list or in law enforcement
in terms of using facial recognition
technology or Geo fencing which is uh a
form of technology that say if you're
having a protest uh law enforcement can
track people's phones and their social
media activity and know who is involved
or hot spot policing which allows them
to look at kind of uh that they're kind
of maps that that allow you to see the
prominence of prime they might happen
and in turn that could lead to over
policing of a particular community so I
think with a lot of the technology there
are some big guiding principles that
could be part of a large sweeping
legislation for example the length of
time that people's information that's
wrapped up in the algorithms is actually
used is important another issue is
particularly when we talk about law
enforcement is the steps that should be
taken after they recognize some want in
facial recognition then what should
happen after that okay they should rely
on their same standards and trainings
and I'll tell you this is extremely
important because take chat GPT is just
another example which has been extremely
popular I have a study with some
colleagues and we were looking at the
influence that say black lives matter
protests have on police reform in cities
it's question everybody wants to know
the answer to like did did the protest
matter did they not and we found that
they that they did in a lot of different
ways depending on the the spe the
specific legislation but what's
important is across roughly 90 of the
largest cities in the US we took chat
GPT to replicate our human analysis
where we had had graduate students at
three different universities University
of Maryland University of North Carolina
Chapel Hill and now one of my colleagues
who is at Washington University so some
great universities students doing this
work and we found that chat GPT could
replicate our analysis at about 85%
people hear that and they think wow
that's really good chat GPT can do that
well maybe in the real world but not
really because in the academic sense
that canot get published what we need
are standards that get to at least the
0.05 uh significance level where we are
95% confident that what we're seeing is
correct ideally it would even be at the
0.01 level 99% correct I mean we're
talking about millions and millions of
data points that go into these
algorithms and when we chat GPT it
actually improved it got up over the 90%
And so I say all this to say from
dealing with bias dealing with diversity
who's included from dealing with the
testing aspect ensuring that uh that the
technology is actually been tested
before it's just applied and then also
thinking about the
significance and confidence that we have
I think those are things that could be
bundled together because one thing I
know having a virtual reality training
program
you know you can dangle the new shiny
thing in front of people and they're
going to want to utilize it but that
doesn't mean they should and I think
that is the responsibility of our
lawmakers to ensure that we are that we
are treating everyone the same and that
we're making sure that when the
technology is deployed that it's not
actually doing more harm than
good so making sure the thresholds are
very high as you said maybe 95 99% and
also our lawmakers are making sure that
the technology has access to everybody
so uh rashan What uh how should we hold
organizations accountable uh for some if
the outcomes are not right for some of
these AI applications in these critical
areas whether it's bias or some of these
other things any suggestions from you
yeah when we start talking about
accountability obviously depending on
which side people following it they're
different perspectives about incentives
versus sanctions I think both can be
applied I think that there could be
trainings and and uh opportunities for
funding for companies to apply for to
create these uh these setups for them to
be able to test their technology one
thing we have to realize is there isn't
a lot of legislation saying that if you
create something and people purchase it
that then you have to be extremely held
accountable for various things if it's
not a product that can harm people and I
think the issue now is how do we think
through the harm that AI Technologies
might be causing I mean of course we
could get into how we think about robots
and cars and that extreme part but if
we're talking about VR goggles and what
that looks like and the deployment of
facial recognition software and eye
tracking and all of that then we have
some things to think through so I think
that there could be
incentives um that could also not just
include money up front but could include
tax breaks if companies engage in
certain types of behaviors but then also
think that there do need to be some um
some precautions taken and actually some
sanctions handed down if companies
aren't going about things in a proper
way and I think that becomes extremely
extremely important in this current ERA
that we're living in that as people are
trying to make sense of it and
understand it and as you know as an
expert and when you talk to experts
people are worried and I think that's
one big thing I always think about the
people who know the most when they're
worried about where something can go
then you want to be very cautious and
you want to approach it in a way that's
not going to cause more harm rather than
good so as you said there are people who
are worried and we don't want to cause
harm
so one of the messages uh that comes
across consistently and that's why we
call it innovate responsibly is how do
you continue down this path of
innovation but uh which you know our
country is famous for but also strike
the balance with responsible development
any suggestions that you have for our
listeners because there is always they
say hey uh we we need to innovate we
don't want too many roadblocks uh Etc
and then there are people who say we we
need to be
careful yeah I mean I I think they go
hand in hand I think the the issue is
that we act as if being Innovative that
a consequence of innovation is uh
casualty and oftentimes what people mean
is the speed by which it happens and we
do understand particularly in the US
context that if you're first typically
you're going to get more Kudos even if
you're wrong and I think that we have
just culturally we have have to think
through that but I think in a globalized
context it means ensuring that people
from different countries different parts
of the world whether it's India the
Middle East uh countries in Africa
countries in Asia countries in Europe
that we need to ensure that people are
sitting at the table and I will say a
lot of the large tech companies have
created and are starting to create these
broader Global uh policy councils of
experts and I think that smaller
companies can do this much quicker and
I'm starting to see that I mean I get
reached out to on a regular basis from
smaller companies saying hey would you
want to be a consultant could you
provide some guidance on some of these
issues and I think there are a lot of
people who could provide this guidance
so if people are starting up a new
company or they started up and they're
trying to get to scale and they're
moving really fast it's nothing for you
to create uh a global advisory Council
that meets four times a year to provide
you with some guidance where every you
know 90 days or so they're able to come
in and say oh you just did what hold up
like let's think about the consequences
of that sometimes Tech CEOs who are
moving or Venture capitalists who are
just thinking about the money and
creating something and selling it
they're not thinking about these other
sides of it and the harm that it can
cause but simply creating a council four
times a year to cause you to say hey
these are the big things you need to
consider and more importantly down the
road if you're going to keep this
company or you're going to sell it these
are some of the things that are going to
happen if you don't address address this
issue now and I think that's why they go
together people perceive Innovation is
about speed but as a social scientist
who have created a lot of these
different types of things having
different people together sometimes the
speed can get you in trouble just take a
little time to slow down make sure that
you have the experts around you that can
provide you with guidance and then make
the decision that's best not just for
the present but also for the
future do you uh rashan having uh what
you just said do you worry about either
a mon or something with some of these
tech companies because you talked about
these smaller companies it takes a lot
today to put together a large language
model now prices will come down but
these the price you know availability of
chips Etc is and does that have an
impact in some of the work that you're
doing so I do worry about that I do
worry about monopolies you know I think
that some of the large tech companies
what they do well they see somebody
creating something and they buy that
company um and then they hire that
person and for that person or those
people that's great I mean that's the
way the game is played um I do think
that once we get inside those companies
we do start to see um diversity in terms
of thought and different cultures and
what's important for these companies to
do is to
identify the smaller companies and the
talent in a diverse in a diverse way
globally in terms of how we're thinking
about it uh the second part of your
question was what it was well I it was
just that it that going if there is a
monopoly would that have an impact on
some of the things that you're doing in
any way yeah most definitely because it
would kind of stiny thoughts um I do
tend to think I'm un sure if that means
that we need legislation to prevent that
I tend to think that we need more
opportunities to create uh opportunities
for people to innovate and I think
that's one of the biggest things is that
when you look at Silicone Valley when we
look at some of the top uh computer
science and engineering schools the
demographics haven't changed a whole lot
and the way that I think about it we've
had time over the past 20 years to
provide opportunities for people in
local communities people who are
geniuses just like people who are at MIT
and Stanford and Harvard and the like
and so we need to create those portals
and those opportunities the same way
that I'm talking about an advisory
Council there could also be a thriving
Community Boards of people who are in
local communities who have created an
App who have created uh something that's
happening in their local community
whoever this Talent if they went through
an incubator they could be part of these
tech companies or auxiliary to them to
actually end up helping to create things
that make the world a better place and
also create Equitable opportunities for
people um across race and class
divides rashan since you just talk about
equity and I brought this up with many
members of Congress and Industry leaders
do you worry we we have a little bit of
a I want what we have a digital divide
in our country country do you worry
about an AI divide uh that could even be
much worse because this is such a
transformative technology uh you know uh
large uh universities can afford uh
Carnegie Stanford can afford to have
large language models maybe uh smaller
colleges community colleges Etc can't
afford and that kind of perpetuates uh
the equity or some of these things that
you're talking about most definitely
uh one of my Brookings colleagues Dr
Nicole Turner Lee has up the center for
technology and Innovation at Brookings
and we received some funding from meta
to actually explore this exact issue and
part of what we were noticing with the
language modeling with the machine
learning processes is where they were
located at and who was excluded from
that you mentioned community colleges it
could also be uh historic historically
black colleges and universities HBCU
Hispanic serving institutions the
smaller rural places ilar to how we were
talking about law enforcement earlier in
which departments have access
universities fall along that same lines
okay so what could be the response to
that what the National Science
Foundation other funders coming from the
federal government they could say in
order to get funding we have to see
diversity with your research team that's
one of the things that we're doing at
the American institutes for research we
want to see diversity of thought why do
we want to see that because research
continues to document that the more
diverse teams are the the better the
Innovation the better the thought
process the better the product and then
ultimately the more money that the cult
that the company makes or the that the
organization is actually able to Garner
so the National Science Foundation which
they've started to do this they've
started to say okay we'll fund you at
one of these large universities but we
want to see you partnering with people
who are at different universities so
Nicole and I we've convened some
stakeholder groups at these universities
to talk about what the barriers are and
I'll just say Morehouse College down in
Atlanta which is an HBCU uh for
primarily for black men that Morehouse
is starting to do this Innovation they
are starting to get some of the funding
to do this Buie State University in
Maryland is starting to do the same
Morgan State universities H has an anime
club and students are starting to
innovate in engineering and computer
science so the talent is there what what
the second thing these companies could
do is they could create pipeline
programs the federal government is
starting to fund those we've seen a lot
of pipeline programs over time and
social sciences and health and education
I've been part of several of them with
the Ford Foundation Robert Wood Johnson
foundation and the like we need them in
those Tech spaces as well and I think
that is something that all of a sudden
will help to transform the field where
when you're around these students you
just see so much Innovation you see so
much geniusness and they haven't had the
ability to actualize that because
they've been cut off from resources and
they haven't had that opportunity I mean
look if you look at most of the heads of
a lot of these companies and the
founders you'll see that when from the
the time they were born something
technological was putting their hands
right not just the phone like everybody
has now but the next best thing back in
the day it was a computer that all you
could do is play Oregan Trail or type
type letters that's all they needed to
innovate and so we need to create
opportunities for youth to innovate for
students to innovate and lawmakers can
actually create those pipeline programs
and also incentivize companies for
creating internship opportunities for
students at h
Hispanic serving institutions Community
College and Rural schools to end up
having these same
opportunities excellent point because we
made that point many times so lawmakers
can create help create some and
companies can create some internship
opportunities for HBCU Hispanic uh
oriented colleges rural in institutions
and community colleges um rashan how
does your lab incorporate feedback from
Nu users such as Law Enforcement
Officers military personnel uh in the
development or refinement of these some
of these training programs yeah really
good question when we talk about Inus is
for us it's fundamental particular when
we were priming the algorithm to make
sure that it was that it was as
representative as it could be we set up
a series of steps that are really
important for people in the tech space
because they just don't always do this
but it would be in their research and
development and policy shops they need
to incorporate that across their
organization so what we would do is
people would go through the technology
we would essentially do an inent
interview ask them a series of questions
we would also ask them a whole bunch of
other stuff about policing that was
important for us they would complete a
survey and then sometimes we would even
have people come back and repeat and
tell us whether or not the algorithm had
increased whether or not there are more
responses now whether or not it's more
robust so that they can actually see how
their input is Incorporated in that
inpire that I just mentioned is so
important if you include people and you
ask them your opin their opinion then
you want to have a mechanism by which to
show them how you've Incorporated their
opinion if in person virtually a
document that says hey these are our
takeaway points and this is what we did
with your information that's part of
what Nicole and I have been doing with
these listening sessions and we've been
putting together public blogs that go
out that actually say we met with a
group of stakeholders that have been
underrepresented and marginalized in the
space here are the top three to five
things we learn from them so for us a
laser and I should mention Dr Long Don
who is now uh heading up laser is that
part of what what we're doing there is
getting that enduser information to then
be recycled back in to better inform the
decisions that we're making to refine
our questions to think about what we're
missing to focus on how to improve it to
provide content back because the great
thing about our program is that
ultimately police officers are using it
to train each other so we want to make
sure that it's best informed by law
enforcement we can't have a law
enforcement program that's informed by
academics and students I mean that there
will just be gaps there are things that
we don't know that they've been trained
to do and that's part of elevating them
as subject matter experts that helps to
break down barriers if you're going to
have a program that's going to go into
local communities the people who need to
be sitting at the table are the people
from these local communities whether not
just in the United States but as I
mentioned other parts around the world
where we know certain technologies have
been deployed and importantly this
collectively all deals with trust which
is something that we've essentially been
talking about companies have to ensure
that people trust their products part of
trusting their products is ensuring that
they've been listened to that they've
been included that they won't be
exploited and part of that means in
centering that they're at the table and
centering Community Voices in that
perspective and throughout the process
to ensure that they've been able to
inform the decisions that have been made
about
Technologies so
you have a tremendous feedback loop uh
getting feed uh getting feedback giving
it back making it transparent I think
that's a very very important uh thing
that you
mentioned rashan finally uh do you see
global uh cooperation opportunities for
some of the things that you're doing
whether it's learning from others or
others learning from you uh because you
know we live now in a global uh world
really yeah most definitely I think
think that Global element is key there
are consultants and stakeholders that I
interact with from around the world and
I think that becomes extremely important
in terms of thinking about the decisions
that are being made there are different
contexts to play what we call in
sociology different social context that
say if you're in Zambia or if you are in
India or if you are in Ireland or if
you're in Amsterdam um and the
Netherlands it all play a different role
and what's happening where people could
take the same technology but the way
that it's applied in those different
context will vary so uring that there
are people that I check in with who are
part of different teams that I bring
into the fold to help inform what's
going on I typically do that in a uh
very specific way typically at the
beginning in the middle and at the end
and then on down the road as a followup
to ensure that we're not missing
something it's like okay what did we
miss who do we have at the table one
luxury that I have being a professor uh
particularly at a place like University
of Maryland is such a diverse place with
people from so many different countries
that often times I just have to look
across campus and bring in different
people who are here as International
students who are immigrants coming in to
be able to sit at the same table and
have a unique conversation or put people
together virtually and I think those are
the decisions that we made I mean if
people saw our Laser team and the
Consultants we work with over time
people say wow this is what things
should look like it's like yes we have
such a diverse people across Race Across
gender ethnicity nationality social
class background ability that was
deliberate and there are a lot of people
who think that you
compromise um the outcome or you some
kind of some kind of way compromise
success by doing that I haven't found it
at all I found that these individuals
are pretty much some of the brightest
and smartest people and hardest working
people I've ever been around the problem
is that often times they don't have
those opportunities because of people's
own individual biases and not
necessarily letting them be able to sit
at the table to help shape and inform
decision
making so a tremendous Global
coordination happening and some of it is
right in your backyard at University of
Maryland as you said it's a virtual UN
in some ways uh of people I've had the
pleasure of visiting many times and I
agree with you uh rashan this has been
uh fabulous uh I could go on for hours
and maybe we'll have you back again uh
but some final remarks for our listeners
as I said you the global listeners uh
what would you like uh for them to learn
or is there anything that You' like them
to do it's we have legislators from
around the world listening
so yeah look I think some of the biggest
takeaways is that aiming to remove bias
and aiming to Center Equity does not
mean compromising on what the product
looks like instead doing those things
actually makes your product better and
builds more Trust it also sets a pathway
forward that we have to think not just
about the present but the future 20 50
100 years down the road when most of us
are not here anymore as these advances
in technology continue to speed up for
lawmakers you have to act because if you
don't then you continue to fall farther
behind as these Technologies advance so
quickly and it doesn't mean that
legislation isn't amended it doesn't
mean that it's not uh even just
completely scrapped and changed but in
the moment do what's best Now by
thinking about the future you can get
some of the best Minds around to tell
you what the technology is going to be
in the next 10 to 20 years like I
already know that because I've seen it
it just hasn't hit the market yet
because the public isn't ready but the
same way that we were developing our
virtual reality training program nearly
a decade ago and now these things are
becoming a thing you have to get ahead
you have to use legislation to get ahead
of the technology and use research
practices by which to guide the
accountability mechanism to ensure that
these when these Technologies hit the
market that they're doing more good
rather than
harm so get ahead of the technology do
uh action I think those are very very
important points because it's not for
today it's also for our future
Generations uh ran this has been uh
tremendous uh I learned a lot I'm sure
our listeners have learned and we' love
for you to come back thanks for the
opportunity and for our listeners to
stay engaged uh because AI regulation
matters creating a just and fair AI uh
system matters to all of us so thank you
so much for being on the show thank you
so much for having
me thanks for tuning in to the
regulating AI innovate responsibly
podcast you'll find links in the show
notes to any resources mentioned on the
show if you're enjoying our podcast
please subscribe so you'll never miss an
episode and leave us a five-star review
