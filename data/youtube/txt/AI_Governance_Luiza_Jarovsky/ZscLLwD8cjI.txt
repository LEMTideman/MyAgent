so this is my second conversation uh
with Max and you know I don't know if
you know Max our first conversation is
still the most popular in my YouTube
channel and so people love hearing from
you they love to receive your updates
directly from you so for those those in
the Privacy field I'm 100% confident
that you know who Max is for those who
don't know uh so max he is the founder
of Nob so you can see you can see the
website here we're going to talk more
about Nob and you'll see the logo and
the background so he is I think probably
the most influential privacy advocate in
the world and he's also a privacy lawyer
last time we spoke about gdpr
enforcement challenges and today we're
speaking about privacy rights in the age
of AI and AI is the topic of the day so
it's great to talk about privacy rights
such an important topic welcome everyone
so I see many many places you can you
can check where people are coming from
if you're joining now you're welcome to
share where you're connecting from
welcome again Max and I want to start
talking about no first by the I took
note of some of no's numbers and they
are impressive so I see here 864 total
cases 51 uh pending cases 1.69 billion
euros in fines in post so no's Jo I
don't know how you do it so it's
incredible and I want you to share a
little bit about no before we invite
people to become members and support if
you want to share something special some
interesting stor something about this
latest year anything you want to share
Max oh um that's very
broad um no just basically for people
that unaware like we're nonprofit
organization we're based in Vienna so we
do basically like consumer rights
organization just for privacy that we
basically enforce the gdpr U most of
what we do is done under article 80
which allows us to represent individuals
and basically bring a case um and um
it's Mo most of it is funded by um
supporting members so people can just
become annoy member for one EUR all the
way to Infinity
um and um yeah that's basically where
where the money comes from We're are 25
people right now um most of it is
lawyers but we also have Engineers Tech
um it developers and so on um to also
build our own software for example to do
some of the things um like in a
automated fancy way um that other
lawyers are still doing doing the very
manual like word version of things yeah
and basically what we're looking for is
or what we're interested in is usually
kind of will F privacy violation so not
like you're okay something was up
and and people just you know there was
no intention or so um but really look
like for you know companies that just
really just ignore the law for you know
profits for um just not giving not
caring about it uh situations like that
that's usually where uh we bring cases
yeah and right now it's more than 5,000
I think supporting members that pay our
bills um yeah that's kind of a bit of an
over you um exactly thank you Max so if
you want if you're not a supporter not a
member yet so you can choose between
basic silver gold and purple so you you
have here you see under Max's name you
you see no's website so you can go there
you can check all and by the way I
always tell I know some of the people in
your team they have great communication
skills and I love that we lawyers know
how it can be horrible to share with the
public when we are defending rights and
and it's I think not every time there is
something new in the Privacy world that
has been of course nobes complaint you
go to no's website is the best source so
they add all the links and they explain
a simple way so what is the core of core
privacy right being violated so it's
really they do a great communication to
be honest it's a tricky thing to kind of
like make it understandable for average
people so that they understand but also
be correct in what you're saying and not
go too far so we we basically what
you'll find you'll usually find in news
update which is like an overview of the
case and we usually then always link the
the complaint for example that we filed
as well well um what we're actually
working on in the future there's already
case management system on the back end
that um feeds into our websit so for
most of the cases that we bring you can
actually go directly into projects and
be like for example now we're talking
about the AI cases today you can
actually go onto the individual case and
be like okay that's the Twitter case
that was filed in I don't know France or
whatever and you see a list of
everything that happened so there's a
date of each email we got from the
regulator and and usually a short
summary of what happened so we're pretty
transparent in what we do um and we'll
probably even link that a bit more up on
the website so that you can find the
news article because the news articles
and the stories right now do not link to
each other um but if you're interested
in any of that we usually try to kind of
have all of that online um
ex if you agree or disagree with you can
at least read them in detail and and you
know have your own view so everything we
are talking about today you can find the
O website so after we finish you can go
there and you'll find all the details
that we are discussing today
so let's start with Twitter SLX so
recent I just read it was last week
there was this conclusion of the
proceeding by the Irish data protection
authority and basically what happened so
that Gro so Twitter's AI assistant they
were using personal data of EU EU users
to train Gro and then no filed a compl
filed a complaint and but in the end so
there was those types of undertakings
and then now the Irish data protection
authorities have happy that Twitter
agreed to add mitigation measures so
they're permanently not using personal
data from EU users to train AI so what I
read so the latest news from no is that
you applied for full investigation so
you were not tell me if I understood
correctly so no is still insisting this
case right or no exactly um to maybe
zoom out a bit what um we what our
understanding of the cases and again the
Irish DPC is not as transparent so it's
sometimes not that clear of what really
happened but um our understanding is
that Twitter and I I'll use Twitter for
the sake of not saying X and for the
sake of the the Irish company we
litigate against is actually still
called Twitter so it's even more correct
to say Twitter than x um and basically
what it what seems to have happened is
that they did a data protection impact
assessment under
35 um for this whole like let's just
scoop up all the data of all the users
for some AI training and um in that they
came to the conclusion that there is
some problems they started to talk to
the Irish regulator um and they were
apparently negotiating about mitigation
measures which you know whatever that is
um in the specific case and it seems
that Twitter has just moved forward
doing this processing anyways despite
still being in negotiations with the
regulator and it seems that has pissed
off the DPC really um to be like guys
you're negotiating with us while you
already do the act that may potentially
violate the gdpr um now you have to know
that in Ireland there is no option for
the regulator to directly enforce the
gdpr and basically say stop it other
than in most other countries but um as
far as we know it's Ireland I think
Denmark and and um Estonia where the U
regulator has to go to the court to get
an order against the company and that is
was basically that is basically what the
DPC did um and the mitigation measure
that was apparently happening but that's
just a conclusion from like how the
facts developed um is that they put like
a little opt out button on the website
so um not really you know and they it
seems still relied on legitimate
interest to say okay we have a
legitimate interest to just scoop up the
data of
everybody now all of that is you see how
Twitter apparently doesn't have a
privacy team anymore or no professional
that actually works on that because once
you go into it you realize this
information is in the English version of
the privacy policy but not in a German
or French version of the privacy policy
then you see that it's inconsistent with
each other that you know the timelines
don't add up anymore so you really see
how
um this Elon Musk kicking everybody out
approach has really hollowed out um
their compliance team it seems at least
that's the outside per perception that
we have right now um yeah and basically
what happened in in Ireland is that they
did like a agreement before court for a
little bit um and now had an so-called
undertaking where Twitter is actually
saying that they will
not use certain data in certain times to
train Gro as a certain module and that
is where the problem comes in because
this undertaking does not say what
happens after these dates I forgot the
exact dates of the undertaking but
sometime is August so is Twitter now
allowed to do the same thing again after
the deadline of this undertaking um then
secondly we know that Gro 2 which is the
one that they now rolled out is already
operational so the personal data that
they used for training the end product
is actually now running and there is no
penalty they got away with murder more
or less it's like you know we're not
going to rob the bank next time is the
undertaking not we you know we actually
have a consequence from robbing the bank
the first time around and that is where
we also see a problem that um there is
not really any any ruling around that um
and it's also rather unclear how much
personal data is still in that AI system
now there's a big discussion of like the
different stages of um training and llm
and there may be Parts where you know
actually the llm itself does not really
contain personal data anymore because
it's chopped up to a level where you
just can't say it's personal data
anymore that is unclear right now how
much there is actually still processing
going on because the undertaking only
concerns the training stage of um the AI
um generation so um it may well be that
there is still stuff in the in in the
actual um llm and that you can even
retrieve so we had open AI cases where
you could literally type in you know
tell me more about Max sh and then all
the details came out and partly wrong
details um so on that we're all not sure
if if this under taking really solves
the problem um obviously the DPC you
know sent that out and all the media is
then taking up oh they did something
against grock how much that is really
efficient and and captures the problem
overall where where we have doubts let's
put it that way um in our cases are
still Al like the undertaking is not
overtaking the cases that are there so
we'll see how that ends up but I could
see if it goes with the other concerned
authorities and maybe at some point to
the edbp they will probably raise the
fact that you know they still got away
with training all the data and making
money from it um and and there was
really no penalty or no consequence from
that so I wonder how much the story is
is already done or if it's just like as
with all the other cases in Ireland a
first little action and then the
European um system follows up and says
too little too late and and you have to
do more so I think that's a bit what
what we expect here and two two things
on on this case so first see the last
communication from the the Irish data
protection auor this was from September
4th and they were were saying as you
were the communication was we relieved
so they they could it looks like H
Twitter committed to permanently so the
date was cped right so it was something
permanent so also on this case uh I I
see so for those that are a bit lost
those that are not in privacy and they
are trying to navigate we are going to
to break down many of those issues so
legitimate interest lawfulness
principles training scraping so we're
going to discuss more so don't don't be
scared you're going to to hear more
about that and the next topic is meta so
I want to to link this with the meta
these are is the same thing as The Meta
case so when I I was reading the
complaint it looks like Twitter so they
they committed to not pro use personal
data of EU users but then we can have
that discussion what is so they're going
to take out whatever is personally
identifiable information however we can
question that the infes and so on and
meta in meta's case it looks like they
they committed to not process data from
EU it's it sounds broader so my question
to you is it the same case so is we all
know so we are all sealing this again
and we going to mention the braan so is
it the same X Essence both the 11
complaints against meta which we're
going to discuss and the Twitter case
are the same have the same essence or is
different it's so fundamentally on on a
high level it's the same because both
are are about using personal data for
training AI models and um maybe to zoom
out for everybody um the first time this
question came up up what with open Ai
and open a there's this edbb paper um
where they kind of like say how far can
you go with with the training data um
and openi seems to have argued from at
least what the edbb says that they said
oh we just you know as an error or so to
say also have some personal data in the
training data in the sense that we get
news articles and Wikipedia and what so
whatnot and there may
a name in the news article there may be
some personal data like that but we're
not like trying to get personal data
into the AI model we are basically on
the sides kind of collect that and then
the question was how far does legitimate
interest go uh because you need a legal
basis for the training stage all these
companies try to now argue legitimate
interest which is going to be really
interesting because if we say you know
you you know if you compare it to for
example data retention where we say okay
you can't have the phone numbers of like
the phone conversations of everybody
just to or like just defect who has
called whom to be precise so the
metadata just to keep it for future
terrorist prevention so we say okay
that's absolutely unconstitutional now
how can they use all the social media
interactions of people to train an AI
model which is probably less of a public
interest and than terrorist prevention
so with some of that we just make
anything under legitimate interest we
have some concerns if that will fly um
obviously especially for companies that
have direct interaction with customers
there would be the option to do an in so
they could say you know do do you want
to support training of AI new technology
wonderful gr give us a consent that you
can actually um that we can actually use
that data that is um at least what we
see legally to be sound right now and to
be honest if I don't know Twitter or
Facebook or whoever uh would get 10 or
20% of Europeans to agree then they
would probably have more than enough
training data to actually get done what
they did and that's bit interesting
because right now they argue um that
legitimate interest is the only way to
do it otherwise Europeans are going to
be locked out and there is a lot of um
in otherwise you would call it
Collective punishment they basically say
if you do not give us all your data all
these modules will simply not be
available in the European Union which is
a bit weird because the prompting phase
of this whole exercise could be legally
separated from the training data so you
could theoretically train stuff on
non-european data and still allow the
end product to be used how much and it
seems more like a you know a punishment
so to say to say if you don't give us
the data in the first step we don't give
you the second part um thatan leun what
he said he sounded exact later he was
dramatic right Yan leun so is his the ma
me Chief scientist they said it's
horrible what the EU is doing so they
are preventing EU users to to use the
most advanced AI models this is horrible
for Innovation this is horrible for the
EU and said why don't ask people right
you can always I was literally like two
months ago or something or one month ago
in Brazil or so and they say the same
thing there they say oh you know the
Wester is going to move ahead if you
don't give us your data so it's
basically each jurisdiction is told
unless you basically give up your rights
and give us everything you have um then
basically will will will cut you off um
and it works it works in public it is
definitely something where um people you
know get excited about and say oh you
are now prohibiting that I can use that
which is really um you know problematic
because it's factually wrong like
anybody can agree to have their data
included anybody can agree to have this
software run um so to basically say
anybody else cannot use it anymore
because someone claimed as privacy
rights is is just yeah you know beating
up uh people against each other in in a
way that um is is yeah how should I say
um Highly
Questionable um but it works for them
and um so if we now back back at the
question legitimate interest I think
there may be some room to discuss um if
there is a legitimate interest if you
basically have incidental data
collection so we have this problem in
many areas that there's just dirty data
so it's generally not personal data but
there are some personal data bits in it
um and for training data there may be
options to kind of overcome that to say
okay how can we clean that data how can
we remove personal Data before we use it
for training you know there may be
options to filter it um what the edbp
has pointed towards is like to at least
not collect or scrape Pages where you
know it's full of personal data so if
you do your data set do not scrape
social media pages and that's literally
in the edbb um first um paper to say you
know if you say you're not trying to get
personal data make some Pro some some
realistic moves to not have personal
data don't just say it um and one of
them was don't use social media Pages
now that is really interesting in that
aspect your question from before what is
similar with meta and Twitter both of
them have explicitly taken the data from
social media as their main big new asset
to say this is actually why our AI is
going to be so much better than the
other is we just scoop up all that data
that definitely falls on the gdpr and
where we definitely need the legitimate
interest or legal basis now talking to
the legitimate interest um we are not
sure that that is a legitimate interest
um there will be Decisions by the court
of justice at some point how far that
goes but we have a very hard time to see
that you can just scoop up the data of
everybody in the whole world to put it
into a system where very relevantly
right now they say you can't get the
data out anymore so your right to
deletion your right to rectification
your right to access is basically done
they all these companies right now tell
you technically we're unable to exercise
these rights so how much it can be a
legitimate interests shoving data into a
system where you know you're not going
to be able to comply with the gdpr later
anymore
is is is already like Highly
Questionable despite the fact how much
data is used and that they usually
cannot tell you which are the recipients
so they tell you anybody in the world
can be the
recipient it's you know if you if you
look at all the metrics of normal gdpr
um legitimate interest tests you kind of
fail on each level so so we wonder if if
if that is a thing and that is basically
where the two are very similar that they
that they move forward and say
legitimate interest is the one we try
here
let's just I I like that we moved
quickly to legis I think it's very dtic
and we should talk more about that
before I want to go back to meta but
let's talk about legitimate interest so
if if we think in a very didactic way so
traditionally when we think about
legitimate interest we have the
three-part test right we have the
purpose test we have the necessity test
and the balancing test I think it's nice
to to think about those three the the
three-part test in the context of AI
model so first if when it start with the
purpose test I like you know I think
many people forget when you think when
you talk about AI models and using the
AI terminology general purpose AI models
they are going to be the basis for AI
systems right so let's take an as an
example open AI so they have GPT so they
are now training GPT 5 the latest is GPT
40 and they have the API and the GPT
store so basically anyone can go now in
the GPT store you can like drink from
this model GPT 40 and you can create
your own GPT now you can create and and
what is interesting I didn't talking we
talking about the purpose test so I did
an experiment so they have this uh usage
policy so when you're creating the GPT
your your own personalized GPT you have
to follow the policy of the GPT store so
they say you cannot offer Financial
advice you cannot offer medical advice
you cannot impersonate so there are many
things that you cannot do and I think
that those those rules are also to to
keep the idea that they're here to
benefit Humanity it's the purpose is a
beneficial and I checked each one of the
in items of the usage policy and you can
find gpts in all categories so sex uh uh
investment Health uh well-being anything
that you see there basically if you type
you will find that so they're not
policing they they I don't know what's
they are saying we are not the Poli here
maybe someone should yeah but then it
undermines the purpose test if if they
might choose okay I'm not the police so
someone should come and check that but
then their purpose test okay they train
a model and they say the model is for
Humanity is great for research but then
anyone can feed from this model which is
basically personal data from straight
from the whole internet and then create
whatever uh harmful uh GPT uh in this
example of open Ai and other other
models the same idea so purpose test for
me is very problematic okay the
necessity test I may stop you on that
one thing what's interesting if you read
the policies they basically make the
technology the purpose so usually in in
the gdpr we have purposes and means
means are usually the technology that
you use and they basically conflate that
into one so the meta privacy policy
basically said the purpose is AI and
it's a bit like you know the purpose of
processing is hard drive or is you know
it's just not a purpose it it that's the
the antithesis of a specific purpose as
we needed in in in article five now
obviously they say it's a general
purpose system so we don't have a
purpose but there you already have a
conflict with with how we usually um
apply the gdpr here it's interesting
that meta uses this argument but open AI
specifically they have a page and by the
way is not in their privacy policy
something that you have to dig into
their help center and there is a
paragraph where they say we rely it's
the perfect you know lawyers paragraph
and and for us it's very interesting so
they say we rely on legitimate interest
and there is a paragraph that they they
justify why and they say we are
technology we are benefiting Humanity we
blah blah blah and but then this whole
idea of models and systems so models
they're training a model that can be
used by anyone to to try to achieve
another purpose that is not saving
Humanity or whatever it's something like
impersonally we have necessity test so
they they might say okay we need
personal data to make it accurate I
don't know whatever they are going to
argue but then uh I think we can also
say and we will question we will talk
about it so data maximization the all
all large language model they will talk
about maximizing so another for to have
more accuracy and then we we can say
maybe with smaller models you could
achieve the same purpose and even
without personal data the same purpose
we can say maybe maybe you could have
contracts with specific entities to have
personal data not scraping from the
and then balancing test is a bit of what
what you said max so the third part of
the third part test is balancing test so
you have to the the purpose and
necessity and as Max was mentioning so
you cannot when you have large language
models you cannot have data subject's
right so you cannot access your data you
cannot ask to rectify it you cannot ask
to your right to be forgotten so in what
that if you're not even respecting basic
data protection right in what sense the
balancing test is being positive for the
data subject so I think it's also and
yeah and I think that is what what we
brought up so far and um it's
interesting because the often times the
argument comes up oh that's you know AI
That's new that gdpr shouldn't apply now
I had the you know questionable luck of
being involved in a lot of the gdpr
negotiations and and that was a big part
of the negotiations we said you know
back then it was big data and
correlations and algorithms that are
going to filter something out of that
the word was not AI that was used but it
was basically a description of exactly
that um and that was very intentional to
actually have these rules to to say okay
you can't have a system where any type
of data goes in for any type of purpose
which stays for any type of time and
anybody can future pull out the data for
any other purpose I mean that is like
you know basically all the red lines we
have in law are are killed now what I
want to um talk about as well is not
just what is currently not working which
I think there is a long list um but also
a question of how can some of this can
be solved and I think that is also um
important and we tried to put that in
complaints a bit as well to say you know
it's not nothing is possible but you
know we really have to think about this
a bit more and dice it up in in smaller
bits and for example for training the
data one option is really to remove
personal data to have synthetic personal
data to have anonymized personal data or
at least pseudonymized if if that's
possible and um so far no one really
made a convincing case that you cannot
have a you know chat bot without sucking
up the personal details of everybody on
Facebook and to be honest open did
exactly that without having the personal
disas of everybody in Facebook so this
necessity part that that you mentioned
before in reality may not be as
necessary as as as pretended maybe you
know maybe the product gets a percent
better fair enough but then this 1% may
just be where the red line of the law
hits and where that is simply not doable
um now that is the first part the second
question then is you can still use
personal data on a mo module potentially
in a prompt for example that is not
where the data is not in the module
itself so I mean you can have personal
data flow through the module so to say
in a prompt um and that could be
interesting how much you know that has a
different legal basis for example so for
example the person can consent to that
may be necessary for the contract
because your contract is you know a I I
always joke like a have a I want to have
a bigger lips filter for images you know
if anybody wants to use that on
Instagram that's probably either consent
or or necessary for the contract if your
service is Filters of I don't know
bigger boobs and fet lips you know that
may be some AI model where where you
absolutely agreed to that um and and I
think we have to divide that up a bit
more and see the pockets where it's
doable and where it's not doable same
thing for the right to access for
example so open a ey told us for example
they cannot tell us where they got the
data from now I assume they know where
their training data set comes from and I
assume that they could run a cury over
that and basically see where you know
which elements they have that matches
Max shs as a um thing for example if I
make an access request um
and same thing may be true for you know
correction for example so they start to
do like some type of filters at the end
um but you can fine tune a model you can
say okay there is an inaccuracy in the
model we need to find unit to kind of
get that inaccuracy out of the model
which could be your right to
rectification under the gdpr if if we
talk about it from a GPR perspective
there may be options to filter certain
things to say okay this is simply a cury
we do not allow because it generally
creates crazy answers um and I think
that is where the responsibility of of
the the makers come in that as with any
new technology usually catches up like
first of all they just throw it out
there and be like that's it and then
gradually we real I how can we need to
kind of you know cut around the corners
to make sure this this is not going
crazy and I think that is where um some
of our um some of our uh work is is is
is aiming at is to be like guys this is
a legal duty if you're all that
Innovative and great which we assume um
then there must be a solution to this as
well and you cannot you know you need to
invest some time and money into into
solving these issues as well I a case by
case uh so an individual who wants to
have access or who wants to delete he
will have to get in touch with the DPO
and say please find tune here to remove
my data or find at least like to be
honest I'm not sure from a gdpr
perspective that's compliant but um
would be a first step is to at least
have a filter to say you for example in
my case open the I say they already have
a filter to just block a name fully but
they can only block it all the way or
nothing at all and then they said I'm a
public figure so therefore they decided
for nothing at all um but I can also
discover about if I say there is one
privacy advocate he has founded a
nonprofit that starts with N and I can
go around and I I will never mention
your name but I still got information
about you right those inferences yeah
like we haven't tried that but right now
for example what we just did at a very
simple thing is usually in a normal
database a very common thing is that
some entry of your basic data is wrong
like your email address or you know
postal address or whatever and we just
basically did with with openi to say you
know um what's the birth date of maxr
and just gave you a random birth date um
um so there needs to be some solution to
kind of overcome that obviously the
birth date is a rather trivial example
but the idea was to have a trivial
example to say even in a trivial
situation you have no option to fix it
um and I think for that we we we do have
um to ask for some software fixed to
actually solve that um and that can be a
filter to a certain extent the problem
would then still be that in in the
module itself there is processing of
personal data that is inaccurate that
will just basically get fixed at the at
the you know after the output phase so
to say um but that would at least be a
first steps to to to have an option for
people um because we do have complaints
where people are told that the murderer
that has killed three kids when that
person has actually never you know
engageed with any of that with very
personal details otherwise where it's
very clear that that's that one person
um and and this will you know be coming
up and that will be a problem and also a
problem to then use these models because
we we also experimented with AI to kind
of really you know do some of the legal
work that that we would do we don't do
that on any personal data right now it's
more like summaries of judgments and
stuff like that um but this technology
is really interesting but we also need
to see how we can use it in a compliant
way and and get it over the line of
actually um having these protections of
fundamental rights also embedded so
what's important for me on everything
I'm saying here is um there are
definitely problems right now but it
would also be interesting to look a bit
at the solutions as well which is
usually the next step then and we hope
that that grally comes up now know and
some examples that you were mentioning
the birth date and and I think I
remember right I think it was January
2023 and I posted okay give me a
biography of Louisa yovi and they gave
they invented a whole bio and convincing
the only thing right was that I'm from
Brazil so this is okay I said it was
ever even flattering it was a very
successful bio it was not harmful for me
but there was that case you probably
heard about of that lawyer is a Fame I
forgot his name is American lawyer and
every time someone was mentioning his
name he was being accused of sexual
harassment so every time every a
reference to his name he was saying I
this is a public figure that has
committed this sexual harassment in this
case and there was a whole story which
was probably so some people in know I
think from the a researcher I don't
remember if it was someone from open AI
or researcher said probably his
information his but he wrote an article
in the same newspaper where this sexual
harassment was being uh narrated and
then now it got merged somewhere way for
now every time you mentioned it's it's
together and and there were other
stories as well so I I I understand that
maybe that's what's technically feasible
now and I like that your you're thinking
like I'd say not being anti- technology
but being okay let let's work let's
think what's feasible now but in in
terms of Case by case the problem is
that okay maybe someone doesn't even
know that their name is being connected
to something negative and then or not
even name as we said but some inference
about that person and then so I think
hard once you kind of get that personal
data into a system um first level you're
liable for it like just normal liable
laws and normal you know just um damages
under the gdpr just apply um then the
second question is someone actually
raises it to say okay I want you to
correct it now can you do that but in
the first step under Article Five you
have the duty to provide accurate
information even if no one ever raises
it so um because as you mentioned like
in many cases people will never know
that there is anything like that in in
it or it may be some system in the
background we now heard the first
stories about like you know using AI for
credit ranking um if you just go to for
example in Austria we have credit
ranking agencies that basically all the
banks rely on you know suddenly you go
to various Banks and all of them give
you I don't know half a percent more on
your loan um you don't know why
basically they don't tell you why and
there may be some score and you may not
know why the score is up and in the
background that may some AI glitch that
that that does that and even if you
don't care about privacy if you have a
loan of half a million euro with like
half a per more that's a shitload of
money you pay extra um um so there there
will be these cases and I think that is
where for example on our side we're
thinking about how we can use AI in the
level that it on the level of the
accuracy that we have right now so that
we say okay we can for example use it as
a first filter as a summary of text of
something like that but we would not use
it to generate text that is outgoing so
to say um as a lawyer I think right now
the level of like the accuracy of these
systems is simply not there to do that
um but there are Pockets spend more time
checking than you would spend writing it
by yourself right every time that at
least for lawyer job many I say wow it's
when you try it okay I'm losing more
time here to correct and worried about
okay maybe it's misinformation if you
type from it's it's the same as a as a
very Junior intern where sometimes it
takes you longer to correct stuff then
if you just write it yourself just with
a big difference that usually that I
doesn't learn as fast as to inters and
you feel like you're you know not
training a person but a system that you
don't get anything from um but anyways
um so I think that is that is our
approach right now at least to say okay
it's interesting don't you know don't
throw it all out and say never ever um
but it's not there yet and I think it's
also what we learned um is there's a lot
of overselling here I mean there's a lot
of just like pretending it can do
that it simply can't do um and that is
also a prom which I guess with new
models is going to go away or just
become less of a problem but um there's
a bit of an overhyped situation right
now as well where people think it can do
anything and and for certain things it's
just not the right tool um and for other
things it's a wonderful tool
so I'm still trying to to know maybe I
heard that developer software developers
love it and I've spoken with some that
they wow it's amazing productivity I
haven't found any yeah for especially
chat chat GPT didn't find but happy to
know that people are some people are
finding it
wonderful on what you do yeah just going
back to before we go back to met and
then I'll talk about Brazil but uh in
this big big topic gdpr so you think so
three op well let's let's imagine three
options so first do you think the gdpr
is fine or we need some sort of
amendment some sort of opinion
interpretation some edpb uh intervention
here to make it to add something else or
to have this official interpretation
that says okay in the case of AI
training and just opening this a paren I
also read everything of the CH GPT task
force very interesting right the the the
adpb the Europe for those not familiar
European data protection board so they
issue very important opinions and they
are now uh doing this research on chat
PT so they they published recently a few
months ago this first part or draft part
of the chat GPT task force with
interesting information with this
intersection of privacy and Ai and and
something that you mentioned so they
said if you want if you want to rely on
legitimate interest you have to take
precautions and measures so among the
measures they suggest is one is
anonymization as Max said and the other
one is not use social media which is
funny for example meta so basically it
is all social media everything Facebook
or Instagram and and even when you when
you see the deals being made so if
you're if you see so open Ai and go and
Google with Gemini they're having big
deal with quora and other social media
platforms they are really interested in
this social information so for me I I
read that and and the impression I got
it looks like a unicorn okay they say
legitimate interest is possible if you
do something that nobody's doing and and
it we don't even know if it's possible
but but it is possible so I'm I we are
hearing this evident super evident legal
Gap now is legitimate interest possible
and if yes how so my question I would
say I know you're you're now you have
the initiative of thinking a lot about
the law and
how Pro procedure and and how we can
change that so you think we can stay
with the GPR as it is or we need some
sort of strong interpretation here to
kind of change the way we've been
interpreting legitimate interest what do
you think so I think for the time being
we're fine with the gdpr as it is I mean
there are some elements that came in
with the eii act when it comes to kind
of unbiasing EI so there's kind of a how
should I say a article 9 legitimate
interest for unbiasing in in the AI act
so that could be interesting as a as as
as a new element that we need here that
no one thought about when drafting
article 9 of the gdpr um so there may be
some some specific issues to change to
be honest what what we just need I think
is call the discussion under the current
legal framework and I must say even for
our own bubble um we're not there yet to
fully understand all the details and I
think most decision makers are more
overwhelmed with this than than really
being on top of it um so we saw for
example this paper by the Hamburg DPA
that I think blew up Linked In where
it's just fundamentally wrong to say
there is no personal data in any AI
system ever I mean you just need to open
up open a ey and and and um type in the
names of some people and you will get
information back out of the system so
just by saying oh it's
tokenized yeah they said there's no no
personal information being stored
because of the to process so there maybe
I like you know ever since I learned how
a hard drive Works where also any bit of
data is split into 1,000 little bits and
stored all over the place anybody that
had like I don't know Windows 95 know
about knew about endless nights of how's
it called
um uh defragmentation because data was
put all over the hard drive so just by
saying oh data is you know split up in
bits is irrelevant if it later is put
back together and and you have to full
picture again so it's it's um you know
some of that is really um you know I
don't know a mix of wishful thinking or
or you know trying not to or trying to
kind of get the whole thing done in one
way and there may be situations where
really
like it's tokenized to a level where
really you can't put it back together
because basically there is some little
bit of personal information that went
into the system it never really you know
got captured in that way and it's not
it's not really represented in any kind
of uh Network um but that may not be
true for all of the AI and just having
these like you know headline grabbing
things of oh we just decide it's all out
or it's all in I'm wondering if that's
really gonna get us anywhere so I think
what what we really need to to have is
maybe also a bit of a you know quiet
calm down going through it bit by bit
and there may be Parts where we say okay
there there is really no agreement right
now then the first logical step is that
we may look at the court of justice to
give advice on how far that can go um
and there is some for example if we look
at Google um search the Google Spain
decision they back then said there is no
legitimate interest of Google to just
scrape the whole internet for commercial
reasons full stop but they said there is
an information interest another
fundamental right by the Google users
that do outweigh kind of the Privacy
right of people if they're like
accidentally captured in the algorithm
so that was interesting because like if
you now look at Ai and we do scraping as
well it's more or less the same same
idea you scrape the inter netw for to
get data we may have ways of saying okay
that may be there may be certain
purposes here where we can accept that
or or not so I'm I'm you know if if we
take that case law and put it next to
the ey scraping it's kind of interesting
to say okay just for the pure purpose of
developing a software that we can make
shitloads of money from in simple terms
is a legitimate interest if that already
failed for Google search how can it work
here but if we say okay the angle is
that we say we're developing new
technology we you know have a research
purpose here we later for example open
source it we you know blah blah blah
whatever you can whatever you can argue
you may actually have a different
balancing situation and to be honest a
lot of that gets very very political so
it it will be interesting where we land
here I could see that for example using
everything you could do to minimize the
personal data could be a big factor to
okay you tried everything there is
legitimate interest because you know you
you you you struck the balance in the
right way it's going to be very hard not
doing that because again like we have
this um you
know is it really necessary de balancing
a situation if you do not do anything to
lift the scale on that one side um and
you just you know load in all the data
anyways then you'll have a hard time
arguing that and I think that is where
where some more thought would go in and
where especially from the technical side
um there needs to be more exchange with
the lawyers of what is technically
feasible what can we do but I refuse to
accept that we can use AI for anything
in mankind and anything is doable with
AI but for example minimizing the data
before training the next AI model is
something that AI cannot do so I'm a bit
like you know um puzzled sometimes
because um sometimes these discussions
really feel strongly like not even
trying and and I think not even trying
is is is not going to help um to
overcome this legitimate interest
discussion yeah I like your optimistic
here and just go going back to to The
Meta thing and I want to bring the
Brazil example also to think how how we
can uh Advance this so just to to
conclude The Meta case so met no feel
filed 11 complaints against meta in the
EU and then after no's complaints there
was a PR preliminary win So Meta said
that they're not going to train to
process EU users data to train the AI in
the EU so this is the what
so far right this is the latest uh
exactly I mean the cases are still
pending maybe to to fill in what we
heard again that is you know rumors that
there was like a like informal edbb get
together Zoom call or whatever they were
on um to kind of tell the Irish DPC
that's not doable and then the Irish
told meta we we basically have to pull
back because the DPC originally told
meta that's all fine they can go ahead
which is a very common theme basically
the Irish DPC first tells these big tech
companies yeah go ahead ahe and then the
rest of Europe is like uh hold my beer
and um so this seems to have happened in
the background here and um that may be
partly the reason why that mattera
actually stopped it now there is no
order or decision or anything so far um
and um that is probably what meta means
with this you know legal uncertainty
that their regulator first tells them
yes and then a couple of weeks later
tells them no however the the legal
certainly comes not from a regulator but
you know if you read the law you
probably would have figured out that
that's a no you know just being happy
that the DPC tells you go ahead anyways
is not anything you should as a
legitimate company rely on but obviously
it fills The Narrative of of you know we
are so confused and we couldn't have
known yes exactly and and so you
probably heard that Brazil had some
similar things so in August the
Brazilian data protection authority
decided that had there a stop met
process so you cannot do that and then
but then now in August 30 there was this
new decision that said that meta can use
personal data from Brazilian users to
train AI with restriction and I want to
share with you some of the restrictions
which I think are are so it's it's funny
from a privacy we are to it it felt to
me a bit of I don't know 2016 or some
some many years ago because it's so it
it's found strange so this is the there
is this compliance plan that was
approved by the Brazilian data
protection authority so I have here I
printed here so I I
item so so what what are the conditions
So Meta can process data from Brazilian
users but it it cannot include data from
people under 18 it has to meta must send
a notification to all users on Facebook
and Instagram so trans okay basic
transparency so app app notification it
also must send a notification to the
email addresses registered it must
include a banner in the article how meta
uses information for generative AI it
must includes a banner in the on the
Privacy Center C Brazilian privacy
Center Easy Link to object so it must
there must be something easy to object H
so basically op out and transparency
also update the Privacy notice for
Brazil to let them know that it's been
used to traini
uh improve the transparency of the opt
out form uh publish in meta's press room
so that everybody can know redu the
reduction of the minimum number of
characters for the request of objection
for because there was a field that
should be why do you want to object so
there was a certain minimum number so
reduce if you're not a user of meta
product so offer a simplified way to to
exercise your opposition so for those gu
ghost
profiles um and that's it so it's it's
really basic right so basically they
said you can do it if you do basic
transparency so it's you do whatever you
want just not under 18 be transparent
send a link and the link should not be
so confusing and then you and the field
to add your opposition should not be so
long so it feels like wow so we we took
all those years of privacy and data
protection to and the decision is okay
do do something that is minimum privacy
you know minimum transparency use use
letters don't don't hide it don't don't
do that and and it's fine what what's
what's your view on that much I mean
that was especially interesting when we
got the meta version like The Meta email
that was a Friday night I then basically
worked on this over the weekend on
Monday we more or less had our complaint
ready um and if you looked at it a
little bit Clos cler the email was for
example having links that made you log
in to even see the privacy policy so you
had to log in usually people have that
on their phone so they may on their
email device which is usually more their
computer often times not even be able to
log in right now and interesting thing
if you just remove one of the like
particles of the email address you could
see the website anybody that Googled it
could find it just if you got from that
information you needed to log in to kind
of have another barrier and there were
20 of these barriers in a row so
basically you had to fill in a reason
why you objected you had to fill in your
jurisdiction again you need to fill in I
think your email address even though
meta definitely has that on file because
they just sent you an email so
um it was interesting how they did
anything that you know in a customer
Journey from a ux perspective you would
usually remove the addit all of that to
make sure that no one in the world ever
objects um and that was basically that
part but um again we're a bit in this
question of are do you even have a
legitimate interest at least if you read
the edbb paper on openi the answer is
probably no um so the question of like
op in or up out wouldn't even come up
and if really they would be so concerned
about the the feelings of people and
their Wishes the very simple thing is do
a popup with an opt-in button um because
you know it's a bit you know absurd to
um just from a practical perspective to
say oh you need to have 20 bells and
whistles and N NES to kind of alarm you
that there is a button where you can
actually deactivate it it would be kind
of like from a user perspective a bit
more interesting to just have a yes or
no popping up right there and bottom
line that's the whole dance like we're
having a dance here around opt in or opt
out um and it's I think not too much to
ask to like put that button there to say
yes or no which they do for tons of
other things I mean for a cookie
you have to do that um so um it's it's a
bit surprising to me that that there is
that much push back especially by these
companies what is it different element
with legitimate interest or not is how
much um you would then
again feature companies that have direct
user access because they can get consent
in reality versus others that do not
have that luxury so um and that's
usually not the big tech companies so um
but that is a political view to be
honest where um from a legal perspective
that's not a reason like to say oh we
need to kind of have legitimate interest
so everybody has the data that is a
policy or a you know Market discussion
that um let's say with my political head
on I have some sympathy for with like my
lawyer's head on that's simply not the
test under this law um so um I think
that was the only argument I came across
that made some sense um
otherwise um ask people if they want to
give up their rights and to be honest a
lot of people do want to give up their
rights and and fair enough you're in a
free society and the liberal system if
people want to I always say if people
want to jump off the bridge they have
freedom to do so so if you want to jump
off the Privacy Bridge go
ahead exactly and uh continue two more
questions so for those that that are
here don't go yet we have a few few more
topics so you mentioned the the right to
Art the gdpr's article where anyone can
file a complaint submit a complaint so
the E the EU AI act also has that
article so article 85 says that anyone
can submit complaints to the relevant
Market surveillance Authority so my
question will no get involved into that
too so are you going to enforce privacy
rights so or let's say more broadly
fundamental rights in the context of the
AI Act is also the plan or no your um so
we I guess at some point yes but to be
honest we right now still at our like
daily operations of like just normal
normal gdpr non compliance where we have
more than enough to do um so this will
kind of come up gradually I we usually
are reactive in the sense that um a lot
of this technology has so
far not hit the market until like half a
year ago or so so we usually look at
what is the problem that people actually
report what is the problem that we see
and then see what we want to do from a
legal perspective rather than saying oh
there is some new law we have to
litigate that law for the sake of it um
if if in reality certain problems do not
arise then then we would not get
ourselves busy with it also um there may
be other people being more um you know
more um equipped to actually do these
things because we are fundamentally a
gdpr organization and I mean when it
comes to personal data the gdpr applies
basically the eii steps back whenever it
comes to personal data that's how the
law Works um and then we can apply our
principles but when it comes to certain
you know very specific problems that go
into
not personal data issues I wonder how
much that's our issue and that may be
then the issue of a consumer rights
organization of some organization doing
I don't know hate speech or whatever it
may be um
where it's more about what you do with
the technology than then the type of
technology so if you you know use AI to
say something like you know drive a car
and you constantly run over people then
maybe we're not the organization to
bring on this AI case because then it's
really more about men's Slaughter and
not about about like privacy um and uh
that that may be the so that's kind of
how we approach it so so far it's it's
going to come up at some point but it's
not a Focus right now I'm confident you
came up you know in our last
conversation I don't know if you
remember I asked you a little bit about
Ai and you were much less involved you
said nah maybe not and now I see you're
super involved so I'm confident that no
it will be yeah and I think we said that
we got that question a year ago already
or two years ago how much we wanted to
do something about Ai and the simp
answer was we haven't seen it in a
consumer product yet um and now we see
it in consumer product we get complaints
on it then we work on it that's how we
usually work and last question for today
so you'll see that the this General AI
debate is very polarized so you even
mentioned the hype so there are people
who are optimistic they talk about
productivity the newest AI tool it's
amazing 30% better other people they are
extremely pessimistic they see that is
horrible for real world harms now now
other the people they are pessimistic in
the future so they see robots and
weapons coming and destroying all of us
so where are you in this polarized
debate do you see yourself as an
optimist yeah so first of all I'm I'm
not sure if I'm the person to kind of
like really trust on these topics
because when it really comes to are they
going to shoot us or not there are other
people that know much more about that I
I'm the Privacy guy here um I think
generally what my take is personally as
with any new technology it's usually
opportunities um that that it brings
and then it's a question of managing it
to kind of make sure that that stuff
does not go wrong all too much um
usually with anything like that we have
growing pains when we had like I don't
know the social first social networks we
had growing pains when they started to
say oh blockchain is going to
revolutionize the world you know um
there's a lot of I think what's
interesting for me it's the first one of
these new technologies where I really
feel that has a lot of potential because
as a privacy person you get a call every
week about the latest that some
company brought out and some journalist
wanting your opinion and I think we went
all the way from Google Glasses to I
don't know what um and most of that you
know is just not worth even wasting your
time um this one definitely is worth um
but um so we I
usually being someone that you know had
programming in school and really likes
all of that there is a lot of really
interesting technology and a lot of
interesting options here um but I think
as with anything we need a realistic
approach we need to say okay that's what
it's capable to do that it's what it's
probably not perfect to do um there are
still problems in that area where maybe
for we can't unleash it on people yet we
can use it to I don't know draw a meme
or whatever which you know fair enough
go ahead do that um and I think that is
the discussion that I that I personally
am interested in not in the you know
doomsday scenario here and the the world
is going to be wonderful there because
if you're in that business for a bit you
realize you know the people should have
loved each other much more and get much
more connected with Facebook turns out
that went exactly the opposite
way so some of these things I I think
are usually coming out in the middle and
that's where the discussion should be
happening and and and really not you
know not engage in that and not move
into it um because of some fears but
also being aware that this usually
everything comes with some problems
attached as well and and we have to work
on
that thank you Max so as long as it's
useful for
anybody I see you overall in this
spectrum I see you as an optimist some
people they say they are much more
negative than so the current of the
debate I would say you like Center
optimistic like realistic optimistic you
mentioned that you you try to use it at
in without personal data so this is
already an optimistic sign and so to let
before uh the before so before I I go
back to Max for his last so max I I will
say the reminder so think about one last
impacting sentence for the audience so
why I uh see the before you I will tell
you now everyone to the audience so
before you go three reminders first if
you want to stay update with the latest
developments in a in Tech AI privacy AI
governance H subscribe to my newsletter
so Wiis newsletter. comom if you want to
join the October cohorts of our AI
governance boot camps say uh your spots
so the September sold out so if you want
to join October this is the website
under my name and don't forget get to
support no so they have uh different
types of membership so that they they
are no not no is a nonprofit they rely
on donations and so membership so go to
their website you can see under Max
names so no. EU you can see the
different ways to support them now back
to Max what's first where people can
find you and I know so you can tell and
also your your last concluding sentence
to this life talk right people can find
me so personally it's always hard to
find me because my inbox and and
everything else is overflowing usually
um so sorry for that um usually what we
do as as he's mentioned is all on on on
IBU and um otherwise on this AI
discussion it's going to be really
interesting to see what what the
authorities say and I think we put them
a bit on the spot there to say you know
this is a problem what is your decision
now and whatever they say will be
interesting because it gives us some
legal certainty I think that is now the
next step that we need is to say okay
these are some of the problems there may
be more coming up um and now we need an
answer of of how we actually work with
that in reality what we may and may not
do and um to be honest I'm I think we're
in a better position asking the question
and necessarily having to answer all of
them um but I think if you go for
example through the complaints
especially the meta one it does raise
every issue and also kind of like does a
legal analysis and on what we think
where this would usually come out um and
and that may already be a bit of an idea
of where the problems May lie and where
we have to take a bit of a closer look
and then really also to think how we can
find Technical Solutions around that so
there I think that is the other question
we're right now basically having cases
on some of the systems as they are but
we all know that a new model is coming
out every half a year um at least for
like each provider and that means tons
of models um and then we can see how we
can you know build in more systems or
more um have new requirements basically
that will
get compliance going and I think that is
um a bit something that that I want to
throw out there is this is not a
monolitic situation that is going to be
that way in 200 years still um all this
is very basic versions yet and I think
there will be iterations that will solve
some of these problems on technical side
as well um which would be great because
then you know you're you're legal you're
compliant and you can go ahead and then
everybody's happy
ideally excellent great and and I hope
to meet you again marks next year so we
met last time in July 2023 so I hope in
202 let's see if you'll still I will ask
the same question about optimistic we
we'll we check again thank you so much
for joining me today it's always a
pleasure Max and people love to hear
from you is always super popular so we
are here so so many people uh watching
it live it's for those who ask me yes it
will be on my YouTube channel probably
next week I will post the recording of
the session thank you so much Max thank
you so much for the audience for joining
and being so participative in and asking
questions and being here active and see
you in the next live session byebye
everyone bye there
