welcome I'm so happy to be here with you
today uh discussing this such an
important topic so we we're discussing
today challenges opportunities and
practical insights related to the AI act
and I want to start with looka from your
perspective during the latest months of
the negotiation what were the most
challenging issues more from the
negotiation
aspect thank you Louisa yes indeed I
mean I've been in Brussels following the
the process the entire time and yeah
some some people would Jo that I was
hiding in the meeting room sometimes
um yeah so I would say you know first of
all just to give you a sense uh of where
this is coming from uh when the AI Act
was first proposed the overall mood was
like this was a premature proposal that
the technology was not mature yet and so
the the the
commission was jumping the gun basically
then after um the public release of CH
GPT AI became such a hype that the mood
became you know you're you're too slow
this is going too
fast uh and so on and so forth so it's
not only uh the fact that people like to
complain but uh also it shows the the
limits of trying to regulate a
technology that moves uh such a pace
that you have a new generation every few
months so indeed I would say uh the the
most challenging moment was the
realization that uh you know um CH GPT
and the underlying Foundation model uh
basically didn't fit in the AI act I
mean if you talk to the commission they
would tell you yeah but we have some
transparency for chatbot um I I doubt
that would have been considered uh you
know sufficient by anyone involved um so
you know for how much the commission
said the proposal was future proof well
it it didn't even last the time of the
negotiations uh and I think that the
European Parliament you know it it took
them more time to find their position
but I think they actually developed a
much more comprehensive approach to
Foundation models um and managed to to
get their their basic idea through um I
think that the most challenging moment
was probably when the negotiations were
went very close to breaking down uh when
you had this technical meeting and
basically the Spanish presidency uh said
that they had no mandate to negotiate on
Foundation models because France Germany
and Italy uh didn't want any hard rules
for foundation models because of the
startups you were mentioning before in
particular M to less extent Alf Alpha so
I think that uh there we we really saw
uh different interests Collide you have
the interest of the commission the
Parliament that had you know a political
pressure to reach an agreement also the
presidency of course uh before the
elections because they they didn't want
to miss this window of opportunity to uh
to come forward with this uh first uh
regulation in the world on artificial
intelligence and of course politicians
they especially before elections they
need victories to bring to their
constituencies to get reelected to get
reappointed and so on and the other hand
you had um some private actors that you
know pushed their their domestic
governments uh toward their interest and
uh their interest was of course not to
have uh rules in these specific sectors
saying that you know uh compared to
other sectors the European companies
still had a
chance uh to to compete with big Tech um
so I would say this was possibly the the
most delicate moment you also had a very
delicate one during the last trialogue
itself on law
enforcement uh when everyone was really
exhausted they had been negotiating for
I think close to 24 hours straight and
you know I think that uh everyone was
really nervous attention was through the
roof and the end they called for a
recess uh and I think that was uh that
was a probably the good call to make
since all you know policy makers are are
humans not AI so they also need rest so
you made a great impression right on all
of us it we saw the pictures like they
were hours and hours so for everyone
that said that European bureaucrats
don't work so that picture showed that
at least with with this topic they are
working hard yeah I mean you know again
this comes back to the political
pressure and time pressure and I think
you know probably then we'll come to the
final text later on but I think that
probably that played an important role
in how the the AI act landed because
there was a political need to find an
agreement by December if they didn't
want to miss this opportunity and you
know with a new mandate you never know
what happens
so and as as you were hiding in the
meeting rooms I'm kidding so as you were
paying attention to the discussions and
and the details of the discussions do
you think that the the members of the
European Parliament they have technical
knowledge what did you feel the
discussions there were all the time
there were technical people involved
well you know this is a technology where
you have very few experts well a lot of
improvised experts but not so many
actual experts and uh especially elected
officials like MPS they don't they are
not elect for their technical knowledge
right they are elected because they
represent their constituents so I think
it took some time for all institutions
to build up expertise in this area just
because it was completely new for
everyone to regulate um I know a few
experts that were in the background
indeed
advising uh and you know like actively
also during the negotiation
I know of uh of uh professors or
also um NOS that were advising on on the
more technical level I would say their
European Parliament they probably
started uh their work early with the Ida
committee this adok
committee uh that was set up uh 2019 I
think something like that um for the
commission it was the White paper so you
know there was some Preparatory work so
the AI act didn't didn't drop from the
sky from one day to another good
interesting so as we were talking about
professors and law so I want to ask a
question to Professor Jen cloudo uh why
I want to hear from you a little bit
about your research if you want to
explain to the audience for those that
are not familiar so why explainability
and transparency in the context of AI
and especially in the context of general
purpose AI system so GPT why people need
to know or is it possible or aren't we
pushing it too much and actually it's
it's not possible so why do these
obligations
matter great uh thank you so much Louisa
for this uh opportunity for this
question also um so of course it's not
easy to answer but I can give of course
my two cents on the topic and I agree
with you that uh and with look at that
uh you know the the the efforts towards
a human Centric approach today I yeah
Act was meaningful in particular in the
second half of the negotiations and um
yeah you mentioned some important
elements there uh you mentioned the
explainability requirements that now we
have for high-risk AI systems um I I I
would like just to connect this with
what was before the act in Europe we
have the gdpr and there was a lot of
emphasis on article 22 of the gdpr which
is the right not to be subject to
automated decision
and the connected rights of individuals
to have a human in the loop in case
decisions are automated and have
significantly or similarly significant
effect on
individuals um then they have or um the
right to contestation right to uh
Express one's view connected to this
there was a right to know the logic of
algorithms but this Duty was just for
data controllers data controllers are
usually just what in the ACT are the
deployers so the users uh like my
University using AI on H students God
know but uh or whatever uh the law
enforcement Authority well law
enforcement are not under the gdpr but
under the law enforcement directive um
you know a companies at Tu AI so they
can
somehow uh give some logic about the
reasoning sorry um about the the the the
decision- making system but now the I
act is covering the gap between the
producer of AI who are the ones that
know I should know at least or should
control or should have um a yes or no
decision on whether we want to go on
some uh uh unexplored uh impossible
black box or white box systems so the
Gap from them from from there to the um
uh users of AI systems uh I think we
needed this step we needed to impose
this duties of explainability on the AI
provider thei producers thei designers
however we want to call them to make
meaningful to make use of article 22 of
the gdpr of a possible Right to
explanation with all the limits of
explanation so this is important in
terms of stakeholders and in terms of
scope and and I think this was a uh this
was something very very uh important
then you asked about generative AI uh
well for generative AI this was also um
very interesting in terms of
policymaking um from the very initial
proposal of the commission we know that
general purpose a general tvi was not in
the proposal but then the political
pressure the media the release of CH GPT
uh in November uh
22 uh uh um raised issue of this urgency
we needed to do something right and it's
super interesting because if the EU
policymaking would be quicker we
wouldn't have the opportunity to add
General P regulation in the in the law
because actually this was added after
one year and half from the first
proposal of the European Commission in
other ways we could say that this law is
in general a AI laws are
intrinsically um um non technologically
neutral because they need to look at
what's happening in the last years but I
think the AI Act is wise in that respect
because it's identifying the issue of
general purpose AI it was not too late
to do that and then putting some
predictability requirements and this is
something important all the the all the
critics all to the AI act say well let's
say critic from rightwing are saying
well we shouldn't regulate because it's
impossible because we don't no because
we cannot predict Etc right but the
point is that the AI Act is giving
predictability to what is permitted and
to what is not permitted gener
generative AI had already been
prohibited in Europe but at National
levels we saw the example of Italy with
the garante data protection authority
that a couple of years ago uh decided to
block J GPT also for the transparency
elements they had several conditions and
lists of why CH GPT should have been uh
blocked in Italy one was about children
and another was about transparency uh um
and also understandability and also the
enforcement of some uh data protection
rights like right to accuracy Erasure
Etc so in that respect I think now the
ACT is saying general purpose AI of
course well there's no Prejudice to the
gdpr so if there are data protection
problems okay the protction authorities
can regulate can decide can block can
give sanction still we now know that uh
if General propos I respect the systemic
risk uh assessment duties and the
transparency duties that are in the
special part of General poosi um chapter
in the AI act uh they can they can
release they can use they can
commercialize the system so yeah and and
and why is it important to know and to
understand I think I think um one thing
we should look at and then I will
conclude is not just technical
transparency technical transparency is
super important the other step is
critical transparency now I'm citing Mel
IL debrand she wrote 12 years ago about
critical transparency as uh the right to
know the risks the right to know the
implications so what what I think this
human centered regulations from the gdpr
to the ACT are trying to do is we don't
need just we we we don't need to know
just uh how the black box works but the
impacts that this black box have on
fundamental rights on Society on human
rights so maybe the Black Box cannot be
opened but the effects of this black box
how this black box affects other things
impacts other things this can be seen
and can be uh prevented so there are
some systems that cannot be explained
but all business models can be mitigated
and and
explained thank you so much and I want
to follow up also now with with another
question so article 29a of the AI act
establishes fundamental rights impact
assessments for highrisk AI system so
deployers have to perform this uh fun
FIA right the the the the acronym
fundamental rights impact assessment
before they deploy a highrisk AI so I
want to ask you how do you see this
impact assessment so do you think it
will be effective and it has a big name
fundamental rights so the way it's it
was legislated so the way the text is
written do you think it will it's it's
what you were expecting so you were one
of the scholars that that were fighting
for it and you were asking for more
protection the final text do you think
it helps protect people or or just kind
of it was diluted and not so so
helpful oh thank you so much for this
question I think it's yeah of course
it's one of the topic close closest to
my heart so I think um just to rapidly
respond to this I will try to be super
brief uh it was introduced by the
European Parliament amendments uh uh and
then it was negotiated there were some
uh turbulences in the last months Luca
knows more about that because we were
reading from his articles uh and the
council the Spanish Council was uh
proposing a mediation because the
council sorry the Spanish presidency of
the council uh was proposing some
mediations in particular because the um
the um the idea that the council and the
commission had was that this freia was
redundant because you already have some
impact assessments uh for example you
have the data protection impact
assessment or you have for social media
for example you have already fundamental
right impact assessment in the DSA in
the Digital Services act article 34 um
so this was this idea that was redundant
so they want to wanted to limit it to
public authorities uh and not to private
authorities and also they want to to
make it mostly
so there was this final uh let's say
fight uh NOS helped a lot to advocate
for this and also Scholars as you said
we we we launched with the Brussels
privacy Hub we launched a a letter from
150 professors signing for a meaningful
fundamental right impact assessment U
but what what is the final taxt the
final compromise so we are happy that
it's not just for public authorities
it's also for private authorities but
just if they uh uh serve public
functions and then in the recital it's
explained that public functions can be
hospitals can be education so this is
good um uh and it applies to Banks and
insurances also explicitly so this is
also very good U the idea is that if you
limit freia just to public authorities
you are losing most most of the problems
right because you're missing the point
because we know that our fundamental
rights are at risk for also in
relationship and mostly to private
companies when we are consumers when we
are customers Etc so that is very good
what is not so good is that something
was moved to the recital the first thing
is participatory approach we really need
that this Fria have the participation of
impacted stakeholders this is still
there but just as a recommendation in
the recital not in the body of the
article so this is a bit disappointing
the other thing is that while in the DSA
the for for social media the frea the
fundamental right impact assessment
should be every year so it should be
regular on a regular basis here in the
AI act they say that this regularity
this cyclic Natura is just when risk
change when the level of risk change so
it's kind of uh arbitraria uh uh uh uh
cycling uh a timeline but yeah I think I
will stop now so I want to ask a
question to risto now so is risto is a
researcher and you you recently
published this uh the EU commission
Manifesto where you talk about
recommendations for the next EU mandate
I think it's very uh timely and
important so I would like you to share a
bit with the audience I'm not sure if
everyone is aware so please share a
little bit about it and from your point
of view uh what are the most important
recommendations and why they
matter yeah thanks a lot for having me
actually it's um interestingly it's my
birthday today what a what a great way
to have you know celebrate my birthday
with you having talking about one of the
first uh ever major comprehensive AI
regulations in the world right so thanks
a lot for having me yeah thank you I
actually before I respond to your
question I want to go very briefly back
to what um both Luca and John claudo
mentioned around General and the kind of
political process around
it I I want to push back a little bit or
like kind of add some nuances to this uh
this discussion so the European
commission initially released uh the a
act draft back in April 2021
and external stakeholders were asked for
input in August 2021 so a lot of like
over 300 different uh stakeholders um
submitted feedback to the European
commission actually already in November
2021 when Slovenia was leading the
council uh presidency they already
introduced an article titled general b
systems that was already before the end
of 2021 and and then in May 2022 France
made very sign France which was then
leading the European uh the Council of
the EU they made very significant
changes to that uh do that specific
article they actually asked very
meaningful requirements from the
developer of CH systems and now think
about when chpt was released November
2022 so actually o over a year of
discussion around General systems
already happened H not all of that was
around you know
very large scale language models or
anything like that it was all kinds of
other types of systems that were
included in the general Pap system
category but actually you should give
people should give a little bit more
credit to the EU institutions and the
policy makers because like arguably they
actually did foresee some of those
things based on also the input of I
don't know academics and civil society
and other stakeholders of course but but
yeah it's not it's not exactly true that
chpd came and you know completely
destroyed the the regulation even though
it did of course have a Major Impact no
doubt about that but anyway I just
wanted to like add that Nuance to the
discussion uh coming back to the topic
um or the question you asked yes um we
recently submitted U or or published an
EU commission Manifesto and we we had
something like you know seven or so
recommendations there but maybe the key
ones that I would highlight is one is
really ensure that the eui office which
is a new regulatory body that the AI act
uh set up is robust and has the ability
to perform various tasks that it has
been set to do uh this is no small feat
because the number of tasks that they
have is actually quite significant they
they have to uh monitor the regulation
how well the regulation is working they
have to try to enforce it they have to
coordinate between member states they
they have like the whole general b
systemic risk designation issue and
topic they have a lot of of different
tasks and the AI office plans to hire up
to 80 people over the next year or so
together with 20 people from the
European commission up to 100 staff uh
so compared to for example the UK safety
Institute which has been um working for
the last year or so already uh they are
at a very early stage and I would
recommend them to you know make sure
that they are in touch with the uks
Institute learn everything that they are
doing make sure that they have enough
money to hire the best people to carry
out these tasks it's uh going to be a
huge challenge second thing we
recommended was actually you know
continuing um developing this regulatory
package around digital Technologies so
uh the the current European commission
or sooning to be the previous one
started the a ility directive which uh
should be continued they should finish
this and arguably it was put on pause
exactly for the reason that the AI act
would finish and then the liability
directive would people could make sure
that it's um quite aligned with the AI
act uh so why is it necessary well the
eua ACT mostly talks about exanti
requirements so requirements uh for
companies before they put something to
the market and and hopefully that that
will reduce risks right but it's not
guaranteed that even if they follow the
Act to the letter that they will avoid
all kinds of Damages and incidents it's
not guaranteed and if a damage or or
some kind of harm occurs who is liable
who is who should bear the cost who
should you know support uh those who
have been harmed I think it's very
crucial to to finish that um legislative
document as well and then finally
there's a a mechanism called the codes
of practices for General p and and these
are B
essentially you know guidelines
documents that companies can follow to
show compliance with their act
especially when it comes to Cha tools uh
or um systems before technical standards
are developed for for those kinds of
models and systems and we think it's
extremely important that those are
drafted with the inclusion of Civil
Society companies industry oftentimes
has a lot of power over technical
standards these guidelines and for good
reasons but Civil Society has very
strong advantages um that they can add
for example they are they don't have
commercial interest they're interested
in the public good uh how how well uh AI
systems work for the for the whole
society and they could bring that
perspective and make sure that the
industry doesn't you know only serve uh
their own interest and and sometimes
they can also bring a lot of expertise
that maybe industry doesn't have so yeah
those those would be the main things
that I would highlight from all the
seven recommendations that we have
people can look up our document and you
know um look for other types of
recommendations there so now let's move
to a more uh Dynamic part of the the the
session today so I want to hear uh from
each of you a little bit from the same
topic so from each of your perspective
when do you see the final text of the EU
AI act what are the most problematic EIC
issues and why so let's start with
LCA well that's easy I'll give you only
one um
typos
um I was actually at an event with some
lawyers few weeks ago and and one of
them told me it's incredible that they
would publish a law with typos it's I
mean from a lawyer
perspective this makes their job so much
easier easier because yeah you know if
you take the part on um open source
software it say the opposite of what is
the the legislature meant to say and you
know if you have a text that is not
polished unclear it's very easy for
companies and lawyers to go around it to
to get it dismissed in court so you know
I think that
the the highest price that the political
momentum had to pay for the AI Act was
the quality of the text so the lawyer
linguist are meant to uh polish the text
uh let's see if they do some Miracles so
but I think there are parts of the text
that cannot be fixed if you take article
six it's a mess I I would challenge
anyone to say they have a solid legal
case to use the filtering conditions for
of article six I think you know the the
text is so uncertain only if you are a
rich company you take the risk to get
fined afterwards so you know I think on
on certain parts the text is truly
self-defeating and that the overall
quality even by the admission of people
that have been involved is it's quite L
thank you Luka uh so J
Cloud yeah so um yeah first of all I
would like to say something I was a bit
disappointed with is the emotional
recognition part um from a from a legal
ethical perspective emotional
recognition is one of the most
problematic and intrusive things um uh
maybe just just uh as as an initial
disclaimer to this answer before I I
dive into the emotional recognition
thing uh I see this was a huge effort uh
it started as a as a safety uh like
product safety instrument and now it's a
fundamental rights General
regulation uh so it was huge and it's
normal that we have typos we have
problems because of course it was huge
with so many stakeholders such an
intense I think was the longest or one
of the longest trialogues everever uh
one of the longest list of amendments
ever more than the gdpr uh much more and
the gdpr was the unpre unprecedented
case and and also about the the the
general purpos development as Riso was
saying just to to to to to clarify on
that yes the Slovenian presidency had
already advanced this but now it's a new
treaty on General AI because we have six
articles you know just to say how it it
grew okay but uh something could have
been done better in terms of emotional
recognition as I was saying in the
initial proposal of the commission
emotional recognition was considered
limited risk and of course it's it's
it's crazy right it shouldn't be
limmited it's it's it's very
problematic uh the parliament had
proposed to burn emotional recognition
but there was this discussion that this
pseudo science you are going to limit
science all these discussions and also
the therap therapeutic use the
anti-suicidal use Etc now it has been
put as high risk but a couple of cases
so education and employment are
prohibited so you cannot detect emotion
of uh in the employment context and in
the educational
context so it's a why not in other
problematic Fields why not on migration
why for migration purposes should we
shouldn't we ban emotional recognition
you know I as you said I've worked a lot
on vulnerability and one of the biggest
sources of vulnerabilities being a
migrant uh uh uh you know facing the
challenges of borders and emotion Rec
contion there it's extremely problematic
it's it's high risk now but it could
have been uh better uh another problem
because you asked to two three bullet
points uh is uh the definition of
vulnerability maybe we can talk it's uh
there are lights and shadows I like the
fact that it has been expanded from the
commission proposal because the
commission was proposing to ban just
vulnerability based on age and
disability now it's also social and
economic conditions article 5B um still
there's something that could have been
uh uh um better included but maybe in
the positive parts we can say that there
is another article that expands this
freia we already mentioned there are
some limits for the fundamental right
impact assessment the participation and
the um the the the periodic uh uh uh
timeline uh maybe last thing that was
also criticized a lot by ngos in the
last moment is article 29 about expost
biometric surveillance it was something
that was added in the very hot
discussion about Article Five so about
biometric surveillance the exante Biomet
the realtime biometric surveillance is
now now more or less limited with
several caveat and disclaimers but the
expost surveillance is is still possible
uh so the expost analysis of biometric
things what we should cherish what we
should treasure is the data protection
laws and data retention laws so we
should now really make sure that this
article 29 will not will be limited by
data protection laws about retention
about you know uh the possibility of not
processing data Beyond purposes Etc
this point of view because if we think
of biometric data and in facial
recognition it will be a type of biomex
then we have at least the gdpr
protection the additional data
protection uh principles and rules
interesting thank you and
Riso yeah I have a couple of uh thoughts
so firstly I think this is a very long
and complex regulation and and so we can
expect it to be very hard to implement
in act uh in practice so I I've heard
some people make the point in
discussions that uh it is basically like
a Christmas tree everybody wanted to add
something and you know it grew and grew
uh and and they got their favorite thing
on the on the tree H as a for some kind
of you know description of of the
complexity or as as a proxy for that uh
the senior policy adviser at the
European Parliament Laura coroli uh she
recently compared gdpr and the act on
LinkedIn and according to her the ACT
has 180 recital so recital are these
background text background information
for the specific Provisions uh compared
to gdpr's 173 recital so more recital uh
it has um 113 articles compared to 99
articles in gdpr and it has 68
definitions compared to 26 definitions
in gdpr and it has 13 annexes and no
annexes in gdpr so and and people
complain about how difficult gdpr
enforcement has been over the last
couple of years we can expect this to be
very challenging for the act as well I
have we received tons of comments
already from some stakeholders saying
hey like it looks good this uh this AI
act on paper but like what does this and
that thing actually in practice mean
like what should we actually need to do
and my response to them usually is well
we should wait for the European
commission to develop guidelines uh
there will be technical standards codes
codes practices you know different
people will develop new services but it
it's going to be challenging right lots
of uh lots of work ahead and and maybe
the second thing I would mention uh here
uh is a general Papi governance actually
in this uh in this document is is quite
weak compared to like some some versions
some uh some negotiation proposals that
were on the table based on some of the
leaks that Luca shared and other
technology journalist for example it
completely lacks third party testing and
auditing compared to like I saw some
version where uh it was independent
testing and red teaming was mentioned
but at the end of the day providers need
to perform model evaluations for example
General a with systemic risk these kinds
of model providers they need to perform
model evaluations just internally uh why
should we trust the what the outcomes of
the that model evaluation that are
coming from the companies uh that's
that's significantly weaker than uh than
could have been reasonable and yeah I'll
stop here because we're running out of
time soon thank you so now let's be
technology Optimist or law laow wise
optimistic is there something to
celebrate so is there what are the the
positive sides so Jan Cloud let's start
with you uh yeah I am an an optimistic
person in general as a lawyer I I try to
take the best of what we have I'm
positive the I act so uh I must say I
I'm reading in the chat there are
different views that no regulation is
better than typos or or something like
that I think we should keep clear in
mind that AI has huge
externalities very high risks that we
cannot just regulate through data
protection because data protection is
the last part and and and it depends on
on on on many scope problems about scope
we cannot just regulate through the
platform problem because AI is affecting
also us offline I was mentioning the
Border there were discussion I see I saw
in the chat about the Border actually it
applies to border so it's not excluded
from the scope the ACT I mean so what is
good first of all red flags we have
something that is prohibited very clear
so what is good I think is that the risk
analysis is not just left to the
autonomy of companies there is a
political decision on what is in the red
zone in the prohib lied Zone this is the
first time this is something where the
European Union is saying we as as
fundamental right Concepts we set some
threshold that cannot be overcome so
this is a first very good thing uh
second is the fact that it was moved
from a product safety Tool uh to a
fundamental right tool and we mentioned
many things about that the attention to
vulnerability the attention to different
levels of risk assessment there is a
risk assessment at the level of uh
deployers uh uh which is the freia and
the risk assessment at the level of
producers which is the risk assessment
article 9 and then we have risk
assessment for general purpose a um it
might seem a mess but actually it's it's
setting important principles then we can
spend 10 years to implement but at least
we have these principles that courts and
Regulators can use um and maybe the last
thing is uh that it's the first law that
clarifies on some important Concepts
that were never in a law like the
concept of buyer as the concept again of
general purpose AI the concept of of of
systemic risk um it's it's broad
principles there are many vague Concepts
but at least for the first time the law
is not uh uh um based on Old Concepts
that might have problems if we think at
the US systems even for data protection
they're still based on T law mostly or
some national National laws like
California Etc but can we really in the
age of information naal capitalism base
the protection of our data just on Tor
law is the same with AI could we just
base the protection of fundamental
rights in the age ofi just on data
protection or platform regulation maybe
not so yeah so looka thank you um well
you know if you look at the status quo I
think indeed the AI Act is an
improvement uh especially in terms of uh
setting out a framework on how to manage
r
and basically to set the boundaries for
for this new technology and what is
allowed and what should not be allowed I
think uh though in terms of uh legal
Clarity which was uh one of the main uh
reason to present this proposal from the
start I
think the legislator could have done a
better job uh the the Mission will have
to do some heavy lifting in terms of uh
clarifying what the text means in
practice with this guide guidelines and
and secondary acts um overall I think
the the EU has taken a leading role also
in terms of uh prohibited practices and
what should be you know not
allowed uh to be used and uh I think
what we saw with the Council of Europe
where they propos that signatories also
issue a moratorium on stuff like social
scoring I think this is one of uh the
the positive sides of the AI act then of
course uh we will see uh quite
significant um compliance cost for
companies especially those in the
highrisk area I think that one of the
risk uh we could see from the AI Act is
that companies prefer not to go and you
know create uh applications in the
highrisk area simply because it's more
costly for them uh but those are
actually the areas uh that might bring
the most benefits to society so you know
as with everything it's a bit of a mix
back uh overall it's better than what we
had before and sets out an horizontal
framework for using art artificial
intelligence that is nowhere to be found
uh at this time in the world I think the
the job is not done I mean as we saw
with the
gdpr it it's the sixth year since the
entry into Force we are only starting to
see now case low and you know uh
International cases uh being uh being uh
brought forward so I think for the A and
and and let's keep in mind that the gdpr
didn't didn't start the process H we had
a data Protection Law and a Privacy Law
before in Europe the AI Act is
completely starting from scratch so I
think this will be a long process uh we
are talking about five to 10 years to
see the most concrete effects in terms
of shaping this uh Emerging
Market uh and at the same time uh I
don't think that the job is completely
done because the this discuss
has also shown that there are limits to
the AI act in terms of what it can do
for copyrighted material uh there will
probably be an initiative of the
Commission in the next mandate on this
uh they already talks to have uh some
other vertical initiatives on AI in the
workplace so I think this will be one of
the you
know this will remain on top of the
agenda uh both in terms of legislation
but also in terms of enforcement in the
next years
risto yeah a few things uh that are
really good in the act one is uh for
example The Innovation measures for
smmes and um EU startups so there's
previously I think it was Article 55 but
now after some kind of reordering and
renumbering I think it's article 62 that
talks about specific measures uh of
innovation so
uh for example there will be Priority
Access for smmes and EU based startups
for regulatory sandboxes so these are
environments where uh smmes can without
you know SE serious repercussions
necessarily they can before they deploy
something to the market they can
experiment get some feedback some
guidance from uh from Regulators from uh
yeah you know that they comply with a
act also they hopefully will receive
some reduced like They will receive some
guidance uh from to comply with the ACT
generally and and the fees will be
reduced for them the compliance cost
will actually be lower uh thanks to
these Innovation measures uh is the Hope
based on this article um also the
commission will regularly
review whether the yeah how how large
these costs are uh for thees and
startups uh to make sure that uh if if
it can they could be reduced if they're
too large so I think that's overall
really good also I think somebody
mentioned earlier the the future
proofness about this regulation I think
everybody all the policy makers actually
quite carefully considered future
proofing the ACT which is partly why
it's quite General and and vague because
they didn't want to be too specific and
be outdated immediately uh so there are
some instruments that allow the the law
to be changed um so delegated Implement
acts these kinds of second legislation
that the commission can develop for
example the commission can change the
definition of AI system they can change
the criteria that exempt AI systems from
higher risk rules uh they can change
what is in the higher risk use cases
category and what isn't there uh they
can change threshold thresholds for
classifying General Pap with systemic
risk um technical documentation they can
change some things there um so yeah a
bunch of things that they can change
which is quite good um to because AI can
advance quite quickly and and we need to
um make the yeah update the law to be in
line with those changes maybe final
thing uh which maybe not everybody paid
attention to but I thought it was really
good so the the ACT covers the whole
value chain better now than they than
the original version did so the original
version kind of focused much more on the
deployers of AI systems but but now
there's kind of more focus on the the
range of stakeholders like the the model
Developers for example the initial ones
especially when it comes to general
purpose AI they have a focus as well the
value chain is quite complicated when it
comes to AI development it's kind of
like car manufacturing there so many
different bits and pieces uh everybody
can reduce everybody has in that value
chain some type of strengths and
advantages and they can reduce certain
risks and not others for example the
initial model developer has a much
stronger position to uh you share
information about the initial mod or the
training data perhaps uh uh help help
the the final deployers comply with the
AI act whereas the final deployers they
know the use case better they are very
heavily involved with the clients they
they know if they want to fine-tune
their initial model with their training
data they can cure it make sure that the
training data is representative and
unbiased and and whatnot so I think that
was a really good addition care about
the value chain make sure that different
stakeholders have some obligations in
that thank you R and the AI Act is only
the beginning and in your view what are
the next step and also if you could
maybe thinking about the audience what
do what do you say to the audience
something that people could do right now
especially those in privacy departments
or compliance Department do you have
something like do you have any
recommendations for for the audience so
please
uho uh sure I I think every everybody
can contribute to trying to interpret uh
the law in some way they can try to
develop some tools that would help with
that for example we at fli have
developed the eui ACT compliance Checker
which is like a very simple tool that
people can just use companies
organizations can kind of go through a
questionnaire and think about you which
one applies to them and kind of finally
have some indication of whether they
would have any legal obligations under
act it's kind of a tool to help them
kind of make sense uh another tool we
have developed is the act Explorer uh
which is basically like a you know
Search tool to check different articles
search for specific things they're
interested in fundamental rights impact
assessment where exactly is that in the
ACT let me just like search it quickly
and stuff like that so I think these
kind of tools like everybody can
contribute in some way uh you can yeah
you can just always educate yourself
about about the act more broadly but I I
would give recommendations to kind of uh
all the experts and the policy makers
who are involved in this uh process as
well yeah continue working on the aab
directive is very important to to
finalize finish that make sure that we
have damages harms um you know covered
and and it's in line with AI act and uh
with AI generally
also uh make sure yeah make sure that AI
office is as competent as possible has
everybody can speak to their machine
learning friends to their legal uh
expert friends uh tell them hey there's
AI office they're hiring maybe you want
to contribute to that process it's like
one of one of a kind institution um and
policy makers hopefully will take it
seriously and make sure that the budget
is serious for this institution the UK
safety Institute has committed uh has
been able to commit something like 100
million pounds uh the EU is still quite
vague about how much money they have for
this so uh that's a very important thing
and maybe
finally I would recommend just kind of
to focus on a larger narrative about
Innovation slightly differently like we
frame The Narrative from like let's
let's uh increase Innovation or that
kind of stuff which is like a very
general thing that everybody talks about
oh AI helps Innovation let's talk about
actual meaningful applications for to to
solve some of the biggest pressing
issues let's talk about AI for reducing
uh climate change make sure like AI
contributes to uh you know Global
poverty and things like that like we
don't want any kind of AI Innovation
maybe we don't want emotion recognition
maybe we want some other tools some
other uh products that actually
meaningfully help us innovate uh in the
direction that benefits everybody so
yeah we frame The Narrative a bit on
Innovation thank you D J
clo yeah so uh um um let's say
recommendations as you said maybe for
the first for the regul later is to
really now Implement Article Five let's
understand what's prohibited in practice
and I I know they're already working on
that DG connect is working hard on that
it will be the very first important
thing because it will be the basis of
all the other uh uh legisl what's what's
what's really article 51 a b c Etc uh
for companies uh the the the most
important thing in my view is to um
first of all uh taking uh seriously the
the other uh pieces of legislation
making sure that there as you said we
already mentioned things that are
already there and if they were taken
more seriously the ACT would be easier
privacy by Design uh impact assessment
in different forms we have in the DSA in
the gdpr ETC if uh we take these things
seriously now it will be easier to to to
adapt to the AI act and for most
companies uh indeed the freia is the
challenge because they as as users it's
mostly they their challenge so trying to
understand how to do impact assessment
building on existing models and
connecting the models most of the people
that will need to do this Freya have
already a data protection impact
assessment that is may be you based on
poor reductionist questioners based
mostly on cyber security we should go to
the next step we should wonder what is
impact on fundamental rights and this
will be this will make things easier for
the
fre thank you Luca
thanks um I'll on what was said before
on the AI office and you know ensure
that it's sufficiently staffed and
resourced I mean if you look at stuff
like Article Five or Annex three on the
highrisk categories it's clear that
these are are uh written in the sand I
mean they they can become out of date
very quickly uh so the commission should
keep the polls on where the industry is
going and engage with stakeholders uh
experts not just as a tick the Box
exercise but actually uh having
meaningful uh exchanges with experts uh
for the private sector of course now
everyone is trying to figure out uh if
uh they fall in the highrisk category or
not I cannot tell you that of course um
what I can tell you is that there will
be plenty of B2B uh Services coming your
way and uh AI
safy uh organizations and so on so
you'll be fully covered I think there
will be a temptation to underestimate
risk uh that should be resisted
especially from startups that need the
money now and can risk a fine for later
I think this will be uh you know
probably punished uh by investors
so that there should be a responsible
behavior in this sense uh but I mean as
I as I said before the text is still not
fully clear uh and legal departments
will have to scratch their heads over it
um let me just conclude by saying that
the AI liability
directive I don't find it particularly
relevant actually a liability for artif
icial intelligence is already covered by
the product liability directive that has
a strict liability regime much stricter
than the AI liability directive which at
this point we don't even know if it will
happen since the
parliament uh is doing an alternative
impact assessment so you know this is uh
still to be seen But actually if it's
not on your radar product liability
directive is much more relevant it will
cover uh all type of products including
software including AI um and probably
Foundation models too so you know the
impact uh that we would see coming from
private enforcement I think will also be
very relevant and I'll close with
that thank you LCA so we are time is
over so where can people find you you
can say anything your newsletter your
blog your your social network works so
Luka where can people find you you can
follow my work on LinkedIn and
X okay
Riso uh same LinkedIn and x uh Twitter
and Jo clo yeah same LinkedIn and x and
maybe just to say follow also the ELO
website our research Department we have
a summer school on this topic and other
initiative so maybe just to say thank
you so much and I hope to see you in the
next live sessions bye-bye everyone
