welcome to the AI policy podcast a
podcast by the wadwani AI Center at
csis I'm Gregory C Allen and I'm Andrew
Schwarz join us as we dive into the
world of AI policy where we will discuss
the implications of this transformative
technology and what governments around
the world are doing about
it welcome back to the AI policy podcast
I'm Gregory Allen today we've got a
discussion with Professor alandre Nelson
who is the heral F Linder professor at
The Institute for advanced study and a
distinguished senior fellow at the
center for American progress from 2021
to 2023 she was the deputy assistant to
President Joe Biden and also the acting
director and principal deputy director
for Science and Society at the White
House Office of Science and Technology
policy in 2024 Dr Nelson was appointed
by President Biden to the national
science board the body that establishes
the policies of the National Science
Foundation and advises Congress and the
president pres alandre Nelson thank you
so much for joining the podcast I'm
delighted to be here thank you for
having me so we're going to have a broad
conversation covering so many different
aspects of AI policy but before we do
that I want to get a little bit of a
sense of you so I'm curious you know how
you actually have this long career at
the intersection of technology in policy
how did you get started how did you end
up at the at the White House and at
Princeton and also how did you become
interested in AI specifically yeah great
question to to begin so I'm a
sociologist of Science and Technology
and my work has often focused on the
social implications of new and emerging
Technologies I've done historical work
and about when communities were first
trying to understand what a then new
genetic science meant for them I spent
10 years sort of tracking the sort of
emergence of direct to Consumer genetics
in my second book is a startup industry
and trying to understand whether that
would stick as an industry and and why
and I was embarking on my third book
which was going to be a kind of bird's
eye view of Science and Technology
policy looking at the policies of the
Obama Administration um in part because
they had done some ambitious work around
genetics so the gene so human genetics
research is kind of a thread through all
of my work and I was very interested in
the fact that President Obama laid in
his second term announced the Precision
medicine initiative this big initiative
to get the genetic of a million
Americans place it in a database for
scientific research from the Human
Genome Project to the Precision medicine
initiative and Obama administration that
sort of trajectory of research had
always also been um a trajectory that
was about computing power and so if you
remember the Human Genome Project is a
collaboration between the Department of
Health and Human Services in NIH and the
department of energy because you needed
these early supercomputer power and so
part of what was happening in the Obama
Administration was also thinking about
what do you do about data how do you
gather it how do you process it and so
you know given my research on human
genome and and genetics it was clear
that very early on that genetic research
was also going to be algorithmic
research right that these were some of
our very first big data sets as we used
to call them and that the work of human
genetics research was really trying to
figure out what do you do with all this
data so by the time you get to things
about a decade ago like genomewide
Association studies you're dealing with
these sort of vast caches of data and
the question is what to do with it so
some of the early kind of algorithmic
systems were in that space and so I had
been thinking about what we used to call
Big Data for a long time part of my
research on the Obama Administration was
also looking at its white papers on big
data and on um by the time you get to
2016 uh Ai and sort of yeah this is the
uh Ed Felton and terara lions report was
a measly intern in the White House
Office of Science and Technology policy
while Ed and terara were working on
those reports so I I remember them very
well okay well you're I you know you're
nodding kind of vigorously so this I'm
telling you your life story I mean so so
I think so that's really how I come to
to Ai and it also means that I think
about AI policy I think always it's
always for me about people like you know
so so so big data sets have never been
abstractions to me they've been about
people and their genetic data and so
that's been one of the ways I think um
that I I think distinctively think about
um AI policy so I think of sociology and
please correct me if I'm wrong because I
don't claim to have a sophisticated
opinion this on this topic but I think
of Sociology as a discipline as like a
we're Outsiders and we're proud of it
and like that is kind of our shtick is
that we're like on the outside analyzing
the universe so how did you make the
choice to jump actually into the policy
world and ultimately become you know
part of the policymaking community I
love that question um it's not only
sociology I mean I think it is all of
Academia I mean so part of how you
become successful as an acade as an
academic researcher is to be
iconoclastic to say everybody else is
wrong and I if everyone would just
listen to my one idea so you know I
would say true of Sociology but I think
also true of the the kind of academic
Enterprise um in some way um you know I
would go back to there's this very
important sociologist Robert Burton I
spent a decade of my career in the
sociology department at Columbia
University Robert meron was on um The
Faculty of Columbia decades before me at
the sociology department and he was
among other things a medical sociologist
and he talked about this
distinction um of studying you know the
medic the sociology of medicine or
sociology in medicine and I think
sociology of Science and Technology and
medicine has I think over the decades
done a little bit of both of those
things um and understood that you can't
really be shouting from outside of the
gates if you don't actually understand
the systems if you don't understand the
science if you don't understand the
technology if the well you can it just
might not be as effective right you can
always shout if want say if your aim is
to to bring greater insight and
understanding and Effectiveness you need
to to understand the sort of full system
that you're talking about got it and was
the 2021 White House gig was that your
first job in government or was there
some earlier
yes so I mean I you know I met in
government a lot of young people like I
imagine when you were an intern at in
the Obama ostp who all their lives
wanted to work in government was all you
know it was the kind of apex of their
lives for me I had started doing so I
was working on this you know bird ey
view of the Obama um Science and
Technology policy world had started
interviewing in 2016 people who had
worked in that office over those eight
years and found myself in a social
network and a kind of there a
sociologist would describe it I find
myself embedded in a social network of
people who were Science and Technology
policy makers and then when it became
clear that the ticket was going to be
Biden Harris you might recall that the
campaign stood up policy committees and
I was asked by se you know one person
several people who had been Who had who
I had interviewed and come to know in
the course of doing my research if I
would serve on uh the science policy
committee which I came to do when I
co-chaired a committee on social and
Behavioral Science in particular as part
of that science policy committee for the
campaign and then surprised to me I was
invited to um interview to be a deputy
at ostp and to um imagine to kind of
reimagine the portfolio I mean recall
that the Biden Administration entered
the entered office at like really the
high Watermark of the the covid-19
pandemic and lots of concerns and
conversations about trust and about
mistrust from everything from science to
government to vaccines there was a real
sense that we had to constitute this
ostp a little bit differently that we
had to have people who knew how to
communicate about science so I'm not
sure during your time who was in the
office but that there was a real attempt
to bring people who had expertise in
science communication and about
conveying to the public sort of more
clearly you know what what the work is
and was and could do and then also to
think about these social implications
and so I became the first deputy
director for Science and Society the
directorate was during your time would
have been called the science directorate
to sort of think about these things
together cool so uh you walk in on day
one and I'm sure there's a lot of things
you walk in on day one because we're in
a pic you walk like what may yeah yeah I
me you know we're sworn zoom in on day
one we're sworn in by the president on
Zoom yeah there's this kind of iconic
picture of the president I think maybe
in the East room with like five big
television screens with all these little
tiles of people's faces with their you
know with their right hands up and we do
the initial weeks of the transition on
conference call and Skype I mean very
few people were actually in the building
because we did not yet have a national
security approved version of Zoom we
didn't have like an Enterprise security
approv so it was Skype that and and
conference calls my goodness okay so you
don't walk in on day one but you start
work on day one it's your first job as a
United States policy maker I'm sure
there's like a lot of things that you
worked on I I want to focus on the AI
portion of the story so how do you get
from day one in office to what
ultimately became the blueprint for an
AI Bill of Rights which was you know one
of the early big outputs from the Biden
White House that you were deeply and
personally involved with right so in
January of 20121 I think you know the
second first or second week my
appointment is announced in Wilmington
Delaware by the president and in the
remarks that I give there I talk you
know I I get two minutes or something to
thank my family and thank my husband and
you know I talk about the fact that it
matters and when we're creating
algorithmic systems in those remarks
that who's at the table how we think
about we're constit how we're
constituting them how we ensure they're
safe and the like and so I came into my
role at ostp with a sort of mandate to
think about you know carrying the Baton
of some of the work frankly that had
been done in the Obama Administration
around beginning to think about if we're
going to like land the plane and get AI
right and have what we needed to do for
Economic Opportunity both for industry
and for individuals deal with the
National Security piece and also make
sure that it is safe for people that we
needed to continue to be thinking about
the kind of cluster of issues around
privacy rights data um circulation and
the like so even before I started I had
been able to speak to that publicly and
then in constituting my team at ostp I
spent time thinking about putting
together a team of computer scientists
people who had expertise in computer
science but who were also good
communicators because it was clear and I
think also a lesson from some of the
prior work that we not only wanted to I
think distill what we thought were s of
best practices around you know AI
governance broadly we wanted to
understand what the American public
broadly kind of thought about it and
thought we should do in the space of AI
governance and we wanted to be able to
communicate clearly going back to this
communication piece that we started with
what it is we were doing and why it
mattered and why people should care and
the like so a science and Society team
had several computer scientists on it it
had people who were legal Scholars of
technology and then as you always have
in the White House policy generalists
people who are just they just know how
to to make the sausage and how to think
about things and so we began a process
by o October of 2021 so I should also
say you know we came into office the
office was the staff was only about 30
people and we really had to staff up and
there were kind of bial Congressional
reports that hadn't been completed these
sorts of things so you know so day one
or day two you know you have people from
the hill yelling at you being like we've
been asking ostp for this report on X
thing for two years now we don't have it
so there was all of that just kind of
like incoming but we were still having
conversations about how we were going to
think about this process and how we
going to address it and we ended up
myself and Eric Lander writing an Abed
and wired in which we sort of propose
and and announce make a call and Eric
Lander at the time was the director of
ostp right yes he was yes okay yeah so
the head of ostp yeah and we make a call
to the American public to say that you
know ostp the White House the president
cares a lot about the capabilities of AI
what the potential it might have to do
both good and harm and we want to begin
engag in a process in which we talk to
all sorts of people so obviously you
know the major constituencies at a place
like ostp are industry Science and
Technology researchers in Academia who
work on Science and Technology but we
wanted to broaden the tent which is why
we use wired and the oped includes an
email address that goes to the White
House so we had an ostp email address
people could write to us and they
scheduled you know they could schedule
time that we set aside time people
working on this team from across the
technology directorate at OST and also
on my team were asked to set as time
time every week to talk to the public
who got in touch with us about about
that so we spent about eight or nine
months having those conversations
meeting with regular folks you would
meet with that usvp from industry and
Academia but we also met with priests
and with rabbis we met with high school
students we took a page from the FDA and
did a series of just listening sessions
where the team just sat there and
listened and we used the FDA 2-minute
timer so anyone could come and sort of
speak their piece and they got two
minutes and we sort of collected all
that data and we did a request for
information about biometric so we were
kind of we just like spent you know 10
months just sort of taking things in and
then we distilled all of this and we
were not it was not a at all a play for
novelty because I think in the space of
technology and Innovation you know you
don't want government to be novel
necessarily um it was really what can we
do to ensure that these systems are safe
and effective and that people can to
have trust in them because the systems
themselves are not trustworthy um even
though we apply the label to them that
we you know in what instances do people
need to know when AI is being used and
how should we think about the you know
that point after decisions have been
made and how we get information back to
people like what should be the kind of
norms that we should be creating and I
think expecting around that so we have a
draft document and then it goes through
inter agency review and all of the
lawyers and all of the redlining and and
the this is the this is the draft
blueprint for an AI Bill of Rights yes
the draft blueprint for an AI Bill of
Rights it's a bit like a Rugby scrum you
know like so like the documents there
and it's just like paper and red lining
and pens and everything and yeah and
then we have then we have a a draft and
uh and we're and then it's released to
the world October of 2022 uh a month
before the release of CHA GPT as a
public facing the product no kidding
okay so talk to us I mean for for some
folks who were like really in you know
two years ago they might not remember it
as well as they remembered it then and
then for some folks maybe they weren't
paying attention at that time because
all they could think about was chat gbt
so what exactly was the blueprint for an
A bill rights what did it do how did it
do it and also it's like it's like a
blueprint right so it's not the AI Bill
of Rights it's this document called AI
Bill of Rights by default but it was a
sort of you know a blueprint how might
we think about these things so it
advances sort of five sort of
propositions five princi principles you
know I've alluded to them already AI
system should be safe and effective
there should be some uh modum of data
privacy which we have yet to achieve on
a federal level there should be
protections against algorithmic
discrimination particularly when AI
systems are being used for consequential
decisions around health care and resume
screening and you know housing access
and these sorts of things there should
be uh notice that you should know when
an AI system is being used particularly
for like for a consequential decision
and that there should be some sort of
fallback so if AI is being used to to
reach a consequential decision about an
important time uh in your life that
there should be somebody that you should
be able to get to at some point like not
you don't want to be caught in uh the
sort of AI version of a telephone Tree
in which you just keep pressing zero
frantically and like you try to get to a
human and you never do so like what is
the recourse that people have not if you
disagree with the recommendation that's
the Spotify algorithm made for you but
like you know if it's a if it's a which
you know sometimes you promised me I
would like this song and it was terrible
exactly you just press like forward
forward forward and then an ad comes on
and you're stuck with it so those are
the kind of five principles but the
document is nearly 75 pages long and
what all of that is the the rest of it
is sort of how do you it's one thing to
say as many organizations have there
have been a few kind of interesting kind
of research papers and meta analyses
that have been like how many academic
and nonprofit and Industry organizations
have issued some kind of principles
right so we were very cogniz like
hundreds of them a lot a lot a lot um
many of them say the same thing many of
them go nowhere so we were very
cognizant of that context and so the
conversation for us as policy makers was
what do you need to do if you if you
want to so if the proposition is that
algorithmic systems AI systems have to
be safe and effective what does that
look like in a at a granular level what
does that look like for a policy maker
what does that look like for someone in
an industry what do you do with that and
so that those were the best practices
that we took from from industry and
elsewhere around red teing adversarial
and not predeployment risk assessment
risk assessment and testing after
deployment of tools and systems so what
were the suite of of tools that we were
beginning to build up as a broader AI
ecosystem as this kind of multi sector
system that could get us to a place
where we said okay these systems are
safe and effective and so we sort of
pose that question what do you do like
that's the policy Maker's question what
are you going to do about it and you
pose so we pose that question about
notice about fall back if you if an AI
system is used around privacy and and
discrimination issues great so uh you
know you've got these five principles
you've got the other 75 pages I remember
my first time reading the blueprint for
AI B of Rights it's kind of got a doozy
of a disclaimer page right there's like
a disclaimer that says this is not a law
this is not an executive order this is
not explicit guidance and directions to
any federal agency so like what what is
this document how is it different from
an executive order how is it different
from a presidential speech like how does
it accomplish what it tries to
accomplish so I think it for for one
thing I would say that the subtitle of
the document is something like making
automated systems work for the American
public so really is not addressed often
policy documents are addressed to us the
like inside the Beltway WS and this was
really addressed to the public and it it
is written and it was an attempt to sort
of demystify the policy issues some of
the leading policy issues around AI
address to the public that reads 75 page
reports from the White House but I think
but I will say this it's very plain you
know it's attempted to be very plainly
stated and the document is not just a
PDF which is for WS it also is a website
that we tried to to the extent that you
can in the brittle you know drw pole
number two you know White House website
or whatever the the sort of back end of
that is make something ux friendly we
attempted to to do that and it was I
mean it was in the spirit I think of
some of the Obama documents that we
started with right like it was Raising
some ideas trying to plan a flag about I
think I think it's very it's fair to say
that like this is a document that relies
upon the White House's and the
president's power to persuade not power
to compel correct right yeah um okay
it's a very it's a bully pulpit document
it is a you know it's like it's an
aspirational document so this is what
you know this is what our our sort of AI
future could look like this is what you
know this is how you could feel
comfortable in that AI future uh you
know if these systems had these five
assurances around them so it was you
know it was a White House white paper I
think is probably the best way to
describe it but it also had a long taale
you know I mean it's been taken up in
different state legislators so very
early I mean within a few months of us
releasing it the Connecticut State
Legislature had a Bill signed by
Governor Lamont that basically said that
state of Connecticut should look to
accomplish its own AI Bill of Rights
kind of based on these principles so
that's a blue State last year and the
Oklahoma State Legislature a Oklahoma AI
Bill of Rights was was put forward that
includes all of the AI Bill of Rights
for as a as a bill and also has others
besides and so I I think it has created
in the public at its best a kind of
Common Sense around what can what should
non-experts be able to to sort of ask of
government and companies around these
systems and I think to start with the
first proposition of the AI Bill of
Rights safe and effective systems is the
very least of it I mean you know we
expect that from all of our consumer
products so we got to get there cool so
well uh tell me about the disclaimer the
disclaimer so you know so I use the word
scrum so part of the kind of a agency
scrum was around and what we say in
government you who has equities in the
AI space right yeah so I think 5 years
prior to 2022 or eight years prior
during the Obama Administration that it
would have been ostp has equities and
the department of energy and one or two
other agencies but by this time it was
very clear that AI was becoming and is
going to be a very powerful both
horizontal and vertical it's going to be
a very powerful
infrastructure Workhorse for all the
work that we do and it is going to have
all these pillars vertical applications
that might be very particular to the
work of HHS versus the Department of
Education versus the Department of
Justice and so there was a lot of
interest as you might imagine and there
was um concern about um as there always
is sort of what are what's the line here
between civilian and military uses
what's the line here between um civilian
uses and things that the intelligence
Community might you know want to do or
need to do or think they need to do with
these Technologies and so the disclaimer
um you know effectively is trying to not
only say you know this is not law or
policy or or whatever um uh in a in a
formal sense but it is also trying to
say um that you know there might be some
some non- civilian uses of AI that um
that you know may not currently or ever
uh abide um these five proposition these
five proposals got it okay so you left
ostp in 2023 but I believe it was after
the executive order came out is that
correct before I left before ah okay got
it yeah so talk to me about that period
of time after the blue print for an AI
Bill of Rights comes out but in the
runup to the executive order coming out
yeah so I mean in my time that was about
we use Chachi BT as a marker I mean I
think it was November to February in my
time I mean you know there was a flurry
I mean those of us who work in the
Science and Technology space have been
thinking and talking about AI for a very
long time I mean let's
recall to where we go back to where we
began the Obama Administration was
working on this in 2016 2015 right oh
that's when that's when the reports came
out they were working on it yeah well
before that right and so those of us in
that in that sort of CTO World CIO World
policy Science and Technology policy
World been thinking about this for a
long time but when you have ai that's
not just huming in the background you
know making you know recommendations for
your Spotify or your Netflix but becomes
a consumer facing product for the first
time the expectation for I think
politicians and policy makers is
different like it just has it totally
reset the table because now you had
people in the general public saying what
is this and what are we going to do
about this and is this a good thing am I
excited should I be excited or should I
not be excited right you know so yeah I
I think I think one marker that we've
we've heard here at csis when we've had
had members of Congress and the Senate
on is Chad gbt was the moment they
started getting asked about AI in their
constituent Town Halls when they went
back to their home districts their home
States it really was a different
political moment for AI and that's the
Firestorm you were thrown into
absolutely and we went from having you
know very close kind of Partners um in
this work who are the you know
colleagues on the hill who have been in
the space of tech policy for a very long
time Senator Warner senator lar
representative of V Clark you know
Senator Booker like you know to exactly
to your point all legislators having to
go home and say something about AI so it
also became it went from being somewhat
a niche issue to being one of the most
important policy issues of the day and
so that meant at ostp we had a lot of
incoming there was a lot of questions
sort of what are we going to do about
this well we had we had actually been
fairly forward leaning I mean with the
the blueprint for an AI of Rights and it
was there was also I think a a sense of
just wanting to calm people down you
know the conversation about existential
risk while we always need to be thinking
about the most catastrophic ends uses of
of very powerful Technologies however
there was this sort of sense that there
were not a lot of people in government
who God blessed them their job every day
is to be like someone's trying to kill
us and they're trying to use AI do it
right there was not there was a sense
that should government be doing this AI
Talent surge that's part of the
president's executive order should we
have many more people working across
government with technical um skills
broadly absolutely yes but the idea that
there were not in the IC and you know
various other places people thinking
about the implications of AI for
security risk was just so you had to
calm kind of calm that down I think and
you just had to sort of be able to
convey to people that there were folks
who had been thinking about this for a
long time and who
understood if not all of the
technological details of a fast-moving
technology because they're not inside
the companies knew enough and we're in
conversations every day and we engaging
companies to make good policy around
this and there was also I think a
challenge the novelty hit the public
felt so it felt so novel to the public
it felt you know we were part of the the
AI hype cycle of two years ago was about
cience and like kind of seamless uses of
this and that this new AI was something
approaching magic two years hence we
live in a world that we know is is not
magical in that regard but there was a
lot of anxiety and so one needed to both
be responsive but also be able to
communicate that people had been had and
are working on these things that there
are as the fact sheet that came out with
the blueprint for an AI rights
demonstrated agencies that already had
authorities and lebers to place
guardrails around AI rather that whether
that's the FTC or the department of of
Education that has now released kind of
best practices for how to use AI in
educational context like someone's home
and the lights are on and and and trying
being able to try to convey that in that
very heady moment was a challenge but I
think ultimately that the administration
during my time and then after my time
there I think really succeeded in doing
that by having just I think the
communication was pretty good there was
a clear set of deliverables going from
the voluntary commitments which I think
was the probably the next big thing
after the blueprint for an AI Bill of
Rights to the president's executive
order which I think does an incredibly
good job of dealing with AI both as I
said as a kind of a horizontal and a
vertical like we're going to lean into
using this for efficiency to do better
service for the public to do all of the
sort of core work of government better
we are going to use government
procurement power to help companies
partner with us as we're about to make
these huge multi-million billion dollar
Investments on systems that are safe
that you know deserve our trust and that
we're also going to engage agencies and
doing what they can already right now as
well as looking forward to ensure that
these tools are steward did well cool so
now You' you've left the White House
you're back at Princeton back at
Princeton I think it's fair to say right
you were there before so I want to sort
of get your perspective now you're an
outsider again and you're looking at
what's going on so I want to get your
reaction on what's going on in Congress
what's going on at the state level
what's going on internationally so let's
start with Congress you testified at the
Senate uh AI Insight Forum that's
organized on a bipartisan basis by
Senate Majority Leader Chuck Schumer um
and his gang of four bipartisan Senators
so what did you make of these forums
primary output that report and what do
you sense is happening or should happen
in Congress right now so that moment
that you described in which you had
legislators going to their home
districts and people coming to the town
hall asking for about AI was was an
extraordinary opening an extraordinary
opportunity a political opportunity to
really move the needle on things that
we've needed to do for a very long time
including very basic things like Federal
data privacy at some level and so I
think as an outsider um you know there
was some hope that that window would
allow us to get some traction and
movement on some technology policy I
mean we really have not had any sort of
major technology policy since probably
the communications decency act in the
late 1990s right I mean that's probably
the last time that we had sort of
muscular this is not how you would have
characterized it when you were in ostp
uh
so we haven't done any major policy yeah
well I mean you know we we I just that's
just to say that it's been a generation
since we I think as a as a country have
looked at the laws that sort of
structure and govern a lot of it has
been sort of tweaking This legal
architecture that had already been built
up over preceding decades I don't think
I don't think anybody's done a massive
rewrite of that architecture right as as
you said in in Generations so I had
Great Hopes it happened pretty soon that
Majority Leader Schumer called these AI
Insight forums to to to come to pass and
you know I hope that they would move
quickly with the kind of speed that the
moment really demanded and you know I
mean I think for Washington and for the
Senate which of the Congressional bodies
is supposed to be more slow and
deliberative let's say historically than
the house it did move at a clip I mean I
think they did sort of nine or 10
sessions over around nine months and
released framework I will say that you
know I felt that it was a missed
opportunity on several levels I had some
misgivings about participating in um a
conversation that was not open to the
public right you know we have we have
the public saying we're really concerned
about Ai and uh you know to have one to
have the response be we're going to
bring Civil Society academic industry
people to sort of have a conversation
about this and to not even have a
portion of it be public C span cameras
yeah yeah it doesn't have to be you know
there was not a gavel but you know it
doesn't have to be gavel to gavel
coverage but opening remarks or you know
something that gave a sort of flavor
they published they published the uh the
written opening remarks I think of
everybody but you're right there was no
cameras I mean and then the framework
itself I think again there was nothing I
think ambitious there there was nothing
when that framework could have I think
been written before you had the nine
meetings of people it you know I I don't
I'm not sure and and there's good things
in the in the in the framework right you
know we need to fund the rest of the
chips and science act that's been
approved all of that R&D funding you
know we want to make the national AI
research resource not just a pilot but
we want to fund it into the future so
there's good things there but none of it
required you know nine meetings of
experts to accomplish I think yeah and I
think you know the original ambition I
don't want to put words in the the
leadership's mouth but I think it was
they were looking at something like a
comprehens piece of legislation and I
think tell me if you disagree where
Congress is headed now appears to be
much more piece by piece right they're
looking at Deep fakes they're looking at
disinformation they're looking at sort
of a handful of other niches that they
want to go after and the sort of idea of
Omnibus legislation surrounding AI I
don't really hear about that much
anymore right yeah I think that one
could imagine an alternative scenario in
which they had moved a little bit faster
and I think would have had a lot more
political will to do an Omnibus but
there also is this fundamental tension
so if you think about the the sort of
congressional hearing that I think was
Senator blal and Senator Holly do around
AI that has Gary Marcus and Sam Sam
Alman Christina Montgomery from IBM and
another colleague whose name hope I'm
forgetting you know one there's lots to
say about that first kind of AI hearing
but one of the things that was really is
an interesting moment for me is when Sam
Altman says regulate us and Gary Marcus
is obviously as Gary is quite concerned
about Ai and sort of encouraging
legislators to to really think about
regulation Christina Montgomery from her
IBM Purge if I'm recalling you know was
very much saying you know IBM is a
company that really believes in
responsible uses of AI and wants to be a
partner in that etc etc but there was
this kind of I think underlying tension
in which that you hear when at one point
if I'm recalling correctly Senator
Kennedy sort of says to Sam Altman well
if we do this kind of AI regulation
something or other are you going to come
run it I don't know if you remember that
moment you know it was kind of like well
you know how seriously are we about this
and do we can we not imagine a role for
government here that doesn't you know
effectively include industry grading its
own homework on on these Technologies so
there's what that was so that was I
think a signal well before the Insight
forums about where we are and then I
think we have this also this other
fundamental tension which is right now
in the science and in the geopolitics
the United States is sort of leading the
world in AI development and employment
and so I think if you're a legislator if
you're a congressman or Senator Congress
person or Senator you're thinking well
if we change the status quo do we lose
the lead and I think that that there
were not I think we've not had good
answers I think there are good answers I
think one could can and must do both but
we've not I think in the in the in the
political space had I think a robust
conversation about that tension yeah so
let's let's change gears to a place
where there is Omnibus AI legislation
and that is the European Union AI act so
on August 1st 2024 the EU AI act entered
into force a lot of the standards that
this regulation is going to mandate
compliance with some of the drafts of
those are out what did you make of the
eui ACT while you were in the White
House and what do you make of it now
well we we tracked it very closely and
there were also other flows like the
trade and Technology Council there were
lots of kind of ongoing conversations
with colleagues in the EU about AI
policy that AI was one of the the sort
of pillars of the trade and Technology
council's work so there was ongoing
conversation so you know I commend you
know they paused the work and I commend
them after the introduction of
generative Ai and I commend them
actually for pausing the work and sort
of and sort of trying to
see if it was fit for purpose applies
what applies what doesn't apply Etc I
mean I think one thing that I heard in
Washington was like oh you know this is
why you can't legislate AI it's always
going to be behind but I think another
way of think about it is that the EU had
a process that allowed them to pause and
sort of refit um reimagine what they
were doing you know I think that it it
remains to be seen I mean they're very
much in implementation stage and that's
when you know things that sound good on
paper sort of Hit the the sort of cold
reality of the headwind of of all the
stuff you know that's coming and so
we'll actually I think we're very I
think we're in a a different phase right
I mean one phase was the act itself and
now we're actually um in the phase of
sort of seeing what it all means and so
I I'm right but now I've got to ask you
to give me a little bit more inside
baseball right so you're having these
these trade and Technology Council
meetings with your European counterparts
are you like jealous are you like gosh I
wish I was helping to draft
comprehensive AI legislation you know
that seems so exciting are you
cautioning them like guys you're going
down the completely wrong path somewhere
in the middle what what what are these
conversations like I think we're we're
curious and we are you know I tell for
myself curious impressed by the scope
and scale of it across 20 Nations 27
Nations I mean you know it is like how
do you get 27 countries to degree on
anything I mean that that actually the
sky is blue no it's not yeah no so that
that alone I mean as anybody who's
worked in government you do have to sort
of look at that with with some
appreciation but there was also you know
also we understood that this is um you
know the Columbia law professor Anu
Bradford uses the you know has given us
the term the Brussels effect which comes
from earlier work on environmental law
in California and political science
called the California effect right but
the sense that there can be one
governance sort of structure or
government structure that has a real
shaping effect um and that was certainly
California um and remains California is
now I think the world's fourth largest
economy so we knew that what happened in
the EU AI act pertained to us right like
it wasn't just we couldn't you know just
couldn't look from afar and say you know
it didn't pertain to us and so I think
there was you know in the conversations
one would certainly try to press for
what would be more beneficial for the
United States and and how people were
thinking about framing things up and but
how how how did you think about that
like how did you think about like what
the United States wants you know what is
in the US's best interest when you're
having a conversation about the EU AI
act right I mean one of the thing I mean
there's I think there's a lot of answers
but one of the things is is of course
that the the leading companies in AI are
American companies and so part of the US
interest is that you want these
companies to to thrive you want them to
do well and you don't want the Brussels
effect to impact productivity economic
growth competitiveness of the United
States I think those that's the kind of
the the sort of high level at the same
time I think what the EU model offers
were ways to think about well it was a
you know it's an experiment and ways to
think about how you begin to build guard
rails and think about guardrails so I
think there can be lots of questions
about and debates about whether it will
ultimately go too far and I think we
don't know because things are just are
in the early stages of being implemented
obviously Mario dragi thinks that it's
going to be a drag on European
competitiveness to have the EU AI act
but I think as a as a scholar I think
it's an empirical question and we'll
have to see you know I I take to heart
and I'm quite concerned about data that
suggests like we've got the Edelman
trust barometer from 2024 which is
multinational data about trust and lack
of trust in Ai and it's very high in the
United States Canada Australia you know
the kind of big Western democracies we
have pu research data that has pretty
high levels of distrust and concern
particularly around work and you know
other kinds of use cases and so I do
think it is all you know from my
perspective it's also in the US interest
to figure out how you build the
infrastructure that you need for trust
in these systems because if you don't
have that they're not going to be
adopted people are not you know you're
not going to have the kind of
enthusiastic option that one might want
to address some of the sort of big
issues that many hope that responsible a
uses of AI might be able to do so I
think it was a little bit of a of a kind
of of of a mixed response but with a
concern that you know is this
effectively you know how do we keep this
out of the lane of just being an attack
on American companies yeah fair enough
and then you've already talked about
this a little bit but I want to bring us
back to the to the state level AI
regulations what do you what do you see
going on here was the California bill of
course that got a lot of attention
around AI safety topics before it was
vetoed by Governor Gavin Nome what do
you see in what's going on in the states
that excites you or concerns you I think
I'm excited about I think the closest
model if we think about the states as
Laboratories for democracy the closest
model that we have for Omnibus AI
governance is Colorado it's a
comprehensive law it's now in the
implementation stage I think things are
happening in the scrum and we'll have to
see what happens on the other end of
that but forward leaning I think strikes
a great balance between guard rails and
you know wanting to drive Innovation
have work for people Etc and California
of course I mean uh has done so you know
s SP 1047 didn't pass which was you know
had a a lot of language around a
particular vision of AI safety but
Governor Nome signed 18 pieces of
legislation related to Ai and so they're
so California is making AI policy new AI
policy right I mean we had been you know
California has been good and I think the
AI executive order is very good on if
you want government to Pivot quickly
what can they use that they already have
what arrows do they already have in
their quiver that allows them to move
quickly and think about AI governance
issu so FTC has done that cfpb for
example but you know California has
really taken the lead around deep fakes
around sexual imagery you know Cam and
these sorts of things and I think we'll
we'll continue to take the lead and I
feel good about having California in
that California effect before the
Brussels effect space because so much of
the industry is there and you've got
legislators who are kind of comfortable
with the technology more than they might
be in some other states you know who
know the ecosystem and who have real
commitments to democratic values around
these Technologies and you know
commitments to um wanting to you know
not staunch Innovation so um I'm so I'm
I'm eager to continue to watch I think
there'll be um lots of new legislation
in California in the new session um as
well so I'll be curious to watch that so
vice president kamla Harris at various
times was described by the Biden
Administration as the
aiar um so you know one of the the point
people for AI policymaking in the White
House in the course of her performing
that role and you performing Your Role
you know you got the opportunity to
engage with her I'm sure on a
substantive basis if you had been aded
in you know a hypothetical future Harris
Administration what would you have
advised that Administration to pursue
and then I think you can guess my next
question after that but let's uh let's
go with this one first yeah well I think
first of all I would Point people to
it's important that the people know that
the vice president really knows her
stuff in this space you know I mean she
she actually it is not for not that she
comes out of a trajectory CER trajectory
of being a California politician and she
has personal relationships she has
social network relationships with a lot
of leading industry players I think she
kind of gets it she is a child of the
Bay Area there there you know I say this
as a a Californian myself like there's a
a kind of fundamental familiarity that I
think would have been tremendously
interesting and exciting for a future
for AI policy I would also say she gave
an extraordinary speech and last
November at the US Embassy in London
about you know the American strategy for
AI policy that was you know about kind
of really striking this balance between
you know running fast but like wearing a
helmet and shinguards and you know all
the stuff that you need to to sort of
protect society as we're doing that and
um so I I think that will be a very
important speech with towley and I hope
that that General sentiment will seep
into some of the work so I would have
been excited to to see in a in a Harris
Walt Administration you know the the
continued kind of expansion and maity of
the president's AI executive order which
you know I think really hits all of the
bases and not in a heavy hand and is
also encouraging the agencies and
government to and and sort of wise use
of AI tools and systems so I think it
would have been a good steady state I
also think you know there were some
concerns from industry that the Biden
administration had been not sufficiently
industry friendly whatever that means
and you know I think a president Harris
would have brought I think a different
orientation than President Biden to to
to Industry I mean these are like this
is a these are these are friend these
are people that she knows so I think she
still would have held the line on on you
know foundational principles about how
these Technologies should advance but
would have opened some interesting space
for new things uh to be happening and I
think as well um because she in my
experience you know she cares quite a
lot about the r dpace I think it would
have been also exciting to see her lead
and and helping us to think about how we
use AI for for different outcomes that
right now are market failure so how do
you you know Healthcare at scale some of
the climate science issues um some of
the space the outer space science I mean
there's there's sets of issues that
don't yet and may never have a kind of
commercialization pathway and I think to
have a champion for that and government
and for taxpayers Investments and these
sort of broader public goods would have
been thrilling yeah so now for the
incoming second Trump Administration
what's like the number one thing you're
you're looking out for in the AI policy
world yeah so one thing to say is that
compared to the Obama Administration
there was not a lot of science policy
and not you know in the Trump trump one
but they did uh they did a pretty good
job in AI I mean you know and so some of
the work that we did in the I think I
think what for for folks who were not
paying attention at the time for folks
who sort of started paying attention to
AI after chat gbt it's easy to forget
that AI policy was pretty bipartisan in
Trump one yeah yeah unclear if that will
continue to be the case but that
certainly I think was the case
historically yeah so there were two AI
executive orders that President Biden
did not resend in fact we you know we
actually implemented them so one was
standing up the national AI initiative
office at ostp another was to establish
the national AI advisory committee that
so that was work that we that was right
in creating the infrastructure that we
needed in government that we carried
forward I think one of the things that's
concerning is that there are a lot of
how how would I say it sort of
contradictory vectors about what might
be happening and so it will be
interesting to see how and whether the
the Trump 2 Administration even wants to
make some kind of comprehensive you know
technology policy or AI policy so you
have with the influence of Elon Musk
someone who has been a funer and an
advocate for a pretty WR program in AI
safety and so that on the one hand might
suggest AI safety Institute not only
continues to stand it is you know made
more muscular it's given more resources
and maybe industry is leaned on
persuaded to offer uh the models early
so they can be tested for before they're
deployed right now we have you know I
think just anthropic who's actually done
that on the other hand you know when you
have the you know potential people still
to be confirmed like pan bonding Bei or
cash Patel who could imagine might sort
of take all the guard rails off AI you
know so you've got you've got both the
sort of polls of kind of strong safety
and the kind of Las fair not even Las
Fair like you know potentially Las fair
plus uses for surveillance and
violations of privacy and for
Retribution quote unquote uh has has
been of that has been promised and so I
think that's concerning so as we move
into this this future this this new
presidential Administration you're going
to continue writing and Publishing on
these issues I'm sure so folks can find
your work through Princeton and through
your other roles Dr Nelson thank you so
much for coming on the AI policy podcast
great to be with you thanks for having
me thanks for listening to this week's
episode of the AI policy podcast be sure
to subscribe on your favorite podcast
platform so you never miss an episode we
also love to hear from you so reach out
at AI policy podcast at cis.org with
your suggestions and feedback finally
don't forget to visit our website csis
.org for our latest research reports and
events this podcast was produced by
Sarah Baker Isaac goldon and stie
McCulla see you next time
