But let me say this. I think if there's
a there's a bias that we need to have,
it's in my view for less regulation
rather than more regulation. Without
global agreement, the only defense we
have is speed. Till international
standard is achieved. We cannot slow
down the development of AI. You you'll
see a very strong technical founder
build a solution and then go look for
the problem. And you've always got to
start with the problem. And the best
person to understand the problem is your
ultimate customer. There's a lot of
money right now uh for AI startups and
VCs are voracious. Venture capitalists
are voracious uh when it comes to early
equity. Don't be afraid to give up some
equity, but make sure that you're
raising money in a responsible fashion.
Welcome to the Regulating AI podcast.
Join host Sanjay Puri as he explores the
dynamic and developing world of
artificial intelligence governance. Each
episode features deep dives with global
leaders at the forefront of regulating
AI responsibly, tackling the challenges
using AI can bring about head-on and
enabling balance without hindering
[Music]
innovation. Welcome to the regulating AI
podcast which is dedicated to promoting
responsible AI practices through
meaningful conversations with global
leaders. I'm your host Sanjay Puri. In
today's episode, we are honored to be
joined by Congressman Nick Begage of
Alaska. Born and raised in Alaska,
Congressman Begage earned his bachelor's
in entrepreneurship from Baylor
University and an MBA from Indiana
University before working at Ford Motor
Company in technology and product
development roles. Since returning to
Alaska in 2004, he's launched numerous
businesses and served as a startup coach
and mentor, helping early stage
companies navigate the path to success.
Congressman, welcome to the Regulating
AI podcast. Thank you for having me.
Congressman, you've had a tremendous
experience as an entrepreneur and now as
a legislator.
It's
obviously the big interest is always how
do you balance innovation versus you
know regulation. How do you see because
you've been on both sides. How do you
see especially when you look at AI how
do you see the balance between
government regulation of AI and allowing
market forces to shape uh the
development of this transformative
technology? Well, it's a great question
and I think that it's one that um
there's no easy answer for, but let me
say this. I think if there's a there's a
bias that we need to have, it's in my
view uh for less regulation rather than
more regulation. I think that uh when
you look at the global competitive
environment uh for artificial
intelligence, you see that um we in
order to have an effective set of
regulations, you've actually got to have
a a globally harmonized set of of rules
of the road. We don't have that right
now. And I think the United States
Congress in particular has to be careful
not to hamstring artificial uh
intelligence development in a way that
would push that work uh to other
jurisdictions. And so I think it it
needs to be carefully constructed. It
needs carefully thought out. There are
uh needs to ensure that there are that
there are guard rails for the
technology, but um we do need to keep
the environment open uh for competition
and amanable to investment. And anytime
that you add too many regulations too
fast to a nent industry, you run the
risk of chasing that work to other
jurisdictions or hampering the
development and delaying the development
of that work in ways that would not uh
otherwise have naturally occurred.
So obviously uh this is a truly
transformative technology I think as
you've said and make sure we don't
hamstring it. Are there some specific uh
guardrails that you think would be uh
helpful for something of this nature,
Congressman? Yeah, I think but I can get
to some of that uh in just a moment. Let
me let me set the stage though with the
way that I perceive what's happening in
AI. I think we have three uh
simultaneously intersecting J curves in
AI. You've got base AI which is rapidly
approaching an a point on that J curve
that we call AGI. Once we pass AGI, we
hit artificial super intelligence. And
that is more of a segment of the curve
that that is beyond AGI. We don't really
know how high it goes, where it
plateaus, if it plateaus at all. So
we've got that J curve. We also have the
J curve of agentic AI. So that is the
ability for uh AI to work on behalf of
individuals and on behalf of companies
or even perhaps governments. So an
agentic AI that's empowered to some
degree to act on another's behalf. Then
we have so it's more of a goal-based AI.
Then we have um physical robotics and
the the AI instantiation thereof. And
these three intersecting J curves create
real challenges for regulators because a
most regulators don't come to the table
with uh a specific set of experiences
that would prepare them to understand
how to regulate the technology but b the
technology itself is moving so rapidly
in in such in many respects
unpredictable ways that uh putting
boundary conditions on the technology
becomes challenging. However, now with
that as the backdrop, getting back to
your to your question, I do think that
there need to be some thoughtful
regulations around the boundary
conditions for agentic AI. Aentic AI
when it starts to work on behalf of an
individual, we have to start thinking
about whether we should empower agentic
AI to for example enter into a contract
relationship.
uh that would perhaps bind someone
financially. Uh should we allow agentic
AI to engage in conversations as though
it is the person uh itself or himself or
herself, right? Do we really want AI to
represent that that that AI is me or
it's you and so there are boundary
conditions be in in the sense of agentic
AI because we are outsourcing individual
agency
to an AI entity on behalf of an
individual and that's where I think we
need to be really cautious. Um, we do
need to make sure that there is some
mechanism for personhood validation when
it comes to agentic AI. Is this agent
truly authorized to work on behalf of
the individual and am I speaking to the
individual's AI or am I speaking to the
individual him or herself? And so those
are some opportunities for us to uh
provide some rules of governance that
make sense uh when you're talking about
an agent and an AI empowered agent
specifically. And so yes, I do think
there are and those some specific
examples uh instances where Congress
does need to act. Ideally, they're doing
so in a harmonized fashion with with
others around the world. Um but I do
think that for the purposes of
protecting the consumer and for
protecting others online
uh from impersonations etc. there is a
need for some governance framework.
Well that's um very helpful and I'm I
hope our listeners we have global
listeners understand uh why we wanted to
have you in there because you've broken
it down. um I might be talking I could
close my eyes and be talking to a CEO of
an AI company. You broke it down
beautifully in those three uh things. So
if I can just um you know follow up on
um some of these things. Um you talked
about agentic AI there is a act of
agency that happens as you said it could
be with a company it could be with the
government. Um where is the
responsibility in your view uh going to
fall? uh is it if some some kind of an
agency contract needs to happen for the
actions is the responsibility
uh you know if something kind of goes
wrong is it the AI company that is
making it the person who's giving the
agency etc those are you thinking about
those kinds of uh guard rails uh
congressman it's a it's a really it's an
interesting question to try to answer in
the using the backdrop of uh speaking
specifically about US regulations, the
backdrop of what was done uh to provide
a certain level of immunity to platforms
um at sort of the dawn of the worldwide
web in the United States. Legislation
was passed that would essentially
absolve platforms of the responsibility,
the historic responsibility of uh
content moderation. And so that content
moderation responsibility if someone
were to say something on a platform that
is not accurate, if it was defamatory,
those things then the liability didn't
fall to the platform operator in most
cases. They fell to the individual
making the statement or the company
making the statement and that's where
the liability went. I think it's going
to this will likely follow a similar
framework ultimately where true
platforms will likely and this is my one
person's opinion but will likely uh
enjoy similar or parallel types of
immunity but when the tech stack when
the application layer comes in over the
top of AI and you have an agentic AI
application I think that that's where it
gets a little thornier because
the the agentic AI publishers will
likely want to want to make the case
that they themselves are platforms, but
to the extent that those operators have
the ability to manage the contract
between uh an individual and their
designated agent and the logic that sits
in between those two individuals or
entities. Uh that's that's where the
liability question becomes uh hard to
answer because unlike
uh the historical parallel that we're
drawing with platforms, AI is different
because it's a it's a blackbox logic
model. So it's very difficult even for
the developer or the or the user of the
application that's that's leveraging an
AI layer to actually be able to
deterministically say that the a the
agent is is operating in the best
possible way for uh the the user or the
individual that's being represented. And
so I think that will create some some
thorny legal questions down the road
because you you can only test this uh
this product so much. you can test test
certain edge cases but um I think there
will there it will probably fall to the
the application publisher because the
individual user will not be able to
understand the logic construction of the
agent well enough to to be liable for
what the agent ultimately does on their
behalf.
No, that's very true. uh Congressman uh
OpenAI just uh recently released um this
so to speak their PhD level researchers
so to speak uh if I were to take uh some
of the points that you raised let's say
these PhD researchers come back with uh
some fantastic uh information and as you
said there's a black box some sometimes
maybe if that uh information is not
accurate but it is relied on because
these are PhD level uh
researchers uh that could be and you
know some of these could be in the area
of chemistry manufacturing biology there
could be issues in terms of
uh you know where is the accountability
and those kinds of things that I think
that's uh some of the things that might
be for us to look at as things are
developing very very fast. Yeah, I I
agree. Those are things to look at and I
think you know when it comes to um when
it comes to PhD level analysis uh really
the these toolkits you can sort of
bifurcate AI into uh
metaanalysis where they're looking at
groups of previously performed studies
in order to draw uh correlations that
that could result in a validated
causation effect. So you've got that
body of work and then you have um sort
of imputed discovery uh work streams
where uh you have some level of uh
intuition that's baked into the AI that
says look you know based on what we've
observed in this body of work this here
are some potential areas of future
discovery that have not been fully
explored but I think in both sets it
will require validation from a
researcher in the real world to confirm
A this metaanalysis has discovered
something novel let's go confirm it or B
this is an area of discovery that we
should further investigate but will
require additional real world
experimentation to validate so I think
in both cases you can't really rely on
that PhD level analysis as the final say
it's all going to have to be validated
by real world real world researchers but
it should make the research effort in
agg aggregate more efficient.
Absolutely. Absolutely. Uh Congressman,
you're from the the great great state of
uh Alaska, one of my favorite places.
When you look at some of these tools
that come in, I mean, one of your uh big
uh mission is to how the technology
makes uh you know, Alaskans succeed. How
in the context of you know these agents
these PhD level uh tools etc. How do you
balance the technological progress uh
that it these tools allow us while also
protecting jobs let's say in Alaska and
economic stability?
It's a it's a great question. It kind of
borders on the metaphysical in some
respects because you know what you do
not want to see is an AI advance. so
rapidly that that the human society in
at large does not have the ability to
adapt fast enough to the to its
disintermediation of work. And this is a
concern that a lot of folks have have
identified for many years, in fact going
back decades, that if AI really were to
uh hit hit the J curves that we're
talking about, it has the potential to
radically transform society. And it gets
and I I mentioned the metaphysical
because it it touches on a point that
also is now being more commonly surfaced
and that is human obsolescence. What
happens to humans humanity's purpose if
uh work as we think of work is is uh
been so disintermediated by uh both both
in the white collar space and the blueco
collar space uh that there's nothing for
people to do and I think this is a valid
concern and you know I know that there
are those out there who have been of the
mind that they've said look through
every technological advancement that's
occurred in the past uh there's been
plenty of work on the other side of that
for uh for humans, right? So instead of
employing armies of typists, now we have
personal computers and you know there's
there's less of a need for the
secretarial uh function than there was
previously. So we can go through and you
anyone can go through the the the move
from an agrarian predominantly agrarian
society to an urban society, the rise of
the white collar workforce, all those
things. there's always been something on
the other side for uh humanity to do
that's made us more profit more
profitable more productive uh gave us
our time back. So all those were good
things but um you know something this
powerful and this wide ranging I think
it does incredibly raise those
questions. They're things that
regulators need to be thinking about.
They're things that AI companies frankly
need to be thinking about. And uh in
this particular instance, there's not a
good sort of silver bullet solution to
what that looks like because we are at
an event horizon of the technology.
There's no putting the genie back in the
bottle on AI, but we can't really see
beyond it either. We don't quite know
what comes post AI.
That is true.
Um not put uh can't put the genie back.
Uh Congressman, sticking with Alaska. Um
Alaska is in many cases a rural state uh
if you really think about it and like
many other uh states in our country. Um
obviously we talked about making sure
you know we don't uh impact a lot of the
population but we also want to make sure
there is no AI divide making sure that
all Alaskans and people even in rural
areas because the promise of AI is
personalized health care personalized
education where a kid in Alaska can have
the same uh physic physician access to a
physician from Harvard as somebody in a
large city can some a kid in Alaska can
have access to a a GP of worldclass
access because of AI. How can we make
sure the rural places like in Alaska
etc. there is no AI divide? It's a it's
a great question. I mean I think the the
base requirement for tapping into the a
we'll call it the AI cloud, the AI suite
of services um is going to be
connectivity. So that's that's table
stakes for everyone worldwide, but
particularly in my state. We need to
make sure that there there is a
sufficient level of connectivity to take
advantage of the AI benefits that will
roll out and are rolling out right now.
Um Starlink has been transformational
for our state. Uh there are so many
communities, in fact,
82% of Alaska's communities are not on a
road system. And so uh without satellite
internet, broadband satellite internet,
there are many people in the state that
would have been left behind already. And
so I think that's been transformational.
I think redundancy is important too.
Having redundant uh core networks so
that you've got uh you know a fiber
alternative in the larger communities
where where it makes economic uh sense
to be able to do that. uh in addition to
Starlink gives you some failover because
we've got to have that redundancy
particularly when you're talking about
satellite networks that may be
interfered with because of cloud cover
or ice or other sorts of weather
conditions. So that's that's table
stakes. I think also you need to make
sure that the that the broadband
capacity is sufficient to serve the
public in a way that allows everyone to
participate in each significant piece of
AI uh of the AI application stack. And
so then the example that you referred
to, you're talking about an individual
interfacing with uh an AI physician,
right? Or an AI uh supported physician.
And you know to the extent that that
inter interface requires imaging and
imagery well that requires a higher
level of broadband uh capacity than if
I'm talking to a chat GPT like interface
and so making sure that everyone has
that level of access is very important.
Um, and then it's it's also about
integrating the technology stack into
the classroom in a way that is
complementaryary to the learning
experience. And so that no matter where
someone happens to be born, where they
grow up, they have the ability, the
optionality to participate in what is
being developed. And I think that's
that's really important too when you
talk about digital divide. Mhm. You
know, you we may start divided based on
where we end up as as the the lottery of
birth works, but uh the technology
provides us an opportunity to come
together if it's available to us.
So, I think what you're saying um
congressman is the connectivity and
obviously the ability in education
that's going to kind of bring these even
up things in rural communities in Alaska
and rest of the the country. I think
that's a a great point. Congressman, at
the start of the conversation when I
asked you about AI regulation, you said
you want to make sure that we stay ahead
of the pack, especially globally. we
have uh a geopolitical I don't know if
the race is the word the right with
China in terms of u you know from a
technological uh standpoint in terms of
geopolitical nature of what we are
trying to do what are your thoughts they
had a u you know the there's a race for
AI dominance right now which has
obviously got
geopolitical
implications Um what are your thoughts
in terms of how we should United States
should position
ourselves while also keeping the
standards that we are known for uh given
that they had this deepseek moment and
other things. Your thoughts?
Well, there's so much to unpack there.
So, um most of our conversation uh thus
far today has focused on the consumer uh
sort of component of artificial
intelligence. how it's going to impact
the workforce, how it's going to impact
education, but there's an entire
separate line of conversation around uh
how does this impact uh intelligence,
national defense
uh capabilities and I think that's where
this becomes a much more
um let's say uh relevant conversation
for nation states where uh individual
nations are are now exploring the
possibility of using AI for
um for network network intensive
offensive operations where you're seeing
uh companies getting attacked through uh
novel DDoS methods and you're seeing
nation state actors looking for novel
ways to attack infrastructure and so
that's where the AI uh race as you
described it uh comes into play because
what what tends to happen in most
industries is that there are compounding
effects up that J curve and so the the
benefits tend to acrue to the early
mover that is able to maintain
acceleration along that curve and so
it's very important as a nation that we
invest in AI not just on the consumer
side but also as it relates to our
national defense capabilities.
Um the one of the challenges with this
particular uh vein of technology is that
unlike uh nuclear technology where we
have globally been able to uh I'll even
use a word suppress that knowledge of of
how people can go about building that
technology. This technology tends to be
heavily open source. it's well
understood how to build the models.
There's no way to prevent uh folks from
really having access to that
information. And because of that,
because that na that barrier cannot be
constructed at this point, it's a it is
a race. It is a race on the AI front.
And uh you know, that's why I think that
there needs to be some global
conversations around how far we allow AI
uh capabilities to go. I think those are
healthy discussions to have uh because
it it is technology that benefits from a
compounding effect and that compounding
effect can lead us down to a to a an end
of a road that we don't really want to
get to.
Uh end of a road that we don't want to
get to and you're saying there needs to
be some kind of a collaboration and you
talked earlier also congressman about
harmonization and things of that nature.
The European Union has got its AI act.
Now we
obviously don't have anything
comparable. What in your view I mean
should we have work on standards? I mean
you said we need to have some kind of a
dialogue happening with other nations or
other countries maybe like-minded
countries. Is that what you're
suggesting? I think that's important. I
think it's I think it's also important
to just realize that the the reality of
the moment is is this without global
agreement the only defense we have is
speed and so it's until uh a a an sort
of international standard is achieved uh
we cannot slow down the development of
AI and from a from a national security.
From a national defense perspective, I
think that most folks recognize that
continued investment in AI is necessary.
Whether the uh regulatory framework uh
can catch up to that is is another
question. Right. Right. Um Congressman,
you had mentioned early on that you know
generally members of Congress are in
many cases not unlike you. you are a
real exception equipped to handle or at
least you know because they're dealing
with on the same day dealing with Hamas,
Ukraine, border security etc. they can't
be what I mean for our listeners who are
you know uh yeah experts and others just
any suggestions in terms of for
something that is so critical and
transformative what would you suggest
this is your first term in there uh and
you've seen this there is an AI caucus
out there there is a you know there's a
task force also and a lot of your
members have been on the podcast and I
ask them always is is what can be done
to maybe uh I don't know how to put it
but raise that level of awareness on
this topic uh with the members. Yeah.
You know, I think it's uh I think it's
conversations like these that help to
raise awareness. I think it's continuing
to hold hearings on the Hill uh and
ideally uh hearings that cross multiple
committees because you don't want those
hearings to be focused only in one
committee. You need to make sure that
people who may not sit on a particular
committee in the house or senate also
have the opportunity to discuss how AI
will or could impact uh their area of
jurisdiction and AI is broad- ranging.
So it there are good reasons why AI will
impact agriculture, will impact energy
and mineral exploration, will impact
education and labor. It will impact
every and is impacting every area of our
society. So I think it's important for
each committee to have uh hearings and
opportunities to to hear from experts in
those domains that are utilizing AI or
are on the verge of utilizing AI uh as a
mechanism for you know industry
disruption uh for efficiency gains for
improvements in discovery etc because
that exposure is what ultimately can
lead to smarter regulatory environment
that will intelligently keep the
innovation space aperture wide open but
also make sure that we have the
appropriate guard rails for the
technology as it's deployed. So having
hearings and having different kinds of
discussions I think is what you're
suggesting. It's the only way because
you know I come to the table with 20
years of technology experience. So I'm
I'm coming into the conversation with
knowledge but a lot of folks come with
different experiences. You've got a lot
of folks who come to the table who are
prior lawyers or they are state house or
state senate members. Some come from the
business community as I do. Others, you
know, they they come from a medical
background, number of doctors in
Congress. So that we all complement one
another as sort of a portfolio of
legislators and it's also incumbent on
people like me to have conversations
with others in the Congress that may not
have as much exposure to the technology
or the underlying themes of the
technology as as people like I do. I
think that's a great point. Um,
Congressman, when we talked about the US
keeping its, you know, technological
leadership in this very important
transformative technology, energy is one
of the key components uh of this because
as you probably w you know better than
most, AI is an energy hungry, energy
dependent. Energy innovation has been
something that you have been focused on
for some time. What are your thoughts? I
mean, we have traditional methods.
People are now grudging up nuclear. I
never thought in my lifetime
bring nuclear back. Uh, and there's now
talk about fusion. But talk to us as an
uh to our viewers in terms of as an
expert. What can we do? Well, I think
there's a couple of things that are
working at
um I don't want to say cross purposes,
but there's there's two counterveailing
winds and we don't know which wind is
going to ultimately prevail. Okay. So,
you mentioned deepseek earlier, right?
Deepseek
purportedly, we don't know for a fact,
purportedly a more efficiently developed
model. So we know uh that there because
of the high training costs of each AI
model, there is a there is a huge
economic incentive to make the modeling
effort more efficient. And so I I would
believe that that's going to continue.
We're going to continue to locate areas
in the AI development space that will
compress the energy requirements for
each incremental model. So that's that's
one giant wind. Another wind is the
voracious appetite for modeling and
particularly not just general modeling
but areas specific modeling. So a lot of
the things that have gotten attention
relate to, you know, general
intelligence, right? where you're
actually what I call it is a supra
intelligent model is what we have right
now where uh Gro 3 uh you know the
latest versions uh of chatbt pro these
these model iterations are smarter than
any one person but in each individual
siloed area are not smarter than the
theme for each individual area. So we
have sort of a supra intelligence model
achieved already. We haven't achieved
some would say we have but we haven't
yet achieved true AGI but super
intelligence in my opinion it we step
into that when the model a singular
model is capable of uh producing
stronger outputs than any subject matter
expert in any field. M so in any case
jumping back to the to to the question
you know I think that u those two
counterveailing wins one for incremental
modeling and the other for efficiencies
in modeling we don't quite know what the
true energy requirements for AI are
going to be long term um but I do
believe that what we've seen already
with data centers with crypto mining and
then you add AI on top of that uh there
is going to continue to be a voracious
push for incremental energy production.
So now the question comes where's the
energy coming from, right? So you do see
a a change in the conversation where
forms of energy that were viewed
previously as being sort of off the
table are now coming back into vogue.
And the reason why nuclear specifically
is coming back is because it's it's argu
frankly inarguably the most efficient
energy production method that we have
right now. You can create more energy
from uranium uh by volume than you can
create from oil and gas by far. Right?
And so and certainly beyond wind and
solar. Now uh we also recognize that AI
and data centers specifically and
certainly this this applies to the
crypto components of data centers they
require stable base load power. So uh
it's very important when you spin up
these systems that they they have
reliable power not just that they have a
certain magnitude of power and battery
technology has not fully caught up with
solar and wind. Now, there's been
advancements, but there's a lot more
work to do in order to efficiently store
uh for long periods of time the energy
that comes off of those variable
systems. And so, I think that's why
you're seeing nuclear come back into
vogue. That's why you're seeing a big
push for um for natural gas as well. And
uh you know at the end of the day you do
not want the supply of energy to become
the limiting factor for industry uh
advancement in AI for the same reasons
we've already discussed in in this in
the podcast today. Um and so I think
people are trying to remove that
potential constraint from the industry
by building ahead of what could be
future energy demand.
So it's going to be interesting as you
said that two counterveailing uh forces
working. So I I strongly believe that
we're going to see more and more
efficient models these small language
models ondevice models and maybe
innovations even in energy that will
come about because the I I I think our
innovators are going to find ways around
this uh but energy is going to be a key
determinator. Uh congressman finally
you've served as a startup mentor u also
and you sit on the science and
technology committee we have a lot of
um startup CEOs and others also who
listen in there when you look into the
future you talked about these three
pillars you know you talk about agentic
AI you talk about AGI and then you talk
about robotics is there one final piece
of um advice that you would give before
we go into our lightning round for them
well you know I I
think when it comes to startup to to
startups and
founders, I think some of the same
advice that I would have given founders
20 years ago is would be the advice that
I would give today. I mean, you you've
got to take a look at the long term.
Look at the enterprise value that you're
building. Start with the customer in
mind, right?
Sometimes, in fact, so many times you
you'll see a very strong technical
founder
uh build a solution and then go look for
the problem. And you've always got to
start with the problem. And the best
person to understand the problem is your
ultimate customer. And so what I've told
people for years is if you start with a
customer and you build the thing they
asked you to build because they told you
they would pay for it, well, at least
you got one customer and at least you
got some revenue. And the worst thing in
the world is to spend a a significant
amount of your life energy building a
product that nobody wants. So start with
the customer, figure out what they need,
make sure they're willing to pay for it,
and then go build it. And if you do
that, what I've told people also for
many years, where there's one, there's
many. So if you have one customer that's
got a problem, you're going to have lots
of customers that have a similar
problem, and that's where you can scale
your operation. So I don't think the
fundamentals of startup development
change. I do think that the speed of
course is is extraordinary. The other
piece of advice that I would give is,
you know, there's a there's a lot of
money right now uh for AI startups and
VCs are voracious. Venture capitalists
are voracious uh when it comes to early
equity. Don't be afraid to give up some
equity, but make sure that you're
raising money uh in a in a responsible
fashion. You know, some some venture
capitalists have a model where they just
want to write checks, the biggest check
possible. They want you to staff up as
rapidly as possible. But as a founder,
it's also your responsibility to make
sure you're deploying the capital
responsibly, that you're putting your
company on a pathway to profitability.
It doesn't mean you're going to start
there. There is the land grab effect,
but also if you're if you're going after
a land grab effect, make sure that you
have some level of stickiness in your
product that will allow customers to
stay with you over time. Because if the
switching costs between you and another
company are low, uh trying to buy
business at a loss is a fool's errand
because you won't be able to keep it
when you try to turn the corner on
profitability.
Ah, fantastic. I don't know if our
listeners ever thought they would be
listening to startup recommendations
from a member of Congress, but he's
given amazing advice. Start with the
customer. Where there's one, there will
be many. And when you take money, take
it wisely. And if you're going for a
land grab, go for it carefully. Um, and
I think that's just uh great great
advice. Uh, Congressman, finally, we
have this uh lightning round of
questions. Just one word answers. uh not
trying to put you on the spot but uh
just fun uh for our listeners who have
attention span of people is getting
smaller smaller smaller with Tik Tok and
everything else. So uh you ready? I'm
ready. I I I may have to be a politician
this time. Yeah, please. You can you can
be a politician. Okay. Uh more important
for AI development, speed or safety?
I think I think speed for most of the AI
technology. I think safety for for some
of the technology we talked about with
respect to intelligence and national
defense. Okay. Uh bigger threat
overregulation or underregulation of AI?
Uh in the short run uh overregulation in
the long run under regulation. Okay.
Will AI create more jobs than it
eliminates? To to be determined. To be
determined. Uh, federal AI regulation or
state byst state approach. Federally for
the broad guard rails, state byst state
for the details. Okay. Open source or
closed uh source AI systems.
Open
source as it relates to consumer
technology would be my preference but I
don't think it should be regulated in
that way. Um and closed source as it
relates to national defense related
issues.
Sounds good. Final one. Uh Congressman,
biggest winner from AI advancement, big
tech or small business? I think actually
small business wins here because it
reduces the the uh AI has the potential
to reduce barriers to entry for small
business in a dramatic way. And so it's
never been easier to start a a company
than it is today. And AI makes it even
easier. So you don't need for most small
businesses, you don't need what used to
be half a million dollars or maybe even
$50,000. You can get started for very
little money. Uh and I think that's a
good thing for small business formation.
Yeah, I I agree with you. Well, that
concludes our conversation with
Congressman uh Nick Begage on the
complex and vital topic of AI and its
regulations. As our listeners can
appreciate, effective AI regulation
requires balancing innovation with
responsibility. I really want to thank
you, Congressman, for taking your time.
really your insights. Uh I think it's
going to be great for this congress to
get your uh input with your
entrepreneurship, your background, the
way you laid out the three pillars uh
and finally how you advise our
entrepreneurs. So to our listeners,
thank you for joining us for this
episode. Please stay tuned and until
next time, I'm Sanjay Puri encouraging
you to stay engaged with these critical
conversations as we collectively shape
the future of AI. Congressman, this was
fantastic. I could have gone on for a
long long period of time but uh I know
how busy you are. So thank you for being
with us.
[Music]
