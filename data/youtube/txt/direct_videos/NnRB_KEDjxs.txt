as well as the workforce in general many
people will have to work with AI they
may not have to be technology specialist
but they will have to understand how it
works I think of lawyers of doctors of
any kind of you know most of the
professional uh profiles that we can
think of and then we need to raise the
number of Technology Specialists I would
say the probably the biggest challenge
we have right now and we are about to
publish the third draft it will be
published um I want to make this very
clear because uh in these days I hear a
lot uh uh complains that Europe is has
weak competitiveness in AI because of
the AI act well I'm sorry I cannot agree
to that um and we work very closely with
the member states because part of the
enforcement and the governance of the AI
Act is indeed under the responsibility
of the member states and of Market
surveillance authorities in the member
states so we have introduced in the leg
legislation itself some ways of being
able to modify parts of the
legislation welcome to the regulating AI
podcast join host Sanjay pury as he
explores the dynamic and developing
world of artificial intelligence
governance each episode features deep
Dives with global leaders at the
Forefront of regulating AI responsibly
tackling the challenges using AI can
bring about head-on and enabling balance
without hindering innovation
[Music]
welcome to another episode of regulating
AI the podcast where we explore the most
pressing issues in AI governance ethics
and policy I'm your host Sanjay Puri and
today we are honored to have with us Dr
Lila sioli director of the EU AI office
at DG connect European
commission lucila has been a key figure
in shaping the eu's AI policies playing
a leading role in the implementation of
the AI act she's also LED major
initiatives including the AI pact
general purpose AI code of practice and
invest AI today we're going to discuss
how the EU AI office is driving Global
AI governance how AI regulation can
balance Innovation and safety and what
lessons the world can learn from
Europe's
approach Lucy welcome to the regulating
AI
podcast thank you very much for having
me
wonderful uh Lucy we have a global
audience uh policy makers think tanks uh
Civil Society Advocates
entrepreneurs so from their perspective
uh you launched the eui office in June
2024 what has been the most surprising
challenge you have encountered in the
first few
months well that's a very good question
indeed because the challenges have been
many there is a maybe a high level one
about the fact that of course many
things happened in the field of AI in
terms of model releases and uh uh simply
technological changes that we as a nent
European AI office had to be had to
follow to monitor to be updated about uh
but then there was uh a second more
mundane challenge which is the challenge
of recruit routing I was given the
possibility which is probably rare in a
public organization to recruit uh um a
significant number of uh uh new
colleagues in the European commission
working in particular on uh the safety
of artificial intelligence and uh I had
the possibility and this is a positive
challenge for me in particular because I
was impressed by the um interest that uh
our call uh received and by the
enthusiasm of many many young people in
the European Union but also beyond the
European Union who are interested to
work on these kind of topics and that's
really uh
refreshing uh Lucy since you talked
about the issue of talent just can we
have a follow on because we have a
global audience you know it's said that
Europe has some of the best AI talent
and obviously global firms also use that
talk a little bit about the talent to
our audience in terms of you obviously
when you were recruiting you must have
seen wide variety of uh people across
and what is uh Europe doing to kind of
nurture and grow this talent because
really it is all about Talent right
Lucy um it's a let's say that Talent is
a very very important part of it and uh
of course here we are recruiting uh
right now technology specialist so
people that have a strong background in
in Ai and in particular in in our AI
office we're looking for people with a
background in the safety of AI um and um
it is not you know it's it's not
something it's not a topic yet that is
very common in h university studies also
because um safety in particular of the
moders is is a trend that emerged
relatively recently for University
curricula to adapt to this kind of
topics so um it is not super easy to
find people with this background but we
are finding them across the European
Union uh sometimes they went to study
outside the European Union um but now
what we really need to focus on is also
well for the I office we are also in
interested in finding lawyers that have
experience for example in uh digital or
Ai and the law and the rule of law and
uh people who have experience in policym
but always in the field of AI and
secondly on a higher level we put in
place policies in the eye office also to
um raise the skills level of the uh
Europeans in the area of AI and here you
have to intervene on citizens that have
to understand what AI is and maybe it's
not as bad as the way it is portrayed in
the media as well as the workforce in
general many people will have to work
with AI they may not have to be
technology specialist but they will have
to understand how it works I think of
lawyers or doctors or any kind of you
know most of the professional uh
profiles that we can think of and then
we need to raise the number of
technology
specialist so it's a wide variety uh
across many many sectors lawyers doctors
uh others that are coming in so I I
think the good news from our listener
standpoint is that uh European Union
really possesses a wide uh range of
skills uh in this area and the future
from that Talent perspective is pretty
uh strong Lucy you also have been
meeting with AI safety uh offices around
the world where do you find uh key areas
of Alli ignment or maybe you know
Divergence in approaches as far as AI
regulation is
concerned well when it comes to
regulation uh so the European Union was
the first uh um jurisdiction to put in
place a regulation on
AI uh now if I consider the countries
that formed the network of safety
institutes there are regulations also in
Korea um and uh there are discussions in
other countries like Australia and there
were also discussions in Canada there
are pieces of registration AI also in
the United States in some
states um so um we all have slightly
different approaches but still uh we
find our uh conversations very useful
our exchang is very useful because we
have very similar objectives and uh as I
said earlier the science in particular
the science of safety of AI is
relatively recent and so there is a
great need that we exchange information
in terms of methodology uh in terms of
benchmarks in terms of tools that we can
use to evaluate and Benchmark uh the
different models so this is where our
conversation is mostly going on top of
even conducting joint uh uh testing
approaches which are also very
interesting
so a lot of uh conversations as uh you
know the EU has established a real
leadership role in terms of some of the
governance and AI perspective that's
happening um Lucy also I think the uh
first draft was published and I think
the of the general purpose AI code of
practice I probably you're working on I
think the second draft was published and
you're working on maybe even the third
what have been some of the most
challenging as ects to align among
different stakeholders
here well there have been uh many
different uh challenges because uh this
is a code of practice uh which gathers
1,000 members in terms of stakeholders
so that's many many different people and
it includes uh the model providers of
course but also uh industry that uses
the models and may develop systems on
top of those models it includes Civil
Society organizations it includes
academics so it it includes a a variety
of of different interest and uh um and
what the code of practice does is to try
to find a balance and a compromise
between the different uh uh parties and
the different needs that are expressed
under the different interest so for
example the model providers of course
they don't want to have uh too much red
tape rightly so um and uh they also want
to make sure that uh their um
confidential information is respected so
that they're not asked to um disclose uh
relevant information for their
businesses um and then of course on the
other side we may have other groups that
instead would like to have have a
greater control uh to make sure that the
models that are being used are actually
safe for
Citizens um I would say the probably the
biggest challenge we have right now and
we are about to publish the third draft
that will be
published um in the next uh days um is
the issue of copyright so the issue of
copyright meaning that um the copyright
holders the right holders uh would like
to be able to assess uh if uh some of
their content has been used in the
training of the of the general purpose
models but it's very good that the
discussion uh is is going because of
course right holders need to be fairly
remunerated and uh uh model providers
need to have a lean way of training
their
models so uh Lucy you made some very
important points one is there are over
thousand stakeholders that you're
balancing so I want to address that
because our listeners are taking lessons
from you around the world because you
have like I said you are ahead of
everybody in that the second thing
you're talking about is the copyright
issue which is a very very important
issue for creators uh who are there
there is this concept of fair use uh in
terms of uh use of copyright materials
is that something that uh you have
thought about or is that going to be up
to the courts because in the US it's
working its way up to the Supreme Court
uh in terms of you know the copyright
issue of the use of data for general
purpose large Foundation models what are
your thoughts or has that been a
discussion in terms of that our
discussion is not in terms of the fair
use because in Europe we have a
different approach we have a European
copyright directive which basically says
that
uh text and data mining is allowed
unless right holders opt out uh from the
point of view of their content and uh um
in that case the opt out has to be
respected by the companies that would
like to use that particular content to
train their model so we come from a
different perspective and uh um we are
trying to you know the the ACT does not
modify the European copyright directive
the AI Act is simply asking companies
and players to respect the European
copyright law and then through the code
of practice we are trying to provide a
practical way to uh implement the way
that this directive can be
respected no that's uh very helpful Lucy
the other issue we talked about is this
thousand stakeholders and I want to kind
of uh follow up on that is the there is
this uh discussion that goes on about
how to balance regulation with
Innovation which the EU is obviously
trying to do in a big way how are you
when you look at it uh do you uh how is
that perspective going on from how to B
make sure that Innovation flows because
this is a very Dynamic organization and
with such a large stakeholders that you
have what are your thoughts in terms of
how to balance that so for for me it may
not be fully correct to talk about
balancing regulation and Innovation
because the term balancing makes me
think that there is a tradeoff between
the two and I'm convinced that there is
no tradeoff between the two uh I think
that uh um if uh people trust the
technology uh people and businesses will
use the technology that creates demand
and that creates incentives for
companies to invest in that technology
so um trust is necessary for Innovation
to take place um it is true that um any
kind of rules may come accompanied by uh
requirements and that and some cost cost
of compliance which should not however
be taken as a bad word I mean cost of
compliance is necessary if there is a
particular issue with the technology and
it's the cost of making sure that trust
is there still we as policy makers have
to make sure that the cost of compliance
is as small as possible and uh this is
what we are trying to do including with
the I act the ACT is a risk based act
meaning that it introduces rules that
are commensurate to the risk that the
technology or the use of the technology
poses so we are not regulating
artificial intelligence all the
applications of artificial intelligence
we are only regulating a small set of
these Technologies in particular the
ones that are particularly risky from
the point of view of violating
fundamental rights and safety but for
the rest which I would say probably 90%
of the market we're not regulating
anything and U I want to make this very
clear because uh in these days I hear a
lot uh uh complains that you Europe is
has weak competitiveness in AI because
of the AI act well I'm sorry I cannot
agree to that not only because the I act
is not even fully applicable and it's
not and it and it will not be applied um
retrospectively but also because uh um
it will only concern a very small number
of companies that have made the choice
of the European AI applications that are
risky from the point of view of the
fundamental rights and the safety and in
95% of the cases we are not saying you
cannot develop this technology but we
are saying when you develop it please be
transparent about it check that the data
are okay check that everything is
documented check that you have given
enough information to the user so that
you minimize incidents check that there
is human oversight and by doing this
which is probably what any serious data
scientist would do When developing such
an application I mean a high-risk
application I think that um I don't find
it particularly invasive in terms of uh
compliance cost so I think uh again for
our listeners I think she's making a
very important point that majority or
over 90% or plus uh applications do not
even uh have to worry about some of
these things and these are only for some
very high-risk applic ation and the the
argument about the balance between
Innovation and regulation is in some
ways a false uh argument because it's uh
most Industries whether you looking at
Aviation or medicine Etc have some kind
of a built-in compliance uh and we don't
we don't complain about those things uh
because we take it as a granted so I
think that's a very very important point
that you're making for our listeners
around the world because this has been a
big uh topic
Lucy also for our
listeners um who are learning from you
how are you going to balance this
regulation within 27 uh EU States
because several countries like take
United States have 50 states within them
Australia has uh different provinces and
others so uh they're all looking to see
how can they learn from you as to how
you're balancing so can you talk a
little bit about that
what first of all I would like to point
out to the fact that in the European
Union where we have 27 member states we
have one AI regulation so this is very
important because I can tell you that
until a couple of years ago all
countries and all governments wanted to
introduce regulation in AI if we did not
have this one AI act we would run the
risk in Europe to have 27 acts and it's
important to have only one because then
the developers of AI know the rules and
they know that the moment they put they
put on the European market uh one of
their products uh it doesn't matter
which country it is from that point on
it will have access to the whole Market
of the European Union which by the way
is a very big
Market um and we work very closely with
the member states because part of the
enforcement and the governance of the AI
Act is indeed under the responsibility
of the member states and of Market
surveillance authorities in the member
states because the way this AI act works
is there are some checks that a deployer
of the uh of the technology has to put
in place if that system is high risk
before it puts uh the system on the
European market and then later if there
is an incident then there is an
authority a market sance Authority from
a member State the same member state
where the incident took place can go and
check if uh the deployer had followed
all the rules and had made all the
necessary checks and is not is or is not
responsible for the incident so we have
to make sure at the European level that
this Market surveillance authorities
work in a coherent way so even if the
legislation is one in the implementation
phase we have to make sure that the
market surveillance authorities all work
in very coherent ways and for this we
have set up a board of member states so
where we meet regularly and where we
also meet with the market surveillance
authorities to exchange information
practices also if uh uh there is a case
that concerns an AI system which affects
more than one country then there is also
a dedicated process where the market
surveillance Authority informs the
European commission and then the
investigation takes place jointly at the
European level no sir this is uh very
helpful for our listeners who are not
from the EU that uh what I think Lucy is
saying is that if they had not put this
thing together companies would have had
to deal with maybe even 27 different
rules and regulations and had to hire
lawyers to deal with each and each and
each and only large companies can do
that who have the resources but smaller
companies would have not been able to do
that and that's the same issue in the
United States and other parts of the
world is what I think Lucy is saying and
they have a coordinated system for doing
this Lucy uh that's very helpful now the
one other question um that comes in is
that AI is moving so so rapidly almost
on a daily basis things keep changing as
you know um and the AI act has specific
Provisions for general purpose AI models
how do you plan to keep uh some of these
Provisions relevant as the technology
keeps evolving um if you can tell our
listeners a little bit in terms of how
do you keep things uh as AI technology
keeps
changing so we have introduced in the
legislation itself some ways of being
been able to modify parts of the
legislation without going through the
full review of the legislation going
going through a full review of a
legislation takes a long time so we have
kept certain elements in ways that can
be updated through um faster instruments
that we call in the European Union
implementing Acts or delegated acts for
example we have a list of use cases that
are captured by um our Provisions in an
Annex and we can modify this uh Annex of
course we have to show evidence if you
want to add another use case so we do
have still have to work a lot before we
can modify the list but rightly so um
but then uh legally speaking or
technically speaking which is modified
by introducing uh an act that takes a
couple of two or three months let's say
to to get through um in the mechanisms
of the European Union and so we have
done this for different elements of the
legislation that are likely uh to be
updated I'll give you another example is
the threshold of uh
computation uh the Flop threshold that
we have for capturing the general
purpose AI models with systemic risk uh
which is something that obviously may
increase as models become larger or
maybe in the future even decrease we
will
see so there are Provisions uh for our
listeners for the uh you know AI act to
evolve as new technologies come in I
think and that's the point that Lucy is
making because that's a very important
Point Lucy lately there has been a lot
of conversation about open source um uh
I'm sure you've heard with deep seek and
other stuff can you tell our listeners
in terms of how how what is your
perspective when you look at open-
source technology which has open weights
listed
clearly well look in the European Union
we are very supportive of Open Source
because uh uh open source well not only
we have a very strong um talent in the
development of Open Source it's been a
sort of like
traditional um skill in the European
Union um and but it is also the
opportunity to have many different
models it's a it offers Choice it offers
uh many benefits also if you want from
the Democratic point of view on the
other hand as you say it may
facilitate uh some um attacks cyber
attacks or other and so we think that uh
um we still want to see the development
of Open Source and we want to use open
Source in the European Union uh but we
think of course the developers of Open
Source have to make sure that they take
a certain steps to protect uh their
models and uh make them robust against
possible cyber attacks or others so very
supportive of Open Source but obviously
there have to be certain uh guidelines
that they need to follow to make sure uh
you know uh that they are safe uh Lucy
from from a standpoint of small uh
businesses and startups uh how are you
making sure that they can also Thrive
under the AI act uh
requirements uh because they don't as I
mentioned earlier they don't have the
resources of large companies they don't
you know they can't engage large teams
of lawyers or Auditors Etc so uh talk to
our listeners who are startups uh early
stage age companies small mediumsized
companies who might be little concerned
in terms of compliance with the eui ACT
um the they shouldn't be concerned
because uh first of all the I act
includes some simplification
requirements for the smaller companies
for example in terms of risk management
and quality management so there are some
simplification in terms of information
provision and
certain elements are simply lighter for
small medium
Enterprises um and um but they don't
need to be concerned because as I was
saying earlier um what we are asking to
do in most cases is a self assessment of
uh
um of the transparency requirements that
companies have put in place in relation
to Ani system and uh uh this is what
many companies do anyway and in fact I
can tell you that uh I often speak to
startups and smmes and I do know a lot
of startups that actually don't have a
problem in putting in place these
requirements and I actually see the
advantage of offering trustworthy Ai and
that are clever enough to use the safety
and the trustworthiness of their AI
system as a reputational brand for for
their
market so uh I think what uh Lucy is
saying is that it is actually in most
cases a self-certification but also it
becomes a differentiator where you can
put uh this kind of a branding that it
is a trustworthy Ai and it really uh
separates you from other or companies
maybe uh who don't have that kind of a
level uh so that's pretty helpful um the
uh Lucy the AI act uh the AI pact has
attracted uh about
170 uh
87 uh organizations 74 from which are
non EU uh this is as of now and it keeps
changing and growing every day what does
this International interest tell you
about the global impact uh of the EU AI
uh regulation
it's very significant there is as you
said
187 companies that signed up to the AI
and a number of them is not European
it's actually American and I am and not
only American because I think uh that we
also have companies from Korea and from
uh other
countries um what I always find
surprising is how useful
also the non-european companies find the
the AI PCT I mean they're very
enthusiastic about it and they also use
it to improve their reputation with
their clients so um we in turn use these
let's say larger companies that signed
up to the commitments of the um aipct to
learn from them how they are
implementing these commitments because
the commitments at the end the day are
requirements of the I act so we see how
they Implement them and then we try to
propose this to the smaller Enterprises
so in theact in reality we have two
circles we have the circle of the
companies who sign up to the commitments
who give us feedback on the
implementation of the commitments
themselves and then we have a much
larger Circles of companies that are
following our webinars our explanations
about the the AI act and its
implementation to which we propose the
implementation of the smaller Circle as
an example uh and the facilitation of um
their
compliance so that's uh really separates
them and there is absolutely a global
drive towards joining this um so that's
uh very helpful to know Lucy you also
emphasized the role of AI factories in
Europe's AI strategy uh tell our
listeners how will these uh contribute
towards uh eu's AI
strategy in the EU AI strategy we want
to build an AI continent we want Europe
to be an AI continent and uh we are a
very different continent from say the
United States because uh we have um um
developments in European Union are
basically d by startups developments in
particular in generative AI they're
driven by startups so our policy is
about making available resources to
these companies to be able to uh train
their models as the training of the
models is normally you know the most
expensive let's say stage of development
of the models themselves and that's why
we have um made available our public
network of supercomputers
uh the European Union started this
exercise a few years ago not for AI but
for uh simply data processing and uh
which has already existed including AI
for many years but I'm saying uh well
before uh the big general purpose AI
moders were born and now we are in the
process of upgrading the supercomputers
with better AI capabilities made in more
gpus um and we are looking at the future
where we also want to build Giga
factories meaning factories with also
important data centers with uh even more
gpus if possible uh where which can
really be used for the training of the
large models not only of the startups
but also uh science models for example
by universities and other
researchers so a lot of resources uh I
think Lucy what you're saying is to
create this Europe becoming an AI
continent there is also this invest AI
program uh which is kind of putting in a
lot of resources can you just briefly
talk a little bit about that I think
there's about a $200 billion that is
invested in for our listeners who are
thinking about uh some of the
opportunities there uh
Lucy yes well the 200 billion EUR
investment includes uh uh commitments
also made by European companies
investing in the European Union
and uh um on top of that we are um
considering the possibility of having um
a supporting kind of fund because uh uh
you see in the European Union at the
moment if there is a weakness is limited
Capital financing this is both from the
public and from the private uh uh from
private sources so uh we want to
stimulate private investment um we are
thinking of a fund we are still
reflecting about it and we will come
forward with with the proposal uh at a
later stage uh but this is going to be
important because it's going to on the
one hand support partly the so-called
gigaa factories because the
gigafactories are so big that they
cannot be supported by subsidies by
public subsidies they will need private
investment and we're thinking of
facilitating and stimulating this
private investment and on the other hand
of course we would like to be able to
support also the scale up of our
startups uh in particular providing the
generative AI models so that then they
can become stronger and also work with
other European industrial sectors to
make sure that AI is integrated in all
in our industrial sectors and that will
bring the comparative advantage of the
European Union so for our listeners
there is this Giga factories there's
also now a conversation about putting
together a fund because as I think Lucy
pointed out in in my conversations with
lot of
entrepreneurs uh there is this desire to
have more of a funding opportunity
especially when you talk about series a
series B series C because uh Lucy AI uh
companies need larger investments just
because of you know the processing power
and data and things of that nature but
that's also being considered um by the
European Union Lucy are there certain
sectors within the EU that you think
will have uh where AI will have a major
impact in terms of Industries um is are
there certain spectors when you look
across and this is for our listeners who
might be thinking hey I have a
company maybe in health or maybe in this
and that uh what are your thoughts on
that well there are many sectors in the
European Union um uh where AI can really
benefit um I would first of all I think
in all the sectors of the economy I
cannot think of any sector that can do
without AI even construction and Agri
food need Ai and they already using it
very well then of course Health Care as
you mentioned Automotive
manufacturing um robotic is not a sector
but I think that robotics is very
important promise for the future for the
impact that AI can have and the European
Union is quite strong in the field of
Robotics um but as I said defense
unfortunately in this days we have to
think a lot of defense and I think AI is
very widely used in that sector as well
so across uh a broad spectrum uh whether
it's in health even defense
uh
construction uh so it's really Financial
Services tourism I mean it doesn't have
to be only heavy industry to be Services
of
course absolutely entertainment I mean I
can't think of a sector which would not
be affected by I and the public
administration of course yeah even in uh
the administration public administration
services to uh citizens I think uh those
are also
applications um Lucy you have uh in the
past mentioned regulatory sandboxes many
times uh can you tell our listeners how
are these being implemented uh across
the EU just what is your brief
definition of a regulatory
sandbox well the regulatory sandbox is a
controlled space where uh startups and
small companies in Europe can go and
test their their AI systems if they have
a doubt a question about the level of
risk and uh they can test their system
in the presence of a relevant competent
Authority so that they can discuss with
the authority if they have to be careful
with something that mem from the AI act
and then uh adjust uh uh the The
Innovation accordingly and there will be
um one regulatory sand box in every
member State and of course the services
for the startups will be for
free wonderful so it's a you know an
enclosed environment in a safe
environment where some of the startups
can come in and you know test out their
applications and it will be in each
member State Lucy uh EU is leading in uh
from a regulatory governance framework
but other countries as you talked about
whether it's a South
Korea Australia Japan India are putting
their their Frameworks together how do
you make sure that uh the EU framework
is still aligned or do you think it's
incumbent on some of these countries to
align themselves with you or do you also
have to keep are you keeping yourself
aware of what is happening with other
countries of course we are always in
discussion with other countries
and because we were the first we are
able to put in place what is known as
the Brussels effect so that those who
come later do look at our AI act and I
noticed that uh the approach is been
replicated in Brazil for example in the
proposal that was on on the table in
Canada but even in some of the proposals
that were in Sacramento and uh um and
and some of the concepts also in
Australia so I think that um there is a
brussel effect and we speak with each
other quite a lot you know International
cooperation in this area is very
important because technology does not
stop at Borders and so I think it will
be simpler also for all companies if we
all try to align towards similar
International
standards finally Lucy I have like a
zillion questions but I also understand
uh your uh busy schedule but if there
were some uh message that you were to
look to giving uh to give to other
countries other regions who are looking
to set up uh policies or uh folks who
are looking at uh working in the EU what
would be your message you've been
through this now uh the challenges the
problems the opportunities as you said
bringing thousand uh stakeholders 27
countries uh if you were to give one or
two uh Pearls of Wisdom or advice to
other countries or leaders who are who
are listening to you what would that
be it's very important to to be open to
many stakeholders and to hear different
points of view and there is a lot of
benefit in in learning from the
different views even when
opposing um and I will certainly
recommend to keep all processes as open
as possible of course always in a
practical way there will be a lot of
challenges there will be a lot of
mountains to climb but one should never
then lose the uh final objective which
is at the end of the day the possibility
to make sure that we live in a world
where the technology can be controlled
and the technology can be used to the
benefit of our societies and our
economies and not to to the detriment of
it so it takes resilience but it's an
objective that can be met so takes
resilience be transparent also focus on
how the technology can help people I
think those are uh very very valuable
insights uh uh from you uh Lucy this has
truly been a very very insightful
conversation in your leadership in AI
governance is really helping shape the
future of you know responsible a and we
really appreciate your time today and
for our listeners if you want to stay
updated on AI policy please
follow uh you know uh Lucio on LinkedIn
and check out eui offices latest updates
uh and thank you for joining on the
regulating AI podcast if you enjoyed
this discussion don't forget to
subscribe rate and share this podcast
until next time keep questioning and
let's build an AI future that benefits
all Lucy this has been very very helpful
and insightful and we really hope to
have you back again with us thank you
very much thank Youk you
[Music]
