Welcome to another episode of Legal for
Tech the podcast. So guys, you do
recognize my voice. As I've said many,
many, many times, it is always Rosie
here. And this is just a group of
students and young professionals who are
very interested in anything that has to
do with technology. And yes, it's
regulation. And today I have to be
honest, it's much more technology I
guess. But we will see. We will see
where this takes us. So um I'm joined by
my friend and colleague Jako today. Hi
Jakma, great to see you.
>> Hi Rosie. Great to see you. I was
thinking that at some point we will all
be young
like workers, not anymore students. And
I hope so.
>> That's that's um that's a great hope
especially today for me. Um I'm
particularly happy as you know. Um but
like yeah I also find it very funny that
I always introduce you as like being
Jakamo but because we have three Jakamos
I guess people never know who you are.
So this is Jako Gregorio by the way.
But that said enough with my talking. Um
we are day interviewing a friend on
LinkedIn and a friend of the podcast
now. Hello, Ben Mey. How are you today?
>> Hello. Thank you for having me. Yes, I'm
very good, thank you.
>> I'm really happy to see you actually
because as I've said when we actually
made the first call for this podcast to
be recorded, um I'm very excited. I
mean, I really love your content and I
believe that our listeners definitely
know who you are. So in any ways in case
they don't please do tell us something
about your career and um how you got
started where you're leading to and most
importantly how you got to know legal
for tech and me specifically.
>> Sure. Yeah. Um so my my background is um
in the sort of STEM subjects
academically. So I I did a physics
undergraduate degree and then later on a
a maths PhD
um via um a sort of meandering period of
being a musician for a while. Um but I
kind of decided um about halfway through
my PhD that I wasn't academia wasn't
really life for me. So I wanted to do
something a bit more kind of
commercially relevant. Um and um I kind
of came across intellectual property law
as something that could use some of my
technical skills but would be a bit more
kind of worldf facing and um yeah I got
into it uh that way. So I joined um EIP
which is an IP law firm uh in the UK uh
based in London um about 10 years ago
now. Um and
I because of my kind of technical
background I largely specialized in um
sort of software technologies and
particular AI. So I've been looking at
this kind of stuff for um quite a long
time. Um became very interested in sort
of a lot of different areas around AI
not just intellectual property. And I
guess around sort of 2022, I um started
having conversations with um a lot of my
colleagues around some of the new kind
of legal questions that were being
raised by this kind of new type of AI,
generative AI. Um and we kind of
realized that, you know, a lot of a lot
of tech companies in particular would be
they'd have sort of general role firms
who were dealing the kind of regulatory
side of things. uh they'd have IP firms
who were dealing with how they would
protect their innovation. Uh these two
things might these two firms might not
be talking to each other that much. Um
and we kind of thought there was a bit
of a a gap in the market here and maybe
that companies could be served better by
having it all under one roof. So we kind
of brought together commercial IP
solicitors, patent attorneys like me and
um we launched a service called Codifi.
Uh and that's kind of um what I've been
doing for the last few years. Um and
then EIP made me a partner earlier in
the year. So that was that was nice. Um
where am I going next? I guess want to
kind of continue growing EIP and Codify.
Um support and champion innovative
companies. Uh help to kind of grow an
ecosystem that's sort of um provides
more benefits than harms. Um and to do
that I think I kind of need to be part
of the debate. um you know continue
making content on LinkedIn and beyond
um provide a counternarrative where
necessary
um and even as far as influencing
government policy wherever that's
possible. Um obviously kind of getting
the message out there um is something is
I guess how we came together on LinkedIn
and um you know I think that what you're
doing with the with the podcast is
great. So I'm really happy to to be here
and share my thoughts with you.
and we are very happy as well to to have
you here. Uh as you as you mentioned in
your background, you you work on AI on a
daily basis, especially uh in the
intersection between uh development and
regulation. Uh so considering what what
are the current uh regulatory approaches
that are global or regional? uh do you
think that these approaches uh right now
are are going in the right direction for
the intersection between development and
regulation for the companies that are
working with AI or do you think it it's
not the right approach?
So I think I think the first thing to
say on regulation is that effective
regulation of AI is is absolutely
needed. Um because there are many many
harms that AI can create um particularly
generous AI and some of them are new uh
some of them are kind of just um maybe
extensions of things which technology
has provided in the past technologies
like social media. Um but the way to
effectively regulate AI is kind of
unclear and the reason for that is to do
to do it because it's sort of you know
it's a it's a global phenomenon there
needs to be some sort of to do it really
effectively ideally you'd have some sort
of global consensus and um you know some
framework in which it would work. But
that's not really um possible because of
the geopolitical aspect. you have um all
of these different countries and um
collections of countries doing pursuing
different goals and having different
positions and they're all the regulatory
approaches that they pursue reflect
that. So if you kind of you know if you
look at the US at least on the kind of
federal level um they're largely
regulating to protect dominance in in
the AI market. So you can see them, you
know, regulating the export of chips,
things like that, but they're actually
doing very little to protect citizens
and um society more broadly in my
opinion. Maybe some states are stepping
in now to kind of fill that gap. Um
China on the other hand, they're looking
to disrupt that dominance. Um but also
they kind of want to maintain some state
control of their information that their
population consumes. So you see more
kind of censorship there. the EU um
obviously the EU
most primarily wants to sort of make
sure that there's a functioning market.
So that's how you might things like the
digital markets act, digital services
act. Um but also protecting the rights
and safety of the citizens. So that's
how why you have the AI act. Um and then
I should also mention the UK because
that's where I am. Um the UK kind of
wants to be pro innovation. Um but at
the moment they're sort of largely
sitting on their hands and we're not
quite sure what they're going to do.
It's starting to look a bit like they're
kind of becoming a bit pro big tech. Um,
but who knows where they're going to go.
But, you know, you can you can kind of
debate which of these is the most worthy
kind of direction to regulate
technology. Uh, and the companies that
create the technology, but ultimately
they're all going to create laws that
reflect their own goals and I guess
their own interests. And the the extent
to which they are able to advance those
interests is how we should judge the
effectiveness of the regulation really.
Um in terms of regulation as you said
like you know there are different
approaches and and thank you for the
kind of overview but the point is like
as you said what's the regulation
bringing us to and you did mention that
the European Union has as its core value
that of seeing a functioning market
which doesn't exactly sit well with the
idea of a market that function in the
way that actually um fosters innovation.
And what I was really struck by when I
read your posts and um and your
interactions on LinkedIn is that you do
believe that innovation doesn't just
come from scale. It comes from
particular
um kind of interest and focus of the of
the use of the right model at the right
time to do the right task. So I was
wondering it may be an unpopular opinion
but do we just not all invest in chachi
PC?
>> Yeah, it's funny you should mention call
it an unpopular opinion because I mean I
think quite a lot of the stuff that I
share on LinkedIn is kind of counter to
the a lot of the um online discourse um
and there are reasons for that but um
when I actually kind of go out into the
world and talk to real people um I find
that the stuff that I say is not
unpopular at all. actually a lot of
people are there's quite an appetite for
the kind of ideas that I have um and
people like me share. Um so I think
probably the most um bold opinion that
I've recently been talking about is the
fact that I think consumer generative AI
um chat GPT and so on is overwhelmingly
a destructive force. Okay. So I think
that um it's a route to cognitive
decline, mental health issues, increased
surveillance, capitalism,
all sorts of other problems. Doesn't
mean I think the technology is bad. Um
but it it may not be bad, but it is
actually it's unreliable. Um you know,
there was a BBC study recently which
showed that in 45% of news summaries,
facts were misrepresented.
Um, and what that tells us is that to
use these tools, they're powerful, but
they need to kind of be in the right
hands. You need someone who's
sufficiently experienced and expert in
the in the area that the AI is talking
about to be able to detect these issues.
And that's why I think that consumer AI
is not a good direction for us to all go
in. However, I think that businesses
with proper experts controlling the
models and proper governance around
them, there is a lot of promise. Um, and
you talked about scale there. Well, a
lot of the most valuable business use
cases actually do not need massive
models. Um, you know, the sort of things
which could revolutionize businesses and
it could be something as simple as like,
you know, an AI which triages emails,
incoming emails or something like that.
You don't need a gigantic GPT five level
model which can also act as a therapist
or can um you know recite Harry Potter
to you or whatever else you want to do.
You actually just need kind of a small
model which is focused on the right
thing with the right plumbed into the
right data um and with the right access
control. That's kind of what how I think
AI this kind of a technology is best
used. Um and I guess that's the kind of
unpopular opinion here. Um and actually
the open model ecosystem so you could
you can argue whether or not it's
actually open source but um open weights
models it's already pretty mature and a
lot of the things that businesses could
benefit from there are already many many
models available in the open weights
market which you could just use you can
use on your own private cloud instance
or you can just run it on the site if
you bigger companies can even run it on
their own premises um and you know maybe
your business need there are 10 tasks
which AI could you do within your
business to to help you make more
productivity or whatever. Um, you might
use 10 different models for that. Um,
and that would probably be far far more
efficient. Um, and basically what what
what happens in this in this world that
I'm describing is that the the LLMs, the
the language models that sit behind this
become a kind of commoditized thing. And
basically you can switch them in and out
and you use the one that's most
appropriate for a given task that you're
trying to do. And the um the kind of
where all the magic happens is actually
in the application layer. So you can
describe you can kind of separate the
infrastructure layer which is the models
and the application layer which is what
the models are doing. And that means if
if all of the innovation is kind of
within the application layer, then you
actually end up with a much better
situation where you don't need a huge
company like OpenAI plugged into plugged
into you, which can, you know, have
ultimate control over the information
that you consume. They can hype their
prices at any time. This kind of thing,
you instead end up with a situation
where companies have a lot more control
of their own um of their own AI. they
can build defensible IP on top of the
AI. Um, and if that happens, then I
think we'll get a much more equitable
system and a much more equitable AI
future. Whether or not it happens is is
still up for up to debate, I suppose.
meaning on a on a technical level uh and
talking about LMS uh maybe one of the
reasons they're less desirable is also
given by the amount of data they require
to function and also the quality of it.
What's your take on the copyright
related argument is for you using LLM
worth the price of the value creativity?
>> Yeah. So this is a big one. Um, in fact
that we're we're to we've just
discovered that tomorrow we're going to
hear the outcome of a big um a big
copyright case in the UK which is Gatin
versus Stability AI. So we'll find out
what the what what the situation is here
in the UK. But um I mean ultimately the
the kind of raw material for um generous
AI is original human created works that
have no AI input at all. the more AI
input there is, the less valuable it is.
Um, and the business models of the early
movers, open AI and so on, um, has been
extremely extractive. Basically treating
all of those works as just some form of
kind of amorphous data which we can just
Uber up and do whatever we want with.
Um, and
we have to move from an extractive model
to a sustainable model. Otherwise, we're
going to have a collapse of the whole
information ecosystem. We're already
seeing that, you know, the internet is
getting largely replaced with AI
generated slot already. So, we do need
to see some sort of shift in order to
have sustainable AI industry and for
companies to be able to use AI
sustainably, we do need to shift to
something where um
human originality is is valued and
remunerated. And copyright is definitely
part of that. copyright. It's the the
legal right which allows people to
control how how their works are used. Um
but it's not enough on its own. We also
need um the kind of startings of a of a
functioning data marketplace or
something similar. I don't know what
it's going to be. methods of preun
ination there has this is a big problem
to be solved but really we need to move
from if you kind of think of think of
chat tp as a kind of napster um we need
to move to what the sort of Spotify is
going to be for training and I don't
know how that's going to happen but
ultimately it will happen
>> super cool I I'm really liking this
conversation I think it's so obvious
because I'm I keep on smiling
unfortunately I business can't see that.
Um, thanks to Zoom, we need to operate
this. Um I wanted to say like okay
so I mean obviously we have talked about
creativity, we have talked about um
scalability
and still I mean still the AI um kind of
investment bubble is a huge bubble and
we know that governments are putting
huge amounts of money into this. So my
question here is are they doing the
wrong thing investing on AI? Also, um
I'm I'm going to share something with
you that um happened this week actually
when I was in Ireland. As I said, you
were doing uh something that was called
Consumer Leadership Academy and one of
the people that was invited there did
mention like is the EU giving so much um
kind of boost to any type of AI
investment going to mean that in the end
we're going to have really really bad AI
to be put money on. So that then
afterwards when the good AI will come
out we will not have the money to invest
in it. So I don't know if like this is
clear as a as a flow of thoughts of
course uh my thoughts are always
flowing. Um but but that's my question
like are we investing on the wrong
thing? Are we too early to invest in
this? Is this really a bubble?
So um I mean there's been a huge amount
of investment in the first movers and
the early stage of journey AI. Um most
of it seems to be kind of a big circular
investing
thing involving open AI at every
juncture. Um I mean basically
it is a bubble of some sort. I think
that you know what what basically
happened Jennifer is that um
OpenAI made this big bet on scale and
they decided that they would put all of
their chips in on scaling this type of
uh this type of architecture
um the the the transformer architecture
which was invented by Google and
they in doing so they basically um
became more and more reckless with the
data practices and then they released it
as a consumer product which was chatbt
and in doing so they got a lot of the
people very excited and they started a
bit of an arms race. Lots and lots of
other companies well which other
companies could compete started to pile
in. We saw that from you know Google,
Meta, Anthropic which kind of splintered
off from OpenAI. Um, and a lot of people
got very excited because they sort of
saw this scaling trend and they thought,
well, if this carries on like this,
we're going to end up with something
that's absolutely incredible and the
most, you know, powerful thing that's
ever been invented by humans. Um, and as
big more and more big powerful companies
sort of piled in, they and their
investors um, hoped that it'd be a sort
of self-fulfilling prophecy. you know,
the more money that comes in, we're just
going to keep this scale going and
eventually, you know, it's going to work
and we're going to have we can do
whatever we want at that point. We can
extract whatever profits we want because
we're now going to control the whole
information ecosystem. But I think a lot
of the investors are going to lose their
shirts here and a lot of money is going
to get lost primarily because we are now
this trend isn't isn't still going. is
actually starting to plateau and the
model performance is actually reaching
some sort of level that we can expect.
GPC5 was not much better than GT4. It
was just a little bit better. Um and I
think what's what we're seeing is that
same performance or similar performance
can now is getting uh can be achieved on
smaller and more smaller models and in
open weights models. So this kind of
idea of um basically the
the underlying business thesis where you
can just
scale scale scale and then once you've
gone so far that nobody else can catch
you up you just basically become a rent
seeker and take whatever profits you
want move into whatever areas the land
grab is almost infinite just go and you
know we'll take that industry we'll take
that industry that won't happen anymore
because there will be alternatives and
as soon as the ex once that OpenAI
decide decide to turn the screw or
whichever other company decide to really
monetize their customers which they're
not doing they're losing money once they
start to monetize their customers you'll
see that they'll just go somewhere else
they'll just start using open models and
the whole thing will collapse I think
the and I think what will be left will
be a very useful technology or set of
technologies and some infrastructure
that's been built around it that we'll
have to think that a new ecosystem will
have to be built realms which hopefully
will be a more equitable one and a
better one. Um, but I think that the the
directions of travel at the moment is is
is completely unsustainable.
Well, like I would point out like as as
I come to just to play the devil's
advocate as I sometimes enjoy doing on
this podcast
we've had if I'm not mistaken something
like Facebook I mean was around being
2008
started off being quite big if I'm not
mistaken. Um we are in 2025 right now.
I'm not great at maths. So you do the
calculus um calculation. Um the question
is like it's still for free now. They
also have Instagram is still for free.
Um X despite Elon Musk's um best
attempts
are still for free. Not completely.
LinkedIn where we met still for free.
Things changed. People are dependent on
social media. That's that's now a fact.
And still it's kind of for free. Yes,
you have the pay or okay kind of
decisions, but it's still for free.
Why should AI be different? Why will
people be so dependent on AI that they
will be potentially prepared to pay for
this type of service?
>> Well, I mean it is the business model is
to create dependencies. That's the best
thing to say. I mean that is what chat
is. That's what OpenAI and its
competitors are doing. If you look, I
mean, keep singling out Open AI, but
let's shift it to Google for a moment.
They're offering free subscriptions to
every student saying we can help you
learn where of course actually it'll do
the opposite of that. It will stop them
being able to learn. People they want
people to be dependent on these
platforms, dependent on AI to do their
thinking. And there is research to show
that that is starting to happen. That's
why, you know, people will become
completely they will absolutely,
you know, lose the ability to do things
without AI if we're not careful. And
that's one of the reasons why regulation
of this stuff is really important. Um,
and but I think that one difference is
that this kind of AI identifier is
extremely expensive. It is just
expensive to run the models. Um so there
is a cost that has to be recruited
somehow by training the models and the
models have to be trained really quite
frequently in order to for them to be
useful otherwise they basically diminish
in usefulness and then to run them at
scale they are is far far more expensive
enterprise than running social media and
they therefore have to monetize the
customers at some point and the there
are a couple of ways they could do that.
They can either make it they can either
do it by subscriptions which they rise
the subscription prices significantly.
That probably will be one option.
They'll probably do all of these things
by the way. They can start to put ads
into the into the responses more. So,
you know, people will pay for chat to be
recommending things for them. Um, you
know, they might not be there'll be sort
of stealth ads maybe. Um, again,
something you might that we might want
to regulate against. Um or there might
be other kind of surveillance capital
tactics uh to influence consumer
behavior. Once you have someone hooked
on your product that you can do a lot
and this is you know this is how
Facebook to use your example has has
been very successful. They basically got
people hooked on their platforms and
then they and Google the same actually.
I mean basically these you get hooked or
you get dependent on these platforms and
then they find a way to monetize you and
in both of those cases it's through
targeted advertising
and I think that chat GBC will be no
different. Um, so yeah, it's it's an
it's an inevitable direction of travel,
but the question is whether it's
necessary because I don't think that
they the the the thing about Facebook is
that you almost can't have you you can
only really have one of it and then
maybe you know a slightly different one
which is Instagram. These they they rely
completely on network effects. The
reason a social network is good is
because it has almost every on the
planet on it. Um, so you can't have like
lots of eating social networks. It just
doesn't make sense. So Facebook has
essentially or Meta essentially has a
bit of a monopoly there and they behave
like monopolists as well. Whereas I
don't think that necessarily has to be
the case with um with AI because I think
that there are that like I've said the
the sort of open model ecosystem means
that lots of lots of companies can
provide AI services and therefore there
can continue to be competition a
functioning market. you don't need to
have this kind of monopolist stuff going
on.
>> Before going to the last question, uh we
wanted to know if is there a trajectory
in AI development or AI provision
business model that you you're most
looking forward uh to or and also if
there is any other trajectory that is
you're scared of.
Uh yeah, I guess I guess we've touched
on some of some of this, but maybe to
distill it down, I I don't think I know
what the business model is, but I I I'm
looking forward to a kind of uh a world
where AI is created sustainably. So, you
know, where um human originality is
remunerated fairly and in a way that's
proportional proportionate to its
importance. So, however that is correct,
I mean, I do think that we're going to
end up with models that can track be
trained on far far smaller but more
curated data sets and I think that that
should allow um companies to basically
pay for data in a sustainable way. I
don't think that we again the big bet so
far has been on scale and I don't think
that that's the necessarily the the
future of AI. So that kind of excites me
as a possibility where we have you know
this just uh more more accessible
ecosystem because we don't need such
scale we have in we have true innovation
which allows things to be scaled back
down and be trained on a much small
amount of data. I mean if you look at
you know humans can do these tasks by
element in most cases and we don't have
anywhere near as much data. So you don't
need there's no fundamental reason you
should need as much data as open air
train
we shouldn't need it. Um so that's kind
of an exciting possibility. Um on the
sort of uh more scary side I guess the
the biggest fear is that just more and
more powers to a very small number of
very very large companies. Um they're
embedded in like all aspects of society.
They control the information we receive.
They squash all competition. They
leverage their power to make sure that
they can't be regulated anymore. And
they extract ever growing profit profits
and rents. And that's pretty much to the
detriment of everyone. That is the
trajectory that we're currently on.
That's because that's what they want to
happen. But I do think that there
probably there will be a day of
reckoning where something breaks. And I
don't know exactly how it's going to
happen. But that's when the bubble will
pop and that's when we'll start to see a
new world of AI emerge. possibly more
like the world before chat GPT, but just
that more technologically advanced um
than it was in 2021 or whatever.
>> Wow. So AI will not change the world
after all. Maybe. Who knows? Who knows?
Um I have I have this question that
obviously we ask a lot of of our guests
but like I guess in this case is
particularly important um especially
linked to the last kind of um conclusion
that you've drawn which is
um I would say um the market is full of
AI skeptics who are also
potentially a bit
um dissuaded from being
um I wouldn't say skeptic but for
keeping their feet on the ground. I
would say that um the market fosters um
AI enthusiasm and who wants to talk with
a bit of um salt in their brain. One one
may say um it's kind of like I wouldn't
say blocks but like maybe you know you
feel that this need um this kind of ide
Yes. But I do think it's great, you
know, like it's it's that kind of a
final sentence that you know, you you
you have to add the positive side and
that's something that I start to notice
also at conferences like people start
like give their all kind of um overview
and then at the end I want to conclude
on the positive side. Um do you have any
books, any suggestion, any podcast, any
movie where maybe the positive side is
not that um predominant and it's not
that needed? Someone that has the
courage to be not against it but not
even woriing it.
>> Yeah. So, um, first of all, it's it's a
great observation you've made there that
everyone has to either preface or end
anything about AI be saying I'm not
anti- AI, but um, and I think that, you
know, I have to do that a bit myself
primarily because I most of my clients,
most people I work with are AI
companies, right? I so I think I'm I can
say that I'm not anti- AI and I spent
most you know I'm pretty we're pretty
like I'd say we're kind of a friend to a
lot of UK and beyond tech companies. Um
but at the same time I'm not going to be
um getting on Sam Alman's Christmas list
anytime soon. Um and I think
there is a sort of yeah there is
there is this sort of prevailing idea
that if you don't say that then you're a
lite. Um but actually I mean I speak to
a lot of these people who probably would
be considered AI skeptics. Um and most
of them are actually just anti the
business practices of the main AI
companies. that's that's usually where
they're actually coming from. Very few
people are there are some people who are
like hardcore against technology and
they usually have their reasons as well.
Um but anyway to going to specifics I
mean I think that the the probably the
some of the best books on this are um
Karen How's Empire of AI uh which she's
a you know journalist who embedded
herself within Open AI had a lot of
access for a long time documented how
reckless that company has been in its uh
consumerization of AI and which has
basically led to where we are now with
Um, so that's that's probably where I
would start. Um, Gary Marcus is taming
Silicon Valley is really good as well on
that. He's um, you know, he he really is
he's not an AI skeptic. Again, he if is
from within the AI AI industry sold an
AI company. Um, but he's a skeptic to
the scaling of language models as the
route to all good things, which I guess
is kind of aligned with my kind of
technical beliefs as well. So yeah,
those are those would be probably the
the two I would go for on the AI side.
Um, one other book that I would like to
highlight which I just think is one of
the most brilliant books on technology
and the way that these companies work
and it's probably influenced quite a lot
of my thinking is uh technofudalism by
Janis Farfrackers. Um, this was written
before GPT or maybe around that time. So
it's not so much about generous AI but
he talks about how platforms move from
being kind of
ultimately entities operating within
capitalism to ones which have broken
capitalism and they're now acting as
feudalist lords extracting rent. And
some of the stuff that I've said today
is based on the idea that that is kind
of where the AI companies want to go
now.
>> Um I don't to be honest.
>> Yeah. So sorry just because the book
that you just cited um I know it is very
stupid of me to to mention but like I
remember this kind of meme that I saw a
couple of um weeks ago which was I don't
know if anyone here is a Game of Thrones
fan and it was kind of like Mark
Zuckerberg with a phase with a with the
body of Daenerys Targaryen with this
idea that like yeah the the queen that
breaks chains that then becomes the
chains and stuff and I I think like it's
exactly like it's the embodiment ment if
you have actually watched the TV series
or even read the books um it's the
embodiment of what you just explained
and I think it's just brilliant that you
brought that up um here today. I'm sorry
I'm I'm being really nerdy here but
anyways
>> well I don't get the friends reference
but uh
I'm glad I'm glad it worked for you.
Oh, on a on a different note, um any
other suggestions that our listeners may
go for or or should we conclude?
>> So, I yeah, so podcasts um so I I do
listen to a few podcasts. They're
usually they're mainly quite UK focused,
but um one that I do think is really
good is um and it is a bit UK focused is
a podcast called Radical by BP BBC
journalist Amal Russian. and um he
basically explores all sorts of
different sort of forward-looking people
and people have done something a bit
radical um and he's had quite a few
discussions on AI. He's had like the
Dario Modi from the from um Anthropic on
there. He's had uh Matthew Prince who's
the CEO of Cloudflare on there but he's
also had um the Italian Italian
physicist Carlo Relli Relli on it. Um so
and he they
he's quite good at exploring. I mean, I
don't necessarily agree with everything
people say on there, but it is really
interesting to kind of hear what they're
saying and where they're coming at it
from. So, just it's not a it's not an AI
focused podcast, but some of the some of
the stuff they talk about there is
really good.
>> I love Radical. Um, I'm a great fan. I
love Amaren. I think he's super funny
and I really thought that the interview
with Amade was brilliant. Um, and I
really loved another one that he did a
couple of I think weeks afterwards with
um, someone that I think is a Salesforce
or
>> something like potentially um,
potentially. I did listen to the actual
interview that was brilliant as well and
I think nobody really looks at the
infrastructure
behind the big names and as much as we
know that there are litigations um
against entropic I mean big ones um but
but I do think we should look at what's
um what's lying underneath because at
the end of the day it's still a kind of
heavy data based infrastructure and I
think sometimes we do imagine this
little robot uh running around the house
and forgets that there's there's data
behind it basically. Um so yeah, that
was great. Um thank you very much Ben
for all the suggestions for all the
ideas that you put into this podcast
which I'm sure will get to the level of
Amal Raj's um radical of course just
because we're great.
>> I have no doubt.
Well, in case Amald is listening, then
you do you should invite Ben as well on
the podcast because we thought it like
I'm sure that um the ideas are not uh
just limited to the ones that were
expressed in this very little time today
by the way.
>> No, absolutely. Yeah, plenty more where
that came from.
>> Right. So, thank you so much, Ben, for
for joining us today on this podcast.
And thank you, Jakamo, for being always
here with me and supporting me and
tolerating me. Um,
that was all for today from the legal
for tech the podcast.
Heat
up
