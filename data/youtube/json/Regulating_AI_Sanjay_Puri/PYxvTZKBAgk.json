{
  "source": "youtube",
  "channel": "Regulating_AI_Sanjay_Puri",
  "playlist_title": "RegulatingAI Podcast: Innovate Responsibly",
  "playlist_url": "https://www.youtube.com/playlist?list=PLGBFGI3ApzqdS70H84yli1Q-j_cqqiJbL",
  "playlist_id": "PLGBFGI3ApzqdS70H84yli1Q-j_cqqiJbL",
  "video_id": "PYxvTZKBAgk",
  "video_title": "AI Governance & Global Policy at ASEAN | Sanjay Puri in Conversation with Congressman Jay Obernolte",
  "video_url": "https://www.youtube.com/watch?v=PYxvTZKBAgk",
  "fetched_at": "2026-01-02T09:25:26.905409+00:00",
  "transcript": [
    {
      "text": "when you let another country have access",
      "start": 0.08,
      "duration": 4.8
    },
    {
      "text": "uh not only critical inf infrastructure",
      "start": 2.96,
      "duration": 3.919
    },
    {
      "text": "but the information about millions of",
      "start": 4.88,
      "duration": 3.679
    },
    {
      "text": "your citizens you know you are",
      "start": 6.879,
      "duration": 3.121
    },
    {
      "text": "definitely taking a risk there and I",
      "start": 8.559,
      "duration": 2.881
    },
    {
      "text": "think the risk is much lower with the",
      "start": 10.0,
      "duration": 4.0
    },
    {
      "text": "US. So",
      "start": 11.44,
      "duration": 4.72
    },
    {
      "text": ">> welcome to the regulating AI [music]",
      "start": 14.0,
      "duration": 5.439
    },
    {
      "text": "podcast with Sanjay Puri. AI is changing",
      "start": 16.16,
      "duration": 6.24
    },
    {
      "text": "the world faster than rules can keep up.",
      "start": 19.439,
      "duration": 4.641
    },
    {
      "text": "So how do [music] we protect people",
      "start": 22.4,
      "duration": 4.24
    },
    {
      "text": "without killing progress? Each week,",
      "start": 24.08,
      "duration": 4.72
    },
    {
      "text": "Sanjay brings you inside conversations",
      "start": 26.64,
      "duration": 4.08
    },
    {
      "text": "with global leaders, [music] policy",
      "start": 28.8,
      "duration": 4.56
    },
    {
      "text": "makers, and innovators who are wrestling",
      "start": 30.72,
      "duration": 5.92
    },
    {
      "text": "with that exact question. So, if you're",
      "start": 33.36,
      "duration": 5.28
    },
    {
      "text": "curious about the future of technology",
      "start": 36.64,
      "duration": 4.32
    },
    {
      "text": "and how it's governed, you're in the",
      "start": 38.64,
      "duration": 5.56
    },
    {
      "text": "right place.",
      "start": 40.96,
      "duration": 3.24
    },
    {
      "text": "From video game developer to voice of",
      "start": 44.559,
      "duration": 4.401
    },
    {
      "text": "California's high desert, our",
      "start": 46.879,
      "duration": 4.801
    },
    {
      "text": "conversation today is with Jay Obernalt,",
      "start": 48.96,
      "duration": 5.2
    },
    {
      "text": "engineer, entrepreneur, pilot, and",
      "start": 51.68,
      "duration": 4.16
    },
    {
      "text": "member [music] of Congress. With a",
      "start": 54.16,
      "duration": 4.399
    },
    {
      "text": "master's in AI and a past lifebuilding",
      "start": 55.84,
      "duration": 4.96
    },
    {
      "text": "games at Farside [music] Studios, he",
      "start": 58.559,
      "duration": 4.401
    },
    {
      "text": "swapped code and controllers for",
      "start": 60.8,
      "duration": 4.319
    },
    {
      "text": "committees. Today he represents",
      "start": 62.96,
      "duration": 4.4
    },
    {
      "text": "California's 23rd [music] district in",
      "start": 65.119,
      "duration": 4.721
    },
    {
      "text": "the US House fighting to bring fiscal",
      "start": 67.36,
      "duration": 4.0
    },
    {
      "text": "discipline, techsavvy [music]",
      "start": 69.84,
      "duration": 4.48
    },
    {
      "text": "leadership and rural community grit to",
      "start": 71.36,
      "duration": 4.48
    },
    {
      "text": "Washington.",
      "start": 74.32,
      "duration": 4.24
    },
    {
      "text": ">> Digitization would it be in governance?",
      "start": 75.84,
      "duration": 5.12
    },
    {
      "text": "What kind of frameworks would you pick",
      "start": 78.56,
      "duration": 4.559
    },
    {
      "text": "on uh congressman specifically between",
      "start": 80.96,
      "duration": 4.64
    },
    {
      "text": "the US AEN relationship?",
      "start": 83.119,
      "duration": 3.601
    },
    {
      "text": ">> Sure. Well, I mean I think the nice",
      "start": 85.6,
      "duration": 2.879
    },
    {
      "text": "thing about AI is that it has the",
      "start": 86.72,
      "duration": 4.56
    },
    {
      "text": "potential to be beneficial in so many",
      "start": 88.479,
      "duration": 5.521
    },
    {
      "text": "different usage contexts. uh and because",
      "start": 91.28,
      "duration": 4.24
    },
    {
      "text": "it's so general purpose I mean I think",
      "start": 94.0,
      "duration": 3.52
    },
    {
      "text": "we can help in a lot of different areas",
      "start": 95.52,
      "duration": 5.68
    },
    {
      "text": "but I think the pitch is uh the US AI",
      "start": 97.52,
      "duration": 6.48
    },
    {
      "text": "stack I mean the US still uh not not to",
      "start": 101.2,
      "duration": 4.4
    },
    {
      "text": "denigrate other countries but I think",
      "start": 104.0,
      "duration": 3.759
    },
    {
      "text": "it's still undeniably true that the US",
      "start": 105.6,
      "duration": 5.28
    },
    {
      "text": "leads the world in AI development and",
      "start": 107.759,
      "duration": 6.0
    },
    {
      "text": "deployment uh and also I think that",
      "start": 110.88,
      "duration": 5.599
    },
    {
      "text": "being our partnersh comes along with a",
      "start": 113.759,
      "duration": 5.04
    },
    {
      "text": "lot of risk reduction and you know what",
      "start": 116.479,
      "duration": 3.841
    },
    {
      "text": "we have seen with some of our",
      "start": 118.799,
      "duration": 3.201
    },
    {
      "text": "competitors is that there are always",
      "start": 120.32,
      "duration": 3.36
    },
    {
      "text": "strings attached We we've found that",
      "start": 122.0,
      "duration": 3.52
    },
    {
      "text": "with Belt and Road, not to to pick on",
      "start": 123.68,
      "duration": 3.759
    },
    {
      "text": "anyone, right? But there's uh there's",
      "start": 125.52,
      "duration": 4.079
    },
    {
      "text": "always seems to be some strings attached",
      "start": 127.439,
      "duration": 5.041
    },
    {
      "text": "when you let another country have access",
      "start": 129.599,
      "duration": 4.161
    },
    {
      "text": "uh not only critical infra",
      "start": 132.48,
      "duration": 3.36
    },
    {
      "text": "infrastructure but the information about",
      "start": 133.76,
      "duration": 4.08
    },
    {
      "text": "millions of your citizens, you know, you",
      "start": 135.84,
      "duration": 3.68
    },
    {
      "text": "are definitely taking a risk there and I",
      "start": 137.84,
      "duration": 3.119
    },
    {
      "text": "think the risk is much lower with the",
      "start": 139.52,
      "duration": 5.28
    },
    {
      "text": "US. So I mean I think that's the pitch.",
      "start": 140.959,
      "duration": 6.241
    },
    {
      "text": ">> A lot of these countries are also, you",
      "start": 144.8,
      "duration": 4.0
    },
    {
      "text": "know, they're setting up a national AI",
      "start": 147.2,
      "duration": 3.039
    },
    {
      "text": "framework. They are dealing with the",
      "start": 148.8,
      "duration": 4.4
    },
    {
      "text": "same usual issue. You know, want to",
      "start": 150.239,
      "duration": 5.761
    },
    {
      "text": "build a great innovation stack but also",
      "start": 153.2,
      "duration": 6.0
    },
    {
      "text": "want to manage safety, security, ethics.",
      "start": 156.0,
      "duration": 5.12
    },
    {
      "text": "Are there any frameworks that you can",
      "start": 159.2,
      "duration": 4.319
    },
    {
      "text": "suggest to them how to balance this",
      "start": 161.12,
      "duration": 4.88
    },
    {
      "text": "innovation versus regulation or",
      "start": 163.519,
      "duration": 4.72
    },
    {
      "text": "innovation versus safety? Congressman,",
      "start": 166.0,
      "duration": 3.599
    },
    {
      "text": ">> what people don't want to hear is that",
      "start": 168.239,
      "duration": 2.961
    },
    {
      "text": "we're just not going to do AI because",
      "start": 169.599,
      "duration": 3.441
    },
    {
      "text": "we're terrified about what the risks",
      "start": 171.2,
      "duration": 3.44
    },
    {
      "text": "could be and we're going to forego all",
      "start": 173.04,
      "duration": 4.88
    },
    {
      "text": "the beneficial uh changes that AI could",
      "start": 174.64,
      "duration": 6.0
    },
    {
      "text": "bring. So we have to strike a balance",
      "start": 177.92,
      "duration": 5.84
    },
    {
      "text": "and it has to be a very uh cleareyed",
      "start": 180.64,
      "duration": 7.679
    },
    {
      "text": "balance between at the same time",
      "start": 183.76,
      "duration": 8.0
    },
    {
      "text": "uh protecting our citizens against the",
      "start": 188.319,
      "duration": 6.0
    },
    {
      "text": "risks of malicious use of AI and",
      "start": 191.76,
      "duration": 5.04
    },
    {
      "text": "balancing that against not wanting to",
      "start": 194.319,
      "duration": 4.481
    },
    {
      "text": "stifle innovation and entrepreneurialism",
      "start": 196.8,
      "duration": 4.64
    },
    {
      "text": "and the deployment of AI. And that's",
      "start": 198.8,
      "duration": 5.04
    },
    {
      "text": "what everyone is struggling with. Uh I",
      "start": 201.44,
      "duration": 4.32
    },
    {
      "text": "think what you what everyone saw in",
      "start": 203.84,
      "duration": 5.36
    },
    {
      "text": "Europe with the AI act uh is that you",
      "start": 205.76,
      "duration": 6.08
    },
    {
      "text": "know they they took a very heavy-handed",
      "start": 209.2,
      "duration": 4.8
    },
    {
      "text": "approach that I think is is already",
      "start": 211.84,
      "duration": 3.84
    },
    {
      "text": "really cost them. If you look at the",
      "start": 214.0,
      "duration": 4.319
    },
    {
      "text": "flight of not just investor capital but",
      "start": 215.68,
      "duration": 4.32
    },
    {
      "text": "uh technical talent out of Europe and",
      "start": 218.319,
      "duration": 4.0
    },
    {
      "text": "into places like the United States and",
      "start": 220.0,
      "duration": 4.239
    },
    {
      "text": "the UK uh that have taken different",
      "start": 222.319,
      "duration": 3.681
    },
    {
      "text": "approaches. We have that discussion",
      "start": 224.239,
      "duration": 4.401
    },
    {
      "text": "about that achieving that balance. Uh we",
      "start": 226.0,
      "duration": 4.959
    },
    {
      "text": "have to at the same time bring up what",
      "start": 228.64,
      "duration": 4.319
    },
    {
      "text": "the risks are. And it's interesting. I",
      "start": 230.959,
      "duration": 3.441
    },
    {
      "text": "was listening to the tail end of your",
      "start": 232.959,
      "duration": 4.321
    },
    {
      "text": "last uh forum there and one of the",
      "start": 234.4,
      "duration": 6.16
    },
    {
      "text": "things that was said that I really uh I",
      "start": 237.28,
      "duration": 6.4
    },
    {
      "text": "really strongly agree with is that",
      "start": 240.56,
      "duration": 6.56
    },
    {
      "text": "most of the illegal uses of AI are",
      "start": 243.68,
      "duration": 5.199
    },
    {
      "text": "already illegal. Not harmful, I should",
      "start": 247.12,
      "duration": 4.16
    },
    {
      "text": "say. Most of the the harmful uses of AI",
      "start": 248.879,
      "duration": 3.92
    },
    {
      "text": "are already illegal. I mean, we were",
      "start": 251.28,
      "duration": 3.44
    },
    {
      "text": "just talking a moment ago about cyber",
      "start": 252.799,
      "duration": 4.0
    },
    {
      "text": "theft. We don't need new rules and new",
      "start": 254.72,
      "duration": 5.039
    },
    {
      "text": "regulations to say that you can't use AI",
      "start": 256.799,
      "duration": 4.56
    },
    {
      "text": "to defraud someone and steal their",
      "start": 259.759,
      "duration": 3.281
    },
    {
      "text": "money. It's already illegal to do that.",
      "start": 261.359,
      "duration": 3.921
    },
    {
      "text": "What we do need uh is we need to make",
      "start": 263.04,
      "duration": 3.76
    },
    {
      "text": "sure our law enforcement agencies are",
      "start": 265.28,
      "duration": 2.639
    },
    {
      "text": "equipped with the tools and the",
      "start": 266.8,
      "duration": 3.28
    },
    {
      "text": "technology they need to detect this, to",
      "start": 267.919,
      "duration": 3.521
    },
    {
      "text": "track it down, and to catch the",
      "start": 270.08,
      "duration": 3.76
    },
    {
      "text": "perpetrators of that fraud. But we don't",
      "start": 271.44,
      "duration": 4.72
    },
    {
      "text": "need new laws that say it's illegal to",
      "start": 273.84,
      "duration": 4.88
    },
    {
      "text": "do that. And that's true in most of the",
      "start": 276.16,
      "duration": 4.319
    },
    {
      "text": "cases of malicious use of AI. And that",
      "start": 278.72,
      "duration": 4.24
    },
    {
      "text": "even goes down to uh some of the cases",
      "start": 280.479,
      "duration": 3.761
    },
    {
      "text": "that you would think are more",
      "start": 282.96,
      "duration": 2.959
    },
    {
      "text": "borderline. I'll give you one example",
      "start": 284.24,
      "duration": 4.56
    },
    {
      "text": "because we talk a lot about bias. And uh",
      "start": 285.919,
      "duration": 5.201
    },
    {
      "text": "I actually think it's uh it's a little",
      "start": 288.8,
      "duration": 3.839
    },
    {
      "text": "humorous when I hear people talk about",
      "start": 291.12,
      "duration": 3.28
    },
    {
      "text": "bias and AI because for me as a",
      "start": 292.639,
      "duration": 4.0
    },
    {
      "text": "technologist, AI is all about bias. You",
      "start": 294.4,
      "duration": 4.4
    },
    {
      "text": "know, you're asking when you're training",
      "start": 296.639,
      "duration": 4.0
    },
    {
      "text": "uh a neural network, you are biasing",
      "start": 298.8,
      "duration": 3.76
    },
    {
      "text": "that neural network and you're doing it",
      "start": 300.639,
      "duration": 4.161
    },
    {
      "text": "on intentionally and on purpose. So uh",
      "start": 302.56,
      "duration": 4.16
    },
    {
      "text": "we have to be very cautious when we use",
      "start": 304.8,
      "duration": 3.52
    },
    {
      "text": "the word bias. But when we use it, we",
      "start": 306.72,
      "duration": 3.759
    },
    {
      "text": "use it in to describe social phenomenon.",
      "start": 308.32,
      "duration": 3.76
    },
    {
      "text": "And one of the things that we're afraid",
      "start": 310.479,
      "duration": 5.041
    },
    {
      "text": "of is that the biases that are used uh",
      "start": 312.08,
      "duration": 5.04
    },
    {
      "text": "that that are exposed in the data that's",
      "start": 315.52,
      "duration": 3.119
    },
    {
      "text": "used to train the AI are going to be",
      "start": 317.12,
      "duration": 3.359
    },
    {
      "text": "reflected in highly consequential",
      "start": 318.639,
      "duration": 5.361
    },
    {
      "text": "decisions that the AI makes. But nothing",
      "start": 320.479,
      "duration": 5.521
    },
    {
      "text": "about that conversation should distract",
      "start": 324.0,
      "duration": 4.0
    },
    {
      "text": "from the fact that most of those biases",
      "start": 326.0,
      "duration": 4.08
    },
    {
      "text": "are already illegal. And I'll give you a",
      "start": 328.0,
      "duration": 3.919
    },
    {
      "text": "specific example. A few years ago, there",
      "start": 330.08,
      "duration": 5.2
    },
    {
      "text": "was a US company that was training an",
      "start": 331.919,
      "duration": 5.601
    },
    {
      "text": "algorithm to automate the screening of",
      "start": 335.28,
      "duration": 4.56
    },
    {
      "text": "résumés. And you probably remember this.",
      "start": 337.52,
      "duration": 4.56
    },
    {
      "text": "So, the idea was that if you have a job",
      "start": 339.84,
      "duration": 4.48
    },
    {
      "text": "opening and you post it and you get",
      "start": 342.08,
      "duration": 4.8
    },
    {
      "text": "10,000 résumés and you want to winnow",
      "start": 344.32,
      "duration": 4.159
    },
    {
      "text": "that down to the hundred that are going",
      "start": 346.88,
      "duration": 4.56
    },
    {
      "text": "to get call back from a human that are",
      "start": 348.479,
      "duration": 4.881
    },
    {
      "text": "going to determine then which 25 people",
      "start": 351.44,
      "duration": 3.599
    },
    {
      "text": "get the interview, right? So, that's",
      "start": 353.36,
      "duration": 4.0
    },
    {
      "text": "that's very beneficial use if you can do",
      "start": 355.039,
      "duration": 5.041
    },
    {
      "text": "that in a way that works. uh you know,",
      "start": 357.36,
      "duration": 4.24
    },
    {
      "text": "you're going to save a lot of human",
      "start": 360.08,
      "duration": 3.04
    },
    {
      "text": "productivity if you could make that",
      "start": 361.6,
      "duration": 3.599
    },
    {
      "text": "work. But in retrospect, we would",
      "start": 363.12,
      "duration": 4.32
    },
    {
      "text": "classify that as a highly consequential",
      "start": 365.199,
      "duration": 3.84
    },
    {
      "text": "decision-making process. In other words,",
      "start": 367.44,
      "duration": 3.599
    },
    {
      "text": "something that deserves extra scrutiny",
      "start": 369.039,
      "duration": 3.44
    },
    {
      "text": "when you're going to automate it because",
      "start": 371.039,
      "duration": 3.361
    },
    {
      "text": "of the consequences of that",
      "start": 372.479,
      "duration": 3.361
    },
    {
      "text": "decision-making on the people that are",
      "start": 374.4,
      "duration": 2.88
    },
    {
      "text": "involved. You know, someone that might",
      "start": 375.84,
      "duration": 2.96
    },
    {
      "text": "have gotten a job that doesn't get it",
      "start": 377.28,
      "duration": 3.44
    },
    {
      "text": "because AI filtered out their resume",
      "start": 378.8,
      "duration": 4.32
    },
    {
      "text": "improperly, right? So, so we we do worry",
      "start": 380.72,
      "duration": 3.759
    },
    {
      "text": "very much about bias in that",
      "start": 383.12,
      "duration": 3.12
    },
    {
      "text": "circumstance. But I mean this these were",
      "start": 384.479,
      "duration": 3.041
    },
    {
      "text": "early days and this wasn't quite",
      "start": 386.24,
      "duration": 3.04
    },
    {
      "text": "recognized at the time. So they",
      "start": 387.52,
      "duration": 3.2
    },
    {
      "text": "developed the algorithm. They went to go",
      "start": 389.28,
      "duration": 4.0
    },
    {
      "text": "test it and it uh exposed some very",
      "start": 390.72,
      "duration": 4.88
    },
    {
      "text": "troubling biases in the algorithm,",
      "start": 393.28,
      "duration": 4.639
    },
    {
      "text": "racial biases and those biases were",
      "start": 395.6,
      "duration": 4.08
    },
    {
      "text": "unintentional but they were baked into",
      "start": 397.919,
      "duration": 3.601
    },
    {
      "text": "the data that was used to train the",
      "start": 399.68,
      "duration": 3.44
    },
    {
      "text": "algorithm and the data you know the",
      "start": 401.52,
      "duration": 3.6
    },
    {
      "text": "algorithm sused out the wrong thing",
      "start": 403.12,
      "duration": 3.84
    },
    {
      "text": "which was to to filter on the basis of",
      "start": 405.12,
      "duration": 4.72
    },
    {
      "text": "race. So, uh, people were horrified by",
      "start": 406.96,
      "duration": 4.959
    },
    {
      "text": "this and rightfully so. But none of that",
      "start": 409.84,
      "duration": 3.44
    },
    {
      "text": "should distract from the fact that, you",
      "start": 411.919,
      "duration": 3.041
    },
    {
      "text": "know, number one, it's great that it was",
      "start": 413.28,
      "duration": 3.359
    },
    {
      "text": "unintentional. It's great that it was",
      "start": 414.96,
      "duration": 3.2
    },
    {
      "text": "caught in testing. It wasn't that",
      "start": 416.639,
      "duration": 3.201
    },
    {
      "text": "algorithm was never deployed. It was",
      "start": 418.16,
      "duration": 3.759
    },
    {
      "text": "corrected. We learned a lot about the",
      "start": 419.84,
      "duration": 4.72
    },
    {
      "text": "way that those biases can can filter",
      "start": 421.919,
      "duration": 4.72
    },
    {
      "text": "into algorithms through training data.",
      "start": 424.56,
      "duration": 4.56
    },
    {
      "text": "But most importantly, it is already",
      "start": 426.639,
      "duration": 4.481
    },
    {
      "text": "illegal",
      "start": 429.12,
      "duration": 4.079
    },
    {
      "text": "to discriminate on the basis of race and",
      "start": 431.12,
      "duration": 4.079
    },
    {
      "text": "hiring in any way, shape, or form. And",
      "start": 433.199,
      "duration": 3.521
    },
    {
      "text": "it does not matter if it's a human doing",
      "start": 435.199,
      "duration": 3.28
    },
    {
      "text": "it or if it's an algorithm doing it. And",
      "start": 436.72,
      "duration": 3.759
    },
    {
      "text": "the if that algorithm had been deployed",
      "start": 438.479,
      "duration": 4.801
    },
    {
      "text": "the moment those biases had been exposed",
      "start": 440.479,
      "duration": 4.56
    },
    {
      "text": "the algorithm would have been illegal to",
      "start": 443.28,
      "duration": 4.16
    },
    {
      "text": "use and people forget about that we",
      "start": 445.039,
      "duration": 4.0
    },
    {
      "text": "don't need I mean people think that well",
      "start": 447.44,
      "duration": 3.12
    },
    {
      "text": "we need to step in you know we need to",
      "start": 449.039,
      "duration": 3.44
    },
    {
      "text": "guard against these uh uh these",
      "start": 450.56,
      "duration": 3.759
    },
    {
      "text": "malicious these uh these negative",
      "start": 452.479,
      "duration": 3.601
    },
    {
      "text": "outcomes and the answer is no no we",
      "start": 454.319,
      "duration": 3.44
    },
    {
      "text": "already have those rules the framework",
      "start": 456.08,
      "duration": 3.92
    },
    {
      "text": "in place and so dealing like with AI",
      "start": 457.759,
      "duration": 6.241
    },
    {
      "text": "like it's brand new is not necessary in",
      "start": 460.0,
      "duration": 6.4
    },
    {
      "text": "most of those cases and when you tell",
      "start": 464.0,
      "duration": 4.56
    },
    {
      "text": "people this when we articulate It makes",
      "start": 466.4,
      "duration": 3.519
    },
    {
      "text": "people a lot more comfortable because",
      "start": 468.56,
      "duration": 3.199
    },
    {
      "text": "people think that AI is largely",
      "start": 469.919,
      "duration": 3.84
    },
    {
      "text": "unregulated right now and that is",
      "start": 471.759,
      "duration": 3.521
    },
    {
      "text": "absolutely not the case. We already",
      "start": 473.759,
      "duration": 4.56
    },
    {
      "text": "talked about the FAA and Nitsa and the",
      "start": 475.28,
      "duration": 4.479
    },
    {
      "text": "FAA and you know there are hundred",
      "start": 478.319,
      "duration": 3.681
    },
    {
      "text": "different examples already in US",
      "start": 479.759,
      "duration": 4.72
    },
    {
      "text": "government where regulatory bodies are",
      "start": 482.0,
      "duration": 4.479
    },
    {
      "text": "having to deal with the effects of AI.",
      "start": 484.479,
      "duration": 4.56
    },
    {
      "text": "Uh and so the the the perception that",
      "start": 486.479,
      "duration": 4.72
    },
    {
      "text": "it's unregulated is completely wrong. We",
      "start": 489.039,
      "duration": 3.921
    },
    {
      "text": "just need to make sure that we massage",
      "start": 491.199,
      "duration": 4.0
    },
    {
      "text": "that framework to make sure that the the",
      "start": 492.96,
      "duration": 5.519
    },
    {
      "text": "the harmful stuff is filtered out and",
      "start": 495.199,
      "duration": 4.961
    },
    {
      "text": "protected against while still enabling",
      "start": 498.479,
      "duration": 3.12
    },
    {
      "text": "the beneficial stuff and I think we'll",
      "start": 500.16,
      "duration": 2.64
    },
    {
      "text": "be fine.",
      "start": 501.599,
      "duration": 3.04
    },
    {
      "text": ">> You know, countries want to have their",
      "start": 502.8,
      "duration": 4.399
    },
    {
      "text": "own system that protects their data,",
      "start": 504.639,
      "duration": 4.56
    },
    {
      "text": "their languages. We we're talking about",
      "start": 507.199,
      "duration": 5.601
    },
    {
      "text": "obviously exporting the US AI stack. How",
      "start": 509.199,
      "duration": 5.601
    },
    {
      "text": "can those two things kind of come",
      "start": 512.8,
      "duration": 4.4
    },
    {
      "text": "together? uh when you look at you know",
      "start": 514.8,
      "duration": 5.2
    },
    {
      "text": "countries like Singapore or others they",
      "start": 517.2,
      "duration": 4.959
    },
    {
      "text": "have tremendous capability in AI they",
      "start": 520.0,
      "duration": 4.48
    },
    {
      "text": "have asan countries have languages that",
      "start": 522.159,
      "duration": 4.481
    },
    {
      "text": "go back hundreds and thousands of years",
      "start": 524.48,
      "duration": 4.479
    },
    {
      "text": "etc. So how do we kind of bring those",
      "start": 526.64,
      "duration": 3.36
    },
    {
      "text": "things together?",
      "start": 528.959,
      "duration": 2.961
    },
    {
      "text": ">> Right. No, I think it's a a great",
      "start": 530.0,
      "duration": 4.24
    },
    {
      "text": "question. Uh you know, and the answer is",
      "start": 531.92,
      "duration": 6.32
    },
    {
      "text": "that if if you look at the scientific",
      "start": 534.24,
      "duration": 7.12
    },
    {
      "text": "research, the most powerful and capable",
      "start": 538.24,
      "duration": 7.039
    },
    {
      "text": "AI is the models that have access to the",
      "start": 541.36,
      "duration": 6.88
    },
    {
      "text": "greatest amount of information, right?",
      "start": 545.279,
      "duration": 5.281
    },
    {
      "text": "Just just in an unqualified statement.",
      "start": 548.24,
      "duration": 4.64
    },
    {
      "text": "Uh and so as a worldwide community, we",
      "start": 550.56,
      "duration": 4.24
    },
    {
      "text": "want our most advanced models to have",
      "start": 552.88,
      "duration": 4.0
    },
    {
      "text": "access to everything. and we can have a",
      "start": 554.8,
      "duration": 3.76
    },
    {
      "text": "discussion about you know copyrighted",
      "start": 556.88,
      "duration": 3.28
    },
    {
      "text": "material and private data all that stuff",
      "start": 558.56,
      "duration": 2.959
    },
    {
      "text": "and you know those are appropriate",
      "start": 560.16,
      "duration": 2.16
    },
    {
      "text": "discussions to have",
      "start": 561.519,
      "duration": 3.76
    },
    {
      "text": ">> as these countries are maturing where do",
      "start": 562.32,
      "duration": 4.639
    },
    {
      "text": "you see some opportunities as far as",
      "start": 565.279,
      "duration": 2.721
    },
    {
      "text": "talent is concerned?",
      "start": 566.959,
      "duration": 3.841
    },
    {
      "text": ">> No that's a a great question u you know",
      "start": 568.0,
      "duration": 6.72
    },
    {
      "text": "I think that a worldwide meritocracy",
      "start": 570.8,
      "duration": 7.12
    },
    {
      "text": "where the best talent rises to uh our",
      "start": 574.72,
      "duration": 5.04
    },
    {
      "text": "distant ancestor you know just a few",
      "start": 577.92,
      "duration": 3.2
    },
    {
      "text": "generations ago that went through Ellis",
      "start": 579.76,
      "duration": 3.199
    },
    {
      "text": "Island or somewhere else. So you know we",
      "start": 581.12,
      "duration": 3.68
    },
    {
      "text": "we were all immigrants and I think that",
      "start": 582.959,
      "duration": 4.32
    },
    {
      "text": "uh I think that if we can get back to a",
      "start": 584.8,
      "duration": 4.159
    },
    {
      "text": "system of meritocracy like that the",
      "start": 587.279,
      "duration": 3.761
    },
    {
      "text": "whole worldwide community will benefit.",
      "start": 588.959,
      "duration": 4.32
    },
    {
      "text": ">> A little fun question couple of",
      "start": 591.04,
      "duration": 5.359
    },
    {
      "text": "countries have named uh a minister for",
      "start": 593.279,
      "duration": 5.921
    },
    {
      "text": "AI. Would you recommend for any of these",
      "start": 596.399,
      "duration": 4.961
    },
    {
      "text": "ASEAN countries to set up a minister for",
      "start": 599.2,
      "duration": 3.759
    },
    {
      "text": "AI?",
      "start": 601.36,
      "duration": 5.68
    },
    {
      "text": "Uh yes, but",
      "start": 602.959,
      "duration": 6.401
    },
    {
      "text": "uh regulating it in a medical device is",
      "start": 607.04,
      "duration": 3.6
    },
    {
      "text": "going to be different than regulating it",
      "start": 609.36,
      "duration": 4.32
    },
    {
      "text": "in a video game, right? So uh the the",
      "start": 610.64,
      "duration": 6.639
    },
    {
      "text": "danger of appointing a a an AI minister",
      "start": 613.68,
      "duration": 6.0
    },
    {
      "text": "is that then they will centralize the",
      "start": 617.279,
      "duration": 5.041
    },
    {
      "text": "regulation of AI within their ministry",
      "start": 619.68,
      "duration": 5.2
    },
    {
      "text": "and therefore accomplish the opposite of",
      "start": 622.32,
      "duration": 4.079
    },
    {
      "text": "what you're trying to accomplish.",
      "start": 624.88,
      "duration": 5.199
    },
    {
      "text": ">> So is it yes or no? for me. I I line",
      "start": 626.399,
      "duration": 6.161
    },
    {
      "text": "with yes, but I'd be very comfortable.",
      "start": 630.079,
      "duration": 4.641
    },
    {
      "text": "I'll give you an example. So, uh you saw",
      "start": 632.56,
      "duration": 4.48
    },
    {
      "text": "the president uh president Biden and",
      "start": 634.72,
      "duration": 5.6
    },
    {
      "text": "executive order uh creating the AI",
      "start": 637.04,
      "duration": 4.479
    },
    {
      "text": "safety institute.",
      "start": 640.32,
      "duration": 4.8
    },
    {
      "text": ">> Uh and President Trump uh uh undid that",
      "start": 641.519,
      "duration": 4.88
    },
    {
      "text": "because we can't use the word safety",
      "start": 645.12,
      "duration": 2.32
    },
    {
      "text": "because that's a Biden thing and",
      "start": 646.399,
      "duration": 3.041
    },
    {
      "text": "therefore it must be bad. Uh and now we",
      "start": 647.44,
      "duration": 4.0
    },
    {
      "text": "call it Casey, right? The center for AI,",
      "start": 649.44,
      "duration": 3.92
    },
    {
      "text": "what is it? Stability and advancement or",
      "start": 651.44,
      "duration": 3.2
    },
    {
      "text": "something like that, whatever the",
      "start": 653.36,
      "duration": 3.44
    },
    {
      "text": "acronym is. uh both both of those are",
      "start": 654.64,
      "duration": 4.72
    },
    {
      "text": "under NIST and it's very important to",
      "start": 656.8,
      "duration": 5.68
    },
    {
      "text": "make the fact the point that NIST is a",
      "start": 659.36,
      "duration": 5.039
    },
    {
      "text": "standard setting agency. It is a",
      "start": 662.48,
      "duration": 4.88
    },
    {
      "text": "nonregulatory agency and folks that is",
      "start": 664.399,
      "duration": 6.401
    },
    {
      "text": "very intentional uh that we're putting",
      "start": 667.36,
      "duration": 6.32
    },
    {
      "text": "the the we're empowering the agency to",
      "start": 670.8,
      "duration": 6.56
    },
    {
      "text": "create and standards and uh and manage",
      "start": 673.68,
      "duration": 6.48
    },
    {
      "text": "international cooperation in an agency",
      "start": 677.36,
      "duration": 5.44
    },
    {
      "text": "without the power to [music] regulate",
      "start": 680.16,
      "duration": 4.56
    },
    {
      "text": "because we do not want them to use that",
      "start": 682.8,
      "duration": 4.24
    },
    {
      "text": "authority to create regulations. We just",
      "start": 684.72,
      "duration": 4.32
    },
    {
      "text": "want them to create standards and I",
      "start": 687.04,
      "duration": 2.88
    },
    {
      "text": "think that that's appropriate [music]",
      "start": 689.04,
      "duration": 3.039
    },
    {
      "text": "and that's that's that's",
      "start": 689.92,
      "duration": 4.0
    },
    {
      "text": "a a way of solving that problem.",
      "start": 692.079,
      "duration": 3.76
    },
    {
      "text": ">> Standards not regulation. That's the",
      "start": 693.92,
      "duration": 4.08
    },
    {
      "text": "last word. Congressman, thank you so",
      "start": 695.839,
      "duration": 5.041
    },
    {
      "text": "much. Your insight, not just technical",
      "start": 698.0,
      "duration": 5.279
    },
    {
      "text": "but also from a legislative standpoint",
      "start": 700.88,
      "duration": 4.639
    },
    {
      "text": "really. Uh as the world is moving",
      "start": 703.279,
      "duration": 4.161
    },
    {
      "text": "towards AI policy, we need more people",
      "start": 705.519,
      "duration": 4.161
    },
    {
      "text": "like you. And I hope our audience",
      "start": 707.44,
      "duration": 3.76
    },
    {
      "text": "understands that there is a huge",
      "start": 709.68,
      "duration": 3.599
    },
    {
      "text": "opportunity for us and Asia to work",
      "start": 711.2,
      "duration": 4.0
    },
    {
      "text": "together. not from an economic",
      "start": 713.279,
      "duration": 3.441
    },
    {
      "text": "standpoint, but I think billions of",
      "start": 715.2,
      "duration": 2.96
    },
    {
      "text": "people will benefit from this. So,",
      "start": 716.72,
      "duration": 3.119
    },
    {
      "text": "please give a big round of applause to",
      "start": 718.16,
      "duration": 4.368
    },
    {
      "text": "Fox. [applause]",
      "start": 719.839,
      "duration": 2.689
    },
    {
      "text": "Thanks for tuning in to the Regulating",
      "start": 726.959,
      "duration": 4.401
    },
    {
      "text": "AI podcast [music] with Sanjay Puri. If",
      "start": 728.88,
      "duration": 4.88
    },
    {
      "text": "you enjoyed today's conversation, don't",
      "start": 731.36,
      "duration": 4.56
    },
    {
      "text": "forget to leave a comment. We'd love to",
      "start": 733.76,
      "duration": 4.16
    },
    {
      "text": "hear what you thought. Share it with",
      "start": 735.92,
      "duration": 4.64
    },
    {
      "text": "someone curious about the future of EI.",
      "start": 737.92,
      "duration": 4.719
    },
    {
      "text": "And join us next time for more stories",
      "start": 740.56,
      "duration": 4.8
    },
    {
      "text": "and insights from the leaders shaping",
      "start": 742.639,
      "duration": 4.88
    },
    {
      "text": "what's ahead right here on the",
      "start": 745.36,
      "duration": 6.2
    },
    {
      "text": "Regulating AI podcast.",
      "start": 747.519,
      "duration": 4.041
    }
  ]
}