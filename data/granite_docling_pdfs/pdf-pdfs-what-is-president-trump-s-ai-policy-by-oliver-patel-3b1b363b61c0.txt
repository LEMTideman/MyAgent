<!-- image -->

Hey

ðŸ‘‹

<!-- image -->

I'm Oliver Patel, author and creator of Enterprise AI Governance .

On Thursday 11 December 2025, President Trump issued an Executive Order on Ensuring a National Policy Framework for AI. This represents the administration's latest attempt at blocking and constraining how U.S. states regulate AI. This article summarises the new Executive Order, situates it in the wider context of Trump's AI policy, assesses the challenges the administration faces in preempting state AI laws, and reflects on what companies should do next.

For a detailed, up-to-date, and visual guide to U.S. AI law and policy (covering the federal and state levels), as well as U.S, China, and EU comparison charts, sign up to secure a 25% discount for my forthcoming book, Fundamentals of AI Governance (2026).

## What just happened?

On 11 December 2025, President Trump issued a new Executive Order that attempts to block states from enforcing existing AI regulations and deter states from enacting new AI laws.

Just five months after the Senate rejected the proposed 10-year moratorium on state AI laws by 99 votes to 1, the administration is having another bite of the cherry-this

time through litigation, funding restrictions, and federal preemption, potentially via new legislation.

However, it is important to note that the latest development is an Executive Order (i.e., a presidential directive), not legislation. Meaningfully preempting state laws in this way would require legislation, which requires approval from both the House of Representatives and the Senate. It does not appear that substantive political changes have occurred in the past few months to render this more likely than it was back in the summer.

Nonetheless, this latest Executive Order is a powerful signal of intent that highlights the administration is digging in on this particular issue, despite the large-scale opposition to the previous 10-year moratorium proposal.

Indeed, the administration has repeatedly stated that its AI policy objective is to 'sustain and enhance America's global AI dominance'. State AI laws have been in the firing line, as part of the wider focus on pursuing deregulation as a means to propel the U.S. as the world's dominant AI power.

Preemption is a U.S. constitutional principle whereby federal law (i.e., law passed by Congress) takes precedence over state law when there are conflicts between the two. When a federal law 'preempts' a state law, the state law is effectively nullified.

However, the controversy regarding state AI law preemption is partly due to the fact that there is no comprehensive federal AI law. And the federal AI laws that are on the books cover narrower domains such as strengthening the U.S. AI industry, support and funding for AI research and infrastructure, and export controls. Where state AI laws focus on responsible AI topics like transparency or bias, there is arguably a lack of federal law to preempt these laws.

Thanks for reading Enterprise AI Governance! Subscribe for free to receive new posts and support my work.

## What is the new Executive Order on AI?

President Trump signed the Executive Order: Ensuring a National Policy Framework for Artificial Intelligence on Thursday 11 December 2025,

An Executive Order is a directive issued by the President to federal agencies and executive branch officials. It is issued by the President unilaterally, does not require Congressional approval and cannot, by itself, override state laws.

The core argument Trump presents in this Executive Order is that the patchwork of many state AI laws creates compliance burdens and administrative complexity that could undermine U.S. competitiveness. Having 50 different AI regulatory regimes, the Executive Order argues, ' makes compliance challenging, particularly for startups '.

Colorado's AI law-Consumer Protections for AI (SB24-205), effective date 30 June 2026-is singled out for criticism, with the Executive Order claiming that such laws tackling 'algorithmic discrimination' may force AI models to produce false results in order to avoid differential treatment of protected groups.

The declared policy of the administration is to establish a 'minimally burdensome national standard' for AI, as opposed to '50 discordant State ones'. To achieve this, the Executive Order directs a multi-pronged set of actions and broader strategy for the U.S. federal government to pursue:

- First, the Attorney General must establish an AI Litigation Task Force within 30 days (of the Executive Order), with the goal of challenging state AI laws in court. The focus will be on identifying state laws that are inconsistent with the U.S. AI policy of 'sustaining and advancing U.S. global dominance in AI'. The grounds for legal challenge could include 'unconstitutional regulation' of interstate commerce or preemption by existing federal regulations.

- Second, the Secretary of Commerce, in consultation with other government leaders, must publish an evaluation of existing state AI laws within 90 days (of the Executive Order), identifying 'onerous' laws that conflict with the U.S. AI policy objective mentioned above. This evaluation must focus on laws that 'require AI models to alter truthful outputs' or that compel organisations to 'disclose information in a manner that would violate the First Amendment'. This is significant, as it explicitly targets laws relating to AI transparency and bias mitigation, two core threads throughout many existing state AI laws.
- Third, the Order imposes funding restrictions on states that are deemed to have 'onerous AI laws'. States identified through the evaluation referenced above will be ineligible for certain categories of federal funding under the Broadband Equity Access and Deployment (BEAD) Program. U.S. government executive departments and agencies are also directed to assess whether they can condition discretionary grants on states agreeing not to enforce their existing AI laws and/or not enacting new AI laws. This could result in government agencies withholding certain types of grant funding from states.
- Fourth, the Federal Communications Commission (FCC), the agency that regulates U.S. communications (e.g., broadcasting, internet, and telecommunications), must initiate work to determine whether to adopt a federal reporting and disclosure standard for AI models that would preempt conflicting state laws. It is important to note that the Executive Order requires the FCC to 'initiate a proceeding'; it

- does not require the FCC to adopt such a standard for AI transparency. However, the implied thinking is that if there is a national standard, this could be argued to supersede state AI laws covering AI reporting and disclosure.
- Fifth, the FTC must issue a policy statement explaining when state laws requiring the alteration of the 'truthful outputs' are preempted by federal prohibitions on deceptive practices, which largely stem from the FTC Act that prohibits 'unfair and deceptive practices'. Again, the implication is that such guidance would strengthen the case for existing federal laws superseding state AI laws in this domain too.
- Finally, the administration will prepare a legislative proposal for a uniform federal AI framework that preempts state laws. However, the proposal would be narrow and would not seek to preempt state laws covering any of the following policy areas:
- child safety;
- AI compute and data centre infrastructure;
- state government procurement and use of AI; and
- other topics to be determined.

This is significant as it highlights the policy areas which the administration deem to be legitimate domains of autonomous state AI lawmaking, even if the result is regulatory

## divergence within the U.S.

Thanks for reading Enterprise AI Governance! Subscribe for free to receive new posts and support my work.

## How did Trump attempt to block state AI laws previously?

This latest Executive Order is not the administration's first attempt to constrain state AI laws. Back in May 2025, the administration proposed adding a 10-year moratorium on state AI laws enforcement to Trump's flagship domestic policy and taxation bill, the 'One Big Beautiful Bill Act' (H.R.1).

I covered the 10-year moratorium in detail in a previous edition of Enterprise AI Governance: Unpacking the 10-year Moratorium on U.S. State AI Laws . Here is a summary of that article.

The proposed moratorium was designed to prevent U.S. states from being able to enforce 'any law or regulation limiting, restricting, or otherwise regulating AI models, AI systems, or automated decision systems' for a period of 10 years. Although this

would not technically have prevented states from introducing and passing new AI laws, the broad restriction on enforcement would have rendered doing so pointless.

This was an attempt by the federal government to preempt state AI laws by blocking states from enforcing laws they had already passed, as well as any new laws they might pass in the future. The stated goal was to halt the 'proliferation of a complex and fragmented patchwork of state AI laws', in support of AI innovation across the country.

The House of Representatives voted to pass the state AI law moratorium by a narrow margin, largely along party lines, with 215 in favour and 214 against. However, following this, the moratorium was decisively rejected. In July 2025, the Senate voted 99 to 1 to remove it from the bill. This followed a significant bipartisan campaign against the provision. A June 2025 letter, signed by 260 state lawmakers, stated that 'states are laboratories of democracy accountable to their citizens and must maintain the flexibility to respond to new digital concerns'. Several Republican state governors also campaigned against the proposal.

The main reason the moratorium proved so controversial was not really about AI. The case (against it) centred on the philosophical objection to the federal government constraining states in this way, particularly given that there is no comprehensive federal AI law to take precedence. The argument was that the states' hands were being

tied, without an alternative federal framework on the table. The fundamentals of the situation do not appear to have meaningfully changed in the months that have passed.

However, the December 2025 Executive Order represents a pivot in strategy. Rather than seeking blanket preemption through legislation-which requires Congressional approval-the administration is now pursuing litigation, agency action, and funding leverage. These approaches can be initiated by the executive branch alone. However, as noted above, the President's legal authority to actually preempt state laws remains limited without legislation. The administration may also pursue new legislation, but this will likely face similar challenges in Congress.

## What AI laws do states have and will Trump succeed in blocking them?

In lieu of comprehensive federal AI law, dozens of U.S. states have enacted AI-related laws. 131 such laws were passed between 2016 and 2024, and over 700 AI-related bills were proposed in 2024 alone. The states with the most AI-related laws are California, Colorado, Maryland, Utah, and Virginia. California has been particularly active, enacting dozens of laws that regulate AI in different ways. These laws cover themes including fairness and accountability, transparency, data privacy, deepfakes, and government use of AI.

However, the administration faces an uphill task in its efforts to block the enforcement and enactment of these laws. Now that the moratorium has been rejected by the Senate due to concerns regarding preemption and the ways in which the federal government can constrain the states, it is fair to argue that subsequent federal legislative proposals will be met with similar levels of scrutiny and controversy.

## What other AI policy actions has this administration taken?

The new Executive Order sits within a broader pro-business and pro-innovation AI policy agenda.

Trump has pivoted away from the Biden administration's AI governance and safety agenda. Promoting U.S. AI leadership-which has always been a core federal AI policy objective-now takes centre stage. One of the first actions taken by Trump at the start of this second term, in January 2025, was to revoke various Biden-era executive orders, including the flagship Executive Order on Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence.

In July 2025, the administration published Winning the Race: America's AI Action Plan , which outlines how the U.S. can achieve and maintain 'unquestioned and

unchallenged global technological dominance' in AI.

I also covered the administration's AI Action Plan in a previous edition of Enterprise AI Governance: What America's AI Action Plan Means for AI Governance . A summary of that explainer piece is provided below.

The AI Action Plan contains dozens of policy recommendations across three pillars:

- Pillar 1. Accelerate AI Innovation
- Pillar 2. Build American AI Infrastructure
- Pillar 3. Lead in International AI Diplomacy and Security

Notably, under Pillar 1, the AI Action Plan recommended withholding funding for AIrelated initiatives from states with 'burdensome AI regulations'. This core idea has now been operationalised through the new Executive Order and its funding restrictions. Moreover, the rejection of the 10-year moratorium by the Senate did not extinguish the underlying policy objective; rather, it has been repackaged and is now pursued through alternative means.

The AI Action Plan is significant because it directly links AI regulations with the ability (or lack thereof) of companies to innovate at speed. Put simply, the Trump

administration believes that AI should not be constrained by regulations and that doing so would impede the U.S. economic and security prospects in a damaging way.

Other recommended policy actions in the AI Action Plan included:

- Taking action to review and remove any existing Federal regulations that impede AI innovation.
- Ensure the federal government only procures 'unbiased' and 'ideologically neutral' large language models.
- Fast-track and streamline processes for data centre construction review, approval, and licensing.
- Advocate for 'pro-innovation' approaches to international AI governance, that reflect 'American values' and shift away from 'burdensome regulations'.

Other notable AI policy measures pursued by this administration include Executive Orders on advancing AI education for American youth (April 2025), accelerating federal permitting for data centre infrastructure (July 2025), preventing 'woke AI' in federal government procurement (July 2025), and promoting the export of the American AI technology stack (July 2025). The TAKE IT DOWN Act, which criminalises the publication of non-consensual intimate deepfakes, was signed into law in May 2025.

## What should companies operating in the U.S. do now?

If you think AI governance is not relevant for your organisation because the current administration is pro-AI and against restrictive AI regulation, you could be in for a rude awakening if things go wrong.

Deregulation does not mean that AI risks no longer apply to you or that you are not exposed. Indeed, the AI Action Plan itself highlights various AI-related risks that could slow innovation, including interpretability, robustness, and misalignment. Furthermore, all enterprises using generative AI at scale are exposed to a litany of (relatively novel) data-related risks. I outlined these in my article on the PROTECT Framework: Managing Data Risks in the AI Era .

The PROTECT Framework empowers you to understand, map, and mitigate the most pertinent data risks that are fuelled by widespread adoption of generative AI, covering themes such as public AI tool usage, rogue internal AI projects, opportunistic vendors, and compliance and copyright breaches. These risks cannot be mitigated without a robust approach to AI governance, which serves as a reminder that AI-specific regulatory compliance is not the sole driver for enterprise AI governance.

Moreover, even the White House's Office of Management and Budget (OMB) describes effective AI governance as 'key to accelerated innovation'. Indeed, the AI governance framework that OMB directs federal agencies to implement-covering AI

development, deployment, procurement, and use-is robust. This suggests that although the U.S. government does not want there to be any regulatory measures getting in the way of U.S. companies' AI activities, it nonetheless recognises that a well-designed and proportionate AI governance framework is important for both risk mitigation and value generation, especially in sensitive domains.

For U.S. companies, the reality today is the same as it was yesterday. There still exists a complex patchwork of many state AI laws to contend with, as well as federal and state laws that meaningfully regulate or implicate AI in specific ways, such as privacy, copyright, employment, and consumer protection laws. Given the complexity of developing different internal AI governance frameworks for different jurisdictions, I always recommend having a company-wide AI governance framework that promotes and facilitates compliance, risk management, and AI-enablement across all the important jurisdictions you operate in.

Thanks for reading! Subscribe below for weekly updates from Enterprise AI Governance.

<!-- image -->

6 Likes