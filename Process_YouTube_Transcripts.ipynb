{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbcebae3-1b3a-4142-b98c-c31adc94be54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import API keys\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # loads .env from the current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19c93593-6573-4bd6-8637-40c169626542",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Iterable, List, Optional, Tuple\n",
    "\n",
    "from yt_dlp import YoutubeDL\n",
    "from yt_dlp.utils import DownloadError\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# Keep exception imports robust across youtube-transcript-api versions\n",
    "try:\n",
    "    from youtube_transcript_api._errors import (  # type: ignore\n",
    "        NoTranscriptFound,\n",
    "        TranscriptsDisabled,\n",
    "        VideoUnavailable,\n",
    "        RequestBlocked,\n",
    "        IpBlocked,\n",
    "        TooManyRequests,\n",
    "    )\n",
    "except Exception:  # pragma: no cover\n",
    "    NoTranscriptFound = TranscriptsDisabled = VideoUnavailable = Exception  # type: ignore\n",
    "    RequestBlocked = IpBlocked = TooManyRequests = Exception  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b96723a-a637-424f-8c02-902420dfa744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_yyyymmdd(s: str) -> datetime:\n",
    "    # s like \"20240115\"\n",
    "    return datetime(int(s[0:4]), int(s[4:6]), int(s[6:8]), tzinfo=timezone.utc)\n",
    "\n",
    "def upload_dt_from_meta(video_meta: Dict[str, Any]) -> Optional[datetime]:\n",
    "    ud = video_meta.get(\"upload_date\")\n",
    "    if isinstance(ud, str) and len(ud) == 8 and ud.isdigit():\n",
    "        return parse_yyyymmdd(ud)\n",
    "\n",
    "    ts = video_meta.get(\"timestamp\")\n",
    "    if isinstance(ts, (int, float)):\n",
    "        return datetime.fromtimestamp(ts, tz=timezone.utc)\n",
    "\n",
    "    return None\n",
    "\n",
    "def ydl_extract_video_date(video_url: str) -> Optional[datetime]:\n",
    "    ydl_opts = {\n",
    "        \"quiet\": True,\n",
    "        \"skip_download\": True,\n",
    "        \"no_warnings\": True,\n",
    "    }\n",
    "    try:\n",
    "        with YoutubeDL(ydl_opts) as ydl:\n",
    "            info = ydl.extract_info(video_url, download=False) or {}\n",
    "    except DownloadError:\n",
    "        # private / needs auth / unavailable / etc.\n",
    "        return None\n",
    "\n",
    "    ud = info.get(\"upload_date\")\n",
    "    if isinstance(ud, str) and len(ud) == 8 and ud.isdigit():\n",
    "        return parse_yyyymmdd(ud)\n",
    "\n",
    "    ts = info.get(\"timestamp\")\n",
    "    if isinstance(ts, (int, float)):\n",
    "        return datetime.fromtimestamp(ts, tz=timezone.utc)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e456585-1c33-4b75-84d7-163e9ee680a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_playlist_url(url: str) -> bool:\n",
    "    # Works for both /playlist?list=... and watch?v=...&list=...\n",
    "    return (\"list=\" in url) or (\"/playlist\" in url)\n",
    "\n",
    "def iter_playlists_from_source(source_url: str) -> Iterable[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    If source_url is already a playlist URL, treat it as a single playlist.\n",
    "    Otherwise assume it's a channel /podcasts tab and enumerate all podcast playlists.\n",
    "    \"\"\"\n",
    "    if is_playlist_url(source_url):\n",
    "        info = ydl_extract_flat(source_url)\n",
    "        yield {\n",
    "            \"playlist_title\": info.get(\"title\") or \"playlist\",\n",
    "            \"playlist_url\": source_url,\n",
    "            \"playlist_id\": info.get(\"id\"),\n",
    "        }\n",
    "    else:\n",
    "        yield from iter_podcast_playlists(source_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72ddfae0-197c-4c78-b91d-09048ec465a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ydl_extract_flat(url: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Use yt-dlp in \"flat\" mode to quickly list entries (podcast playlists/videos)\n",
    "    without downloading any media.\n",
    "    \"\"\"\n",
    "    ydl_opts = {\n",
    "        \"quiet\": True,\n",
    "        \"skip_download\": True,\n",
    "        \"extract_flat\": True,\n",
    "        \"ignoreerrors\": True,\n",
    "        \"extractor_args\": {\"youtube\": {\"playlist_ajax\": \"true\"}, \n",
    "                           \"youtubetab\": {\"approximate_date\": \"true\"}},\n",
    "    }\n",
    "    with YoutubeDL(ydl_opts) as ydl:\n",
    "        info = ydl.extract_info(url, download=False)\n",
    "        if info is None:\n",
    "            raise RuntimeError(f\"yt-dlp returned no info for {url}\")\n",
    "        return info\n",
    "\n",
    "\n",
    "def normalize_url(u: str) -> str:\n",
    "    if u.startswith(\"http\"):\n",
    "        return u\n",
    "    if u.startswith(\"/\"):\n",
    "        return \"https://www.youtube.com\" + u\n",
    "    return \"https://www.youtube.com/\" + u\n",
    "\n",
    "\n",
    "def playlist_url_from_entry(entry: Dict[str, Any]) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Try to get a playlist URL from a yt-dlp entry (varies by extractor/version).\n",
    "    \"\"\"\n",
    "    for key in (\"url\", \"webpage_url\"):\n",
    "        v = entry.get(key)\n",
    "        if isinstance(v, str) and v:\n",
    "            v = normalize_url(v)\n",
    "            if \"list=\" in v or \"/playlist\" in v:\n",
    "                return v\n",
    "\n",
    "    pid = entry.get(\"id\")\n",
    "    if isinstance(pid, str) and pid:\n",
    "        return f\"https://www.youtube.com/playlist?list={pid}\"\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def iter_podcast_playlists(podcasts_tab_url: str) -> Iterable[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    On /podcasts, yt-dlp typically returns entries that correspond to podcast playlists.\n",
    "    \"\"\"\n",
    "    info = ydl_extract_flat(podcasts_tab_url)\n",
    "    for e in info.get(\"entries\") or []:\n",
    "        if not e:\n",
    "            continue\n",
    "        pl_url = playlist_url_from_entry(e)\n",
    "        if not pl_url:\n",
    "            continue\n",
    "        yield {\n",
    "            \"playlist_title\": e.get(\"title\") or \"podcast\",\n",
    "            \"playlist_url\": pl_url,\n",
    "            \"playlist_id\": e.get(\"id\"),\n",
    "        }\n",
    "\n",
    "\n",
    "def iter_videos_from_playlist(playlist_url: str) -> Iterable[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Returns video entries with at least id + title.\n",
    "    \"\"\"\n",
    "    info = ydl_extract_flat(playlist_url)\n",
    "    for e in info.get(\"entries\") or []:\n",
    "        if not e:\n",
    "            continue\n",
    "        vid = e.get(\"id\")\n",
    "        if not isinstance(vid, str) or not vid:\n",
    "            continue\n",
    "        yield {\n",
    "            \"video_id\": vid,\n",
    "            \"video_title\": e.get(\"title\") or \"\",\n",
    "            \"video_url\": f\"https://www.youtube.com/watch?v={vid}\",\n",
    "            \"upload_date\": e.get(\"upload_date\"),  # YYYYMMDD sometimes\n",
    "            \"timestamp\": e.get(\"timestamp\"),      # unix seconds sometimes\n",
    "        }\n",
    "\n",
    "\n",
    "def load_processed_video_ids(manifest_path: Path) -> set[str]:\n",
    "    if not manifest_path.exists():\n",
    "        return set()\n",
    "    ids: set[str] = set()\n",
    "    with manifest_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                obj = json.loads(line)\n",
    "                if obj.get(\"status\") == \"ok\":\n",
    "                    ids.add(obj[\"video_id\"])\n",
    "            except Exception:\n",
    "                continue\n",
    "    return ids\n",
    "\n",
    "\n",
    "def append_manifest(manifest_path: Path, record: Dict[str, Any]) -> None:\n",
    "    manifest_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with manifest_path.open(\"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "\n",
    "def transcript_to_text(segments: List[Dict[str, Any]]) -> str:\n",
    "    \"\"\"\n",
    "    youtube-transcript-api segments look like:\n",
    "    {\"text\": \"...\", \"start\": 12.34, \"duration\": 3.21}\n",
    "    \"\"\"\n",
    "    lines = [(s.get(\"text\") or \"\").replace(\"\\n\", \" \").strip() for s in segments]\n",
    "    lines = [ln for ln in lines if ln]\n",
    "    return \"\\n\".join(lines) + \"\\n\"\n",
    "\n",
    "\n",
    "def fetch_and_save_transcript(\n",
    "    out_dir: Path,\n",
    "    channel: str,\n",
    "    playlist_meta: Dict[str, Any],\n",
    "    video_meta: Dict[str, Any],\n",
    "    ytt_api: YouTubeTranscriptApi,\n",
    "    languages: List[str],\n",
    "    sleep_s: float = 0.25,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Saves ONLY:\n",
    "      - JSON: metadata + transcript segments\n",
    "      - TXT: plain text transcript\n",
    "    Also logs to manifest.jsonl so reruns skip already processed videos.\n",
    "    \"\"\"\n",
    "    manifest_path = out_dir / \"manifest.jsonl\"\n",
    "    json_dir = out_dir / \"json\" / channel\n",
    "    txt_dir = out_dir / \"txt\" / channel\n",
    "\n",
    "    video_id = video_meta[\"video_id\"]\n",
    "    now = datetime.now(timezone.utc).isoformat()\n",
    "\n",
    "    try:\n",
    "        fetched = ytt_api.fetch(video_id, languages=languages)\n",
    "        segments = fetched.to_raw_data()\n",
    "        #segments = ytt_api.get_transcript(video_id, languages=languages)\n",
    "\n",
    "        payload = {\n",
    "            \"source\": \"youtube\",\n",
    "            \"channel\": channel,\n",
    "            \"playlist_title\": playlist_meta.get(\"playlist_title\"),\n",
    "            \"playlist_url\": playlist_meta.get(\"playlist_url\"),\n",
    "            \"playlist_id\": playlist_meta.get(\"playlist_id\"),\n",
    "            \"video_id\": video_id,\n",
    "            \"video_title\": video_meta.get(\"video_title\"),\n",
    "            \"video_url\": video_meta.get(\"video_url\"),\n",
    "            \"fetched_at\": now,\n",
    "            \"transcript\": segments,  # list[{\"text\",\"start\",\"duration\"}]\n",
    "        }\n",
    "\n",
    "        json_dir.mkdir(parents=True, exist_ok=True)\n",
    "        txt_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        (json_dir / f\"{video_id}.json\").write_text(\n",
    "            json.dumps(payload, ensure_ascii=False, indent=2),\n",
    "            encoding=\"utf-8\",\n",
    "        )\n",
    "        (txt_dir / f\"{video_id}.txt\").write_text(\n",
    "            transcript_to_text(segments),\n",
    "            encoding=\"utf-8\",\n",
    "        )\n",
    "\n",
    "        append_manifest(\n",
    "            manifest_path,\n",
    "            {\n",
    "                \"video_id\": video_id,\n",
    "                \"channel\": channel,\n",
    "                \"playlist_url\": playlist_meta.get(\"playlist_url\"),\n",
    "                \"status\": \"ok\",\n",
    "                \"fetched_at\": now,\n",
    "            },\n",
    "        )\n",
    "\n",
    "    except (TranscriptsDisabled, NoTranscriptFound, VideoUnavailable) as e:\n",
    "        append_manifest(\n",
    "            manifest_path,\n",
    "            {\n",
    "                \"video_id\": video_id,\n",
    "                \"channel\": channel,\n",
    "                \"playlist_url\": playlist_meta.get(\"playlist_url\"),\n",
    "                \"status\": \"no_transcript\",\n",
    "                \"error\": str(e),\n",
    "                \"fetched_at\": now,\n",
    "            },\n",
    "        )\n",
    "    except (RequestBlocked, IpBlocked, TooManyRequests) as e:\n",
    "        append_manifest(\n",
    "            manifest_path,\n",
    "            {\n",
    "                \"video_id\": video_id,\n",
    "                \"channel\": channel,\n",
    "                \"playlist_url\": playlist_meta.get(\"playlist_url\"),\n",
    "                \"status\": \"blocked\",\n",
    "                \"error\": str(e),\n",
    "                \"fetched_at\": now,\n",
    "            },\n",
    "        )\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        append_manifest(\n",
    "            manifest_path,\n",
    "            {\n",
    "                \"video_id\": video_id,\n",
    "                \"channel\": channel,\n",
    "                \"playlist_url\": playlist_meta.get(\"playlist_url\"),\n",
    "                \"status\": \"error\",\n",
    "                \"error\": repr(e),\n",
    "                \"fetched_at\": now,\n",
    "            },\n",
    "        )\n",
    "    finally:\n",
    "        time.sleep(sleep_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e5dd051-a88a-4601-8055-49d359ab8392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_id_from_input(s: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Accepts:\n",
    "      - raw video id: \"l0qFvnlCHI0\"\n",
    "      - watch url: \"https://www.youtube.com/watch?v=l0qFvnlCHI0\"\n",
    "      - youtu.be short url: \"https://youtu.be/l0qFvnlCHI0\"\n",
    "    Returns video_id or None.\n",
    "    \"\"\"\n",
    "    s = s.strip()\n",
    "    if not s:\n",
    "        return None\n",
    "\n",
    "    # raw ID (YouTube IDs are typically 11 chars; be permissive but safe-ish)\n",
    "    if \"http\" not in s and \"/\" not in s and \"?\" not in s and \"&\" not in s:\n",
    "        return s\n",
    "\n",
    "    # try to parse URLs without adding new deps\n",
    "    if \"watch?v=\" in s:\n",
    "        vid = s.split(\"watch?v=\", 1)[1].split(\"&\", 1)[0]\n",
    "        return vid or None\n",
    "\n",
    "    if \"youtu.be/\" in s:\n",
    "        vid = s.split(\"youtu.be/\", 1)[1].split(\"?\", 1)[0].split(\"&\", 1)[0].split(\"/\", 1)[0]\n",
    "        return vid or None\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def iter_videos_from_list(inputs: Iterable[str]) -> Iterable[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Produces video_meta dicts compatible with fetch_and_save_transcript().\n",
    "    Title/date are filled later (via yt-dlp fallback).\n",
    "    \"\"\"\n",
    "    for s in inputs:\n",
    "        vid = video_id_from_input(s)\n",
    "        if not vid:\n",
    "            continue\n",
    "        yield {\n",
    "            \"video_id\": vid,\n",
    "            \"video_title\": \"\",  # will be populated via yt-dlp if desired\n",
    "            \"video_url\": f\"https://www.youtube.com/watch?v={vid}\",\n",
    "            \"upload_date\": None,\n",
    "            \"timestamp\": None,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4a9b7c9-e00d-45ea-b21d-f53bd49465fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_podcast_tab_transcripts(\n",
    "    channels: List[Tuple[str, str]],\n",
    "    out_dir: Path = Path(\"data/youtube\"),\n",
    "    languages: Optional[List[str]] = None,\n",
    "    sleep_s: float = 0.25,\n",
    "    min_upload_date: datetime = datetime(2024, 1, 1, tzinfo=timezone.utc),\n",
    "    videos: Optional[List[str]] = None, \n",
    ") -> None:\n",
    "    if languages is None:\n",
    "        languages = [\"en\"]\n",
    "\n",
    "    manifest_path = out_dir / \"manifest.jsonl\"\n",
    "    processed = load_processed_video_ids(manifest_path)\n",
    "    ytt_api = YouTubeTranscriptApi()\n",
    "\n",
    "    # NEW: direct videos/urls mode (still uses manifest + date filter)\n",
    "    if videos:\n",
    "        channel = \"direct_videos\"\n",
    "        pl = {\n",
    "            \"playlist_title\": \"direct_videos\",\n",
    "            \"playlist_url\": None,\n",
    "            \"playlist_id\": None,\n",
    "        }\n",
    "\n",
    "        for v in iter_videos_from_list(videos):\n",
    "            if v[\"video_id\"] in processed:\n",
    "                continue\n",
    "\n",
    "            # date filter (same as playlist flow)\n",
    "            upload_dt = upload_dt_from_meta(v)\n",
    "            if upload_dt is None:\n",
    "                upload_dt = ydl_extract_video_date(v[\"video_url\"])  # also can provide title if you want, see note below\n",
    "\n",
    "            if upload_dt is None or upload_dt < min_upload_date:\n",
    "                continue\n",
    "\n",
    "            # optional: fill in title for nicer filenames/logging\n",
    "            # (minimal change: reuse yt-dlp extract again only if title missing)\n",
    "            if not v.get(\"video_title\"):\n",
    "                try:\n",
    "                    info = ydl_extract_flat(v[\"video_url\"])\n",
    "                    v[\"video_title\"] = info.get(\"title\") or \"\"\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            print(f\"    Fetching: {v.get('video_title','')} [{v['video_id']}] ({upload_dt.date()})\")\n",
    "            fetch_and_save_transcript(\n",
    "                out_dir=out_dir,\n",
    "                channel=channel,\n",
    "                playlist_meta=pl,\n",
    "                video_meta=v,\n",
    "                ytt_api=ytt_api,\n",
    "                languages=languages,\n",
    "                sleep_s=sleep_s,\n",
    "            )\n",
    "            processed.add(v[\"video_id\"])\n",
    "        return\n",
    "\n",
    "\n",
    "    for channel, podcasts_url in channels:\n",
    "        print(f\"\\n== Channel: {channel} | {podcasts_url}\")\n",
    "        playlists = list(iter_playlists_from_source(podcasts_url))\n",
    "\n",
    "        for pl in playlists:\n",
    "            print(f\"  - Playlist: {pl['playlist_title']}\")\n",
    "\n",
    "            for v in iter_videos_from_playlist(pl[\"playlist_url\"]):\n",
    "                if v[\"video_id\"] in processed:\n",
    "                    continue\n",
    "\n",
    "                # NEW: date filter\n",
    "                upload_dt = upload_dt_from_meta(v)\n",
    "                if upload_dt is None:\n",
    "                    upload_dt = ydl_extract_video_date(v[\"video_url\"])  # fallback\n",
    "\n",
    "                if upload_dt is None or upload_dt < min_upload_date:\n",
    "                    # skip if unknown or too old\n",
    "                    continue\n",
    "\n",
    "                print(f\"    Fetching: {v['video_title']} [{v['video_id']}] ({upload_dt.date()})\")\n",
    "                fetch_and_save_transcript(\n",
    "                    out_dir=out_dir,\n",
    "                    channel=channel,\n",
    "                    playlist_meta=pl,\n",
    "                    video_meta=v,\n",
    "                    ytt_api=ytt_api,\n",
    "                    languages=languages,\n",
    "                    sleep_s=sleep_s,\n",
    "                )\n",
    "                processed.add(v[\"video_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7033f369-18a2-4b3f-9b5e-84b1bec5b8ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad3d278f-dad2-4c40-8189-58d26d3bd5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] [jsc] Remote components challenge solver script (deno) and NPM package (deno) were skipped. These may be required to solve JS challenges. You can enable these downloads with  --remote-components ejs:github  (recommended) or  --remote-components ejs:npm , respectively. For more information and alternatives, refer to  https://github.com/yt-dlp/yt-dlp/wiki/EJS\n",
      "WARNING: [youtube] ldBrCJENOJ8: n challenge solving failed: Some formats may be missing. Ensure you have a supported JavaScript runtime and challenge solver script distribution installed. Review any warnings presented before this message. For more details, refer to  https://github.com/yt-dlp/yt-dlp/wiki/EJS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fetching: International AI Governance Explained: EU vs US vs China — The Future of AI Regulation [ldBrCJENOJ8] (2025-10-10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] NnRB_KEDjxs: Some tv client https formats have been skipped as they are missing a url. YouTube may have enabled the SABR-only or Server-Side Ad Placement experiment for the current session. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
      "WARNING: [youtube] [jsc] Remote components challenge solver script (deno) and NPM package (deno) were skipped. These may be required to solve JS challenges. You can enable these downloads with  --remote-components ejs:github  (recommended) or  --remote-components ejs:npm , respectively. For more information and alternatives, refer to  https://github.com/yt-dlp/yt-dlp/wiki/EJS\n",
      "WARNING: [youtube] NnRB_KEDjxs: n challenge solving failed: Some formats may be missing. Ensure you have a supported JavaScript runtime and challenge solver script distribution installed. Review any warnings presented before this message. For more details, refer to  https://github.com/yt-dlp/yt-dlp/wiki/EJS\n",
      "WARNING: [youtube] NnRB_KEDjxs: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fetching: Balancing AI Governance & Innovation: Lessons from the EU Ft. Lucilla Sioli | RegulatingAI Podcast [NnRB_KEDjxs] (2025-03-07)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] [jsc] Remote components challenge solver script (deno) and NPM package (deno) were skipped. These may be required to solve JS challenges. You can enable these downloads with  --remote-components ejs:github  (recommended) or  --remote-components ejs:npm , respectively. For more information and alternatives, refer to  https://github.com/yt-dlp/yt-dlp/wiki/EJS\n",
      "WARNING: [youtube] PnxM30ezvmQ: n challenge solving failed: Some formats may be missing. Ensure you have a supported JavaScript runtime and challenge solver script distribution installed. Review any warnings presented before this message. For more details, refer to  https://github.com/yt-dlp/yt-dlp/wiki/EJS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fetching: Discussing rapid advancements of AI with Nick Begich | The RegulatingAI Podcast [PnxM30ezvmQ] (2025-04-16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] [jsc] Remote components challenge solver script (deno) and NPM package (deno) were skipped. These may be required to solve JS challenges. You can enable these downloads with  --remote-components ejs:github  (recommended) or  --remote-components ejs:npm , respectively. For more information and alternatives, refer to  https://github.com/yt-dlp/yt-dlp/wiki/EJS\n",
      "WARNING: [youtube] mMK_YeRrYrI: n challenge solving failed: Some formats may be missing. Ensure you have a supported JavaScript runtime and challenge solver script distribution installed. Review any warnings presented before this message. For more details, refer to  https://github.com/yt-dlp/yt-dlp/wiki/EJS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fetching: UNESCO’s AI Ethics Framework Ft. Prof. Emma Ruttkamp-Bloem | The RegulatingAI Podcast [mMK_YeRrYrI] (2025-03-07)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] [jsc] Remote components challenge solver script (deno) and NPM package (deno) were skipped. These may be required to solve JS challenges. You can enable these downloads with  --remote-components ejs:github  (recommended) or  --remote-components ejs:npm , respectively. For more information and alternatives, refer to  https://github.com/yt-dlp/yt-dlp/wiki/EJS\n",
      "WARNING: [youtube] glkmS74l_o0: n challenge solving failed: Some formats may be missing. Ensure you have a supported JavaScript runtime and challenge solver script distribution installed. Review any warnings presented before this message. For more details, refer to  https://github.com/yt-dlp/yt-dlp/wiki/EJS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fetching: Exploring AI Ethics with Francesca Rossi: Insights from IBM's Global Leader | RegulatingAI Podcast [glkmS74l_o0] (2025-01-30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] [jsc] Remote components challenge solver script (deno) and NPM package (deno) were skipped. These may be required to solve JS challenges. You can enable these downloads with  --remote-components ejs:github  (recommended) or  --remote-components ejs:npm , respectively. For more information and alternatives, refer to  https://github.com/yt-dlp/yt-dlp/wiki/EJS\n",
      "WARNING: [youtube] OxRk-YKbZyg: n challenge solving failed: Some formats may be missing. Ensure you have a supported JavaScript runtime and challenge solver script distribution installed. Review any warnings presented before this message. For more details, refer to  https://github.com/yt-dlp/yt-dlp/wiki/EJS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fetching: Patrik Gayer on Open-Source AI and Global Policy | The RegulatingAI Podcast [OxRk-YKbZyg] (2025-01-22)\n"
     ]
    }
   ],
   "source": [
    "# From the Regualting AI podcast: \n",
    "# https://www.youtube.com/watch?v=ldBrCJENOJ8 \n",
    "\n",
    "# ReRun\n",
    "download_podcast_tab_transcripts(\n",
    "    channels=[(\"Regulating_AI_Sanjay_Puri\", \"https://www.youtube.com/playlist?list=PLGBFGI3ApzqdS70H84yli1Q-j_cqqiJbL\")],\n",
    "    videos=[\n",
    "        \"https://www.youtube.com/watch?v=ldBrCJENOJ8\", # EU vs US vs China \n",
    "        \"https://www.youtube.com/watch?v=f62JIPXT8Cs\", # EU AI Act\n",
    "        \"https://www.youtube.com/watch?v=NnRB_KEDjxs\", # EU AI Act\n",
    "        \"https://www.youtube.com/watch?v=PnxM30ezvmQ\", # AI innovation versus regulation\n",
    "        \"https://www.youtube.com/watch?v=mMK_YeRrYrI\", # UNESCO’s AI Ethics Framework \n",
    "        \"https://www.youtube.com/watch?v=glkmS74l_o0\", # Francesca Rossi from IBM\n",
    "        \"https://www.youtube.com/watch?v=OxRk-YKbZyg\", # Open-source AI\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc39634-1f5e-465b-a703-706b673ede21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec53b09-47b5-41f0-9346-02550641fb54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d6a3ff2-ff67-4d7a-a37e-2445389978d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Channel: Regulating_AI_Sanjay_Puri | https://www.youtube.com/playlist?list=PLGBFGI3ApzqdS70H84yli1Q-j_cqqiJbL\n",
      "  - Playlist: RegulatingAI Podcast: Innovate Responsibly\n",
      "    Fetching: AI Governance & Global Policy at ASEAN | Sanjay Puri in Conversation with Congressman Jay Obernolte [PYxvTZKBAgk] (2026-01-02)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] Dyp6pOOUZbM: Video unavailable. This video has been removed by the uploader\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fetching: AI in Everyday Life and Cognitive Assistance | Prof. Antonio Krüger | RegulatingAI Podcast [q9cYwaHg5_g] (2025-05-02)\n",
      "    Fetching: RegulatingAI Podcast: How AI Impacts Civil Rights – A Conversation with Koustubh \"K.J.\" Bagchi [VgMEU8x7sMw] (2025-05-02)\n",
      "    Fetching: Empowering Africa Through AI: Dr. Shikoh Gitau's Vision for Equitable AI Development [CrTi5ZFrlXg] (2025-05-02)\n",
      "    Fetching: Why the US Needs to Lead AI Innovation – Congressman Jake Auchincloss Speaks Out [77xencIffAg] (2025-05-02)\n",
      "    Fetching: Congressman Gabe Amo on AI Policy and the Future of Responsible Regulation | RegulatingAI Podcast [AcMPFkOosKY] (2025-04-02)\n",
      "    Fetching: Bipartisan AI Regulation and the Future of AI with Congressman Ted Lieu | Regulating AI Podcast [G8ja7UVN8AE] (2025-04-02)\n",
      "    Fetching: The Intersection of AI, Regulation and Economic Growth with David Schweikert | Regulating AI Podcast [n9qMEKuf1DI] (2025-04-02)\n",
      "    Fetching: The Future of Responsible AI with Dr. Richard Benjamins | RegulatingAI Podcast [_aL54D2bFLY] (2025-04-02)\n",
      "    Fetching: The Future of AI Policy with US Congresswoman Suzan DelBene | The RegulatingAI Podcast [XwEPufPQxA8] (2025-04-02)\n",
      "    Fetching: The Future of AI & Public Policy: A Deep Dive with Prof. Ramayya Krishnan | The RegulatingAI Podcast [MeRpVvO0rz4] (2025-03-02)\n",
      "    Fetching: How AI’s Rapid Growth is Outpacing Regulation Ft. Brian Schmidt | The RegulatingAI Podcast [t5-37m99QbM] (2025-03-02)\n",
      "    Fetching: Ethics, AI, & Medicine: The Future of Healthcare with Dr. Dominique Monlezun [sLOftSU1Qpc] (2025-03-02)\n",
      "    Fetching: Tom Wheeler on AI's Future and Regulation Challenges | The RegulatingAI Podcast [u89TknxsymM] (2025-02-02)\n",
      "    Fetching: Balancing Innovation & Safety: The Future of AI Regulation in America Ft. Congressman Scott Franklin [gfjHixhkMkY] (2025-02-02)\n",
      "    Fetching: The Fight for Fairness and Transparency in AI Systems with Faiza Patel of Brennan Center for Justice [v5VhcEdiAiw] (2025-01-02)\n",
      "    Fetching: AI and Society: Balancing Innovation, Governance, and Democracy in a Rapidly Changing World [luAhiGKqWrE] (2025-01-02)\n",
      "    Fetching: The Future of Open-Source AI and Its Global Implications with Professor S. Alex Yang [Bd8m6nJo3Lo] (2025-01-02)\n",
      "    Fetching: Overcoming the Cultural Clash Between AI Innovation and Data Privacy with Prof. Norman Sadeh of CMU [mX_oD0NNOM0] (2025-01-02)\n",
      "    Fetching: How AI Is Reshaping Industries and Society with Professor Ruslan Salakhutdinov [U9jzi3uaeMA] (2025-01-02)\n",
      "    Fetching: Breaking Down the Senate AI Policy Roadmap with Senator Todd Young of the United States Senate [4xxu0A6ZXHU] (2025-01-02)\n",
      "    Fetching: AI's Role in Accelerating Drug Development and Clinical Trials | RegulatingAI Ft. Raphael Townshend [OXJjpImlgqY] (2025-01-02)\n",
      "    Fetching: Addressing Bias in AI To Build Trust in Technology | RegulatingAI Podcast Ft. Dr. Rashawn Ray [dcb4MNzusN4] (2025-01-02)\n",
      "    Fetching: Regulating AI Innovation for National Security and Healthcare with Senator Mike Rounds [mH_fmoGA5No] (2025-01-02)\n",
      "    Fetching: Protecting Consumer Rights in the Age of AI with Atty Gen Charity Rae Clark & Rep Monique Priestley [6_H6DOPA4UE] (2025-01-02)\n",
      "    Fetching: Protecting Creative Rights in the AI Era with Keith Kupferschmid, CEO of Copyright Alliance [ddlTxgtbXRs] (2025-01-02)\n",
      "    Fetching: AI Development and Cultural Values with Maria Luciana Axente - Regulating AI Podcast [Pl4thf_AkXw] (2025-01-02)\n",
      "    Fetching: Empowering Diverse Creators in the AI Era with Lianne Baron - Regulating AI Podcast [HQB1Vi-f45w] (2025-01-02)\n",
      "    Fetching: Balancing Innovation and Regulation in AI with Zico Kolter | Regulating AI Podcast [6WYypVdyb7A] (2025-01-02)\n",
      "    Fetching: Harnessing Evolutionary Principles To Guide AI Development with Professor Paul Rainey [jhtvSgA5yps] (2025-01-02)\n",
      "    Fetching: Understanding China’s AI Policy and Tech Growth with Jaap van Etten | Regulating AI Podcast [-4oH21l2N7I] (2025-01-02)\n",
      "    Fetching: Understanding Robot Learning and Its Societal Impact with Dr. Abhinav Valada | Regulating AI Podcast [fQeHep7mqQ0] (2025-01-02)\n",
      "    Fetching: AI's Impact on Healthcare and Legislation with Congressman Buddy Carter | Regulating AI Podcast [OD2irwbhBsA] (2025-01-02)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# rerun\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Pass podcast URLs as function inputs\u001b[39;00m\n\u001b[32m      3\u001b[39m channels = [\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m#    (\"TWIML_AI_Sam_Charrington\", \"https://www.youtube.com/playlist?list=PLILZm3MRkvH83C46bZ4rPmB-jKWBltWkP\"), # partially done\u001b[39;00m\n\u001b[32m      5\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33mRegulating_AI_Sanjay_Puri\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mhttps://www.youtube.com/playlist?list=PLGBFGI3ApzqdS70H84yli1Q-j_cqqiJbL\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m     10\u001b[39m \u001b[38;5;66;03m#    (\"AI_Policy_CSIS\", \"https://www.youtube.com/playlist?list=PLnArnDQHeUqeErR8mbkEGUqzGD2b5O3Cc\"),\u001b[39;00m\n\u001b[32m     11\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43mdownload_podcast_tab_transcripts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata/youtube\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43men\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msleep_s\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 81\u001b[39m, in \u001b[36mdownload_podcast_tab_transcripts\u001b[39m\u001b[34m(channels, out_dir, languages, sleep_s, min_upload_date, videos)\u001b[39m\n\u001b[32m     78\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     80\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m    Fetching: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv[\u001b[33m'\u001b[39m\u001b[33mvideo_title\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv[\u001b[33m'\u001b[39m\u001b[33mvideo_id\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mupload_dt.date()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m \u001b[43mfetch_and_save_transcript\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m    \u001b[49m\u001b[43mout_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchannel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchannel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplaylist_meta\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvideo_meta\u001b[49m\u001b[43m=\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m    \u001b[49m\u001b[43mytt_api\u001b[49m\u001b[43m=\u001b[49m\u001b[43mytt_api\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlanguages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlanguages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m    \u001b[49m\u001b[43msleep_s\u001b[49m\u001b[43m=\u001b[49m\u001b[43msleep_s\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m processed.add(v[\u001b[33m\"\u001b[39m\u001b[33mvideo_id\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 139\u001b[39m, in \u001b[36mfetch_and_save_transcript\u001b[39m\u001b[34m(out_dir, channel, playlist_meta, video_meta, ytt_api, languages, sleep_s)\u001b[39m\n\u001b[32m    136\u001b[39m now = datetime.now(timezone.utc).isoformat()\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     fetched = \u001b[43mytt_api\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlanguages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    140\u001b[39m     segments = fetched.to_raw_data()\n\u001b[32m    141\u001b[39m     \u001b[38;5;66;03m#segments = ytt_api.get_transcript(video_id, languages=languages)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Course_Alexey_Grigorev\\MyAgent\\.venv\\Lib\\site-packages\\youtube_transcript_api\\_api.py:73\u001b[39m, in \u001b[36mYouTubeTranscriptApi.fetch\u001b[39m\u001b[34m(self, video_id, languages, preserve_formatting)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfetch\u001b[39m(\n\u001b[32m     52\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     53\u001b[39m     video_id: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m     54\u001b[39m     languages: Iterable[\u001b[38;5;28mstr\u001b[39m] = (\u001b[33m\"\u001b[39m\u001b[33men\u001b[39m\u001b[33m\"\u001b[39m,),\n\u001b[32m     55\u001b[39m     preserve_formatting: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     56\u001b[39m ) -> FetchedTranscript:\n\u001b[32m     57\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[33;03m    Retrieves the transcript for a single video. This is just a shortcut for\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[33;03m    calling:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     68\u001b[39m \u001b[33;03m    :param preserve_formatting: whether to keep select HTML text formatting\u001b[39;00m\n\u001b[32m     69\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m     70\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m     71\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m        \u001b[49m\u001b[43m.\u001b[49m\u001b[43mfind_transcript\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[43m        \u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreserve_formatting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreserve_formatting\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Course_Alexey_Grigorev\\MyAgent\\.venv\\Lib\\site-packages\\youtube_transcript_api\\_transcripts.py:137\u001b[39m, in \u001b[36mTranscript.fetch\u001b[39m\u001b[34m(self, preserve_formatting)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m&exp=xpe\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._url:\n\u001b[32m    136\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PoTokenRequired(\u001b[38;5;28mself\u001b[39m.video_id)\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_http_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m snippets = _TranscriptParser(preserve_formatting=preserve_formatting).parse(\n\u001b[32m    139\u001b[39m     _raise_http_errors(response, \u001b[38;5;28mself\u001b[39m.video_id).text,\n\u001b[32m    140\u001b[39m )\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m FetchedTranscript(\n\u001b[32m    142\u001b[39m     snippets=snippets,\n\u001b[32m    143\u001b[39m     video_id=\u001b[38;5;28mself\u001b[39m.video_id,\n\u001b[32m   (...)\u001b[39m\u001b[32m    146\u001b[39m     is_generated=\u001b[38;5;28mself\u001b[39m.is_generated,\n\u001b[32m    147\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Course_Alexey_Grigorev\\MyAgent\\.venv\\Lib\\site-packages\\requests\\sessions.py:602\u001b[39m, in \u001b[36mSession.get\u001b[39m\u001b[34m(self, url, **kwargs)\u001b[39m\n\u001b[32m    594\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[32m    595\u001b[39m \n\u001b[32m    596\u001b[39m \u001b[33;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m    597\u001b[39m \u001b[33;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[32m    598\u001b[39m \u001b[33;03m:rtype: requests.Response\u001b[39;00m\n\u001b[32m    599\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    601\u001b[39m kwargs.setdefault(\u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m602\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Course_Alexey_Grigorev\\MyAgent\\.venv\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Course_Alexey_Grigorev\\MyAgent\\.venv\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Course_Alexey_Grigorev\\MyAgent\\.venv\\Lib\\site-packages\\requests\\adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    641\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Course_Alexey_Grigorev\\MyAgent\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Course_Alexey_Grigorev\\MyAgent\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Course_Alexey_Grigorev\\MyAgent\\.venv\\Lib\\site-packages\\urllib3\\connection.py:571\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    568\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    570\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m571\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    574\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.11.14-windows-x86_64-none\\Lib\\http\\client.py:1395\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1393\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1394\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1395\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1396\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1397\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.11.14-windows-x86_64-none\\Lib\\http\\client.py:325\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    323\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    327\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.11.14-windows-x86_64-none\\Lib\\http\\client.py:286\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.fp.readline(_MAXLINE + \u001b[32m1\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    287\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    288\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.11.14-windows-x86_64-none\\Lib\\socket.py:718\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    716\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m718\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    719\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    720\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.11.14-windows-x86_64-none\\Lib\\ssl.py:1314\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1310\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1311\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1312\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1313\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1314\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1315\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1316\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.11.14-windows-x86_64-none\\Lib\\ssl.py:1166\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1164\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1165\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1166\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1167\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1168\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# rerun\n",
    "# Pass podcast URLs as function inputs\n",
    "channels = [\n",
    "#    (\"TWIML_AI_Sam_Charrington\", \"https://www.youtube.com/playlist?list=PLILZm3MRkvH83C46bZ4rPmB-jKWBltWkP\"), # partially done\n",
    "    (\"Regulating_AI_Sanjay_Puri\", \"https://www.youtube.com/playlist?list=PLGBFGI3ApzqdS70H84yli1Q-j_cqqiJbL\"),\n",
    "#    (\"AI_Governance_Luiza_Jarovsky\", \"https://www.youtube.com/@LuizaJarovsky/podcasts\"), # done\n",
    "#    (\"CEPS_Think_Tank\", \"https://www.youtube.com/@CEPSThinkTank/podcasts\"),\n",
    "#    (\"AI_Policy_CSIS\", \"https://www.youtube.com/@Legal4Tech/podcasts\"), \n",
    "#    (\"Legal4Tech\", \"https://www.youtube.com/@Legal4Tech/podcasts\"),\n",
    "#    (\"AI_Policy_CSIS\", \"https://www.youtube.com/playlist?list=PLnArnDQHeUqeErR8mbkEGUqzGD2b5O3Cc\"),\n",
    "]\n",
    "download_podcast_tab_transcripts(channels, out_dir=Path(\"data/youtube\"), languages=[\"en\"], sleep_s=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc367a9-6b05-4fd6-b07a-8de32db8af51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927c961d-5d00-4848-9c02-7b7a03099cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rerun\n",
    "download_podcast_tab_transcripts(\n",
    "    channels=[(\"Legal4Tech\", \"https://www.youtube.com/playlist?list=PLj1oI1joplmggONYVxg_pa3LHZa0y2B84\")],\n",
    "    videos=[\n",
    "        \"https://www.youtube.com/watch?v=6tqsftznuN0\", # EU AI Act enforcement\n",
    "        \"https://www.youtube.com/watch?v=0nWoQTqS8xQ\", # EU AI Act enforcement\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882df913-8b69-4aa7-aad8-62708d1d08d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rerun\n",
    "download_podcast_tab_transcripts(\n",
    "    channels=[(\"CEPS_Think_Tank\", \"https://www.youtube.com/@CEPSThinkTank/podcasts\")],\n",
    "    videos=[\n",
    "        \"https://www.youtube.com/watch?v=yWyLDQN2Rfc\",\n",
    "        \"https://www.youtube.com/watch?v=n7bDGczA5oE\", \n",
    "        \"https://www.youtube.com/watch?v=ky_ESWrvHwo\", \n",
    "        \"https://www.youtube.com/watch?v=StcBR-s8_E4\", \n",
    "        \"https://www.youtube.com/watch?v=IseK-FxpUOs\", \n",
    "        \"https://www.youtube.com/watch?v=zVa8HiLfmp8\"\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf607c09-21e5-4803-a736-10a5ad8474f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7b5204-bca2-4b56-8b93-28e22e84308b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d64ab8f-1b67-4a38-84b9-602ee6d057c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acdadca-df04-4dde-862b-4d82add157ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453a4b86-fb48-4801-967f-b56550c2e6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_podcast_tab_transcripts(\n",
    "    channels=[(\"TWIML_AI_Sam_Charrington\", \"https://www.youtube.com/watch?v=YgQxlKPeC-g&list=PLILZm3MRkvH83C46bZ4rPmB-jKWBltWkP\")],\n",
    "    videos=[\n",
    "        \"https://www.youtube.com/watch?v=l0qFvnlCHI0\",\n",
    "        \"https://www.youtube.com/watch?v=fS34g5gdPsQ\",\n",
    "        \"https://www.youtube.com/watch?v=nEbMiczJ_gc\",\n",
    "        \"https://www.youtube.com/watch?v=HScABWB98Kw\",\n",
    "        #\"https://www.youtube.com/watch?v=GmypOIq1LV8\", #done\n",
    "        \"https://www.youtube.com/watch?v=zisE1p2plxk\", \n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f0abec-35d2-4d41-8674-980f4d88c907",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_podcast_tab_transcripts(\n",
    "    channels=[(\"AI_Policy_CSIS\", \"https://www.youtube.com/playlist?list=PLnArnDQHeUqeErR8mbkEGUqzGD2b5O3Cc\")],\n",
    "    videos=[\n",
    "        \"https://www.youtube.com/watch?v=vTf4Skp2_bA\", # AI regulation in China\n",
    "        \"https://www.youtube.com/watch?v=sC4_4twgWI4\", # AI bubble concerns\n",
    "        \"https://www.youtube.com/watch?v=4DG-f-3b2rI\", # EU AI Code of Practice\n",
    "        \"https://www.youtube.com/watch?v=DlJ1RRCRMds\", # AI regulation in California \n",
    "        \"https://www.youtube.com/watch?v=MAPqErwZzv0\", # Trump against AI regulation\n",
    "        \"https://www.youtube.com/watch?v=uzSF29l5Lf0\", # EU AI Act delays\n",
    "        \"https://www.youtube.com/watch?v=WkX_Xc60qYE\", # future of American AI regulation\n",
    "        \"https://www.youtube.com/watch?v=frZcvn11uco\", # AI's impact on the labor market\n",
    "        \"https://www.youtube.com/watch?v=GeJ0lWMkV1w\", # Trump against AI regulation\n",
    "        \"https://www.youtube.com/watch?v=-pf5XlFYhrQ\", # AI regulation in China\n",
    "        \"https://www.youtube.com/watch?v=P792YGrvTNs\", # American and European AI policy\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58157464-dad3-4452-aa41-34f6f6d23e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_podcast_tab_transcripts(\n",
    "    channels=[(\"Legal4Tech\", \"https://www.youtube.com/playlist?list=PLj1oI1joplmggONYVxg_pa3LHZa0y2B84\")],\n",
    "    videos=[\n",
    "        \"https://www.youtube.com/watch?v=4cw-fXPOedo\", # Digital Omnibus\n",
    "        \"https://www.youtube.com/watch?v=1JiPzmZ97kU\", # Digital Omnibus\n",
    "        \"https://www.youtube.com/watch?v=sdJDwiXqGAI\", # GenAI and copyright laws\n",
    "        \"https://www.youtube.com/watch?v=0srLa3fC0Lw\", # Copyright laws & AI bubble concerns\n",
    "        \"https://www.youtube.com/watch?v=8KQAeken94w\", # Digital regulation & judicial enforcement\n",
    "        \"https://www.youtube.com/watch?v=ZOwk3wrzSHs\", # from EU law to national law\n",
    "        \"https://www.youtube.com/watch?v=zjtoyn06zxE\", # EU Data Act \n",
    "        \"https://www.youtube.com/watch?v=Sfza4J-YjGA\", # AI regulation in the UK\n",
    "        \"https://www.youtube.com/watch?v=PQQf8gpUa0c\", # intellectual property\n",
    "        \"https://www.youtube.com/watch?v=1U9FaQBzwJA\", # synthetic data\n",
    "        \"https://www.youtube.com/watch?v=vVAccNCrUNA\", # fighting big tech\n",
    "        \"https://www.youtube.com/watch?v=BdCa0INMiTo\", # risk management for LLMs\n",
    "        \"https://www.youtube.com/watch?v=KUNKsybJPhY\", # brand visibility\n",
    "        \"https://www.youtube.com/watch?v=6tqsftznuN0\", # EU AI Act enforcement\n",
    "        \"https://www.youtube.com/watch?v=0nWoQTqS8xQ\", # EU AI Act enforcement\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538e038a-9240-4ed4-bcfa-a460159c8ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rerun\n",
    "# Not all podcast episodes are accessible on GitHub\n",
    "download_podcast_tab_transcripts(\n",
    "    channels=[(\"DataTalksClub\", \"https://www.youtube.com/playlist?list=PL3MmuxUbc_hK60wsCyvrEK2RjQsUi4Oa_\")],\n",
    "    videos=[\n",
    "        \"https://www.youtube.com/watch?v=LBuGzyOkx7c\", # Explainability\n",
    "        \"https://www.youtube.com/watch?v=YncdlUscUOo\", # Knowledge graphs & LLMs\n",
    "        \"https://www.youtube.com/watch?v=HwCR59VuYn4&t=7s\", # Agentic AI\n",
    "        \"https://www.youtube.com/watch?v=1aMuynlLM3o\", # AI infrastructure\n",
    "        \"https://www.youtube.com/watch?v=AlCFKbFIEM8\", # Data engineering\n",
    "        \"https://www.youtube.com/watch?v=eC3RNuI6ow0\", # LLM evals\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e070008b-0f5a-4d08-8045-6f103c0484e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7777a9-159e-44cc-9353-1f919c26761c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82163220-241b-4536-9e75-bd1b866233f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process these seperately: \"DataTalksClub_Alexey_Grigorev\", \"https://www.youtube.com/@DataTalksClub/podcasts\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2a9ff3-09f9-456e-8138-6e9bbab55e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efba4676-bcc0-4f0d-a665-3f0f3f8ab3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correctly processed TWIML AI podcast videos\n",
    "# https://www.youtube.com/watch?v=<video_id>\n",
    "#3Zu8Zsqw26s # done\n",
    "#GmypOIq1LV8 # done Assessing the Risks of Open AI Models (Sayash Kapoor)\n",
    "\n",
    "# To download: \n",
    "# AI Regulation and Automated Decisioning with Peter van der Putten: https://www.youtube.com/watch?v=l0qFvnlCHI0\n",
    "# RAG Risks: Why Retrieval-Augmented LLMs Are Not Safer with Sebastian Gehrmann: https://www.youtube.com/watch?v=fS34g5gdPsQ\n",
    "# Ensuring Privacy for Any LLM with Patricia Thaine: https://www.youtube.com/watch?v=nEbMiczJ_gc\n",
    "# AI Agents: Substance or Snake Oil with Arvind Narayanan: https://www.youtube.com/watch?v=HScABWB98Kw\n",
    "# Assessing the Risks of Open AI Models with Sayash Kapoor: https://www.youtube.com/watch?v=GmypOIq1LV8 # done\n",
    "# The Decentralized Future of Private AI with Illia Polosukhin: https://www.youtube.com/watch?v=zisE1p2plxk\n",
    "\n",
    "# Successfully processed videos from the The RegulatingAI Podcast\n",
    "#iKg00zm99xk\n",
    "#XNRvEwqrlfw\n",
    "#m1Ipy31auzg\n",
    "#dI8cF4Xy0dI\n",
    "#2YvNfV5iZFo\n",
    "#9X0u3jZJfX8\n",
    "#cE2fOZx2wFY\n",
    "#mQ1G3Kj5N8U\n",
    "#zHq9Q2c8cF4\n",
    "#rQm4QyJ6s7g\n",
    "#xUe1Kk4n5jA\n",
    "#4fX9m7PZq1s\n",
    "#s0kKZk9f0Lw\n",
    "#3V4sR8nF2zY\n",
    "#0mC6Y7kqfRA\n",
    "#ZK1Bv5xYpF4\n",
    "#7rJ0qKX2mW8\n",
    "#JXz4F8RZkqE\n",
    "#6R3vFZK2H9q\n",
    "#D2mF4Kp8q7E\n",
    "#K9pZx5L4F2r\n",
    "#M4xZp9q2L5E\n",
    "#8FZK3m4q9xR\n",
    "#5pFZ4L9Kx2E\n",
    "#H4qZpF9m5xL\n",
    "#m8ZKq5F9pL4\n",
    "#Zp9Fq5K4xLm\n",
    "#4FZqKp9m5xL\n",
    "#9mZK4Fq5pLx\n",
    "#q5ZK4F9mLpX\n",
    "#L4ZK5F9pqmX\n",
    "#pF9ZK4q5LmX\n",
    "#9P3qC-21scQ\n",
    "#CYR2Dwvqqfs\n",
    "#57oNlwKiUVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202e608d-63a9-49ac-93c0-bffe640c16bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need the following from TWIML: \n",
    "# AI Regulation and Automated Decisioning with Peter van der Putten: https://www.youtube.com/watch?v=l0qFvnlCHI0\n",
    "# RAG Risks: Why Retrieval-Augmented LLMs Are Not Safer with Sebastian Gehrmann: https://www.youtube.com/watch?v=fS34g5gdPsQ\n",
    "# Ensuring Privacy for Any LLM with Patricia Thaine: https://www.youtube.com/watch?v=nEbMiczJ_gc\n",
    "# AI Agents: Substance or Snake Oil with Arvind Narayanan: https://www.youtube.com/watch?v=HScABWB98Kw\n",
    "# Assessing the Risks of Open AI Models with Sayash Kapoor: https://www.youtube.com/watch?v=GmypOIq1LV8 # done\n",
    "# The Decentralized Future of Private AI with Illia Polosukhin: https://www.youtube.com/watch?v=zisE1p2plxk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fd9088-bce5-4ddd-bc4b-8d3d48ad0f93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5db7263-c57e-4617-b5d6-29734140f3c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655c360e-db22-4404-a2c5-f3955978a9f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2a9d92-153f-412f-a833-dfeeb80d1bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b860f1c-f879-4caa-aa5d-e43dd8ec5f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
